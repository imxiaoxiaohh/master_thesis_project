paper_id,equation_id,ground_truth_eq,ground_truth_description,generated_equation,generated_description
2024.acl-short.12,1,ECE=\sum_{i=1}^{B}\frac{n_{b_{i}}}{N}|acc(b_{i})-conf(b_{i})|,"where \(i\) denotes \(i\)-th bin, \(N\) is the total instance count of the dataset, \(acc(b_{i})\) and \(conf(b_{i})\) represent the accuracy and confidence of the bin \(b_{i}\), and \(n_{b_{i}}\) is the instance number of the bin \(b_{i}\)",ECE=\sum_{m=1}^{M}\frac{|B_m|}{n}\left|acc(B_m)-conf(B_m)\right|,"ECE is computed as the weighted average of the absolute difference between accuracy and confidence across M bins, where $|B_m|$ is the number of samples in bin $m$, $n$ is the total number of samples, $\mathrm{acc}(B_m)$ is the accuracy in bin $m$, and $\mathrm{conf}(B_m)$ is the average confidence in bin $m$."
2024.acl-short.12,2,"GECE=\frac{|M(pred,ref)-\frac{1}{n}\sum_{i=1}^{n}p(t_{i})|}{\alpha\cdot[E(\bigtriangledown_{ins})\cdot\bigtriangledown_{ins}]}","where \(pred\) and \(ref\) represent the generated text and the referenced ground truth, respectively",GECE=\frac{1}{B}\sum_{b=1}^{B}\left|METEOR(b)-Conf(b)\right|\cdotFreq(b)\cdotGradSim(b),"GECE is computed as the average, over all bins, of the absolute difference between METEOR and confidence, weighted by average word frequency and gradient similarity for each bin."
2024.acl-short.14,1,"P(cot,T|KG) || =P((s_{1},t_{1}),\cdots,(s_{n},t_{n}),T|KG) || =\prod_{i=1}^{n}P((s_{i},t_{i})|(s_{1},t_{1}),\cdots,(s_{i-1},t_ {i-1}),KG)\cdot || P(T|(s_{1},t_{1}),\cdots,(s_{n},t_{n}),KG) || =\prod_{i=1}^{n}P(t_{i}|(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}),KG)\cdot || \prod_{i=1}^{n}P(s_{i})|t_{i},(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}),KG)\cdot || P(T|(s_{1},t_{1}),\cdots,(s_{n},t_{n}),KG)",,"P(Y|G)=\prod_{i=1}^{N} P(y_i | y_{<i}, G)",The probability of generating the full text $Y$ given the knowledge graph $G$ is decomposed into the product of probabilities of generating each sentence $y_i$ conditioned on the previously generated sentences and the graph.
2024.acl-short.14,2,"L_{seq}=-logP((s_{1},t_{1}),\cdots,(s_{n},t_{n}),T|KG) || =-\sum_{i=1}^{n}logP(t_{i}|(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}) || KG)-\sum_{i=1}^{n}logP(s_{i})|t_{i},(s_{1},t_{1 }),\cdots,(s_{i-1} || t_{i-1}),KG)-\sum_{i=1}^{n}logP(T|(s_{1},t_{1 }),\cdots,(s_{n} || t_{n}),KG)",,"L=-\sum_{i=1}^{n}\log P((s_{i}, t_{i}) | (s_{1}, t_{1}),\ldots, (s_{i-1}, t_{i-1}),KG)-\log P(T | (s_{1}, t_{1}),\ldots, (s_{n}, t_{n}),KG)",The cross-entropy loss \(\mathcal{L}\) sums the negative log-likelihoods of the sentence-triple pairs and the overall text given the knowledge graph.
2024.acl-short.14,3,"L_{re}=-\textbf{log}P(r|h,t,T) || =-\textbf{log}\prod_{i=1}^{m}P(r_{i}|r_{<i},h,t,T)",,"L_{rel}=-\sum_{j=1}^{m}\log P(r_j | h_j, t_j, T)","The relation extraction loss \(L_{rel}\) is defined as the negative log-likelihood of predicting the correct relation \(r_j\) given the head entity \(h_j\), tail entity \(t_j\), and the generated text \(T\), summed over all \(m\) sampled triples."
2024.acl-short.14,4,L=\alpha_{1}L_{seq}+\alpha_{2}L_{re},where \(\alpha_{1}\) and \(\alpha_{2}\) are parameters to tune,L=L_{seq}+\lambda L_{re},"The total loss \(L\) is the sum of the sequential sentence-level generation loss \(L_{seq}\) and the backward relation extraction loss \(L_{re}\), weighted by a hyperparameter \(\lambda\)."
2024.acl-short.15,1,"(o^{I},o^{S})=f(x)",where \(f(\cdot)\) is the joint model; \(\mathbf{o}^{I}\) and \(\mathbf{o}^{S}\) denotes an intent label and a slot sequence,P(y|x;\theta),The joint probability of output labels \(\mathbf{y}\) given input sentence \(\mathbf{x}\) and model parameters \(\theta\).
2024.acl-short.15,2,"\hat{Q}_{[i,j]}=norm(Q_{[i,j]})","where \(\mathrm{norm}(\cdot)\) denotes row normalization, which constrains the values to lie between 0 and 1",\hat{Q}=IPOT(C),The final alignment matrix \(\mathbf{\hat{Q}}\) is computed by applying the IPOT algorithm to the cost matrix \(\mathbf{C}\).
2024.acl-short.15,3,"L_{RLA}=-\sum_{[i,j]}\hat{Q}_{[i,j]}\log(\sigma(1-C_{[i,j]}))","where \(\sigma\) denotes the sigmoid function, and \(1-\mathbf{C}_{[i,j]}\) denotes the cosine similarity between \(\mathbf{h}_{i}\) and \(\mathbf{h}^{\prime}_{j}\)","L_{align}=\sum_{i=1}^{L}\sum_{j=1}^{L}\hat{Q}_{[i,j]}\cdot\|h_i-h'_j\|_2^2","where \(\mathcal{L}_{\text{align}}\) is the representation-level alignment loss, \(\hat{\mathbf{Q}}_{[i,j]}\) is the normalized alignment score between token representations \(\mathbf{h}_i\) and \(\mathbf{h}'_j\), and \(\|\cdot\|_2^2\) denotes squared Euclidean distance."
2024.acl-short.15,4,P^{I}_{x}=softmax(W^{I}h_{CLS}+b^{I}) || P^{I}_{x^{\prime}}=softmax(W^{I}h^{\prime}_{CLS}+b^{I}),,"o^{I}=decoder^{I}(h_{CLS}),\quado^{I\prime}=decoder^{I}(h^{\prime}_{CLS})","where \(\mathrm{decoder}^{I}\) is the intent classification layer, and \(\mathbf{o}^{I}\), \(\mathbf{o}^{I\prime}\) are the predicted intent logits for the original and code-switched sentences, respectively."
2024.acl-short.15,5,P^{S}_{x}=softmax(W^{S}h_{[1:-1]}+b^{ S}) || P^{S}_{x^{\prime}}=softmax(W^{S}h^{\prime}_{[1:-1]}+b^{S}),,P^{S}_{x}=softmax(W^{S}h_{[1:-1]}+b^{S}),"where \(\mathbf{P}^{S}_{\mathbf{x}}\) denotes the slot label probability distributions for each token in \(\mathbf{x}\), and \(\mathbf{W}^{S}\), \(\mathbf{b}^{S}\) are the slot filling decoder parameters."
2024.acl-short.15,6,"L_{I}=CE(P^{I}_{x},P^{I}) || L_{S}=\frac{1}{L}\sum_{i=1}^{L}CE(P^{S}_{[x,i]},P^{S}_{i})",,"L_{I}=-\sum_{k} y^{I}_{k}\logP^{I}_{x,k},\quadL_{S}=-\sum_{t}\sum_{k} y^{S}_{t,k}\logP^{S}_{x,t,k}","where \(y^{I}_{k}\) and \(y^{S}_{t,k}\) are the one-hot ground truth labels for intent and slot at position \(t\), respectively, and \(\mathbf{P}^{I}_{\mathbf{x},k}\), \(\mathbf{P}^{S}_{\mathbf{x},t,k}\) are the predicted probabilities."
2024.acl-short.15,7,L_{PLA}=\underbrace{KL(P^{I}_{x^{\prime}} || P^{I}_{x})}_{Intent PLA}+\underbrace{KL(P^{S}_{x^{\prime}} || P^{S}_{x}) }_{Slot PLA},"where \(\mathrm{KL}(\cdot)\) denotes Kullback-Leibler divergence (Kullback and Leibler, 1951) to measure the difference between two distributions","L_{PLA}=KL(P^{I}_{x}\parallelP^{I}_{x^{\prime}})+\frac{1}{L}\sum_{i=1}^{L}KL(P^{S}_{[x,i]}\parallelP^{S}_{[x^{\prime},i]})",The prediction-level alignment loss \(\mathcal{L}_{\text{PLA}}\) is the sum of KL divergences between the intent and slot distributions of the original and code-switched sentences.
2024.acl-short.15,8,"L_{SD}=\underbrace{KL(P^{[I,t-1]}_{ kT} || P^{[I,t]}_{latent SD})}_{Intent SD}+\underbrace{\frac{1}{L}\sum_{i=1}^{L}KL(P^{[S,t-1]}_{[x,i]} || P^{[S,t]}_{[x,i]}) }_{Slot SD}","where \(\mathbf{P}^{[I,t]}_{\mathbf{x}}\) denotes the probability distribution of intent, \(\mathbf{P}^{[S,t]}_{[\mathbf{x},i]}\) of slot at \(i\)-th token","L_{SD}=\underbrace{KL(P^{t-1, I}_{x}\|P^{t, I}_{x})}_{Intent SD}+\underbrace{KL(P^{t-1, S}_{x}\|P^{t, S}_{x})}_{Slot SD}","where \(\mathbf{P}^{t, I}_{\mathbf{x}}\) and \(\mathbf{P}^{t, S}_{\mathbf{x}}\) denote the intent and slot probability distributions at epoch \(t\), respectively."
2024.acl-short.15,9,L=L_{I}+L_{S}+L_{RLA}+L _{PLA}+L_{SD},,L=L_{I}+L_{S}+\lambda_{1}L_{RLA}+\lambda_{2}L_{PLA}+\lambda_{3}L_{SD},"The total loss \(\mathcal{L}\) is a weighted sum of the intent loss, slot loss, representation-level alignment loss, prediction-level alignment loss, and self-distillation loss, with hyperparameters \(\lambda_{1}, \lambda_{2}, \lambda_{3}\) controlling the contributions of the alignment and distillation terms."
2024.acl-short.16,1,Y=W_{0}^{l}X+\Lambda_{b}^{l}B^{l}\Lambda_{d}^{l}A^{l}X,,Y^{(l)}=lora_{B}^{(l)}\left( s_{d}^{(l)}\odot\left( lora_{A}^{(l)} X^{(l)}\right)\right)+s_{b}^{(l)},"\(Y^{(l)}\) is the output of the LoRA module at layer \(l\), computed by applying the down-projection \(lora_{A}^{(l)}\), elementwise scaling \(s_{d}^{(l)}\), up-projection \(lora_{B}^{(l)}\), and bias \(s_{b}^{(l)}\) to the input \(X^{(l)}\)."
2024.acl-short.16,2,"I_{A^{l}}=|\nablaL(\theta)|,\overline{T}^{(t)}_{A^{l }}=\beta_{1}\overline{T}^{(t-1)}_{A^{l}}+(1-\beta_{1})I^{(t)}_{A^{l}} || U^{(t)}_{A^{l}}=|I^{(t)}_{A^{l}}-\overline{I}^{(t)}_{A^{l}}|,\overline{U}^{(t)}_{A^{l}}=\beta_{2}\overline{U}^{(t-1)}_{A^{l}}+(1-\beta_{2} )U^{(t)}_{A^{l}} || s^{(t)}_{A^{l}}=mean(\overline{T}^{(t)}_{A^{l}}\circ\overline{U}^{(t)}_{A^{l}})",,S_{A^{l}}=E_{t}\left[\left\|\nabla_{A^{l}}L(t)\right\|_{F}\right],"\(S_{A^{l}}\) denotes the freezing score for the low-rank tensor \(A^{l}\), computed as the expected Frobenius norm of its gradient over training steps \(t\)."
2024.acl-short.16,3,r(t)=\{{ll}0&0\leq t<t_{i}\\1-(1-\frac{t-t_{i}}{T-t_{i}-t_{f}})^{3}&t_{i}\leq t<T-t_{f}\\1&otherwise,"where \(t\) refers to current #step, \(T\) is the total number of fine-tuning steps","r(t)=0, & t < t_{i}\\\left(\frac{t-t_{i}}{T-t_{i}-t_{f}}\right)^{3}, & t_{i}\leq t < T-t_{f}\\1, & t\geq T-t_{f}","$r(t)$ denotes the fraction of projection matrices to freeze at training step $t$ following a cubic schedule, where $t_{i}$ is the initial step, $T$ is the total number of steps, and $t_{f}$ is the number of final steps during which all matrices are frozen."
2024.acl-short.20,1,"E(h,r,t)=\sum_{i=1}^{k}w_{i}(q)M_{i}(h,r,t)","where \(\mathtt{E}(\mathtt{h},\mathbf{r},\mathbf{t})\) is the ensemble score for \(\mathbf{t}\) given query \(\mathtt{q}=(\mathbf{h},\mathbf{r},?)\)","E(h,r,t)=\sum_{i=1}^{k} w_iM_i(h,r,t)","The ensemble score for a candidate tail \(\mathbf{t}\) is a weighted sum of the scores assigned by each model \(\mathtt{M}_i\), with weights \(w_i\)."
2024.acl-short.20,2,"M_{i}(h,r,t)\getsM_ {i}(h,r,t)-\min_{t^{\prime}\inE}M_{i}(h,r,t^{\prime}) || M_{i}(h,r,t)arrow\frac{M_{i}(h,r,t)}{\max_{t^{\prime}\inE}M_{i}(h,r,t^{\prime})}",,"\hat{M}_{i}(h,r,t)=\frac{M_{i}(h,r,t)-\min_{t'\inE}M_{i}(h,r,t')} {\max_{t'\inE}M_{i}(h,r,t')}-\min_{t'\inE}M_{i}(h,r,t')}","where \(\hat{\mathtt{M}}_{\mathtt{i}}(\mathbf{h},\mathbf{r},\mathbf{t})\) is the max-min normalized score for candidate tail \(\mathbf{t}\) from model \(\mathtt{M}_{\mathtt{i}}\) for query \((\mathbf{h},\mathbf{r},?)\)."
2024.acl-short.20,3,"f(M_{i},q)=\underset{t^{\prime}\inE}{mean}(M_{i}(h,r,t^{\prime})) || \underset{t^{\prime}\inE}{ var}(M_{i}(h,r,t^{\prime}))",,"f_{i}(q)=\left[\max_{t\inE}M_{i}(h,r,t),\;\min_{t\inE}M_{i}(h,r,t),\;mean_{t\inE}M_{i}(h,r,t),\;std_{t\inE}M_{i}(h,r,t)\right]","\(\mathbf{f}_{\mathtt{i}}(\mathtt{q})\) is the feature vector for model \(\mathtt{M}_{\mathtt{i}}\) on query \(\mathtt{q}\), consisting of the max, min, mean, and standard deviation of its normalized scores over all candidate tails."
2024.acl-short.20,4,"w_{1}(q)=MLP_{1}(f(M_{1},q) || f(M_{2},q) ||  || f(M_ {k},q))",,"w_{i}(q)=MLP_{i}\left(f(M_{1},q)\ || \,f(M_{2},q)\ || \,\ldots\ || \,f(M_{k},q)\right)",The query-dependent ensemble weight for model \(\mathtt{M}_{\mathtt{i}}\) is computed by passing the concatenated feature vectors from all models through a model-specific MLP.
2024.acl-short.20,5,"L=\sum_{t\inN}\max(E(h,r,t)-E(h,r,t^{*})+m,0)",where \(\mathtt{m}\) is the margin hyperparameter,"L(q)=\sum_{t^{-}\inN}\max\left(0,\gamma-E(h,r,t^{*})+E(h,r,t^{-})\right)","where \(\mathcal{L}(\mathtt{q})\) is the margin-based loss for query \(\mathtt{q}\), \(\gamma\) is the margin, \(\mathbf{t}^{*}\) is the gold entity, and \(\mathtt{N}\) is the set of negative samples."
2024.acl-short.25,1,"s_{i}=\sigma(\frac{1}{\beta_{i}}(log\frac{\mu_{i}}{1-\mu_{i}}+\textit{log}\alpha_{i})) || m_{i}=min(1,max(0,s_{i}(\zeta-\gamma)+\gamma))",,"m_{i}\simHardConcrete(\log\alpha_{i},\beta_{i})",The mask variable \(m_{i}\) for each neuron is sampled from a hard concrete distribution parameterized by location \(\log \alpha_{i}\) and temperature \(\beta_{i}\).
2024.acl-short.25,2,"min(1,max(0,\sigma(log\alpha_{i})(\zeta-\gamma)+\gamma))",,"m_{i}=\min(1,\max(0,\sigma(\log\alpha_{i})\cdot (\zeta-\gamma)+\gamma))","During inference, the mask \(m_{i}\) is computed deterministically using the sigmoid of the location parameter \(\alpha_{i}\) and the constants \(\gamma\) and \(\zeta\)."
2024.acl-short.25,3,"L_{m}(f(m\odot\theta),x)=\sum_{i=1}^{I}log(P(x_{p+i}|x_{<p+i}))",,L_{adv}=-\sum_{i=p}^{p+I}\log P(x_i\mid x_{<i}; m\odot\theta),"The adversarial loss \(\mathcal{L}_{adv}\) is defined as the negative log-likelihood of the PII tokens, conditioned on the preceding context and the masked model parameters."
2024.acl-short.25,4,"L_{adv}(f(m\odot\theta),x)=-\sum_{t=1}^{T}log(P(x_{t}|x_{<t}))",,"L_{adv}(f(m\odot\theta),x)=-\sum_{t=1}^{T}\log P(x_t\mid x_{<t})","\(\mathcal{L}_{adv}(f(m\odot\theta),x)\) denotes the adversarial loss, defined as the negative log-likelihood of the original language modeling objective over the sequence \(x\)."
2024.acl-short.25,5,R(m)=-\frac{1}{|m|}\sum_{i=1}^{|m|}\sigma(log\alpha_{i}-\beta_{i}log \frac{-\gamma}{\zeta}),,R(m)=\sum_{i=1}^{n} (1-m_i),"The regularization term \(R(m)\) penalizes the number of neurons that are masked (i.e., where \(m_i = 0\)), encouraging sparsity in the selected neurons."
2024.acl-short.3,1,"\Delta(G_{1},G_{2})=\min_{ops}\sum_{i=1}^{n}w(op_{i})",,"\Delta(G_{1}, G_{2})=APTED(G_{1}, G_{2})",The tree edit distance \(\Delta\) between the predicted AST \(G_{1}\) and the ground-truth AST \(G_{2}\) is computed using the APTED algorithm.
2024.acl-short.3,2,"TSED=\max\{1-\frac{\delta}{MaxNodes(G_{1},G_{2})},0\}",,"TSED(G_{1}, G_{2})=\frac{\Delta(G_{1}, G_{2})}{\max(|G_{1}|, |G_{2}|)+\epsilon}","TSED is the normalized tree edit distance between ASTs \(G_{1}\) and \(G_{2}\), where \(|G_{1}|\) and \(|G_{2}|\) are the number of nodes in each tree and \(\epsilon\) is a small constant for numerical stability."
2024.acl-short.39,1,"Bio(m,co(m))=f_{gen}(m,co(m))",where biography is generated by the model \(f_{gen}\) given the personal attribute of interest (\(m\)) and the co-occurring attributes (\(co(m)\)),P(y\midx),The probability of generating a biography $\mathbf{y}$ given the structured infobox attributes $\mathbf{x}$.
2024.acl-short.39,2,"Bio(\phi,co(m))=f_{gen}(\phi,co(m))",,"Bio(mask(m), co(m))=f_{gen}(mask(m), co(m))",where the biography is generated by the model \(f_{gen}\) given the co-occurring attributes \(co(m)\) and the target attribute \(m\) is masked (not provided).
2024.acl-short.39,3,"Bio(f,co(m))=f_{gen}(f,co(m)),do(m\to f)","where \(do(m\to f)\) denotes the do operator (Pearl, 2009), e","Bio(m',co(m))=f_{gen}(m',co(m))","where the personal attribute of interest is replaced by an alternative value \(m'\), while the co-occurring attributes \(co(m)\) remain unchanged, and the biography is generated by the model \(f_{gen}\)."
2024.acl-short.40,1,"L_{e}=\frac{1}{N}\sum_{i=1}^{N}(\cos(S_{1,i},S_{2,i})-\cos(E_{1,i},E_{2,i}))^{2}","where \(N\) is the batch size, and \(S\) and \(E\) contain the target text SEM vectors and the predicted output SEM vectors respectively",L_{MSE}=\frac{1}{N}\sum_{i=1}^{N}\left\|h_i^{(1)}-h_i^{(2)}\right\|^2,$\mathcal{L}_{\text{MSE}}$ is the mean squared error loss between the sentence embeddings $\mathbf{h}_i^{(1)}$ and $\mathbf{h}_i^{(2)}$ produced by the twin subnetworks for each sample $i$ in a batch of size $N$.
2024.acl-short.40,2,"L_{o}=CE(T,O)=-\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{M} (T_{ij}\cdot\log(O_{ij}))","where \(N\) is the batch size, \(M\) the vocabulary size, \(T\) is the target text and \(O\) is the output text","L_{t}=-\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{T_i}\log P(y_{i,j}\mid y_{i,1:j-1},SEM_i)","where \(N\) is the batch size, \(T_i\) is the length of the \(i\)-th target sentence, \(y_{i,j}\) is the \(j\)-th target token, and \(\mathrm{SEM}_i\) is the input sentence embedding for sample \(i\)"
2024.acl-short.41,1,E(y)=h(\beta+\sum_{j=1}^{J}f_{j}(x_{j})),"where \(h(\cdot)\) is the activation function used in the output layer, e",y=f_1(x_1)+f_2(x_2)+\cdots+f_p(x_p)+\epsilon,"The target variable \( y \) is modeled as the sum of functions \( f_j \) of each input variable \( x_j \), plus an error term \( \epsilon \)."
2024.acl-short.41,2,h(E[y])=\beta+\sum_{j=1}^{J}f_{j}(x_{j(tab)})+\sum_{k=1}^{ K}f_{k}(x_{k(top)}),,E(y)=h\left(\beta+\sum_{j=1}^{J_{tab}} f_{j}^{tab}(x_{j(tab)})+\sum_{k=1}^{K_{top}} f_{k}^{top}(x_{k(top)})\right),"where \(f_{j}^{tab}\) and \(f_{k}^{top}\) are the shape functions for the tabular and topical features, respectively."
2024.acl-short.43,1,P(c|s)=\frac{\exp(b_{c}\cdot\frac{1}{T}\sum_{t=1}^{T}x_{t})}{\sum_{c^{\prime}=1}^{N}\exp(b_{c^{\prime}}\cdot\frac{1}{T}\sum_{t=1}^ {T}x_{t})},,P(c\mid s)=\frac{\exp(w_c^\toph+b_c)}{\sum_{c'=1}^{N}\exp(w_{c'}^\toph+b_{c'})},"\(P(c \mid s)\) is the posterior probability of language \(c\) given sentence \(s\), where \(\mathbf{h}\) is the aggregated sentence embedding, \(\mathbf{w}_c\) and \(b_c\) are the weight vector and bias for class \(c\), and \(N\) is the total number of languages."
2024.acl-short.43,2,"V_{c,t}(s)=b_{c}\cdotx_{t}",,"V_{c,t}(s)=b_{c}\cdotx_{t}","\(\mathbf{V}_{c,t}(s)\) is the logit for language \(c\) and word-level feature \(\mathbf{x}_{t}\) in sentence \(s\)."
2024.acl-short.49,1,CEF=\frac{\sum_{i=0}^{n}(I_{i}-\overline{I} )(M_{i}-\overline{M})}{\sqrt{\sum_{i=1}^ {n}(I_{i}-\overline{I})^{2}}\sqrt{\sum_{i=1}^ {n}(M_{i}-\overline{M})^{2}}},where \(\overline{x}=\frac{1}{n}\sum_{i=1}^{n}x_{i}\) (the sample mean),"CEF=corr(I,M)",The Correlational Explanatory Faithfulness (CEF) metric is defined as the Pearson correlation coefficient between prediction impact \(\mathcal{I}\) and mention importance \(\mathcal{M}\).
2024.acl-short.49,2,"TVD(P,Q)=\frac{1}{2}\sum_{x}|P(x)-Q(x)|",where P and Q are probability distributions over discrete classes,"TVD(p, q)=\frac{1}{2}\sum_{c} |p(c)-q(c)|","where \(p\) and \(q\) are the model's predicted probability distributions over classes before and after the intervention, respectively, and \(c\) ranges over all classes."
2024.acl-short.49,3,CCT=\frac{E_{M}(TVD)-E_{-M}(TVD)}{STD(TVD)}\sqrt{\frac{|M || \neg M|}{|M\cup\neg M|^{2}}},"where \(M\) indicates that the explanation mentions the IA, and \(|M|\) indicates the number of examples with explanation mentions",CCT=\frac{\sum_{i=1}^{n} (TVD_i-\overline{TVD})(M_i-\overline{M})}{\sqrt{\sum_{i=1}^{n} (TVD_i-\overline{TVD})^2}\sqrt{\sum_{i=1}^{n} (M_i-\overline{M})^2}},"where \(\text{TVD}_i\) is the total variation distance for intervention \(i\), and \(\mathcal{M}_i\) is the binary mention importance for intervention \(i\)."
2024.acl-short.5,1,"s_{ori}(x_{i}|x_{<i})= || \{{ll}\log P_{M_{e}}(x_{i}|x_{<i})-\log P_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{ori,i}^{\alpha}\\-\infty,&x_{i}\notinV_{ori,i}^{\alpha}\\s_{imp}(x_{i}|x_{<i})=\\\{{ll}(1+\beta)Y_{M_{a}}(x_{i}|x_{<i})-\beta Y_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{imp,i}^{\alpha}\\-\infty,&x_{i}\notinV_{imp,i} || s_{int}(x_{i}|x_{<i})= || \{{ll}(1+\beta)Y_{M_{e}}(x_{i}|x_{< i})-\beta Y_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{imp,i}^{\alpha}\\-\infty,&x_{i}\notinV_{imp,i}",,s_{ori}(x_{i}|x_{<i}) &=\log p_{exp}(x_{i}|x_{<i})-\alpha\log p_{am}(x_{i}|x_{<i})\\s_{imp}(x_{i}|x_{<i}) &=\log p_{exp}(x_{i}|x_{<i})-\alpha\log p_{am}(x_{i}|x_{<i})+\beta\cdotKL(p_{exp}(\cdot|x_{<i})\| p_{am}(\cdot|x_{<i})),"$s_{\text{ori}}(x_{i}|x_{<i})$ and $s_{\text{imp}}(x_{i}|x_{<i})$ are the contrastive logit scores for the original and improved contrastive decoding, respectively, where $p_{\text{exp}}$ and $p_{\text{am}}$ are the expert and amateur language model probabilities, $\alpha$ and $\beta$ are hyperparameters, and $\text{KL}$ denotes the Kullback-Leibler divergence."
2024.acl-short.5,2,"V_{ori,i}^{\alpha}=\{w|P_{M_{e}}(w|x_{<i})>\alpha\max_{w\inV}P_{M_{e}}(w|x_{<i})\} || V_{imp,i}^{\alpha}=\{w|Y_{M_{e}}(w| x_{<i})>\log\alpha+\max_{w\inV}Y_{M_{e}}(w|x_{<i})\}",,"V_{\cdot,i}^{\alpha}=\left\{ x_i\mid Y_{M_{\cdot}}(x_i|x_{<i})\geq\max_{x'_i} Y_{M_{\cdot}}(x'_i|x_{<i})-\alpha\right\}","The adaptive plausibility constraint $\mathcal{V}_{\cdot,i}^{\alpha}$ is the set of tokens whose logits are within $\alpha$ of the maximum logit at position $i$."
2024.acl-short.53,1,"L_{FT}=\frac{1}{|D_{M}|}\sum_{d\inD_{M}}L(d;\Phi _{0},\Delta\Phi)","where \(\mathcal{D}_{M}\) is the KE dataset and \(d\) is a fact edit example, \(L\) is the cross entropy loss function applied to autoregressive models, \(\Phi_{0}\) denotes the set of original weights of the language model that are kept frozen, and \(\Delta\Phi\) denotes the additional parameters used by the PEFT adapters","L=\frac{1}{N}\sum_{i=1}^{N}\ell(f_{\theta}(x_i), y_i)","$\mathcal{L}$ denotes the average loss over $N$ training examples, where $f_{\theta}(x_i)$ is the model prediction for input $x_i$ and $y_i$ is the corresponding target label."
2024.acl-short.53,2,h=W_{0}x+BAx=(W_{0}+BA)x,,W'=W+BA,"\(W'\) is the adapted weight matrix, \(W\) is the original weight matrix, and \(B\) and \(A\) are the trainable low-rank matrices in LoRA."
2024.acl-short.56,1,h^{\prime}=SoftMax(h\cdoth^{\prime T})\cdoth^{\prime},,"h_{inter}=Interaction(h,h^{\prime})",The interaction representation $\mathbf{h}_{\text{inter}}$ is computed by applying an interaction function to the prior memory $\mathbf{h}$ and the posterior memory $\mathbf{h}^{\prime}$.
2024.acl-short.56,2,"\mu^{\prime}_{1},...,\mu^{\prime}_{n}\\\log(\sigma^{\prime 2}_{1}),...,\log(\sigma^{\prime 2}_{n})=[h_{1};h^{\prime}_{1}]\\\cdots\\[h_{n};h^{\prime}_{n}]W^{\prime}_{u}\","where \(W^{\prime}_{u}\) is trainable parameters of \(q_{\phi}(z|r,c)\)","\mu^{\prime},\log\sigma^{\prime 2}=MLP([h;h^{\prime}])",The mean and log-variance of the posterior Gaussian are computed by passing the concatenation of prior and posterior memory through an MLP.
2024.acl-short.57,1,"a_{k}^{pred}=\operatorname*{arg\,max}_{a_{k}}\!P(a_{k}|q_{k},H_{k},D)",,"a_{k}^{pred}=M(q_{k}, D, H_{k})","The predicted answer \(a_{k}^{pred}\) at turn \(k\) is generated by the model \(\mathcal{M}\) given the current question \(q_{k}\), the document \(D\), and the history \(H_{k}\)."
2024.acl-short.57,2,"P(a_{k}|q_{k},H_{k},D)=P(a_{k}|q_{k},H_{k}^{\star},D)",,"P(a_{k}|q_{k},H_{k},D)=P(a_{k}|q_{k},H_{k}^{\star},D)",The probability of the answer given the original history should equal the probability given the augmented history.
2024.acl-short.57,3,"L_{CE}=CE(QA_{\theta^{\prime}}(q_{k},H_{k},D),a_{k}^{gold}) || L_{Cons}=D_{KL}(QA_{\theta^{\prime}}(q_{k},H_{k},D) || QA_{\theta^{\prime}}(q_{k},H_{k}^{\star},D)) || L_{T}=L_{CE}+\lambda L_{Cons}",,L_{T}=L_{CE}+\lambda L_{Cons},"Total loss \(L_{T}\) is the sum of the cross-entropy loss \(L_{CE}\) and the consistency loss \(L_{Cons}\), weighted by hyperparameter \(\lambda\)."
2024.acl-short.62,1,R(\tau)=\frac{1}{T}\sum_{t=1}^{T}r_{t},,R(\tau)=\frac{1}{T}\sum_{t=1}^{T} r_{t},The total trajectory reward \(R(\tau)\) is defined as the average of the token-level rewards \(r_t\) over the response length \(T\).
2024.acl-short.62,2,p(\tau^{i}\succ\tau^{j})&=\frac{\exp(R(\tau^{i}))}{\exp(R(\tau^{i}))+\exp(R(\tau^{j}))}\\&=\sigma(R(\tau^{i})-R(\tau^{j})),where \(\tau^{i}\) and \(\tau^{j}\) represent two different responses generated from the same prompt,P(y^{(1)}\succ y^{(2)})=\frac{\exp(R(\tau^{(1)}))}{\exp(R(\tau^{(1)}))+\exp(R(\tau^{(2)}))},The probability that response \(y^{(1)}\) is preferred over \(y^{(2)}\) is given by a softmax over their trajectory rewards.
2024.acl-short.62,3,"&L=-E_{(\tau^{i},\tau^{j})\simD}[\log\sigma(R(\tau^{i})-R(\tau^{j}))]\\&=-E_{(\tau^{i},\tau^{j})\simD}[\log\sigma((\frac{1}{T^{i}}-\frac{1}{T^{j}})\sum_{t\in U_{0}}r_{t}\\&+\frac{1}{T^{i}}\sum_{t\in U_{1}}r_{t}^{i}-\frac{1}{T^{j}}\sum_ {t\in U_{1}}r_{t}^{j})]",,L_{NLL}=-\log\sigma\left(\frac{1}{|U_1|}\sum_{t\in U_1}\left( r_t^i-r_t^j\right)\right ),The negative log-likelihood loss is computed using the sigmoid of the average reward difference over the changed tokens between responses \(\tau^i\) and \(\tau^j\).
2024.acl-short.62,4,"L\approx-E_{(\tau^{i},\tau^{j} )\simD}[\log\sigma(\frac{1}{T^{i}}\sum_{t\in U_{1}}r_{t}^{i}-\frac{ 1}{T^{j}}\sum_{t\in U_{1}}r_{t}^{j})]",,"L=-E_{(\tau^{i},\tau^{j})\simD}\left[\log\sigma\left(\frac{1}{T}\sum_{t\in U_{1}} r_{t}^{i}-\frac{1}{T}\sum_{t\in U_{1}} r_{t}^{j}\right)\right]",where \(T\) is the (equal) length of both responses and \(U_{1}\) indexes the changed tokens.
2024.acl-short.66,1,"H(t,a)=\mathds{1}[\{(i,t)\in a\}=\varnothing]",,"\hat{y}_{t} is a hallucination\iff\forall j,\, a_{t,j}=0","A target word \(\hat{y}_{t}\) is considered a hallucination if it is not aligned to any source word, i.e., all alignment scores \(a_{t,j}\) are zero."
2024.acl-short.66,2,"HR(x,\hat{y},a)=\frac{1}{|\hat{y}|}\sum_{t=1}^{|\hat{y}|}H(t,a)",,"HR=\frac{\sum_{t=1}^{T} H(t,a)}{T}",The Hallucination Rate (HR) is the proportion of hallucinated target words among all target words in a sentence.
2024.acl-short.66,3,"H_{wait-k}(t,a)=\mathds{1}[\{(s,t)\in a\mid s\geq t+k\}=\varnothing]",,"GHall(t, a, g)=\mathds{1}\left[\{(i, t)\in a\mid i\leq g(t)\}=\varnothing\right]",GHall indicates whether target word \(\hat{y}_t\) is a hallucination with respect to the source prefix up to position \(g(t)\).
2024.acl-short.66,4,"R(y_{i},x_{j})=P(y_{i}\midy_{<i},x_{\leq i+k-1}) || \quad-P(y_{i}\midy_{<i},x_{\leq i+k-1, (j,\textbf{0})}) || R(y_{i},y_{j})=P(y_{i}\midy_{<i},x_{\leq i+k-1}) || \quad-P(y_{i}\midy_{<i,(j,\textbf{0} )},x_{\leq i+k-1})",,"R(y_{i}, w_{j})=f(y_{i}\midEnc(x_{1:i+k-1}\setminus w_{j}),Dec(y_{<i}\setminus w_{j}))-f(y_{i}\midEnc(x_{1:i+k-1}),Dec(y_{<i}))","The relevance \(R(\text{y}_{i}, w_{j})\) is defined as the difference in the model's output for \(\text{y}_{i}\) when the word \(w_{j}\) (either a source word \(\text{x}_{j}\) or a target word \(\text{y}_{j}\)) is deactivated from the encoder or decoder network, respectively, compared to when all words are present."
2024.acl-short.66,5,"R(y_{i})_{source-side}=\max\{|R(y_{i},x_ {j})|\} || R(y_{i})_{target-side}=\max\{|R(y_{i},y _{j})|\}",,"SR_i &=\max_{j} |R(y_i,x_j)|\\TR_i &=\max_{j} |R(y_i,y_j)|","SR\(_i\) and TR\(_i\) denote the maximum absolute relevance of source-side and target-side words to the generation of \(\text{y}_i\), respectively."
2024.acl-short.66,6,TSSR(y_{i})=\frac{R(y_{i})_{target-side}}{R(y_{i} )_{source-side}},,TSSR(y_{i})=\frac{R(y_{i})_{target-side}}{R(y_{i})_{source-side}},The TSSR for word \(\text{y}_{i}\) is defined as the ratio of its maximum target-side relevance to its maximum source-side relevance.
2024.acl-short.68,1,"T_{i}=\operatorname*{Top\_}{d\inM}k\f(s_{i},d)",,"T_{i}=TopK_{d\inM}\left( f(s_{i}, d)\right)",The set of top-\(k\) passages \(\mathcal{T}_{i}\) for medical code \(c_{i}\) is obtained by selecting the \(k\) passages \(d\) from the corpus \(\mathcal{M}\) with the highest similarity scores to the surface name \(s_{i}\).
2024.acl-short.68,2,"e_{i}=LLM([Prompt,t_{i,1},\cdots,t_{i,k}])",where \(t_{i}\in\mathcal{T}_{i}\) stands for the retrieved passages in Eq,e_{i}=LLM(T_{i}),"\(e_{i}\) is the summarized knowledge for medical code \(c_{i}\), generated by applying the LLM to the retrieved passages \(\mathcal{T}_{i}\)."
2024.acl-short.68,3,"h_{i}^{k}=PLM(X_{i}^{k}),\;\;\widehat{y}_{i,1}=MLP ( || _{k\inS}h_{i}^{k})",,"\hat{y}_{i}=g_{\phi}(X_{i}^{d},X_{i}^{m},X_{i}^{p})","where \(\hat{y}_{i}\) is the predicted outcome for patient \(p_{i}\) given the flattened documents for diseases, medications, and procedures."
2024.acl-short.68,4,"e_{i}=HyGT(G,V_{i}),\widehat{y}_{i,2}=MLP(e_{i})",where \(\mathbf{e}_{i}\) is the representation of patient \(i\) after hypergraph transformer,"\widehat{y}_{i,2}=f_{\theta}(v_{i})","where \(v_{i}\) is the hospital visit for patient \(p_{i}\) and \(f_{\theta}\) is the local model (e.g., HyGT) producing the prediction \(\widehat{y}_{i,2}\)."
2024.acl-short.68,5,"L_{aug}=E_{(V_{i},y_{i})\simP}\;\ell(\widehat{y}_{i,1},y_{i})+\lambdaD_{KL}(\widehat{y}_{i,1},\widetilde{y}) || L_{loc}=E_{(V_{i},y_{i})\simP}\;\ell(\widehat{y}_{i,2},y_{i})+\lambdaD_{KL}(\widehat{y}_{i,2},\widetilde{y})",,"L=\lambda_{1}\cdotL_{task}(\widehat{y}_{i,1}, y_{i})+\lambda_{2}\cdotL_{task}(\widehat{y}_{i,2}, y_{i})+\lambda_{3}\cdotL_{cons}(\widehat{y}_{i,1},\widehat{y}_{i,2})","The overall co-training loss combines the task losses for both predictors and a consistency loss between their predictions, weighted by hyperparameters \(\lambda_{1}\), \(\lambda_{2}\), and \(\lambda_{3}\)."
2024.acl-short.71,1,"hyp^{*}=\operatorname*{arg\,max}_{hyp\inhyps}utility(hyp)",,"hyp^{*}=\arg\max_{hyp_i\inhyp}E_{hyp_j\sim p(\cdot)}\left[ U(hyp_i,hyp_j)\right]",The optimal hypothesis \(\mathit{hyp}^{*}\) is selected by maximizing the expected utility \(U\) over the distribution of hypotheses \(p(\cdot)\).
2024.acl-short.71,2,"utility(hyp)\approx\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}} metric(hyp,\textit{ref})",,"utility(hyp)\approx\frac{1}{m}\sum_{i=1}^{m}metric(hyp,ref_i)",The utility of a hypothesis is approximated as the average metric score between the hypothesis and each of the m sampled references.
2024.acl-short.71,3,\overline{\textit{ref}}=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textit{ ref},,\overline{\textit{ref}}=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textit{ref},The aggregate reference representation \(\overline{\textit{ref}}\) is computed as the average of the representations of all sampled references in the set \(\textit{refs}\).
2024.acl-short.71,4,"utility(hyp)\approxmetric(hyp,\overline{\textit{ref}})",,"utility(hyp)\approxmetric(hyp,\overline{\textit{ref}})",The utility of a hypothesis is approximated by computing the metric between the hypothesis and the aggregated reference representation.
2024.acl-short.71,5,ChrF_{\beta}=\frac{(1+\beta^{2})\cdotChrP\cdotChrR}{\beta^{2}\cdotChrP+ChrR} || ChrP=\frac{|hyp\cap\textit{ref}|}{|hyp|} and ChrR=\frac{|hyp\cap\textit{ref}|}{|\textit{ref}|},"where

\[\text{ChrP}=\frac{|hyp\cap\textit{ref}|}{|hyp|}\text{ and }\text{ChrR}=\frac{|hyp \cap\textit{ref}|}{|\textit{ref}|},\]

and the parameter \(\beta\) controls the relative importance of precision and recall",chrF=\frac{2\cdotprecision\cdotrecall}{precision+recall},chrF is the F-score computed from character n-gram precision and recall between a hypothesis and a reference.
2024.acl-short.71,6,\overline{\textit{ref}}=\frac{1}{m}\underbrace{\biguplus}_{\textit{ref}\in\textit{refs}}\textit{ref},where \(\biguplus\) is an operation that sums up the counts of each n-gram,\overline{\textit{ref}}[g]=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textit{ref}[g],\(\overline{\textit{ref}}[g]\) is the average count of n-gram \(g\) across all references in the set \(\textit{refs}\).
2024.acl-short.71,7,"\textbf{{hyp}},\\textbf{{ref}},\\textbf{{src}}=emb(\textbf{{hyp}}),\emb(\textbf{{ref}}),\emb(\textbf{{src}})",,"h_{src},\h_{hyp},\h_{ref}\inR^{d}","where \(\mathbf{h}_{\text{src}}\), \(\mathbf{h}_{\text{hyp}}\), and \(\mathbf{h}_{\text{ref}}\) are the \(d\)-dimensional embeddings of the source, hypothesis, and reference sentences, respectively."
2024.acl-short.71,8,"comet(\textbf{{hyp}})=score(\textbf{{hyp}},\\textbf{{ref}},\\textbf{{src}})",,"COMET(hyp, ref, src)=f(\textbf{hyp},\textbf{ref},\textbf{src})","The function \(f\) is a feed-forward neural network that takes the embeddings of the hypothesis, reference, and source as input and outputs a scalar quality score."
2024.acl-short.71,9,\overline{\textbf{{ref}}}=\frac{1}{m}\sum_{\textbf{{ref}}\in\textbf{{ref}}}emb(\textbf{{ref}}),,\overline{\textbf{ref}}=\frac{1}{m}\sum_{\textbf{ref}\in\textbf{refs}}\textbf{ref},The aggregated reference embedding \(\overline{\textbf{ref}}\) is computed as the mean of the individual reference embeddings \(\textbf{ref}\) over the set of references \(\textbf{refs}\).
2024.acl-short.71,10,"comet(\textbf{{hyp}})\approxscore(\textbf{{hyp}},\\overline{\textbf{{ref}}},\\textbf{{src}})",,"comet(\textbf{hyp})=score(\textbf{hyp},\\overline{\textbf{ref}},\\textbf{src})",where \(\overline{\textbf{ref}}\) is the aggregated reference embedding.
2024.acl-short.72,1,h_{i}=XLMRoberta-Layer^{1}(x_{i}),"where \(h_{i}\) is the representation of the ""[CLS]"" token",h_{i}=XLMR(x_{i}),\(h_{i}\) is the 768-dimensional representation of the \(i\)-th DOM node encoded by the first layer of XLM-Roberta.
2024.acl-short.72,2,\hat{h}_{i}=Transformer(Linear(h_{i})),where the linear layer projects \(h_{i}\) to 256-dimensional embeddings for efficient modeling,H'=Transformer(H),where \(H'\) denotes the encoded node representations output by the 3-layer transformer model.
2024.acl-short.72,3,P(y^{k}_{i}=1|x_{i})=Sigmoid(MLP(\hat{h}_{i})),,P(y^{k}_{i}=1|x_{i})=\sigma\left(W_{k}\hat{h}_{i}+b_{k}\right),"where \(W_{k}\) and \(b_{k}\) are the weights and bias for the \(k\)-th label, and \(\sigma\) denotes the sigmoid function."
2024.acl-short.72,4,"L=\sum_{k=1}^{6}\sum_{i=1}^{n}CrossEntropy(P(y^{k}_{i}|x_{i}), Y^{k}_{i})",where \(\mathcal{Y}^{k}_{i}\) is the ground truth label,L=-\frac{1}{n}\sum_{i=1}^{n}\sum_{k=1}^{6}\left[ y^{k}_{i}\log P(y^{k}_{i}=1|x_{i})+(1-y^{k}_{i})\log (1-P(y^{k}_{i}=1|x_{i}))\right],where \(L\) is the average binary cross-entropy loss over all nodes and label categories.
ICLR_2024_oral_1,1,I(\theta):=E_{\Upsilon\sim p_{\theta}} [\nabla_{\theta}\log p_{\theta}(\Upsilon)\cdot\nabla_{\bm {\theta}}\log p_{\theta}(\Upsilon)^{\top}],,I(\theta) :=E_{\Upsilon\sim p_{\theta}(\cdot\mid\pi)}\left[\nabla_{\theta}\log p_{\theta}(\Upsilon\mid\pi)\nabla_{\theta}\log p_{\theta}(\Upsilon\mid\pi)^\top\right],The Fisher information matrix \(\mathcal{I}(\mathbf{\theta})\) is the expected outer product of the score function of the trajectory distribution under parameter \(\mathbf{\theta}\) and policy \(\pi\).
ICLR_2024_oral_1,2,E_{D\sim p_{\theta^{\star}}}([\widehat{\theta} (D)-\theta^{\star})(\widehat{\theta}(D)-\theta^{\star})^{\top}]\succeq T^{-1}\cdotI(\theta^{\star})^ {-1},,Cov\left[\widehat{\theta}(D)\right]\succeq\frac{1}{T}I(\theta^{\star})^{-1},The covariance of any unbiased estimator \(\widehat{\mathbf{\theta}}(\mathfrak{D})\) is lower bounded by the inverse Fisher information scaled by the number of samples \(T\).
ICLR_2024_oral_1,3,E_{D\sim p_{\theta^{\star}}}[\|\widehat{\theta} (D)-\theta^{\star}\|_{2}^{2}]=tr(E_{ D\sim p_{\theta^{\star}}}[(\widehat{\theta}(D)-\theta^{\star})(\widehat{\theta}(D)-\theta^{\star})^{\top}])\geq T^{-1}\cdottr(I(\theta^{\star})^{-1}),,E_{D\sim p_{\theta^{\star}}}\left[\|\widehat{\theta}(D)-\theta^{\star}\|^{2}\right]\geqTr\left(T^{-1}\cdotI(\theta^{\star})^{-1}\right),The mean-squared error of any unbiased estimator of \(\mathbf{\theta}^{\star}\) is lower bounded by the trace of the inverse Fisher information matrix scaled by \(T^{-1}\).
ICLR_2024_oral_1,4,"I(\theta^{\star},\pi_{exp}):=E_{\tau\sim p_{\theta^{\star}}(\cdot\mid\pi_{exp})}[\nabla_{\theta}\log p_{\theta^{\star}}(\tau\mid\pi_{exp})\cdot\nabla_{\theta}\log p_{\theta^{\star}}(\tau\mid\pi_{ exp})^{\top}]",,I(\theta^{\star};\pi_{exp}):=E_{\Upsilon\sim p_{\theta^{\star}}(\cdot\mid\pi_{exp})}\left[\nabla_{\theta}\log p_{\theta^{\star}}(\Upsilon\mid\pi_{exp})\cdot\nabla_{\theta}\log p_{\theta^{\star}}(\Upsilon\mid\pi_{exp})^{\top}\right],The Fisher information matrix under exploration policy \(\pi_{\mathrm{exp}}\) quantifies the information about \(\mathbf{\theta}^{\star}\) contained in trajectories generated by \(\pi_{\mathrm{exp}}\).
ICLR_2024_oral_1,5,"\arg\min_{\pi}tr(I(\theta^{\star},\pi)^{-1})",,"\pi_{exp}^{\star}\in\arg\min_{\pi_{exp}}~tr\left(I(\theta^{\star},\pi_{exp})^{-1}\right)",The optimal exploration policy minimizes the trace of the inverse Fisher information matrix with respect to the exploration policy.
ICLR_2024_oral_1,6,"s_{h+1}=f_{\theta}(s_{h},a_{h})+w_{h}","where \(s_{h}\) and \(a_{h}\) are the current state and action, \(w_{h}\sim\mathcal{N}(0,\sigma_{w}^{2}\cdot I)\) is Gaussian process noise, and \(f_{\mathbf{\theta}}\) are the nominal dynamics","s_{h+1}\sim P_{\theta}(\cdot\mid s_h, a_h)",The next state \(s_{h+1}\) is sampled from the transition kernel \(P_{\mathbf{\theta}}\) given the current state \(s_h\) and action \(a_h\).
ICLR_2024_oral_1,7,"I(\theta,\pi)=\sigma_{w}^{-2}\cdotE_{p_{\theta}(\cdot\mid\pi)}[\sum_{h=1}^{H}\nabla_{\theta}f_{\theta}(s_{h},a_ {h})\cdot\nabla_{\theta}f_{\theta}(s_{h},a_{h})^{\top}]",,"I(\theta,\pi)=E_{\tau\sim p_{\theta}(\cdot\mid\pi)}\left[\sum_{h=1}^{H}\nabla_{\theta} f_{\theta}(s_h, a_h)^{\top}\Sigma_w^{-1}\nabla_{\theta} f_{\theta}(s_h, a_h)\right]","where \(\Sigma_w = \sigma_w^2 I\) is the covariance of the Gaussian process noise, and the expectation is over trajectories induced by policy \(\pi\) under parameter \(\mathbf{\theta}\)."
ICLR_2024_oral_1,8,"\pi_{exp}=\arg\min_{\pi}E_{\theta\sim q_{0}}[tr (I(\theta,\pi)^{-1})]",,"\arg\min_{\pi}\;E_{\theta\sim\rho}\left[tr\left(I(\theta,\pi)^{-1}\right)\right]",Optimal exploration policy under domain randomization minimizes the expected trace of the inverse Fisher information over a distribution \(\rho\) on parameters \(\mathbf{\theta}\).
ICLR_2024_oral_1,9,E_{\theta\sim q_{\theta}}[E_{\tau_{ sim}\sim p_{\theta}(\cdot\midA(\uptau_{real}) )}[\|\uptau_{real}-\uptau_{sim}\|_{2}^{2}]],"where \(p_{\mathbf{\theta}}(\cdot\mid\mathcal{A}(\mathbf{\uptau}_{\mathrm{real}}))\) denotes the distribution over trajectories generated by the simulator with parameter \(\mathbf{\theta}\), and playing the same sequence of actions as were played in \(\mathbf{\uptau}_{\mathrm{real}}\)","E_{\theta\sim q_{\phi}}\left[\ell\left(\uptau_{real},\,p_{\theta}(\cdot\mid\pi_{exp})\right)\right]",Expected loss between the real trajectory and simulated trajectories under parameter distribution \(q_{\mathbf{\phi}}\).
ICLR_2024_oral_10,1,"R=\{r_{1},\dots,r_{m}\}",where each ray \(\mathbf{r}_{i}\in\mathbb{R}^{6}\) is associated with a known pixel coordinate \(\mathbf{u}_{i}\),"r_{i}=(o_{i},d_{i})","Each camera is represented as a set of rays \(\mathbf{r}_{i}\), where each ray is defined by its origin \(\mathbf{o}_{i}\) and direction \(\mathbf{d}_{i}\)."
ICLR_2024_oral_10,2,"r=\langled,m\rangle\inR^{6}","where \(\mathbf{m}=\mathbf{p}\times\mathbf{d}\in\mathbb{R}^{3}\) is the moment vector, and importantly, is agnostic to the specific point on the ray used to compute it",r=d\\p\timesd,where \(\mathbf{r}\) is the 6D Plücker coordinate representation of a ray with direction \(\mathbf{d}\) passing through point \(\mathbf{p}\).
ICLR_2024_oral_10,3,"d=R^{\top}K^{-1}u,\qquadm=(-R^{\top}t)\timesd",,"d_{i}=R^{\top}K^{-1}\tilde{u}_{i},\quadm_{i}=c\timesd_{i}",where \(\tilde{\mathbf{u}}_{i}\) is the homogeneous pixel coordinate and \(\mathbf{c}\) is the camera center in world coordinates.
ICLR_2024_oral_10,4,"c=\operatorname*{arg\,min}_{p\inR^{3}}\\sum_{\langled,m\rangle\inR}\lVertp\timesd-m\rVert^{2}",,c=\arg\min_{x\inR^3}\sum_{i=1}^m\left\| (d_i\times (x-p_i))\right\|^2,The camera center \(\mathbf{c}\) is estimated as the point minimizing the sum of squared distances to all rays in the bundle.
ICLR_2024_oral_10,5,"P=\operatorname*{arg\,min}_{\|H\|=1}\sum_{i=1}^{m}\|Hd_{i}\timesu_{i}\|",,"P=\operatorname*{arg\,min}_{P\inR^{3\times 3}}\sum_{i=1}^{m}\left\|d_i^{pred}-Pd_i^{identity}\right\|^2",where \(\mathbf{d}_i^{\text{pred}}\) are the predicted ray directions and \(\mathbf{d}_i^{\text{identity}}\) are the corresponding directions from the identity camera.
ICLR_2024_oral_10,6,f_{feat}(I)=f\inR^{p\times p\times d},,"F=\{f_1,\dots,f_m\}","where $\mathbf{F}$ is the set of $m$ patch features extracted from the image, with each $\mathbf{f}_i$ corresponding to a patch and its associated ray."
ICLR_2024_oral_10,7,"\{\hat{R}\}_{i=1}^{N}=f_{Regress}(\{f_{i},u_{i}\}_{i=1}^{N\cdot p^{2}})",,\hat{r}_{i}=f_{ray}\left(\left[f_{i};u_{i}\right]\right),"where \(\hat{\mathbf{r}}_{i}\) is the predicted ray for patch \(i\), computed from the concatenated spatial feature \(\mathbf{f}_{i}\) and normalized pixel coordinate \(\mathbf{u}_{i}\) via the ray regression network \(f_{\text{ray}}\)"
ICLR_2024_oral_10,8,L_{recon}=\sum_{i=1}^{N}\|\hat{R}_{i}- R_{i}\|_{2}^{2},,"L_{ray}=\frac{1}{N p^2}\sum_{i=1}^{N}\sum_{j=1}^{p^2}\left\|\hat{r}_{i,j}-r_{i,j}\right\|_2^2","The ray reconstruction loss \(\mathcal{L}_{\text{ray}}\) is the mean squared error between predicted rays \(\hat{\mathbf{r}}_{i,j}\) and ground truth rays \(\mathbf{r}_{i,j}\) over all images and patches."
ICLR_2024_oral_10,9,x_{t}=\sqrt{\alpha_{t}}x_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,"where \(\epsilon\sim\mathcal{N}(0,\mathbf{I})\) and \(\alpha_{t}\) is a hyper-parameter schedule of noise weights such that \(x_{T}\) can be approximated as a standard Gaussian distribution","q(x_{t}|x_{0})=N(x_{t};\sqrt{\alpha_{t}}x_{0}, (1-\alpha_{t})I)","where \(\mathbf{x}_{t}\) is the noisy sample at time \(t\), \(\mathbf{x}_{0}\) is the original sample, and \(\alpha_{t}\) controls the noise schedule."
ICLR_2024_oral_10,10,"L(\theta)=E_{t,x_{0},\epsilon}\|x_{0}-f_{\theta }(x_{t},t)\|^{2}",,"\hat{x}_{0}=f_{\theta}(x_{t}, t)",where \(f_{\theta}\) is a neural network parameterized by \(\theta\) that predicts the original (denoised) sample \(\mathbf{x}_{0}\) from the noisy input \(\mathbf{x}_{t}\) and timestep \(t\)
ICLR_2024_oral_10,11,"\{\hat{R}\}_{i=1}^{N}=f_{Diffusion}(\{f_{i},u_{i},r_{i,t}\}_{i=1}^{N\cdot p^{2}},t) || r_{i,t}=\sqrt{\bar{\alpha}_{t}}r_{i}+\sqrt{1-\bar{\alpha}_{t}}\epsilon","where the noisy rays \(\mathbf{r}_{i,t}\) can be computed as:

\[\mathbf{r}_{i,t}=\sqrt{\bar{\alpha}_{t}}\mathbf{r}_{i}+\sqrt{1-\bar{\alpha}_{t}}\epsilon","\{\hat{R}\}_{i=1}^{N}=f_{Diffuser}(\{f_{i},u_{i},\tilde{R}_{i}, t\}_{i=1}^{N\cdot p^{2}})","where \(\tilde{\mathcal{R}}_{i}\) are the noisy rays at timestep \(t\), and \(f_{\text{Diffuser}}\) is the denoising network conditioned on features, pixel coordinates, noisy rays, and time embedding."
ICLR_2024_oral_11,1,"O_{ij}=\sum_{v=1}^{k}I[y_{ij}\neq y_{ij}^{(v)}],\forall j\in Y_{i}",where \(\mathbb{I}[\cdot]\) is the indicator function and \(y_{ij}\) is the \(j\)-th candidate label of \(\mathbf{x}_{i}\),O_{ij}=\sum_{l=1}^{k}I\left[ y_{ij}\notin Y_{i}^{(l)}\right],$O_{ij}$ denotes the number of times the $j$-th candidate label $y_{ij}$ of instance $\mathbf{x}_i$ does not appear in the candidate label sets $Y_{i}^{(l)}$ of its $k$-nearest neighbors.
ICLR_2024_oral_11,2,\gamma_{i}=\lceil\tau(|Y_{i}|-1)\rceil,where \(\lceil\cdot\rceil\) is the ceiling function that returns the least integer greater than or equal to the given number,r_{i}=\sum_{j\in Y_{i}}I[O_{ij}\geq\tau],The number of eliminated candidate labels for instance \(\mathbf{x}_{i}\) is the count of its candidate labels whose \(O_{ij}\) exceeds the pruning threshold \(\tau\).
ICLR_2024_oral_11,3,\widetilde{Y}_{i}=Top-\gamma_{i}-argmax_{j\in Y_{i}}(O_{ij}),where \(\mathrm{Top}\text{-}\gamma_{i}\text{-}\mathrm{argmax}_{i}\) returns a subset of indices (i,"S_{i}=arg\,max_{\substack{A\subseteq Y_{i}\\|A|=\gamma_{i}}}\sum_{j\inA} O_{ij}",The set \(\mathcal{S}_{i}\) contains the \(\gamma_{i}\) candidate labels of instance \(\mathbf{x}_{i}\) with the highest down-voting values \(O_{ij}\).
ICLR_2024_oral_11,4,"P(O_{iy^{\prime}}^{(\xi_{i})}<O_{iy})\leq\sum_{j=1}^{k}\sum_{m=\xi_{i}} ^{|Y_{i}^{\prime}|}\binom{|Y_{i}^{\prime}|}{m}\eta^{m}(1-\eta)^{(|Y_{i}^{\prime }|-m)}b_{\delta_{k}}(k,j)",,P\left(O_{iy} > O_{iy^{\prime}}^{(|Y_{i}^{\prime}|-\gamma_{i}+1)}\right)\leq\sum_{m=0}^{k}P(O_{iy}=m)\cdotP\left(\sum_{y^{\prime}\in Y_{i}^{\prime}}I[O_{iy^{\prime}}\geq m]\geq\gamma_{i}\right),"where \(O_{iy}\) is the down-voting statistic for the true label, \(O_{iy^{\prime}}\) are the down-voting statistics for false candidate labels, and \(O_{iy^{\prime}}^{(|Y_{i}^{\prime}|-\gamma_{i}+1)}\) is the \((|Y_{i}^{\prime}|-\gamma_{i}+1)\)-th order statistic among the false candidate labels."
ICLR_2024_oral_11,5,"P(O_{iy}^{(\xi_{i}^{2})}<O_{iy})-P(O_{iy}^{(\xi_{i}^{1})}<O _{iy})\leqslant\sum_{j=1}^{k}\sum_{m=\xi_{i}^{2}}^{\xi_{i}^{1}-1}\binom{|Y^{\prime}_{i}|}{m}\eta^{m}(1-\eta)^{|Y^{\prime}_{i}|-m}b_{\delta_{k}}(k,j)",,"P(O_{iy^{\prime}}^{(\xi_{i}^{2})}<O_{iy})-P(O_{iy^{\prime}}^{(\xi_{i}^{1})}<O_{iy})\leq\sum_{j=1}^{k}\sum_{m=\xi_{i}^{1}}^{\xi_{i}^{2}-1}\binom{|Y_{i}^{\prime}|}{m}\eta^{m} (1-\eta)^{(|Y_{i}^{\prime}|-m)} b_{\delta_{k}}(k,j)",where \(\xi_{i}^{1} = (|Y_{i}^{\prime}|-\gamma_{i}^{1}+1)\) and \(\xi_{i}^{2} = (|Y_{i}^{\prime}|-\gamma_{i}^{2}+1)\).
ICLR_2024_oral_13,1,"q(x_{t}|x_{t-1})=N(x_{t};\sqrt{1-\beta_{t}}x_{t},\beta_{t}I ),\quadfor t\in\{1,...,T\}","where \(\beta_{t}\in(0,1)\) is the scheduled variance at step \(t\)",q(x_{1:T}\mid x_{0})=\prod_{t=1}^{T} q(x_{t}\mid x_{t-1}),The joint distribution of the forward diffusion process is given by the product of conditional Gaussians at each timestep.
ICLR_2024_oral_13,2,x_{t}=\sqrt{\bar{\alpha}_{t}}x_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,"where, \(\bar{\alpha}_{t}=\prod_{i=1}^{t}(1-\beta_{t})\)","q(x_{t}|x_{0})=N\left(x_{t};\sqrt{\bar{\alpha}_{t}} x_{0}, (1-\bar{\alpha}_{t})I\right)",where \(\bar{\alpha}_{t} = \prod_{s=1}^{t} (1 - \beta_{s})\) is the cumulative product of the noise schedule up to step \(t\).
ICLR_2024_oral_13,3,\hat{x}_{0}^{t}=\frac{x_{t}-\sqrt{1-\bar{\alpha}_{t}}\epsilon_{\theta}(x_{t}) }{\sqrt{\bar{\alpha}_{t}}},,"\hat{x}_{0}=\frac{x_{t}-\sqrt{1-\bar{\alpha}_{t}}\,\epsilon_{\theta}(x_{t})}{\sqrt{\bar{\alpha}_{t}}}",where \(\hat{x}_{0}\) denotes the predicted clean data sample given the noisy input \(x_{t}\) and the noise estimate \(\epsilon_{\theta}(x_{t})\).
ICLR_2024_oral_13,4,"x_{t-1}=\sqrt{\bar{\alpha}_{t-1}}\hat{x}_{0}^{t}+\sqrt{1-\Text-conditional diffusion models, such as Stable Diffusion (Rombach et al., 2022), employ classifier-free diffusion guidance (Rombach et al., 2022) to steer the sampling process. Given a text prompt\(p\), its embedding\(e_{p}=f(p)\) is computed using a pre-trained CLIP text encoder\(f(\cdot)\)(Radford et al., 2021; Cherti et al., 2023). In the reverse process, the conditional sampling adheres to Eq. (3) and Eq. (4), but the predicted noise\(\epsilon_{\theta}(x_{t})\) is changed to:\[\epsilon_{\theta}(x_{t},e_{\theta})+s(\underbrace{\epsilon_{\theta}(x_{t},e_ {p})-\epsilon_{\theta}(x_{t},e_{\theta})}_{text-conditional noise prediction})","where, \(e_{\theta}\) represents the prompt embedding of an empty string, and \(s\) determines the guidance strength, controlling the alignment of the generation to the prompt","p_{\theta}(x_{t-1}|x_{t})=N\left(x_{t-1};\mu_{\theta}(x_{t}, t),\beta_{t}I\right)","where \(\mu_{\theta}(x_{t}, t) = \frac{1}{\sqrt{1-\beta_{t}}}\left(x_{t} - \frac{\beta_{t}}{\sqrt{1-\bar{\alpha}_{t}}}\epsilon_{\theta}(x_{t})\right)\)"
ICLR_2024_oral_13,5,"d=\frac{1}{T}\sum_{t=1}^{T}\|\epsilon_{\theta}(x_{t},e_{p})-\epsilon_{\theta} (x_{t},e_{\theta})\|_{2}",,"D(p)=\frac{1}{T}\sum_{t=1}^{T}\left\|\epsilon_{\theta}(x_{t}, e_{p})-\epsilon_{\theta}(x_{t}, e_{\theta})\right\|_{2}",where \(D(p)\) denotes the average magnitude of text-conditional noise predictions across all sampling steps for prompt \(p\).
ICLR_2024_oral_13,6,"L(x_{t},e)=\|\epsilon_{\theta}(x_{t},e)-\epsilon_{\theta}(x_{t},e_{\emptyset})\|_{2}",,"\min_{e'\inR^{N\times d}}\left\|\epsilon_{\theta}(x_{t}, e')-\epsilon_{\theta}(x_{t}, e_{\theta})\right\|_{2}^{2}+\lambda\| e'-e\|_{2}^{2}","where \(e'\) is the optimized embedding, \(e\) is the original prompt embedding, \(e_{\theta}\) is the empty prompt embedding, and \(\lambda\) is a regularization parameter."
ICLR_2024_oral_13,7,"SS_{e^{i}}=\frac{1}{T}\sum_{t=1}^{T}\|\nabla_{e^{i}}L(x_{t}, e)\|_{2}",,s_{i}=\left\| e_{i}-e_{i}^{*}\right\|_{2},"where \(e_{i}\) is the original embedding of token \(i\), and \(e_{i}^{*}\) is the optimized embedding of token \(i\) after minimizing \(\mathcal{L}(x_{t},e)\) with respect to \(e_{i}\) while keeping other token embeddings fixed."
ICLR_2024_oral_14,1,"F^{*}&=\operatorname*{argmax}_{F}p(F|D _{src},D_{tgt})=\operatorname*{argmax}_{F}p(D_{src},D_{tgt}|F)\cdot p(F)\\&=\operatorname*{argmax}_{F}\{\underbrace{\log p(D_{src},D _{tgt}|F)}_{data term}+\underbrace{\log p(F)}_{prior term}\}",,"F^{*}=\arg\max_{F}\; p(F|D_{src}, D_{tgt})",The optimal correspondence field \(F^*\) is defined as the one that maximizes the posterior probability given the source and target feature descriptors.
ICLR_2024_oral_14,2,"X_{t}=\sqrt{\alpha_{t}}X_{0}+\sqrt{1-\alpha_{t}}Z,\quad Z\simN(0,I)",where \(\alpha_{t}=\prod_{i=1}^{t}(1-\beta_{i})\),"q(X_t|X_{t-1})=N\left(X_t;\sqrt{1-\beta_t} X_{t-1},\beta_t I\right)",Forward diffusion transition at time step \(t\) is a Gaussian with mean \(\sqrt{1-\beta_t} X_{t-1}\) and covariance \(\beta_t I\).
ICLR_2024_oral_14,3,"X_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(X_{t},t;K)+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t}}}\Big{(}X_{t}-\sqrt{\alpha_{ t}}F_{\theta}(X_{t},t;K)\Big{)}+\sigma_{t}Z",where \(\sigma_{t}\) is the covariance value of Gaussian distribution at time step \(t\),"X_{t-1}=\mu_{\theta}(X_{t}, t)+\sigma_{\theta}(X_{t}, t) Z,\quad Z\simN(0, I)","where \(\mu_{\theta}(X_{t}, t)\) and \(\sigma_{\theta}(X_{t}, t)\) are the mean and standard deviation predicted by the diffusion model at time step \(t\), and \(Z\) is standard Gaussian noise."
ICLR_2024_oral_14,4,"F^{*}=F_{\theta}(D_{src},D_{tgt})\approx\underset{F }{argmax}\\underbrace{\log p(D_{src},D_{tgt}|F)}_{data term}","where \(\mathcal{F}_{\theta}(\cdot)\) and \(\theta\) represent a feed-forward network and its parameters, respectively","F^{*}=F_{\theta}(F_{init}, C^{l})",where \(\mathcal{F}_{\theta}\) is the conditional diffusion-based network that estimates the dense correspondence field \(F^{*}\) given the initial correspondence \(F_{\text{init}}\) and the local matching cost \(C^{l}\).
ICLR_2024_oral_14,5,"F^{*}=F_{\theta}(D_{src},D_{tgt})\approx\underset{F}{argmax}\p(F|D_{src},D_{tgt}) || =\underset{F}{argmax}\{\underbrace{\log p(D_{ src},D_{tgt}|F)}_{data term}+\underbrace{\log p(F)}_{prior term}\}",,"F^{*}=\underset{F}{argmax}\\log p(F|D_{src}, D_{tgt})",where \(F^{*}\) is the correspondence field that maximizes the posterior probability given source and target descriptors.
ICLR_2024_oral_14,6,"F_{t}=\sqrt{\alpha_{t}}F_{0}+\sqrt{1-\alpha_{t}}Z,\quad Z\simN(0,I)",where \(F_{0}\) is the ground-truth correspondence,"F_{t}=\sqrt{\alpha_{t}} F_{0}+\sqrt{1-\alpha_{t}} Z,\quad Z\simN(0, I)",where \(F_{0}\) is the ground-truth correspondence field and \(\alpha_{t} = \prod_{i=1}^{t}(1-\beta_{i})\).
ICLR_2024_oral_14,7,"F_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(X_{t},t;D_{src},D_{tgt})+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t }}}\Big{(}X_{t}-\sqrt{\alpha_{t}}F_{\theta}(F_{t},t;D_{src },D_{tgt})\Big{)}+\sigma_{t}Z","where \(\mathcal{F}_{\theta}(F_{t},t;D_{\mathrm{src}},D_{\mathrm{tgt}})\) directly predicts the denoised correspondence \(\hat{F}_{0,t}\) with source and target features, \(D_{\mathrm{src}}\) and \(D_{\mathrm{tgt}}\), as conditions","F_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(F_{t}, t; K)+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t}}}\left(F_{t}-\sqrt{\alpha_{t}}F_{\theta}(F_{t}, t; K)\right)+\sigma_{t}Z","where \(\sigma_{t}\) is the covariance value at time step \(t\) and \(K\) denotes the conditioning information (e.g., initial correspondence and local matching cost)."
ICLR_2024_oral_14,8,"C(i,j)=\frac{D_{src}(i)\cdot D_{tgt}(j)}{\|D_{src}(i)\|\|D_{tgt}(j)\|}","where \(i\in[0,h_{\text{src}})\times[0,w_{\text{src}})\), \(j\in[0,h_{\text{tgt}})\times[0,w_{\text{tgt}})\), and \(\|\cdot\|\) denotes \(l\)-2 normalization",C_{ij}=\frac{D_{src}(i)\cdot D_{tgt}(j)}{\|D_{src}(i)\|_2\|D_{tgt}(j)\|_2},\(C_{ij}\) denotes the cosine similarity-based matching cost between the \(i\)-th source and \(j\)-th target feature descriptors.
ICLR_2024_oral_14,9,"L=E_{F_{0},t,Z\simN(0,I),D_{src},D_{tgt}}[\|F_{0}-F_{\theta}(F_{t},t;F_{init },C^{l})\|^{2}]",,"L_{diff}=E_{F_{0}, Z, t}\left[\left\|Z-F_{\theta}\left(F_{t}, t; F_{init}, C^{l}\right)\right\|^{2}\right]","where \(Z\) is the Gaussian noise added in the forward process, and \(\mathcal{F}_{\theta}\) predicts the noise given the noised correspondence \(F_{t}\), timestep \(t\), initial correspondence \(F_{\mathrm{init}}\), and local matching cost \(C^{l}\)."
ICLR_2024_oral_15,1,"\nabla_{\Theta}L_{SDS}=E_{t,p,\epsilon}[w(t)(\epsilon_{\phi}(I_{RGB}^{p};t,\tilde{I}_{RGB}^{r},\Delta p)-\epsilon)\frac{\partial I_{RGB}^{p}}{\partial\Theta}]","where \(w(t)\) is a weighting function, \(\epsilon_{\phi}(\cdot)\) is the predicted noise by the 2D diffusion prior \(\phi\), and \(\Delta p\) is the relative camera pose change from the reference camera \(r\)","L_{SDS}=E_{p, t,\epsilon}\left[\left\|\phi\left(I_{RGB}^{p}+w(t)\epsilon, t\right)-\phi\left(\tilde{I}_{RGB}^{r}, t\right)\right\|_2^2\right]","SDS loss measures the squared distance between diffusion model features of the noisy rendered image and the reference image, averaged over camera poses, timesteps, and noise."
ICLR_2024_oral_15,2,L_{Ref}=\lambda_{RGB} || I_{RGB}^{r}-\tilde{I}_ {RGB}^{r} || _{2}^{2}+\lambda_{A} || I_{A}^{r}-\tilde{I}_{A}^{r} || _{2}^{2},where \(\lambda_{\text{RGB}}\) and \(\lambda_{\text{A}}\) are the weights which are linearly increased during training,L_{ref}=\lambda_{RGB}\| I_{RGB}^{r}-\tilde{I}_{RGB}^{r}\|_2^2+\lambda_{A}\| I_{A}^{r}-\tilde{I}_{A}^{r}\|_2^2,"where \(\lambda_{\text{RGB}}\) and \(\lambda_{\text{A}}\) are weighting coefficients for the RGB and alpha (transparency) losses, respectively."
ICLR_2024_oral_15,3,"\nabla_{\Theta}L_{SDS}=E_{t,p,\epsilon}[w(t)(\epsilon_{\phi}(I_{RGB}^{p};t,e)-\epsilon)\frac{\partial I_{RGB }^{p}}{\partial\Theta}]",where \(e\) is the CLIP embeddings of the input text description,"\nabla_{\Theta}L_{SDS}^{text}=E_{t,p,\epsilon}\left[w(t)\left(\epsilon_{\phi}(I_{RGB}^{p}; t,text, p)-\epsilon\right)\frac{\partial I_{RGB}^{p}}{\partial\Theta}\right]",where the text prompt replaces the reference image as the conditioning input to the diffusion prior.
ICLR_2024_oral_15,4,d(x)=\sum_{i}\alpha_{i}\exp(-\frac{1}{2}(x-x_{i})^ {T}\Sigma_{i}^{-1}(x-x_{i})),where \(\Sigma_{i}\) is the covariance matrix built from scaling \(\mathbf{s}_{i}\) and rotation \(\mathbf{q}_{i}\),"D(x)=\sum_{i=1}^{N}\alpha_{i}\cdotN(x\midx_{i},\Sigma_{i})","$D(\mathbf{x})$ is the spatial density at position $\mathbf{x}$, computed as the sum of weighted opacities $\alpha_{i}$ of all Gaussians, where each Gaussian is centered at $\mathbf{x}_{i}$ with covariance $\Sigma_{i}$."
ICLR_2024_oral_15,5,"I^{p}_{fine}=f_{\phi}(I^{p}_{coarse}+\epsilon(t_{start}) ;t_{start},c)","where \(\epsilon(t_{\text{start}})\) is a random noise at timestep \(t_{\text{start}}\), \(c\) is \(\Delta p\) for image-to-3D and \(e\) for text-to-3D respectively","I^{p}_{refined}=f_{\phi}(I^{p}_{coarse}+\epsilon; t,\tilde{I}_{RGB}^{r},\Delta p)","where \(f_{\phi}(\cdot)\) denotes the multi-step denoising process by the 2D diffusion prior, \(\epsilon\) is random noise, \(t\) is the timestep, \(\tilde{I}_{\text{RGB}}^{r}\) is the reference RGB image, and \(\Delta p\) is the relative camera pose."
ICLR_2024_oral_15,6,L_{MSE}= || I^{p}_{fine}-I^{p}_{coarse} || ^{2}_{2},,L_{MSE}=E_{p}\left[\left\|I^{p}_{fine}-I^{p}_{UV}\right\|_{2}^{2}\right],where \(I^{p}_{\text{UV}}\) is the rendered image from the current UV-space texture at camera view \(p\)
ICLR_2024_oral_16,1,"H(x_{t})=\{{cc}\max\{H(\hat{x}_{t}),R_{t}(s_{t},a_{t })\},&if\ || \hat{x}_{t}-x_{t} || _{2}<\delta\\R_{t}(s_{t},a_{t}),&otherwise\","where \(R_{t}(s_{t},\mathbf{a_{t}})\) is the return of a given \((s_{t},\mathbf{a_{t}})\); \(\delta\) is a threshold value of state-embedding difference; and \(\hat{x}_{t}=f_{\phi}(\hat{s}_{t})\) is \(x_{t}=f_{\phi}(s_{t})\)'s nearest neighbor in \(\mathcal{D}_{E}\)","H(x_{t})\leftarrow\max\left( H(x_{t}),\; G_{t}\right)",The episodic memory buffer updates the stored highest return for state embedding \(x_t\) by taking the maximum between the current stored value \(H(x_t)\) and the newly observed return \(G_t\).
ICLR_2024_oral_16,2,"Q_{EC}(f_{\phi}(s_{t}),a_{t})=r_{t}(s_{t},a_{t})+\gamma H(f_{\phi}(s_ {t+1}))",,"Q_{EC}(f_{\phi}(s_{t}),a_{t})=H(x_{t})","where \(Q_{EC}(f_{\phi}(s_{t}),\mathbf{a_{t}})\) is the episodic memory-based Q-value for state \(s_{t}\) and action \(\mathbf{a_{t}}\), and \(H(x_{t})\) is the highest return stored for the projected state \(x_{t}\)."
ICLR_2024_oral_16,3,"L_{\theta}^{EC}=(y(s,a)-Q_{tot}(s,a;\theta))^{2}+\lambda(Q_{EC}(f_{\phi}(s),a)-Q_{tot}(s,a;\theta))^{2}","where \(y(s,\mathbf{a})\) is one-step TD target; \(Q_{tot}\) is the joint Q-value function parameterized by \(\theta\); and \(\lambda\) is a scale factor","L_{\theta}^{EC}=\lambda\left(Q_{\theta}(f_{\phi}(s_{t}),a_{t})-Q_{EC}(f_{\phi}(s_{t}),a_{t})\right)^2+(1-\lambda)\left(Q_{\theta}(f_{\phi}(s_{t}),a_{t})-y_{t}\right)^2","where \(\lambda\) is a weighting coefficient, \(Q_{\theta}\) is the parameterized Q-function, \(Q_{EC}\) is the episodic control target, and \(y_{t}\) is the standard one-step TD target."
ICLR_2024_oral_16,4,"L(\phi,\psi)=(H_{t}-f_{\psi}(f_{\phi}(s_{t})))^ {2}",,"L_{EmbNet}=E_{(s_{t}, H_{t})\simD_{E}}\left[\left( f_{\psi}(f_{\phi}(s_{t}))-H_{t}\right)^{2}\right]","The EmbNet loss \(\mathcal{L}_{\text{EmbNet}}\) is the expected squared error between the predicted highest return from the embedding and the true highest return, over samples from the episodic memory buffer \(\mathcal{D}_{E}\)."
ICLR_2024_oral_16,5,"L(\phi,\psi)=(H_{t}-f_{\psi}^{H}(f_{\phi}(s_{t}|t)|t ))^{2}+\lambda_{rcon} || s_{t}-f_{\psi}^{s}(f_{\phi}(s_{t}|t)|t) || _{2}^{2}",where \(f_{\psi}^{H}\) predicts the highest return; \(f_{\psi}^{s}\) reconstructs \(s_{t}\); \(\lambda_{rcon}\) is a scale factor,"L_{dCAE}=\| s_{t}-f_{\omega}(f_{\phi}(s_{t}), t)\|_{2}^{2}",where \(f_{\omega}\) is the decoder network that reconstructs the state \(s_{t}\) from its embedding \(f_{\phi}(s_{t})\) and timestep \(t\).
ICLR_2024_oral_16,6,"\eta^{*}(s^{\prime}):=V^{*}(s^{\prime})-\max_{a^{\prime}}\!Q_{\theta^{-}} (s^{\prime},a^{\prime})",,"\eta^{*}(s^{\prime}) :=V^{*}(s^{\prime})-\max_{a^{\prime}} Q_{\theta^{-}}(s^{\prime},a^{\prime})","\(\eta^{*}(s^{\prime})\) is the difference between the true value \(V^{*}(s^{\prime})\) and the predicted value via the target network \(\max_{\mathbf{a}^{\prime}} Q_{\theta^{-}}(s^{\prime}, \mathbf{a}^{\prime})\)."
ICLR_2024_oral_16,7,"r^{p}=\gamma\hat{\eta}(s^{\prime})=\gammaE_{\pi_{\theta}}[\eta(s^{\prime})]\simeq\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}\eta_{\max}(s^{\prime})=\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}(H(f_ {\phi}(s^{\prime}))-\max_{a^{\prime}}\!Q_{\theta^{-}}(s^{\prime},a^{\prime}))",where \(N_{call}(s^{\prime})\) is the number of visits on \(\hat{x}^{\prime}=\mathrm{NN}(f_{\phi}(s^{\prime}))\in\mathcal{D}_{E}\); and \(N_{\xi}\) is the number of desirable transition from \(\hat{x}^{\prime}\),"r^{p}(s,a,s^{\prime})=\gamma\,\xi(s^{\prime})\,\hat{\eta}(s^{\prime})",where \(\xi(s^{\prime})\) is the desirability indicator for \(s^{\prime}\); \(\hat{\eta}(s^{\prime})\) is the estimated value gap; and \(\gamma\) is the discount factor.
ICLR_2024_oral_16,8,"L_{\theta}^{p}=(r(s,a)+r^{p}+\gamma\!\max_{a^{\prime}}\!Q_{\theta^{-} }(s^{\prime},a^{\prime})-Q_{\theta}(s,a))^{2}",,"L_{\theta}^{p}=(y(s,a)+r^{p}-Q_{tot}(s,a;\theta))^{2}",where \(r^{p}\) is the episodic incentive reward defined in Eq. 7.
ICLR_2024_oral_16,9,"\nabla_{\theta}L_{\theta}^{p}=-2\nabla_{\theta}Q_{\theta}(s,a)(\Delta\varepsilon _{TD}+r^{p})=-2\nabla_{\theta}Q_{\theta}(s,a)(\Delta\varepsilon_{TD}+\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}\eta_{\max}(s^{\prime}))",,"\nabla_{\theta}L_{\theta}^{p}=2\left(r(s,a)+r^{p}+\gamma\!\max_{a^{\prime}}\!Q_{\theta^{-}}(s^{\prime},a^{\prime})-Q_{\theta}(s,a)\right)\left(-\nabla_{\theta}Q_{\theta}(s,a)\right)","The gradient of the loss \(L_{\theta}^{p}\) with respect to \(\theta\) is proportional to the TD error, scaled by the negative gradient of the Q-function."
ICLR_2024_oral_16,10,"L_{\theta}^{p}=(r(s,a)+r^{p}+\beta_{c}r^{c}+\gamma max_{a^{\prime}}Q_{tot}(s^{\prime},a^{\prime};\theta^{-})-Q_{tot}(s,a;\theta))^{2}",where \(\beta_{c}\) is a scale factor,"L_{\theta}^{final}=\left(r(s,a)+r^{p}+r^{c}+\gamma\!\max_{a^{\prime}}\!Q_{\theta^{-}}(s^{\prime},a^{\prime})-Q_{\theta}(s,a)\right)^{2}","The final loss function incorporates the environment reward \(r\), episodic incentive \(r^{p}\), intrinsic reward \(r^{c}\), and the target Q-value for policy learning."
ICLR_2024_oral_21,1,"g(G)=\operatorname*{arg\,max}_{c\in\{1,2,\cdots,C\}}N_{c}",where a label with a smaller index is taken by our ensemble classifier when there are ties,"g(G)=\arg\max_{c\in\{1,2,\cdots,C\}} N_c",The ensemble graph classifier \(g\) predicts the class with the highest number of sub-graph votes.
ICLR_2024_oral_21,2,"N_{c}-M\leq N_{c}^{p}\leq N_{c}+M,\,\forall c\in\{1,2,\cdots,C\}",,N_{l}^{p}\geq N_{l}-M,The number of sub-graphs predicted as class \(l\) after perturbation is at least the original number minus the number of corrupted sub-graphs.
ICLR_2024_oral_21,3,"M\leq M^{p}=\lfloor\frac{N_{l}-\max_{c\in\{1,2,\cdots,C\}\setminus\{l\}}(N_{c }-I(l<c))}{2}\rfloor",,"M <\frac{1}{2}\left( N_{l}-\max_{c\in\{1,2,\cdots,C\}\setminus\{l\}}\left( N_{c}-I(l < c)\right)\right)","where \(M\) is the number of corrupted sub-graphs, \(N_{l}\) is the number of sub-graphs predicted as label \(l\), and the right-hand side quantifies the robustness margin required for the ensemble classifier to maintain its prediction under perturbations."
ICLR_2024_oral_23,1,"p_{\sigma}(y)=\int p(y|x)\,p(x)\,dx=\int g_{\sigma}(y-x)\,p(x)\,dx",where \(g_{\sigma}(z)\) is the density of \(z\),p_{\sigma}(y)=\int p(y|x) p(x) dx,The density of noisy images \(p_{\sigma}(y)\) is obtained by marginalizing the clean image density \(p(x)\) with the conditional noise model \(p(y|x)\).
ICLR_2024_oral_23,2,"D_{KL}(p(x)\,\|\,p_{\theta}(x))\leq\int_{0}^{\infty}E_{y}\big{[}\|\nabla\log p_{\sigma}(y)-s_{\theta}(y)\|^{2}\big{]}\,\sigma\, d\sigma",,"\int_{0}^{\infty}E_{p_{\sigma}(y)}\left[\left\| s_{\theta}(y)-\nabla\log p_{\sigma}(y)\right\|^2\right] w(\sigma)\,d\sigma","The integrated score-matching loss measures the expected squared error between the learned score function \(s_{\theta}(y)\) and the true score \(\nabla \log p_{\sigma}(y)\), averaged over all noise levels \(\sigma\) with weighting function \(w(\sigma)\)."
ICLR_2024_oral_23,3,"\nabla\log p_{\sigma}(y)=(\mathop{E}_{x}[x\,|\,y]-y)/\sigma^{2}",,\nabla\log p_{\sigma}(y)=\frac{1}{\sigma^{2}}\left(E[x|y]-y\right),"The score of the noisy density at \(y\) equals the posterior mean of \(x\) given \(y\), minus \(y\), divided by \(\sigma^2\)."
ICLR_2024_oral_23,4,"MSE(f_{\theta},\sigma^{2})=\mathop{E}_{x,y}\Bigl{[}\|x-f_{\theta}(y)\|^{2}\Bigr{]}",,"E_{x,z}\left[\|f_{\theta}(x+z)-x\|^{2}\right]",where \(f_{\theta}(y)\) is the denoiser network trained to predict the clean image \(x\) from the noisy observation \(y=x+z\)
ICLR_2024_oral_23,5,"D_{KL}(p(x)\ || \,p_{\theta}(x))\leq\int_{0}^{\infty}\Bigl{(} MSE(f_{\theta},\sigma^{2})-MSE(f^{\star},\sigma^{2})\Bigr{)}\,\sigma^{-3}\,d\sigma","where \(f^{\star}(y)=\mathop{\mathbb{E}}_{x}[x\,|\,y]\) is the optimal denoiser","D_{KL}(p(x)\,\|\,p_{\theta}(x))\leq\int_{0}^{\infty}E_{y}\Bigl{[}\|f_{\theta}(y)-E_{x}[x\,|\,y]\|^{2}\Bigr{]}\,\frac{1}{\sigma^{2}}\,\sigma\,d\sigma","The KL divergence between the true and model densities is bounded by the integrated mean squared error of the denoiser, weighted by \(1/\sigma^{2}\)."
ICLR_2024_oral_23,6,"f(y)=\nabla f(y)\,y=\sum_{k}\lambda_{k}(y)\langle y,e_{k}(y)\rangle e_{ k}(y)",,"f(y)=\sum_{k=1}^{d}\lambda_{k}(y)\,\langle e_{k}(y), y\rangle\, e_{k}(y)","where \(\lambda_{k}(y)\) and \(e_{k}(y)\) are the eigenvalues and eigenvectors of the Jacobian \(\nabla f(y)\), respectively."
ICLR_2024_oral_23,7,"MSE(f,\sigma^{2})=\mathop{E}_{y}\![2\sigma^{2}\, tr\,\nabla f(y)+\|y-f(y)\|^{2}-\sigma^{2}d]",,"MSE(f,\sigma^{2})=E_{y}\left[\|f(y)-y\|^{2}+2\sigma^{2}tr(\nabla f(y))-d\sigma^{2}\right]","where \(\operatorname{tr}(\nabla f(y))\) is the trace of the Jacobian of \(f\) at \(y\), and \(d\) is the dimensionality of \(y\)"
ICLR_2024_oral_23,8,"f^{\star}(y)=y+\sigma^{2}\nabla\log p_{\sigma}(y)=\operatorname*{E}_{ x}[x|y] || \nabla f^{\star}(y)=Id+\sigma^{2}\nabla^{2}\log p_{\sigma}(y)=\sigma^ {-2}Cov[x\,|\,y]",,"f^{\star}(y)=E_{x}[x\,|\,y],\qquad\nabla f^{\star}(y)=\frac{1}{\sigma^{2}}\,Cov[x\,|\,y]","The optimal denoiser is the posterior mean, and its Jacobian is the posterior covariance scaled by \(1/\sigma^2\)."
ICLR_2024_oral_23,9,"MSE(f^{\star},\sigma^{2})=\operatorname*{E}_{y}[tr \,Cov[x\,|\,y]]=\sigma^{2}\operatorname*{E}_{y}\bigl{[}tr\,\nabla f^{\star}(y)\bigr{]}=\sigma^{2}\operatorname*{E} _{y}\biggl{[}\sum_{k}\lambda_{k}^{\star}(y)\biggr{]}",,"MSE(f^{\star},\sigma^{2})=E_{y}\!\left[tr\,Cov[x\,|\,y]\right]=E_{y}\!\left[\sum_{k}\lambda_{k}^{\star}(y)\right]","where \(\lambda_{k}^{\star}(y)\) are the eigenvalues of the posterior covariance matrix \(\mathrm{Cov}[x\,|\,y]\)"
ICLR_2024_oral_23,10,"\operatorname*{E}_{x}\biggl{[}\sum_{k}\Bigl{(}(1-\lambda_{k}(x))^{2}\langle x,e_{k}\rangle^{2}+\lambda_{k}(x)^{2}\sigma^{2}\Bigr{)}\biggr{]}",,"MSE_{oracle}(\sigma^{2})=E_{x,z}\left[\sum_{k=1}^{d}\frac{\sigma^{2}}{\sigma^{2}+\langle x, e_k\rangle^2}\, z_k^2\right]","The oracle denoising error in a fixed basis, where \(z_k = \langle z, e_k \rangle\) are the noise coefficients."
ICLR_2024_oral_23,11,"\sigma^{2}{\sum_{k}\lambda_{k}(x)}=\sum_{k}\frac{\sigma^{2}\langle x,e_{k}\rangle^{2}}{\langle x,e_{k}\rangle^{2}+\sigma^{2}}\sim\sum_{k}\min(\langle x,e_{k}\rangle^{2},\sigma^{2})=M\sigma^{2}+\|x-x_{M}\|^{2}","where \(x_{M}=\sum_{\langle x,e_{k}\rangle^{2}>\sigma^{2}}\langle x,e_{k}\rangle\,e_{k}\) is the \(M\)-term approximation of \(x\) with the \(M\) basis coefficients \(\langle x,e_{k}\rangle\) above the noise level, and \(\sim\) means that the two terms are of the same order up to multiplicative constants (here smaller than 2)","\operatorname*{E}_{x}\biggl{[}\sum_{k}\frac{\langle x,e_{k}\rangle^{2}\sigma^{2}}{\langle x,e_{k}\rangle^{2}+\sigma^{2}}\biggr{]}",the oracle denoising error in a fixed basis with optimal shrinkage factors
ICLR_2024_oral_23,12,M\sigma^{2}+\|x-x_{M}\|^{2}\sim\sigma^{2\alpha/(\alpha+1)},,\|x-x_{M}\|^{2}\sim\sigma^{2}M\sim\sigma^{\frac{2\alpha}{\alpha+1}},"The oracle denoising error decays as a power law in the noise level, determined by the coefficient decay rate \(\alpha\)."
ICLR_2024_oral_24,1,dx_{t}=f_{t}(x_{t})dt+g(t)d w_{t}\quadx_{0}\sim p_{data}(x),,"dx_t=f(x_t, t)\,dt+g(t)\,dw_t","The stochastic differential equation (SDE) governing the evolution of the data sample \(\mathbf{x}_t\) in the diffusion model, where \(f\) is the drift, \(g\) is the diffusion coefficient, and \(\mathbf{w}_t\) is a Wiener process."
ICLR_2024_oral_24,2,"dx_{t}=[f_{t}(x_{t})-g_{t}^{2}\nabla_{ x}\log p(x_{t},t)]dt+g(t)dw_{t},\quadx_{1}\simN(0,I_{d})","where \(p(\cdot,t)\) is the marginal density of (1) at time \(t\) and \(\nabla_{\mathbf{x}}\log p_{t}\) is known as the score function",dx_{t}=\left[f_{t}(x_{t})-g(t)^{2}\nabla_{x_{t}}\log p_{t}(x_{t})\right]dt+g(t)d\overline{w}_{t},"The time-reversed SDE for the diffusion model, where \(\overline{\mathbf{w}}_{t}\) denotes a standard Wiener process in the reverse time direction."
ICLR_2024_oral_24,3,"dx_{t}=[f_{t}(x_{t})-\frac{1}{2}g_{t}^{2}\nabla_{x}\log p(x_{t},t)]dt,\quad x_{1}\simN(0,I_{d})",,"\frac{dx_{t}}{dt}=f_{t}(x_{t})-g_{t}^{2}\nabla_{x}\log p(x_{t}, t)","The corresponding ODE for the time-reversed SDE, sharing the same path-wise measure, with drift adjusted by the score function."
ICLR_2024_oral_24,4,"dx_{t}=v_{t}(x,t)dt+g_{t}dw_{t}\quad s.t.\quad(x_{0},x_{1})\sim\Pi_{0,1}(x_ {0},x_{1}):=p_{0}\times p_{1}",,"dx_{t}=f_{t}(x_{t})dt+g_{t}dw_{t},\quadx_{0}\sim p_{0}(x),\x_{1}\sim p_{1}(x)",A general SDE describing a bridge process that connects two distributions \(p_{0}\) and \(p_{1}\) via drift \(f_{t}\) and diffusion \(g_{t}\).
ICLR_2024_oral_24,5,"\min_{a_{t}}\int_{\tau}^{1}\lVerta_{t}\rVert_{2}^{2}dt+(m_{1}-m_{1})^{T} R(m_{1}-m_{1})& s.t\underbrace{dx_{t}\\dv_{t}}_{dm_{t}}&=v_{t}\\a_{t}(x_{t},v_{t},t)dt+\underbrace{0&0\\0&g_{t}}_{g_{t}}dw_{t},\\m_{\tau}:=x_{\tau}\\v_{\tau}&=x_{\tau}\\v_{\tau},&R=r&0\\0&r\otimesI_{d},&x_{1}\sim p_{data}",,"&\min_{u_{t}}\E\left[\int_{0}^{1}\frac{1}{2}\|u_{t}\|^{2}dt\right]\\&subject to:\\&\quaddx_{t}=v_{t}dt,\\&\quaddv_{t}=u_{t}dt+g_{t}dw_{t},\\&\quad (x_{0},v_{0})\sim p_{0}(x,v),\quad (x_{1},v_{1})\sim p_{1}(x,v)","The stochastic optimal control (SOC) bridge problem in phase space seeks a control process \(\mathbf{u}_{t}\) minimizing the expected quadratic control cost, subject to linear momentum dynamics with initial and terminal joint distributions \(p_{0}\) and \(p_{1}\)."
ICLR_2024_oral_24,6,"a^{*}(m_{t},t)=g_{t}^{2}P_{11}(\frac{x_{1}-x_{t}}{1-t}-v_{t})\quadwhere:\quad P_{11}=\frac{-4}{g_{t}^{2}(t-1)}",,v_{1}^{*}=\frac{x_{1}-x_{t}}{1-t},The optimal terminal velocity is given by the linear interpolation between the current state \(\mathbf{x}_{t}\) and the target \(\mathbf{x}_{1}\).
ICLR_2024_oral_24,7,"dx_{t}\\dv_{t}=v_{t}\\F_{t}dt+0&0\\0&h_{t}dw_{t}\quads.t\quadm_{0}:=x_{0}\\v_{0}\simN(\mu_{0},\Sigma_{0}) || Bridge Matching SDE:F_{t}:=F_{t}^{b}(m_{t},t)\equiva_{t}^{*}(m_{t},t), h(t):=g(t) || Probabilistic ODE:F_{t}:=F_{t}^{p}(m_{t},t)\equiva_{t}^{*}(m_{t},t)-\frac{1}{2}g_{t}^{2 }\nabla_{v}\log p(m,t), h(t):=0",,"SDE:\quad &a^{*}(m_{t},t)=g_{t}^{2}P_{11}\left(\frac{x_{1}-x_{t}}{1-t}-v_{t}\right)\\ODE:\quad &a^{*}(m_{t},t)=g_{t}^{2}P_{11}\left(\frac{x_{1}-x_{t}}{1-t}-v_{t}\right)+g_{t}^{2}\nabla_{v}\log p(m_{t},t)","The force (acceleration) term for the SDE is the optimal control from Equation 6, while for the ODE it additionally includes a score term involving the gradient of the log-density with respect to velocity."
ICLR_2024_oral_24,8,"m_{t}=\mu_{t}+L_{t}\epsilon=\mu_{t}+L_{t}^{xx}\epsilon_{0}\\L_{t}^{xv}\epsilon_{0}+L_{t}^{vv}\epsilon_{1},\nabla_{v}\log p_{t}:=-\ell_{t}\epsilon_{1}","where \(\boldsymbol{\Sigma}_{t}=\mathbf{L}_{t}\mathbf{L}_{t}^{\mathsf{T}}\), \(\epsilon=\begin{bmatrix}\boldsymbol{\epsilon}_{0}\\ \boldsymbol{\epsilon}_{1}\end{bmatrix}\sim\mathcal{N}(\mathbf{0},\mathbf{I}_{2d})\) and \(\ell_{t}=\sqrt{\frac{\Sigma_{t}^{xx}}{\Sigma_{t}^{xx}\Sigma_{t}^{xx}-(\Sigma _{t}^{xx})^{2}}}\)","m_{t}=\mu_{t}+L_{t}\epsilon,\quad\epsilon\simN(0,I_{2d})","where \(\mathbf{L}_{t}\) is the Cholesky factor of \(\boldsymbol{\Sigma}_{t}\) such that \(\boldsymbol{\Sigma}_{t} = \mathbf{L}_{t} \mathbf{L}_{t}^{\top}\), and \(\boldsymbol{\epsilon}\) is a standard normal random vector."
ICLR_2024_oral_24,9,"a^{*}(m_{t},t)=4x_{1}(1-t)^{2}-g_{t}^{2}P_{11}[ (\frac{L_{t}^{xx}}{1-t}+L_{t}^{xv})\epsilon_{0}+L_{t}^{vv}\epsilon_{1}]",,F_{t}=\alpha_{t}x_{1}+\beta_{t}\epsilon_{1},"where \(\alpha_{t}\) and \(\beta_{t}\) are time-dependent coefficients, \(\mathbf{x}_{1}\) is the target data point, and \(\boldsymbol{\epsilon}_{1}\sim\mathcal{N}(\mathbf{0},\mathbf{I}_{d})\) is standard Gaussian noise."
ICLR_2024_oral_24,10,"\min_{\theta}E_{t\in[0,1]}E_{x_{1}\sim p_{ data}}E_{m_{t}\sim p_{t}(m_{t}|x_{1})}\lambda(t)[\|F_{t}^{\theta}(m_{t},t;\theta)-F _{t}(m_{t},t)\|_{2}^{2}]",Where \(\lambda(t)\) is known as the reweight of the objective function across the time horizon,"L_{force}(\theta)=E_{m_{t}, t}\left\|F_{t}^{\theta}(m_{t}, t;\theta)-F_{t}(m_{t}, t)\right\|_{2}^{2}",where \(\mathbf{F}_{t}^{\theta}\) is the neural network output and \(\mathbf{F}_{t}\) is the target force term.
ICLR_2024_oral_24,11,"x_{t_{i+1}}\\v_{t_{i+1}}=\Phi(t_{i+1},t_{i})x _{t}\\v_{t}+\sum_{j=0}^{w}\int_{t_{i}}^{t_{i+1} }(t_{i+1}-\tau)z_{\tau}\cdotM_{i,j}(\tau) d\tau\s_{t}^{\theta}(m_{t_{i-j}},t_{i-j}))\\\int_{t_{i}}^{t_{i+1}}z_{\tau}\cdotM_{i,j}(\tau) d\tau\cdots_{t}^{\theta}(m_{t_{i-j}},t_{i-j})",,x_{t+\delta}\\v_{t+\delta}=x_{t}\\v_{t}+\frac{1-e^{-\delta}}{1} & 1-e^{-\delta}\\0 & e^{-\delta}v_{t}\\F_{t}^{\theta}\end{latex> <description>where\(\delta\) is the integration step size and the exponential integrator allows simultaneous update of both position and velocity using the learned force term.</description>,where \(\delta\) is the integration step size and the exponential integrator allows simultaneous update of both position and velocity using the learned force term.
ICLR_2024_oral_24,12,"\tilde{x}_{1}^{SDE}=\frac{(1-t)(F_{t}^{\theta}+v_{t })}{g_{t}^{2}P_{11}}+x_{t}, or \quad\tilde{x}_{1}^{ODE}=\frac{F_{t}^{\theta}+g_{t}^{2}P_{ 11}(\alpha_{t}x_{t}+\beta_{t}v_{t})}{4(t-1)^{2}+g_{t}^{2}P_{ 11}(\alpha_{t}\mu_{t}^{x}+\beta_{t}\mu_{t}^{v})}",,"\tilde{x}_{1}=x_{t}+(1-t)v_{t}+\frac{(1-t)^{2}}{4}F_{t}^{\theta}(m_{t}, t)","where \(\tilde{\mathbf{x}}_{1}\) is the estimated data point at time \(t\), \(\mathbf{x}_{t}\) and \(\mathbf{v}_{t}\) are the current state and velocity, and \(\mathbf{F}_{t}^{\theta}\) is the trained force term."
ICLR_2024_oral_25,1,"\underbrace{\nu(x)>0,\\\forall x\inInterior(M_{o})}_{Case 1: inside the open surface},\quad\underbrace{\nu(x)=0,\\\forall x\in\partialM_{o}}_{Case 2: on the surface boundary},\quad\underbrace{\nu(x)<0,\\Otherwise}_{ Case 3: outside the open surface}",where \(\nu\) can be instantiated as the signed geodesic distance to the open surface boundary living on the watertight template,M_{o}=\left\{x\inM\mid\nu(x) > 0\right\},The open surface \(\mathcal{M}_{o}\) is defined as the set of points on the template sphere \(\mathcal{M}\) where the mapping \(\nu(\mathbf{x})\) is positive.
ICLR_2024_oral_25,2,L_{mSDF-reg}(\theta_{mSDF})=\underbrace{\sum_{u:v_{\theta_{ ndSF}}(u)\geq 0}L_{nuber}(v_{\theta_{noster}}(u))}_{ Encourage hole opening}+\underbrace{\tau\cdot\sum_{{c}u^{\prime}:v_{\theta_{ ndSF}}(u^{\prime})=0\\u^{\prime} visible from some q\in Q}L_{nuber}(v_{\theta_{n ober}}(u^{\prime})-\epsilon)}_{Regularize holes from being too large},,"L_{hole}=E_{x\simM}\left[\max\left(0,\epsilon-|\nu_\theta(x)|\right)\right]","The hole-opening loss \(\mathcal{L}_{\text{hole}}\) encourages the mSDF values \(\nu_\theta(x)\) on the template manifold \(\mathcal{M}\) to have a magnitude at least \(\epsilon\), promoting clear separation between open surface and boundary regions."
ICLR_2024_oral_25,3,"u^{\prime}=\frac{|\nu_{1}|}{|\nu_{1}-\nu_{2}|}\cdot u_{2}-\frac{|\nu_{2}|}{|\nu_{1}-\nu_{2}|}\cdot u_{1},\quad\nu_{1}<0<\nu_{2}",,\nu^{\prime}=\frac{s_{i}\nu_{j}-s_{j}\nu_{i}}{s_{i}-s_{j}},"The interpolated mSDF value \(\nu^{\prime}\) at a mesh vertex extracted along edge \((p_{i}, p_{j})\), where \(s_{i}\) and \(s_{j}\) are SDF values and \(\nu_{i}\), \(\nu_{j}\) are mSDF values at the edge endpoints."
ICLR_2024_oral_26,1,E=({cccc}W^{(l)\top}&W^{(2)\top}&W^{(l)\top}&W^{(l)\top}\\\hline\ddots&W^{(2)\top}&W^{(2)\top}&W ^{(l)\top}\\),where \(\mathbf{\mathrm{W}}^{(l)\top}\) denotes the transposed weight matrix,"V_{i} &=b^{(l)}_{i} &if node  i is in layer  l\\0 &otherwise\\E_{ij} &=W^{(l)}_{ij} &if node  i in layer  l-1,\, j in layer  l\\0 &otherwise","\(\mathbf{V}_{i}\) assigns the bias of node \(i\) as its node feature, and \(\mathbf{E}_{ij}\) assigns the weight connecting node \(i\) in layer \(l-1\) to node \(j\) in layer \(l\) as the edge feature."
ICLR_2024_oral_26,2,"V_{probe}=\Big{(}x,\alpha\Big{(}W^{(1)}x+b^{(1)}\Big{)},f(x)\Big{)}^{\top}",,"V_{probe}=f(x)=W^{(2)}\,\alpha\big(W^{(1)}x+b^{(1)}\big)+b^{(2)}","\(\mathbf{V}_{\text{probe}}\) denotes the probe node feature, i.e., the output of the neural network for a specific input \(\mathbf{x}\)."
ICLR_2024_oral_26,3,"e_{ij}^{(k+1)}=\phi_{e}^{(k+1)}\Big{(}\Big{[}v_{i}^{(k)},e_{ij}^{(k)},v_{j}^{(k)}\Big{]}\Big{)}",where \(k\) is the layer index in our network,"E^{(k+1)}_{ij}=\phi_{e}\left(E^{(k)}_{ij},\,V^{(k)}_i,\,V^{(k)}_j\right)",The updated edge features at layer \(k+1\) are computed by applying a neural network \(\phi_{e}\) to the current edge features and the features of the sender and receiver nodes.
ICLR_2024_oral_26,4,"m_{ij}=\phi_{scale}(e_{ij})\odot\phi_{m}([v_ {i},v_{j}])+\phi_{shift}(e_{ij})",,m_{ij}^{(k+1)}=\gamma_{e}^{(k+1)}\left(e_{ij}^{(k+1)}\right)\odotv_i^{(k)}+\beta_{e}^{(k+1)}\left(e_{ij}^{(k+1)}\right),"where \(\gamma_{e}^{(k+1)}\) and \(\beta_{e}^{(k+1)}\) are FiLM functions applied to the updated edge features, and \(\odot\) denotes elementwise multiplication."
ICLR_2024_oral_26,5,v_{ij}=(W_{scale}^{value}e_{ij} )\odot(W_{n}^{value}v_{j})+ W_{shift}^{value}e_{ij},,"V_{ij}=\phi_{scale}(e_{ij})\odot\phi_{V}([v_i,v_j])+\phi_{shift}(e_{ij})","where \(\mathbf{V}_{ij}\) is the updated value in the self-attention module for node pair \((i, j)\), incorporating multiplicative and additive modulation by edge features."
ICLR_2024_oral_27,1,\sum_{i=1}^{N_{k}}W(A_{i}^{k})=W(\bigcup_{i=1}^{N_{k}}A_{i}^{k})=W(A^{0}),,W(A^0)=\sum_{n=1}^{N_k} W(A_n^k),The white Gaussian noise over the entire pixel \(A^0\) is equal to the sum of the white Gaussian noise over its \(N_k\) sub-pixels \(A_n^k\).
ICLR_2024_oral_27,2,"(W(A^{k})|W(A^{0})=x)\simN(\bar{\mu},\bar{\Sigma}),\quadwith \bar{\mu}=\frac{x}{N_{k}}u,\bar{\Sigma}=\frac{1}{N_{k}} (I_{N_{k}}-\frac{1}{N_{k}}uu^{\top})","where \(\mathbf{u}=(1,\ldots,1)^{\top}\)","\left(W(A^{k})\mid W(A^{0})=x\right)\simN\left(\frac{x}{N_{k}}1,\,\nu_{k}\left(I-\frac{1}{N_{k}}11^{\top}\right)\right)",The conditional distribution of the sub-pixel white noise values given the total pixel value is a multivariate normal with mean proportional to the observed sum and a covariance reflecting the constraint.
ICLR_2024_oral_27,3,"(W(A^{k})|W(A^{0})=x)=\bar{\mu}+UZ=\frac{x}{N_{k}} u+\frac{1}{\sqrt{N_{k}}}(Z-\langle Z\rangleu),\quadwith Z\sim(0,I)",where \(\langle Z\rangle\) is the mean of \(Z\),"W(A^{k})=\frac{x}{N_{k}}u+Uz,\quadz\simN(0,I_{N_{k}})",where \(\mathbf{z}\) is a standard normal random vector and \(\mathbf{U} = \sqrt{N_{k}}\mathbf{\bar{\Sigma}}\) is the square root of the conditional covariance.
ICLR_2024_oral_27,4,T(W)(A)=\int_{x\in A}\frac{1}{|\nablaT(T^{-1}(x))|^{\frac{1}{2}}}W(T^{-1}(x))\dx,where \(\left|\nabla\mathcal{T}\right|\) is the determinant of the Jacobian of \(\mathcal{T}\),T(W)(A)=\int_{T^{-1}(A)} dW(x),"where \(\mathcal{T}(W)(A)\) is the transported noise over set \(A\), and the integral is taken over the preimage \(\mathcal{T}^{-1}(A)\) with respect to the white noise measure \(dW(x)\)."
ICLR_2024_oral_27,5,G(p)=\frac{1}{\sqrt{|\Omega_{p}|}}\sum_{A_{s}^{k}\in\Omega_ {p}}W_{k}(A_{s}^{k})\,,\hat{W}_{T}(p)=\frac{1}{|S_{p}|}\sum_{i\inS_{p}} W(A^{k})_i,where \(\mathcal{S}_{\mathbf{p}}\) is the set of sub-pixels in \(\mathbb{A}^{k}\) covered by the warped polygon corresponding to pixel \(\mathbf{p}\)
ICLR_2024_oral_27,6,"z_{i}=\alpha x_{i-1}+(1-\alpha)x_{i},\quad z_{i}\simN(0,\,\sigma_{z }^{2}),\quadwith \sigma_{z}^{2}=\alpha^{2}+(1-\alpha)^{2}",,z_{i}=(1-\alpha)x_{i}+\alpha x_{i+1},where \(z_{i}\) is the linearly interpolated value between \(x_{i}\) and \(x_{i+1}\) with interpolation parameter \(\alpha\).
ICLR_2024_oral_27,7,"z_{i}|x_{i},x_{i-1}\simN(\mu_{\infty},\sigma_{\infty}^{2}),\quadwith \{{l}\mu_{\infty}=\alpha x_{i-1}+(1-\alpha)x_{i}\\\sigma_{\infty}^{2}=1-(\alpha^{2}+(1-\alpha)^{2})=1-\sigma_{z}^{2}",,"z\simN(\alpha x_{i-1}+(1-\alpha)x_{i},\\alpha(1-\alpha))",where \(z\) is a Brownian bridge sample between \(x_{i-1}\) and \(x_{i}\) with mean \(\alpha x_{i-1} + (1-\alpha)x_{i}\) and variance \(\alpha(1-\alpha)\).
ICLR_2024_oral_28,1,\lVertA\hat{x}^{\star}-b\rVert_{2}^{2}\leq(1+\epsilon)\lVertAx^{\star}-b\rVert_{2}^{2},,\lVertA\hat{x}^{\star}-b\rVert_{2}^{2}\leq (1+\epsilon)\lVertAx^{\star}-b\rVert_{2}^{2}+\delta,"The learned parameters \(\hat{\mathbf{x}}^{\star}\) achieve \(\ell_2\) loss close to the optimal loss, up to a multiplicative \((1+\epsilon)\) and additive \(\delta\) factor."
ICLR_2024_oral_28,2,\tau_{i}=\|u_{i}\|_{2}^{2}=a_{i}^{T}(A^{T} A)^{-1}a_{i}=\max_{x\inR^{d}}(a_{i}^{T}x)^{2}/\|Ax\|_{2}^{2},,\tau_{i}=a_{i} (A^{\top}A)^{+}a_{i}^{\top}=\lVertu_{i}\rVert_{2}^{2},"\(\tau_{i}\) is the leverage score of the \(i\)-th row of \(\mathbf{A}\), measuring the influence of that row in the least squares fit."
ICLR_2024_oral_28,3,\|A\tilde{x}^{*}-b\|_{2}^{2}\leq(1+\epsilon)\|Ax^{*}-b\|_{2}^{2},,\|A\tilde{x}^{*}-b\|_{2}^{2}\leq (1+\epsilon)\|Ax^{\star}-b\|_{2}^{2},The squared error of the fitted model using the sampled data is at most a factor \((1+\epsilon)\) larger than the optimal squared error achievable with all data.
ICLR_2024_oral_28,4,\|\tilde{p}-b\|_{2}^{2}\leq(1+\epsilon)\underset{degree d polynomial p}{\min}\|p-b\|_{2}^{2},,\int_{\ell}^{u} (b(x)-\tilde{p}(x))^{2} dx\leq (1+\epsilon)\cdot\min_{p\inP_d}\int_{\ell}^{u} (b(x)-p(x))^{2} dx,"The squared \(L_2\) error of the fitted polynomial \(\tilde{p}\) over \([\ell, u]\) is at most \((1+\epsilon)\) times the minimum possible squared \(L_2\) error achievable by any degree \(d\) polynomial."
ICLR_2024_oral_28,5,"I_{\mu}^{S}(i,j)=\Pr_{\mu}[\xi_{j}=1|\xi_{i}=1\wedge\xi_{\ell}=1\forall\ell\inS]-\Pr_{\mu}[\xi_{j}=1|\xi_{\ell}=1\forall\ell\inS]",,"\left(I_{\mu}^{S}\right)_{ij}=P_{\mu}\left[\xi_j=1\mid\xi_i=1,\{\xi_\ell=0\}_{\ell\inS}\right]-P_{\mu}\left[\xi_j=1\mid\{\xi_\ell=0\}_{\ell\inS}\right]","The \((i,j)\)-th entry of the one-sided influence matrix \(\mathcal{I}_{\mu}^{\mathcal{S}}\) quantifies the change in the probability that index \(j\) is selected, conditioned on index \(i\) being selected and all indices in \(\mathcal{S}\) not being selected, relative to the probability that \(j\) is selected conditioned only on \(\mathcal{S}\) not being selected."
ICLR_2024_oral_29,1,"\frac{dx}{d\sigma}=-\sigma\nabla_{x}\log p _{\sigma}(x)\quad\sigma\in[\sigma_{min},\sigma_{max}]",where the term \(\nabla_{\mathbf{x}}\log p_{\sigma}(\mathbf{x})\) is known as the _score function_ of \(p_{\sigma}(\mathbf{x})\)(Song et al,"\frac{dx}{d t}=f(x, t)","The probability flow ODE describes the time evolution of the variable \(\mathbf{x}\) under the vector field \(\mathbf{f}(\mathbf{x}, t)\)."
ICLR_2024_oral_29,2,"f_{\theta}(x,\sigma)=c_{skip}(\sigma)x+c_{out}(\sigma)F_{\theta}(x,\sigma)","where \(\mathbf{F}_{\mathbf{\theta}}(\mathbf{x},\sigma)\) is a free-form neural network, while \(c_{\text{skip}}(\sigma)\) and \(c_{\text{out}}(\sigma)\) are differentiable functions such that \(c_{\text{skip}}(\sigma_{\text{min}})=1\) and \(c_{\text{out}}(\sigma_{\text{min}})=0\)","f_{\theta}(x,\sigma)=x+(\sigma-\sigma_{min})\,g_{\theta}(x,\sigma)",The consistency model is parameterized as the input plus a scaled neural network output to satisfy the boundary condition at \(\sigma_{\text{min}}\).
ICLR_2024_oral_29,3,"L^{N}(\theta,\theta^{-})=E[\lambda(\sigma_{i} )d(f_{\theta}(x_{\sigma_{i+1}},\sigma_{i+1}),f_{\theta}_{-}(\tilde{x}_{\sigma_{i}},\sigma_{i}))]",where \(\tilde{\mathbf{x}}_{\sigma_{i}}=\mathbf{x}_{\sigma_{i+1}}-(\sigma_{i}-\sigma_{ i+1})\sigma_{i+1}\nabla_{\mathbf{x}}\log p_{\sigma_{i+1}}(\mathbf{x})|_{\mathbf{x}= \mathbf{x}_{\sigma_{i+1}}}\),"L_{CM}(\theta)=E_{i,\,x,\,z}\left[\left\|f_{\theta}(x+\sigma_{i}z,\sigma_{i})-f_{\theta}(x+\sigma_{i+1}z,\sigma_{i+1})\right\|_{2}^{2}\right]",The consistency matching loss encourages the outputs of the consistency model at adjacent noise levels to be close for the same underlying data point and noise realization.
ICLR_2024_oral_29,4,\theta^{-}arrowstopgrad(\mu\theta^{-}+(1-\mu)\theta),,\theta^{-}\leftarrow\alpha\theta^{-}+(1-\alpha)\theta,The teacher network parameters \(\mathbf{\theta}^{-}\) are updated as an exponential moving average of the student parameters \(\mathbf{\theta}\) with decay rate \(\alpha\).
ICLR_2024_oral_29,5,"L_{CT}^{N}(\theta,\theta^{-})=E[\lambda(\sigma_{i})d(f_{\theta}(x+\sigma_{i+1}z,\sigma_ {i+1}),f_{\theta^{-}}(x+\sigma_{i}z,\sigma_{i}))]",,"L^{N}_{CT}(\theta,\theta^{-})=E\left[\lambda(\sigma_{i})\, d\left(f_{\theta}(x_{\sigma_{i+1}},\sigma_{i+1}),\,f_{\theta^{-}}(x_{\sigma_{i}},\sigma_{i})\right)\right]","where \(\mathbf{x}_{\sigma_{i+1}} = \mathbf{x} + \sigma_{i+1}\mathbf{z}\), \(\mathbf{x}_{\sigma_{i}} = \mathbf{x} + \sigma_{i}\mathbf{z}\), with \(\mathbf{x} \sim p_{\text{data}}(\mathbf{x})\) and \(\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})\)."
ICLR_2024_oral_29,6,"\lim_{N\to\infty}L^{N}(\theta,\theta^{-})=\lim_{N\to\infty}L^{N}_{CT}(\theta,\theta^{-})=E\Big{[}\big{(} 1-\frac{\sigma_{min}}{\sigma_{i}}\big{)}^{2}(\theta-\theta^{-})^{2}\Big{]}\quadif\theta^{-}\neq\theta || \lim_{N\to\infty}\frac{1}{\Delta\sigma}\frac{d L^{N}(\theta,\theta^{-})}{d\theta}=\{{ll}\frac{dL}{d\theta}E\Big{[}\frac{\sigma_ {min}}{\sigma_{i}^{2}}\Big{(}1-\frac{\sigma_{min}}{\sigma_{i}}\Big{)}(\theta-\xi)^{2}\Big{]},&\theta^{-}=\theta\\+\infty,&\theta^{-}\prec\theta\\-\infty,&\theta^{-}>\theta",,"\lim_{N\to\infty}L^{N}(\theta,\theta^{-})=E_{z\simN(0,1)}\left[(\theta-\theta^{-})^2\right]",The limiting value of the consistency matching objective as \(N\to\infty\) equals the expected squared difference between the student and teacher parameters when they are not equal.
ICLR_2024_oral_29,7,"d(x,y)=\sqrt{\lVertx-y\rVert_{2}^{2}+c^{2}}-c",,"d(x,y)=\sqrt{\|x-y\|_2^2+c^2}-c","The Pseudo-Huber metric function, where \(c > 0\) is a small constant controlling the smoothness near zero."
ICLR_2024_oral_29,8,"N(k)=\min(s_{0}2^{\lfloor\frac{1}{N}\rfloor},s_{1})+1,\quad K^{\prime}=\Big{|}\frac{K}{\log_{2}[s_{1}/s_{0}]+1}\Big{|}",,"N(k)=\min\left(s_0\cdot 2^{\frac{k}{K}},\, s_1\right)+1","where \(N(k)\) is the number of discretization steps at training step \(k\), \(s_0\) and \(s_1\) are hyperparameters controlling the minimum and maximum number of steps, and \(K\) is the total number of training iterations."
ICLR_2024_oral_3,1,"\theta^{*}\in\operatorname*{arg\,min}_{\theta\inR^{d}}f(\theta),\\\where f(\theta)\triangleqE_{X\sim\mu}[F(\theta,X) ]=\sum_{i\inN}\mu_{i}F(\theta,i)",,\min_{x\inR^d} f(x)=E_{\xi\simD} [F(x;\xi)],"$f(x)$ is the expected value of the loss function $F(x; \xi)$ over the data distribution $\mathcal{D}$, where $x$ is the parameter vector to be optimized."
ICLR_2024_oral_3,2,"\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{n+1}),\\\\forall\n\geq 0","where, roughly speaking, \(H(\mathbf{\theta},i)\) contains gradient information \(\nabla_{\mathbf{\theta}}F(\theta,i)\), such that \(\mathbf{\theta}^{*}\) solves \(\mathbf{h}(\mathbf{\theta})\triangleq\mathbb{E}_{X\sim\mathbf{\mu}}[H(\mathbf{\theta},X)]= \sum_{i\in\mathcal{N}}\mu_{i}H(\mathbf{\theta},i)=\mathbf{0}\)","\theta_{n+1}=\theta_n-\beta_n\nabla F(\theta_n, X_n)","Here, \(\mathbf{\theta}_{n}\) denotes the parameter vector at iteration \(n\), \(\beta_{n}\) is the step size, and \(\nabla F(\mathbf{\theta}_n, X_n)\) is the stochastic gradient evaluated at \(\mathbf{\theta}_n\) and sample \(X_n\)."
ICLR_2024_oral_3,3,"K_{ij}[x]\triangleq\frac{P_{ij}(x_{j}/\mu_{j})^{-\alpha}}{\sum_{k\inN}P_{ik}(x_{k}/\mu_{k})^{-\alpha}},\quad\quad\forall\,i,j\in N",,"K[x](i,j)\triangleq\frac{P(i,j)\,\exp\left(-\alpha\,\frac{x(j)}{\mu(j)}\right)}{\sum_{k\inN}P(i,k)\,\exp\left(-\alpha\,\frac{x(k)}{\mu(k)}\right)}","The non-linear transition kernel \(\mathbf{K}[\mathbf{x}]\) defines the probability of transitioning from node \(i\) to node \(j\) as a function of the current empirical distribution \(\mathbf{x}\), the base Markov kernel \(\mathbf{P}\), the target distribution \(\mathbf{\mu}\), and the self-repellence parameter \(\alpha>0\)."
ICLR_2024_oral_3,4,"Draw:\qquad X_{n+1}\simK_{X_{n},\cdot}[x_{n}]",,"\theta_{n+1}=\theta_{n}+\beta_{n+1} H(\theta_{n}, X_{n+1}),\quad X_{n+1}\simK[x_n](X_n,\cdot),\quadx_n=\frac{1}{n+1}\sum_{k=0}^n\delta_{X_k}","The SA-SRRW algorithm updates the parameter vector \(\mathbf{\theta}_{n}\) using stochastic approximation with noise sequence \(\{X_n\}\) generated by the self-repellent random walk transition kernel \(\mathbf{K}[\mathbf{x}_n]\), where \(\mathbf{x}_n\) is the empirical distribution of visited nodes up to time \(n\)."
ICLR_2024_oral_3,5,"\quadx_{n+1}=x_{n}+\gamma_{n+1}(\delta_{X_{n+1}}-x_{n}) || \quad\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{ n+1})",,"\theta_{n+1}=\theta_{n}+\beta_{n+1} H(\theta_{n}, X_{n+1})",The parameter vector is updated using the stochastic approximation step with the new sample \(X_{n+1}\) drawn from the SRRW kernel.
ICLR_2024_oral_3,6,"\theta_{n}\xrightarrow[n\to\infty]{a.s.}\theta^{*}\quadand\quad(\theta_{n}-\theta^{*})/\sqrt{\beta_{n}}\xrightarrow[n\to\infty]{dist.}N(0,V_{\theta}^{(k)}(\alpha))",,"\sqrt{\gamma_{n}^{-1}}x_{n}-\mu\\\theta_{n}-\theta^{*}\xrightarrow{d}N\left(0,\Sigma^{(k)}(\alpha)\right)","As \(n\to\infty\), the scaled joint error vector of the empirical distribution and optimization iterates converges in distribution to a normal distribution with zero mean and asymptotic covariance matrix \(\mathbf{\Sigma}^{(k)}(\alpha)\) depending on the timescale regime \(k\) and the SRRW parameter \(\alpha\)."
ICLR_2024_oral_3,7,"x_{n}=\frac{\sum_{i=1}^{n}\omega_{i}\theta_{X_{i}}+\omega_{0}x_{0}}{\sum_{i=0}^{n}\omega_{i}},\\where\\\omega_{0}=1,\\and\\\omega_{n}=\frac{\gamma_{n}}{\prod_{i=1}^{n}(1-\gamma_{i})}",,x_{n}=\frac{\sum_{k=0}^{n}\gamma_{k}\delta_{X_{k}}}{\sum_{k=0}^{n}\gamma_{k}},"The iterate $\mathbf{x}_{n}$ is the weighted empirical measure of the states $\{X_{k}\}_{k=0}^{n}$, with weights given by the step sizes $\gamma_{k}$."
ICLR_2024_oral_3,8,"x_{n}\xrightarrow[n\to\infty]{a.s.}\mu,\quadand\quad\gamma_{n}^{-1/2}(x_{n}-\mu)\xrightarrow[n\to\infty]{dist.}N(0,V_{x}(\alpha)) || where\quadV_{x}(\alpha)=\sum_{i=1}^{N-1 }\frac{1}{2\alpha(1+\lambda_{i})+2-\mathds{1}_{\{a=1\}}}\cdot\frac{1+\lambda_ {i}}{1-\lambda_{i}}u_{i}u_{i}^{T}",,"x_{n}\xrightarrow[n\to\infty]{a.s.}\mu,\qquadand\qquad\frac{x_{n}-\mu}{\sqrt{\gamma_n}}\xrightarrow[n\to\infty]{dist.} N(0,V_{x}(\alpha))","The weighted empirical measure sequence \(\mathbf{x}_n\) converges almost surely to the target distribution \(\boldsymbol{\mu}\), and its normalized error converges in distribution to a normal distribution with zero mean and covariance \(\mathbf{V}_{\mathbf{x}}(\alpha)\)."
ICLR_2024_oral_3,9,\tfrac{d}{dt}z(t)=g(z(t))\triangleqH(\theta(t))^{T}\pi[x(t)]\\\pi[x(t)]-x(t)\inR^{D+N},"where matrix \(\mathbf{H}(\boldsymbol{\theta})\triangleq[H(\boldsymbol{\theta},1),\cdot,H( \boldsymbol{\theta},N)]^{T}\in\mathbb{R}^{N\times D}\) for any \(\boldsymbol{\theta}\in\mathbb{R}^{D}\)",\frac{d}{dt}\theta(t)\\x(t)=h(\theta(t))\\\mu-x(t),The coupled mean-field ODE describing the limiting dynamics of the optimization variable \(\boldsymbol{\theta}(t)\) and the empirical distribution \(\mathbf{x}(t)\).
ICLR_2024_oral_3,10,J(\alpha)\!\triangleq\!\nabla g(z^{*})\!=\!\nablah(\theta^{*})&-\alphaH(\theta^{*})^{T}(P^{T}\!+\mathds{I})\\0_{N\!\times\!D}&2\alpha\mu\mathds{1}^{T}\!-\!\alpha\mathds{P}^{T}\!\!-\!(\alpha\!+\!1)\mathds{I}\!\triangleq\!J_{11}&J_{12}(\alpha)\\J_{21}&J_{22}(\alpha),,J(\alpha)\triangleq\nablah(\theta^*) &H(\theta^*)^T\nabla_{x}\pi[\mu]\\0 &-I\inR^{(D+N)\times (D+N)},"where \(\mathbf{J}(\alpha)\) is the Jacobian of the mean-field ODE at equilibrium, with \(\nabla \mathbf{h}(\boldsymbol{\theta}^*)\) the Jacobian of the mean field, \(\mathbf{H}(\boldsymbol{\theta}^*)\) as defined above, \(\nabla_{\mathbf{x}} \boldsymbol{\pi}[\boldsymbol{\mu}]\) the Jacobian of the stationary distribution of the SRRW kernel with respect to \(\mathbf{x}\), and \(\mathbf{I}\) the \(N \times N\) identity matrix."
ICLR_2024_oral_3,11,"\beta_{n}^{-1/2}(\theta_{n}-\theta^{*} )\\\gamma_{n}^{-1/2}(x_{n}-\mu)\xrightarrow[n\to\infty]{ait.}N(0,V^{(k)}(\alpha))",,"\sqrt{\beta_n}^{-1}\theta_n-\theta^*\\x_n-\mu\xrightarrow[n\to\infty]{dist.} N\left(0,V^{(k)}(\alpha)\right)","where \(\mathbf{V}^{(k)}(\alpha)\) is the asymptotic covariance matrix for the joint fluctuations of the optimization error and empirical measure, under step size regime \(k\) and self-repellence parameter \(\alpha\)."
ICLR_2024_oral_3,12,U\triangleq\sum_{i=1}^{N-1}\frac{1+\lambda_{i}}{1-\lambda_{i}}\cdotH^{T}u_{i}u_{i}^{T}H&H^{T}u_{i}u_{i}^{T}\\u_{i}u_{i}^{T}H&u_{i}u_{i}^{T}\triangleqU_{11}&U_{12}\\U_{21}&U_{22},,"U\triangleqE_{i\sim\mu}[H(\theta^*,i)H(\theta^*,i)^{T}] &0_{D\times N}\\0_{N\times D} &diag(\mu)-\mu\mu^T","where \(\mathbf{U}\) is the block covariance matrix of the noise terms in the joint CLT, with the upper-left block corresponding to the covariance of \(H(\boldsymbol{\theta}^*,i)\) under \(\boldsymbol{\mu}\), and the lower-right block to the covariance of the empirical measure."
ICLR_2024_oral_3,13,V^{(k)}(\alpha)=V^{(k)}_{\theta }(\alpha)&0_{D\times\!N}\\0_{N\!\times\!D}&V_{x}(\alpha),,V^{(k)}(\alpha)=V_{\theta}^{(k)}(\alpha) &0\\0 &V_{x}(\alpha),"where \(\mathbf{V}_{\boldsymbol{\theta}}^{(k)}(\alpha)\) and \(\mathbf{V}_{\mathbf{x}}(\alpha)\) are the asymptotic covariance matrices for the optimization and sampling components, respectively, in cases \(k=1,3\)."
ICLR_2024_oral_31,1,P(z;H)=\mathds{1}(H(z)<\bar{H}),where \(\bar{\mathcal{H}}\) is a threshold and \(\mathds{1}(\cdot)\) is indicator function,P(z;H)=I[H(z) <\tau],"Here, \(\mathbb{I}[\cdot]\) is the indicator function and \(\tau\) is a threshold for the score \(\mathcal{H}(z)\)."
ICLR_2024_oral_31,2,P_{t}(z)=P(z;H_{t}),,"P_t(z;H_t)\in\{0,1\}",The dynamic pruning probability \(\mathcal{P}_t(z;\mathcal{H}_t)\) at step \(t\) is a binary value depending on the current score \(\mathcal{H}_t\).
ICLR_2024_oral_31,3,"P_{t}(z)=r,&H_{t}(z)<\bar{H}_{t}\\0,&H_{t}(z)\geq\bar{H}_{t}","where \(\bar{\mathcal{H}}_{t}\) is the mean value of all the scores \(\mathcal{H}_{t}\) and \(r\in(0,1)\) is a predefined hyper-parameter as the pruning probability",P_{t}(z;H_{t})=Bernoulli\left(1-\frac{H_{t}(z)}{\bar{H}_{t}}\right),"where \(\mathcal{P}_{t}(z;\mathcal{H}_{t})\) is the random pruning indicator for sample \(z\) at epoch \(t\), \(\mathcal{H}_{t}(z)\) is the score of sample \(z\) at epoch \(t\), and \(\bar{\mathcal{H}}_{t}\) is the adaptive threshold."
ICLR_2024_oral_31,4,"H_{t+1}(z)=H_{t}(z),&z\inD\backslashS_{t}\\L(z),&z\inS_{t}",,"H_{t+1}(z)=L(z), &if  z is not pruned at epoch  t\\H_{t}(z), &if  z is pruned at epoch  t",where \(\mathcal{L}(z)\) is the loss value of sample \(z\) in the current epoch and \(\mathcal{H}_{t}(z)\) is the previous score.
ICLR_2024_oral_31,5,"\operatorname*{arg\,min}_{\theta\in\Theta}\mathop{E}_{z\inD }[L(z,\theta)]=\int_{z}L(z,\theta)\rho(z)dz",,E_{z\sim\rho(z)}[L(z)],where \(\mathcal{L}(z)\) is the loss for sample \(z\) and \(\rho(z)\) is the data distribution.
ICLR_2024_oral_31,6,"\operatorname*{arg\,min}_{\theta\in\Theta}\mathop{E}_{z\inS _{t}}[\gamma_{t}(z)L(z,\theta)]=\operatorname*{arg\,min}_{\theta\in\Theta}\frac{1}{c_{t}}\int_{z}L(z,\theta)\rho(z)dz","where \(c_{t}=\mathbb{E}_{z\sim\rho}[1-\mathcal{P}_{t}(z)]=\int_{z}\rho(z)(1-\mathcal{ P}_{t}(z))dz\), \(c_{t}\in(0,1)\) is a constant for temporal status \(t\)","\operatorname*{arg\,min}_{\theta\in\Theta}\int_{z}\gamma_{t}(z)L(z,\theta)(1-P_{t}(z))\rho(z)dz",where \(\gamma_{t}(z)=1/(1-\mathcal{P}_{t}(z))\) is the rescaling factor applied to each sample's loss after pruning.
ICLR_2024_oral_31,7,\frac{1}{c_{t}}=\frac{|D|}{|\sum_{z\inD}(1-P_{t}( z))|}\simeq\frac{|D|}{|S_{t}|}\RightarrowE[\nabla_{\theta}L(S_{t})]\simeq\frac{|D|}{|S_{t}|}\mathop{E}[\nabla_{\theta}L(D)],,|S_{t}|=\sum_{z\inD} (1-P_{t}(z)),The number of samples in the pruned dataset \(\mathcal{S}_{t}\) is the sum over all original samples of their retention probabilities.
ICLR_2024_oral_31,8,"P_{t}(z)=r,&H_{t}(z)<\tilde{H}_{t}\wedge t<\delta\cdot C\\0,&H_{t}(z)\geq\tilde{H}_{t}\lor t\geq\delta\cdot C",,"S_{t}=InfoBatch-pruned dataset, & t <\delta\cdot C\\D, & t\geq\delta\cdot C","where \(\mathcal{S}_{t}\) is the training set at epoch \(t\), \(\delta\) is the annealing ratio, and \(C\) is the total number of epochs."
ICLR_2024_oral_32,1,"sim(I,t)=\langle M_{image}(I),M_{text}(t)\rangle/( || M_{image}(I) || _{2} || M_{text}(t) || _{2})",,"sim(I, t)=\frac{M_{image}(I)\cdot M_{text}(t)}{\|M_{image}(I)\|\|M_{text}(t)\|}",Cosine similarity between the image and text embeddings produced by their respective encoders.
ICLR_2024_oral_32,2,M_{image}(I)=PViT(I),,"M_{image}(I)=P\,ViT(I)",The CLIP image representation is obtained by applying a linear projection matrix \(P\) to the output of the vision transformer \(\text{ViT}(I)\).
ICLR_2024_oral_32,3,"\hat{Z}^{l}=MSA^{l}(Z^{l-1})+Z^{l-1},\quad Z^{l}=MLP^{l}(\hat{ Z}^{l})+\hat{Z}^{l}",,Z^{\ell+1} &=Z^{\ell}+MSA(Z^{\ell})\\Z^{\ell+1} &=Z^{\ell+1}+MLP(Z^{\ell+1}),"At each layer \(\ell\), the token matrix \(Z^\ell\) is updated by adding the outputs of a multi-head self-attention (MSA) block and then an MLP block, each applied in a residual fashion."
ICLR_2024_oral_32,4,M_{image}(I)=PViT(I)=P[Z^{0}]_{cls}+\underbrace{\sum_{ l=1}^{L}P[MSA^{l}(Z^{l-1})]_{cls}}_{MSA\terms}+\underbrace{\sum_{l=1}^{L}P[MLP^{l}(\hat{Z}^{l}) ]_{cls}}_{MLP\perms},,M_{image}(I)=P\left( [Z^0]_{cls}+\sum_{l=1}^L\left( [MLP^l(MSA^l([Z^{l-1}]_{cls})+[Z^{l-1}]_{cls})]+[MSA^l([Z^{l-1}]_{cls})]\right)\right),The image representation \(M_{\text{image}}(I)\) is expressed as a linear projection of the sum of the initial class token and the layerwise contributions from each MSA and MLP block in the ViT.
ICLR_2024_oral_32,5,"[MSA^{l}(Z^{l-1})]_{cls}=\sum_{h=1}^{H}\sum_{i=0}^{N}x_{i} ^{l,h},\\\x_{i}^{l,h}=\alpha_{i}^{l,h}W_{VO}^{l,h}z_{i}^{l-1}","where \(W_{VO}^{l,h}\in\mathbb{R}^{d\times d}\) are transition matrices and \(\alpha_{i}^{l,h}\in\mathbb{R}\) are the attention weights from the class token to the \(i\)-th token (\(\sum_{i=0}^{N}\alpha_{i}^{l,h}=1\))","[MSA^{l}(Z^{l-1})]_{cls}=\sum_{h=1}^{H}\sum_{j=0}^{N}\alpha_{h,j}^{l} V_{h}^{l} z_{j}^{l-1}","The output at the class token from the \(l\)-th MSA layer is a sum over all attention heads and input tokens, where \(\alpha_{h,j}^{l}\) are the attention weights and \(V_{h}^{l}\) are the value projection matrices for each head."
ICLR_2024_oral_32,6,"\sum_{l=1}^{L}P[MSA^{l}(Z^{l-1})]_{cls}=\sum_{l=1}^{L}\sum_{h=1 }^{H}\sum_{i=0}^{N}c_{i,l,h},\\c_{i,l,h}=Px_{i}^{l,h}",,"\sum_{l=1}^{L}\sum_{h=1}^{H}\sum_{i=0}^{N}P x_{i}^{l,h}","The image representation is decomposed into a sum over layers, heads, and tokens, where each term is the projected contribution of a single head and token."
ICLR_2024_oral_32,7,"V_{explained}(T)=\frac{1}{K}\sum_{k=1}^{K}\| Proj_{T}(c_{k}-c_{avg})\|_{2}^{2}, where c_{avg}=\frac{1}{K}\sum_{k=1}^{K}c_{k}",,Var_{T}=\frac{1}{K}\sum_{k=1}^{K}\left\|Proj_{T}(c_k)\right\|_2^2,The variance explained by a set of text directions \(\mathcal{T}\) is the average squared norm of the projection of the head outputs \(c_k\) onto the span of \(\mathcal{T}\).
ICLR_2024_oral_35,1,P_{d}\approx 12lh^{2}+Vh\hskip 28.452756pt(1)\hskip 36.135ptP_{e}\approx(1-\rho)P_{d}+\rho(4h^{2}+8h^{2}N_{e})l,,P_{d}=12hl^{2}+13lVh,"The parameter count \(P_{d}\) of a dense LLM is calculated as a function of hidden size \(h\), number of layers \(l\), and vocabulary size \(V\)."
ICLR_2024_oral_35,2,"L(P,D)=\frac{A}{P^{\alpha}}+\frac{B}{D^{\beta}}+E\hskip 14.226378pt(3)\hskip 28.452756ptTC\approx 6PD\hskip 14.226378pt(4)\hskip 28.452756ptIC\approx 2PD\hskip 14.226378pt(5)",,L=E+A P^{-\alpha}+B D^{-\beta}\hskip 28.452756pt(3),"The test loss \(L\) is modeled as the sum of an irreducible constant \(E\) and two reducible terms that decrease as the parameter count \(P\) and dataset size \(D\) increase, with \(A\), \(B\), \(\alpha\), and \(\beta\) as fitting constants."
ICLR_2024_oral_35,3,eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n }&re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2}&re>n || eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n }&re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2}&re>n,,n=t\cdot p\cdot d,"The number of devices required for optimal hardware efficiency is the product of tensor, pipeline, and data parallelism degrees."
ICLR_2024_oral_35,4,energy_{hard}=\sum_{i\in hardware\_set}(P_{i}\cdoteff_{i}\cdot n_{i}\cdot t_{i}) || energy_{oper}=energy_{hard}\cdotPUE,,eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n} & re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2} & re>n,"Hardware efficiency \(\mathit{eff}_{re}\) as a function of the number of devices \(re\), optimal device count \(n\), and fitting constants \(\gamma_0, \gamma_1, \gamma_2\)."
ICLR_2024_oral_35,5,CO2eq_{oper}=energy_{oper}\cdot carb\_int,,energy_{oper}=energy_{hard}\cdotPUE,Total operational energy is the product of hardware energy consumption and the power usage effectiveness (PUE) of the data center.
ICLR_2024_oral_35,6,CO2eq_{emb}=\sum_{i\in hardware\_set}\frac{t_{i}\cdotCO2eq_{chip_{i}}}{lifetime_{i}},,energy_{oper}=energy_{hard}\cdotPUE,The total operational energy consumption is the product of hardware energy consumption and the data center's Power Usage Effectiveness (PUE).
ICLR_2024_oral_36,1,"\gamma,\beta=MLP^{mod}(\tilde{c}) || ModLN_{c}(f_{j})=LN(f_{j})\cdot(1+\gamma)+\beta",,ModLN_{c}(f_{j})=\gamma(\tilde{c})\odotLN(f_{j})+\beta(\tilde{c}),"The camera-modulated layer normalization function, where $\mathrm{LN}$ is layer normalization, $\gamma(\mathbf{\tilde{c}})$ and $\beta(\mathbf{\tilde{c}})$ are learned affine transformations of the camera embedding, and $\odot$ denotes element-wise multiplication."
ICLR_2024_oral_36,2,f_{j}^{cross}=CrossAttn(ModLN_{c}(f_{j}^{in});\{h_{i}\}_{i=1}^{n})+f_{j}^{in} || f_{j}^{self}=SelfAttn(ModLN_{c}(f_{j}^{cross} );\{ModLN_{c}(f_{j}^{cross})\}_{j})+f_{j}^{cross},,"f^{out}_{j}=MLP^{tfm}\left(SA\left(CA\left(ModLN_{c}(f^{in}_{j}),\{h_{i}\}_{i=1}^{n}\right)\right)\right)","The output triplane feature for the \(j\)-th entry is computed by sequentially applying camera-modulated layer normalization, cross-attention with image features, self-attention, and a transformer MLP sub-layer."
ICLR_2024_oral_36,3,f_{j}^{out}=MLP^{tfm}(ModLN_{c}(f_{j}^{self}))+f_{j}^{self},,f_{j}^{out}=MLP^{tfm}(ModLN_{c}(f_{j}^{self}))+f_{j}^{self},The output feature for the \(j\)-th triplane entry after the transformer layer is computed by applying a camera-modulated MLP to the self-attended feature and adding a residual connection.
ICLR_2024_oral_36,4,"L_{recon}(x)=\frac{1}{V}\sum_{v=1}^{V}( L_{MSE}(\hat{x}_{v},x_{v}^{GT})+\lambdaL_{LPIPS}(\hat{x}_{v},x_{v}^{GT}))","where \(\mathcal{L}_{\mathrm{MSE}}\) is the normalized pixel-wise L2 loss, \(\mathcal{L}_{\mathrm{LPIPS}}\) is the perceptual image patch similarity (Zhang et al",L_{rec}=\frac{1}{V}\sum_{v=1}^{V}\left\|\hat{x}_v-x^{GT}_v\right\|_1,The reconstruction loss \(\mathcal{L}_{\mathrm{rec}}\) is defined as the average \(\ell_1\) distance between the rendered images \(\mathbf{\hat{x}}_v\) and the ground-truth images \(\mathbf{x}^{GT}_v\) over all \(V\) views.
ICLR_2024_oral_37,1,"z_{t}=z_{0}+\int_{0}^{t}f(z_{s},s)ds","where the hidden state \(z_{t}\in\mathbb{R}^{d}\) evolves with certain dynamics characterized by a neural network \(f:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\), \(z_{0}\) is the initial state, and \(s\) represents time in integrals","\frac{dz(t)}{dt}=f(z(t), t;\theta)",The time derivative of the hidden state $\mathbf{z}(t)$ is parameterized by a neural network $f$ with parameters $\theta$.
ICLR_2024_oral_37,2,"z_{t}=z_{0}+\int_{0}^{t}f(z_{s},s)ds+\int_{0}^{t}g(z_{s},s)dB_{s}","where \(z_{t}\) is a latent state that evolves over time, \(f:\mathbb{R}^{d}\times\mathbb{R}\rightarrow\mathbb{R}^{d}\) is the drift function to capture the evolving dynamics, \(g:\mathbb{R}^{d}\times\mathbb{R}\rightarrow\mathbb{R}^{d\times\omega}\) is the diffusion function to reflect the uncertainties, and \(B_{s}\) is an \(d\)-dimensional Brownian motion (Wiener Process)","dz_{t}=f(z_{t}, t)\,dt+g(z_{t}, t)\,dw_{t}","where \(g(z_{t}, t)\) is the diffusion coefficient and \(w_{t}\) denotes a standard Wiener process (Brownian motion)."
ICLR_2024_oral_37,3,"\min_{\theta}R_{\nu}(h_{\theta})=\min_{\theta}E_{(z,y)\simD (z_{M+1:M+L},y_{M+1:M+L})}[h_{\theta}(z)\neq y]","where \(\nu\) is the distribution of the stochastic path (Boue & Dupuis, 1998) of \(\mathcal{D}\) along timestamps \(T\) to \(T+T^{*}\), \(z_{M+1:M+L}\) and \(y_{M+1:M+L}\) are short for \(z\) and \(y\) at the timestamps \(\{t_{M+1},\dots,t_{M+L}\}\), \(R_{\nu}\) is the risk of a learning model \(h_{\theta}\) parameterized by parameters \(\theta\)","\{(x_{i|M+l}, y_{i|M+l})\}_{i=1}^{N}\simD(x, y\mid t_{M+l}),\quad l=1,\dots, L","where the data of the unseen target domains at timestamps \(t_{M+l}\) are sampled from the evolving distribution \(\mathcal{D}(x, y \mid t_{M+l})\)."
ICLR_2024_oral_37,4,"\hat{z}_{i|m+1}^{k}=\underset{z_{i|m+1}^{k}=\underset{z_{i|m+1}^{k}\in S_{m+1}^{k}}{argmin}}Dist(z_{i|m}^{k},z_{j|m+1}^{k})","where \(\text{Dist}:\mathcal{Z}\times\mathcal{Z}\rightarrow[0,+\infty)\) is a distance metric defined over the embedding space, \(\mathbb{S}_{m+1}^{k}\) be the set of \(N_{B}\) data points sampled from \(\mathcal{D}_{m+1}\) (short for \(\mathcal{D}(z,y|t_{m+1})\)) with class \(y=k\in\{1,",\hat{z}_{m+1}^{k}=\arg\min_{z\inZ_{m+1}^{k}}\| z-z_{m}^{k}\|_{2},The closest sample \(\hat{z}_{m+1}^{k}\) in class \(k\) at time \(t_{m+1}\) to \(z_{m}^{k}\) at \(t_{m}\) is selected by minimizing the Euclidean distance in latent space.
ICLR_2024_oral_37,5,"\hat{z}_{i|m+\lambda}=Interp(z_{i|m}^{k},\hat{z}_{i|m+1}^{k},\lambda)=(1-\lambda)z_{i|m}^{k}+\lambda\hat{z}_{i|m+1}^{k},\forall z_{i|m}^{k}\inS_{m}^{k}","where the interpolation rate \(\lambda\in(0,1)\) is sampled from a Beta distribution \(\mathcal{B}(\beta_{1},\beta_{2})\), \(\beta_{1}\) and \(\beta_{2}\) are the parameters of the Beta distribution, and \(\mathbb{S}_{m}^{k}\) consists of instances sampled from \(k\)-th class of \(m\)-th domain","\tilde{z}_{i|m,\lambda}^{k}=(1-\lambda) z_{i|m}^{k}+\lambda\hat{z}_{i|m+1}^{k},\quad\lambda\in [0,1]","where \(\tilde{z}_{i|m,\lambda}^{k}\) denotes the interpolated latent representation for class \(k\) between domain \(m\) and \(m+1\), parameterized by interpolation coefficient \(\lambda\)."
ICLR_2024_oral_37,6,"\hat{z}_{m^{\prime}}^{k}=z_{m}^{k}+\int_{t_{m}}^{t_{m^{\prime}}}f_{k}(\hat{z}_ {s}^{k},s)ds+\int_{t_{m}}^{t_{m^{\prime}}}g_{k}(\hat{z}_{s}^{k},s)dB_{s}","where the latent variable \(\hat{z}_{m^{\prime}}^{k}\) is transformed from \(m\)-th domains latent variable \(z_{m}^{k}\), and \(f_{k}\) is the drift function of the \(k\)-th class to capture the evolving patterns, and \(g_{k}\) is the diffusion function of the \(k\)-th class to characterize the stochastics of the latent representations","z_{t_{m^{\prime}}}^{k}=z_{t_{m}}^{k}+\int_{t_{m}}^{t_{m^{\prime}}}f(z_{s}^{k},s)ds+\int_{t_{m}}^{t_{m^{\prime}}}g(z_{s}^{k},s)dB_{s}","where \(z_{t_{m^{\prime}}}^{k}\) is the latent representation of class \(k\) at time \(t_{m^{\prime}}\), \(f\) and \(g\) are the drift and diffusion functions, and \(B_{s}\) is Brownian motion, modeling the evolution of class-conditional latent representations from \(t_{m}\) to \(t_{m^{\prime}}\)."
ICLR_2024_oral_37,7,J_{mle}=\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_{B}}-\frac{1}{MKN_ {B}}\Big{(}\logD(z=\hat{z}_{i|m+1}^{k}|z=z_{i|m}^{k})+\logD \big{(}z=\hat{z}_{i|m+\lambda}^{k}|z=z_{i|m}^{k}\big{)}\Big{)},,"L_{PA}=-\sum_{m=1}^{M-1}\sum_{k=1}^{K}\sum_{i=1}^{N_B}\log p_{SDE-EDG}\left(\hat{z}_{i|m+\lambda}^{k}\mid z_{i|m}^{k}; f_k, g_k\right)","where \(\mathcal{L}_{\text{PA}}\) is the path alignment loss, \(p_{\text{SDE-EDG}}\) denotes the likelihood under the SDE-EDG model parameterized by drift \(f_k\) and diffusion \(g_k\), and the loss is summed over all domains, classes, and samples in the IFGET."
ICLR_2024_oral_37,8,"D(y=k|z,t=t_{m})=\frac{D(z|y=k,t=t_{m})\timesD(y=k|t=t_{m})}{\sum_{k^{\prime}=1}^{K}D(z|y=k^{\prime},t=t_{m})\timesD(y=k^{\prime}|t=t_{m})}","where we model \(\mathcal{D}(z|y=k,t=t_{m})\) with non-parametric model, and \(\mathcal{D}(y|t=t_{m})\) as a neural net with input as timestamp \(t\), function denoted as \(r(t)\)",p(y|z_{m^{\prime}})=\frac{p(z_{m^{\prime}}|y)p(y)}{\sum_{y^{\prime}}p(z_{m^{\prime}}|y^{\prime})p(y^{\prime})},"The predictive distribution \(p(y|z_{m^{\prime}})\) is given by Bayes' rule, where \(p(z_{m^{\prime}}|y)\) is the likelihood of the latent representation at time \(t_{m^{\prime}}\) given class \(y\), and \(p(y)\) is the prior probability of class \(y\)."
ICLR_2024_oral_37,9,"D(z|y=k,t=t_{m})=\frac{\sum_{\hat{z}_{i}\in\hat{S}_{m}^{k}}- exp(-Dist(z,\hat{z}_{i}))}{|\hat{S}_{m}^{k}|}",where \(\hat{S}_{m}^{k}\) includes instances sample from learned SDE-EDG belong to \(k\)-th class of \(m\)-th domain,"D(z|y=k,t=t_{m})=\frac{1}{|\hat{S}_{m}^{k}|}\sum_{z_{j|m}^{k}\in\hat{S}_{m}^{k}}K(z, z_{j|m}^{k}; h)","where \(\mathcal{K}(z, z_{j|m}^{k}; h)\) is a kernel function (e.g., Gaussian) with bandwidth \(h\), and \(\hat{S}_{m}^{k}\) is the set of instances from class \(k\) at domain \(m\)."
ICLR_2024_oral_37,10,"J_{cls}=\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_{B}}-\frac{1}{MKN _{B}}\logD(y=k|z=z_{i},t=t_{m})",,"J_{cls}=-\frac{1}{N}\sum_{i=1}^{N}\logD(y_i|z_i, t_i)","where \(N\) is the number of samples, \(y_i\) is the label, \(z_i\) is the latent representation, and \(t_i\) is the timestamp for the \(i\)-th sample."
ICLR_2024_oral_38,1,P_{F}^{\top}(x)\propto\exp(-E(x)),where \(P_{F}^{\top}(x)\) is the distribution of sampling an object \(x\) induced from marginalizing over the trajectories conditioned on \(x=s_{T}\),p_{E}(x)=\frac{\exp(-E(x))}{Z_{E}},"The Boltzmann distribution over objects \(x\) with energy function \(\mathcal{E}(x)\), where \(Z_{\mathcal{E}}\) is the normalization constant."
ICLR_2024_oral_38,2,"L_{DB}(s,s^{\prime})=(\log F(s)+\log P_{F}(s^{\prime}|s)-\log F(s^{\prime})-\log P_{B}(s|s^{\prime}))^{2}","where the flow \(F(s)\) for the terminal state \(s_{T}=x\) is defined to be identical to the exponent of the negative energy \(\exp\left(-\mathcal{E}(x)\right)\), i","L_{DB}=E_{(s, a, s')\sim D}\left[\left(\log F(s)+\log P_{F}(s'|s)-\log F(s')-\log P_{B}(s|s')\right)^2\right]",The detailed balance loss \(\mathcal{L}_{\mathrm{DB}}\) encourages consistency between forward and backward flows along state transitions sampled from data \(D\).
ICLR_2024_oral_38,3,L_{TB}=(\log Z+\sum_{t=0}^{T-1}\log P_{F}(s_{t+1}|s_{t} )-E(x)-\sum_{t=0}^{T-1}\log P_{B}(s_{t}|s_{t+1}))^{2},,L_{TB}(\tau)=\left(\log Z+\sum_{t=0}^{T-1}\log P_{F}(s_{t+1}|s_t)-\sum_{t=0}^{T-1}\log P_{B}(s_t|s_{t+1})-E(x)\right)^2,"where \(\tau = (s_0, s_1, \dots, s_T)\) is a trajectory with terminal state \(x = s_T\), and \(Z\) is a learnable normalization constant."
ICLR_2024_oral_38,4,L_{subTB}=(\log F(s_{U})+\sum_{t=U}^{U+L-1}\log P_{F}(s_ {t+1}|s_{t})-\log F(s_{U+L})-\sum_{t=U}^{U+L-1}\log P_{B}(s_{t}|s_{t+1})) ^{2},,L_{subTB}=\left(\log Z+\log F(s_U)+\sum_{t=U}^{U+L-1}\log P_F(s_{t+1} | s_t)-E(x)-\log F(s_{U+L})-\sum_{t=U}^{U+L-1}\log P_B(s_t | s_{t+1})\right)^2,"where \(s_U\) and \(s_{U+L}\) are the start and end states of the sub-trajectory, and \(x = s_T\) is the terminal object."
ICLR_2024_oral_38,5,"L_{FL}(s,s^{\prime})=(\log\tilde{F}(s)+\log P_{F}(s^{\prime}| s)-E(s)+E(s^{\prime})-\log\tilde{F}(s^{\prime})-\log P _{B}(s|s^{\prime}))^{2}",where \(\tilde{F}(s)=F(s)\exp\left(\mathcal{E}(s)\right)\) is the re-parameterized flow function and \(\mathcal{E}(s^{\prime})-\mathcal{E}(s)\) is the energy gain associated with the transition from \(s\) to \(s^{\prime}\),"L_{FL-GFN}(s,s^{\prime})=\left(\log F(s)+\log P_{F}(s^{\prime}|s)-E(s^{\prime})-\log P_{B}(s|s^{\prime})\right)^2",where \(\mathcal{E}(s^{\prime})\) is the energy assigned to the intermediate state \(s^{\prime}\) and serves as a local credit signal for training.
ICLR_2024_oral_38,6,E(x)\approx\Phi_{\theta}(\tau)=\sum_{t=0}^{T-1}\phi_{\theta}(s_{t}\to s_{t+1}),"where \(\tau=(s_{0},s_{1},\ldots,s_{T})\), \(x=s_{T}\), and the potential functions are defined on state transition \(s_{t}\to s_{t+1}\)","E(x)=\sum_{t=0}^{T-1}\phi_{\theta}(s_t, s_{t+1})","The terminal energy \(\mathcal{E}(x)\) is decomposed as the sum of learnable potential functions \(\phi_{\theta}(s_t, s_{t+1})\) over the state transitions along the trajectory."
ICLR_2024_oral_38,7,"L_{LED}(s,s^{\prime})=(\log\tilde{F}(s)+\log P_{F}(s^{\prime} |s)+\phi_{\theta}(s\to s^{\prime})-\log\tilde{F}(s^{\prime})-\log P_{B}(s|s^{\prime}))^{2}",,"L_{LED}(s,s')=\left(\log F(s)+\log P_F(s'|s)-\phi_\theta(s\to s')-\log F(s')-\log P_B(s|s')\right)^2",where \(\phi_\theta(s \to s')\) is the learnable potential function assigned to the transition \(s \to s'\).
ICLR_2024_oral_38,8,\ell_{LS}(\tau)=E_{z\simBern(\gamma)} [(\frac{1}{T}E(s_{T})-\frac{1}{C}\sum_{t=0}^{T-1}z_{t}\phi_{\theta}(s_{t}\to s_{t+1}))^{2}],,L_{pot}(\tau)=\left(E(x)-\sum_{t=0}^{T-1}\phi_{\theta}(s_t\to s_{t+1})\right)^2+\lambda\cdotVar_{t}\left[\phi_{\theta}(s_t\to s_{t+1})\right],"where the first term enforces accurate energy decomposition and the second term, weighted by $\lambda$, penalizes the variance of potentials along the trajectory."
ICLR_2024_oral_39,1,"\epsilon_{\theta}(o_{t}^{(k)},k|h_{t-1},a_{t-1})=(1+\eta)\epsilon_{\theta}(o_{ t}^{(k)},k|h_{t-1},a_{t-1})-\eta\epsilon_{\theta}(o_{t},k|h_{t-1})",where \(\eta\) controls action conditioning strength,"p(o_{t}\mid h_{t-1}, a_{t-1})",The probability distribution over the next observation frames \(o_{t}\) conditioned on the history frames \(h_{t-1}\) and the action \(a_{t-1}\).
ICLR_2024_oral_39,2,"L_{MSE}=\|\epsilon-\epsilon_{\theta}\Big{(}\sqrt{1-\beta^{(k)}}o_{t}+\sqrt{\beta^{(k)}}\epsilon,\,k\Big{|}h_{t-1},a_{t-1}\Big{)}\|^{2}","where \(\epsilon\sim\mathcal{N}(0,I)\), and \(\beta^{(k)}\in\mathbb{R}\) are a set of \(K\) different noise levels for each \(k\in[1,K]\)","E_{o_{t},h_{t-1},a_{t-1},\epsilon,k}\left[\left\|\epsilon-\epsilon_{\theta}\left(\sqrt{\overline{\alpha}_k}o_{t}+\sqrt{1-\overline{\alpha}_k}\epsilon, k\mid h_{t-1}, a_{t-1}\right)\right\|^2\right]","The loss function for training the denoising model \(\epsilon_{\theta}\), where \(\epsilon\) is sampled noise and \(\overline{\alpha}_k\) is the cumulative product of the noise schedule at step \(k\)."
ICLR_2024_oral_39,3,"o_{t}^{(k-1)}=\alpha^{(k)}(o_{t}^{(k)}-\gamma^{(k)}\epsilon_{\theta}(o_{t}^{( k)},k|h_{t-1},a_{t-1}))+\xi,\quad\xi\simN\big{(}0,\sigma_{k}^{2}I\big{)}","where \(\gamma^{(k)}\) is the denoising step size, \(\alpha^{(k)}\) is a linear decay on the current denoised sample, and \(\sigma_{k}\) is a time varying noise level that depends on \(\alpha^{(k)}\) and \(\beta^{(k)}\)","o_{t}^{(k-1)}=\frac{1}{\sqrt{1-\beta^{(k)}}}\left( o_{t}^{(k)}-\beta^{(k)}\epsilon_{\theta}(o_{t}^{(k)}, k\mid h_{t-1}, a_{t-1})\right)","where \(o_{t}^{(k)}\) is the noisy observation at step \(k\), and \(\beta^{(k)}\) is the noise schedule parameter."
ICLR_2024_oral_39,4,RDG=\frac{\|s_{0}-s_{goal}\|_{2}-\|s_{T}-s_{goal}\|_{2}}{\|s_{0}-s_{goal}\|_{2}},"where \(s_{T}\) represents the underlying block locations after executing the policy, \(s_{0}\) and \(s_{\text{goal}}\) represents the initial and goal block locations",RDG=\frac{1}{N}\sum_{i=1}^{N}\left( d_{init}^{(i)}-d_{final}^{(i)}\right),"where \(d_{\text{init}}^{(i)}\) and \(d_{\text{final}}^{(i)}\) are the initial and final distances to the goal for block \(i\), and \(N\) is the number of blocks."
ICLR_2024_oral_4,1,p(Y\mid X)=\sum_{Z}p_{LM}(ZY\mid X)=\sum_{Z}p_{LM}(Y\mid XZ)p_{LM}(Z\mid X),where \(p_{\text{LM}}\) denotes the likelihood assigned to a sequence by a language model and apposition of variables (_e,"p(Z\mid X, Y)","Conditional probability of the latent chain of thought \(Z\) given the question-answer pair \((X, Y)\)."
ICLR_2024_oral_4,2,"p_{LM}(Z\mid X,Y)=\frac{p_{LM}(XZY)}{\sum_{Z^{\prime}}p_{ LM}(XZY^{\prime}Y)}\propto p_{LM}(XZY)",,"p_{LM}(Z\mid X,Y)=\frac{p_{LM}(XZY)}{\sum_{Z'} p_{LM}(XZ'Y)}","where \(p_{\text{LM}}(Z\mid X,Y)\) is the posterior probability of the latent sequence \(Z\) given prefix \(X\) and suffix \(Y\), and the denominator sums over all possible latent sequences \(Z'\)."
ICLR_2024_oral_4,3,L(Z;\theta)=\sum_{0\leq i<j\leq n}(\log\frac{R(z_{1:i}\top)\prod_{k=i+1}^{j}q_{GFN}(z_{k}\mid z_{1:k-1})q_{GFN}(\top\mid z_ {1:j})}{R(z_{1:j}\top)q_{GFN}(\top\mid z_{1:i})})^{2},,L_{SubTB}(Z)=\left(\log\frac{q_{GFN}^{\top}(Z)}{R(Z)}-\log\sum_{Z'\inZ} q_{GFN}^{\top}(Z')\right)^2,"The Subtrajectory Balance (SubTB) loss for a sequence \(Z\) measures the squared difference between the log-likelihood assigned to \(Z\) by the GFlowNet policy (normalized over all sequences) and the log of its unnormalized reward, encouraging the policy to sample sequences proportionally to their reward."
ICLR_2024_oral_41,1,"q_{0t}(x_{t}|x_{0})=N(x_{ t}|\alpha_{t}x_{0},\sigma_{t}^{2}I)","where \(\alpha_{t}\) and \(\sigma_{t}\) are referred to as the noise schedule, satisfying \(\alpha_{t}^{2}+\sigma_{t}^{2}=1\)","q_{0t}(x_t |x_0)=N(x_t;\sqrt{\alpha_t}x_0, (1-\alpha_t)I)","The conditional distribution of the noisy sample \(\mathbf{x}_t\) given the original data \(\mathbf{x}_0\) at timestep \(t\), where \(\alpha_t\) is a variance schedule parameter."
ICLR_2024_oral_41,2,"dx_{t}=f(t)x_{t}dt+g(t )dw_{t},\quadx_{0}\sim q_{0}(x_{0})","where \(\mathbf{w}_{t}\) is the standard Wiener process, \(f(t)=\frac{\mathrm{d}\log\alpha_{t}}{\mathrm{d}t}\) and \(g(t)=2\sigma_{t}^{2}\frac{\mathrm{d}\log(\sigma_{t}/\alpha_{t})}{\mathrm{d}t}\)",dx_{t}=f(t)x_{t}dt+g(t)dw_{t},"where \(f(t)\) and \(g(t)\) are time-dependent drift and diffusion coefficients, and \(\mathbf{w}_{t}\) denotes the standard Wiener process."
ICLR_2024_oral_41,3,"dx_{t}=[f(t)x_{t}-g(t)^{2}\nabla_{x_{t}}\log q_{t}(x_{t})]dt+g (t)d\bar{w}_{t},\quadx_{T}\sim q_{T} (x_{T})",where \(\bar{\mathbf{w}}_{t}\) is a standard Wiener process in the reverse time,dx_{t}=\left[ f(t)x_{t}-g(t)^{2}\nabla_{x_{t}}\log q_{t}(x_{t})\right]dt+g(t)d\bar{w}_{t},where \(\bar{\mathbf{w}}_{t}\) is the standard Wiener process in reverse time.
ICLR_2024_oral_41,4,"L(\theta):=E_{t\simU(0,T),x_{0}\sim q_{0}(x_{0}),\epsilon\simN (0,I)}[\|\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon,t)-\epsilon\|_{2}^{2}]",,"E_{t,x_{0},\epsilon}\left[\left\|\epsilon-\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon, t)\right\|^{2}\right]","where \(\mathbf{\epsilon}\sim\mathcal{N}(0,\mathbf{I})\) is standard Gaussian noise and \(\mathbf{\epsilon}_{\theta}\) is the noise prediction network."
ICLR_2024_oral_41,5,"\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}=\frac{\alpha_{t}}{\sqrt{1-\alpha_{t}^{2}}}\frac{d\alpha_{t}}{dt}\nabla_{x}\log q_{t}(x)-\frac{\partial\nabla_{x }\log q_{t}(x)}{\partial t}\sigma_{t}",,"\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}=-\frac{d\sigma_{t}}{dt}\nabla_{x}\log q_{t}(x)-\sigma_{t}\frac{\partial}{\partial t}\nabla_{x}\log q_{t}(x)",The partial derivative of the noise prediction network with respect to time consists of a term involving the derivative of the noise schedule and a term involving the time derivative of the score function.
ICLR_2024_oral_41,6,"\lim\sup_{t\to 0+}\|\frac{\partial\epsilon_{\theta}(x,t )}{\partial t}\|\to\infty;\quad\lim\sup_{t\to 0+}\|\frac{\partial\nabla_{x}\log q_{t}(x)}{\partial t}\sigma_{t}\|\to\infty",,"\limsup_{t\to 0+}\left\|\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}\right\|=\infty\quador\quad\limsup_{t\to 0+}\left\|\frac{\partial\nabla_{x}\log q_{t}(x)}{\partial t}\right\|=\infty",Either the Lipschitz constant of the noise prediction network or the time derivative of the score function diverges as \(t\to 0\).
ICLR_2024_oral_41,7,\nabla_{x}\log q_{t}(x)=\nabla_{x}\log (\frac{1}{\sqrt{2\pi}}\exp(-\frac{\|x\|_{2}^{2}}{2}) )=-x,,\nabla_{x}\log q_{t}(x)=-\frac{x}{\sigma_{t}^{2}+\alpha_{t}^{2}},The score function for the marginal distribution \(q_{t}(\mathbf{x})\) when the data is standard normal.
ICLR_2024_oral_41,8,"K(t,t^{\prime})=\frac{E_{x_{t}}[\|\epsilon_{\theta} (x_{t},t)-\epsilon_{\theta}(x_{t},t^{\prime})\|_{2}]}{\Delta t}",where \(\Delta t=|t-t^{\prime}|\),"Lip_{t}(\epsilon_{\theta}) :=\sup_{x}\left\|\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}\right\|",Lipschitz constant of the noise prediction network \(\mathbf{\epsilon}_{\theta}\) with respect to time \(t\).
ICLR_2024_oral_41,9,"L(\epsilon_{\theta}):=E_{t\simU(0,T),x_{0}\sim q(x_{0}),\epsilon\simN(0,I)} [\|\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon,f_{T}(t))-\epsilon\|_{2}^{2}]","where \(f_{\mathbb{T}}(t)=\max_{1\leq i\leq n}\{t_{i-1}\in\mathbb{T}:t_{i-1}\leq t\}\) for \(t<\tilde{t}\), while \(f_{\mathbb{T}}(t)=t\) for \(t\geq\tilde{t}\)","L_{E-TSDM}(\theta):=E_{i\simU(1,n),\, t\simU(t_{i-1},t_{i}),\,x_{0}\sim q_{0}(x_{0}),\,\epsilon\simN(0,I)}\left[\left\|\epsilon_{\theta}(\alpha_{t_{i-1}}x_{0}+\sigma_{t_{i-1}}\epsilon, t_{i-1})-\epsilon\right\|_{2}^{2}\right]","where \(t_{i-1}\) is the left endpoint of the \(i\)-th sub-interval in the partition of \([0,\tilde{t})\), and the network is trained using this shared timestep condition."
ICLR_2024_oral_41,10,"p_{\theta}(x_{t-1}|x_{t})=N(x_{t-1};\frac{\alpha_{t-1}}{\alpha_{t}}(x_{t}-\frac{\beta_{t}}{\sigma_{t}}\epsilon_{\theta}(x_{t},f_{T} (t))),\eta_{t}^{2}I)","where \(\beta_{t}=1-\frac{\alpha_{t}}{\alpha_{t-1}}\), and \(\eta_{t}^{2}=\beta_{t}\)","dx_{t}=\left[f(t)x_{t}-g(t)^2\nabla_{x_{t}}\log q_{t}(x_{t}; f_{T}(t))\right]dt+g(t)d\bar{w}_{t},\quadx_{T}\sim q_{T}(x_{T})",where \(q_{t}(\mathbf{x}_{t}; f_{\mathbb{T}}(t))\) denotes the marginal distribution under the shared timestep condition mapping \(f_{\mathbb{T}}(t)\).
ICLR_2024_oral_41,11,"\|\epsilon^{*}(x,f_{T}(t)-\epsilon(x,t)\|\leq\sigma_{\tilde{t}}K (x)\Delta t+B(x)\Delta\sigma_{\max}",,"\|\epsilon^{*}(x,f_{T}(t))-\epsilon(x,t)\|\leq C\cdot\sup_{s\in [t_{i-1}, t_i]}\left\|\frac{\partial\epsilon(x,s)}{\partial s}\right\|\cdot (t_i-t_{i-1})","where \(C\) is a constant and \([t_{i-1}, t_i]\) is the sub-interval containing \(t\)."
ICLR_2024_oral_41,12,"K(x)=\sup_{t\neq\tau}\frac{\|\nabla_{x}\log q_{t }(x)-\nabla_{x}\log q_{\tau}(x )\|}{|t-\tau|},\quad B(x)=\sup_{t}\|\nabla_{x}\log q_{t}(x)\|",,"\Delta t=\max_{1\leq i\leq n} (t_i-t_{i-1}),\quad\Delta\sigma_{\max}=\max_{1\leq i\leq n} |\sigma_{t_i}-\sigma_{t_{i-1}}|",where \(\Delta t\) is the maximum width of the sub-intervals and \(\Delta \sigma_{\max}\) is the maximum difference in \(\sigma_t\) between adjacent sub-interval endpoints.
ICLR_2024_oral_44,1,"I(S;Z)=D_{KL}(p(s,z)\|p(s)p(z))",,"I(s;z)=E_{p(s,z)}\left[\log\frac{p(s|z)}{p(s)}\right]",\(I(\mathbf{s}; \mathbf{z})\) denotes the mutual information between states \(\mathbf{s}\) and skills \(\mathbf{z}\).
ICLR_2024_oral_44,2,"I_{W}(S;Z)=W(p(s,z),p(s)p(z))",where \(I_{\mathcal{W}}(S;Z)\) is the Wasserstein dependency measure (WDM) (Ozair et al,"I_{W}(S;Z)=\inf_{q\inQ}E_{q(s,z)}\left[ d(s,\tilde{s})\right]","\(I_{\text{W}}(S;Z)\) denotes the Wasserstein dependency measure between states \(S\) and skills \(Z\), where \(d(s, \tilde{s})\) is a distance metric (e.g., temporal distance) and the infimum is over all couplings \(q \in \mathcal{Q}\) with marginals matching the joint and product of marginals."
ICLR_2024_oral_44,3,"I_{W}(S;Z)=\sup_{\|f\|_{L}\leq 1}E_{p(s,z)}[f(s,z)]-E_{p(s)p(z)}[f(s,z)]","where \(\|f\|_{L}\) denotes the Lipschitz constant for the function \(f:\mathcal{S}\times\mathcal{Z}\rightarrow\mathbb{R}\) under the given distance metric \(d\), _i","I_{W}(S;Z)=\sup_{f\inLip_1}E_{p(s,z)}[f(s,z)]-E_{p(s)p(z)}[f(s,z)]","where the supremum is over all 1-Lipschitz functions \(f\), providing a dual form for the Wasserstein dependency measure."
ICLR_2024_oral_44,4,"I_{W}(S;Z)\approx\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}E_{p( s,z)}[\phi(s)^{\top}\psi(z)]-E_{p(s)}[\phi(s)]^{\top}E_{p(z)}[\psi(z)]",,"\sup_{\|\phi\|_{L}\leq 1,\,\|\psi\|_{L}\leq 1}\;E_{p(s,z)}\left[\phi(s)^{\top}\psi(z)\right]-E_{p(s)p(z)}\left[\phi(s)^{\top}\psi(z)\right]","where $\phi:\mathcal{S}\rightarrow\mathbb{R}^{D}$ and $\psi:\mathcal{Z}\rightarrow\mathbb{R}^{D}$ are $1$-Lipschitz functions parameterizing the score function $f(s,z)=\phi(s)^{\top}\psi(z)$."
ICLR_2024_oral_44,5,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}E_{p(\tau,z)}[\phi(s_{T})^{\top}\psi(z)]-E_{p(\tau)}[\phi(s_{T})]^{\top}E_{p(z)}[\psi(z)] || =\sup_{\phi,\psi}\sum_{t=0}^{T-1}(E_{p(\tau,z)}[(\phi(s_{t+1})-\phi(s_{t}))^{\top}\psi(z)]-E_{p(\tau)}[\phi(s_{t+1})-\phi(s_{t})]^{\top}E_{p(z)}[\psi(z)])",,"I_{W}(S_{T};Z)=\sum_{t=1}^{T}\left(E_{p(s_{t},z)}[\phi(s_{t})^{\top}\psi(z)]-E_{p(s_{t})}[\phi(s_{t})]^{\top}E_{p(z)}[\psi(z)]\right)",The Wasserstein dependency measure between the final state and skill can be decomposed as a sum over time steps of the difference between joint and marginal expectations of the score function.
ICLR_2024_oral_44,6,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1}E_{p(\tau,z)}[\sum_{t=0}^{T-1}(\phi(s_{t+1})-\phi(s_{t}))^{\top}(z-\bar{z}) ]",where \(\bar{z}=\mathbb{E}_{p(z)}[z]\),"\sup_{\|\phi\|_{L}\leq 1}\sum_{t=0}^{T-1}\left(E_{p(\tau,z)}\left[(\phi(s_{t+1})-\phi(s_{t}))^{\top}z\right]-E_{p(\tau)}[\phi(s_{t+1})-\phi(s_{t})]^{\top}E_{p(z)}[z]\right)","This objective maximizes the expected alignment between temporal differences in the state embedding and the skill latent vector, under independent Lipschitz constraints on the state encoder."
ICLR_2024_oral_44,7,"\sup_{\pi,\phi}\E_{p(\tau,z)}[\sum_{t=0}^{T-1}(\phi(s_{t+1})-\phi(s_{t}))^{\top}z]\\s.t.\\\|\phi(s)-\phi(s^{\prime})\|_{2}\leq 1,\\\forall(s,s^{\prime})\inS_{adj}",where \(\mathcal{S}_{\mathrm{adj}}\) denotes the set of adjacent state pairs in the MDP,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L,temp}\leq 1}E_{p(\tau,z)}\left[\sum_{t=0}^{T-1}(\phi(s_{t+1})-\phi(s_{t}))^{\top}z\right]","where the Lipschitz constraint $\|\phi\|_{L,\mathrm{temp}}\leq 1$ is defined with respect to the temporal distance metric $d_{\mathrm{temp}}(s_1,s_2)$."
ICLR_2024_oral_45,1,"x^{\prime}(t)=Ax(t)+Bu(t),\quad y(t)=Cx(t)+Du(t)",,\frac{d}{dt} x(t) &=A x(t)+B u(t)\\y(t) &=C x(t)+D u(t),"The continuous-time linear state space model equations, where \(x(t)\) is the state, \(u(t)\) is the input, \(y(t)\) is the output, and \(\mathbf{A}, \mathbf{B}, \mathbf{C}, \mathbf{D}\) are system matrices."
ICLR_2024_oral_45,2,"x_{n}=\bar{A}x_{n-1}+\bar{B}u_{n},\quad y_{n}=\bar{ C}x_{n}+\bar{D}u_{n}","where \(\bar{\mathbf{A}},\bar{\mathbf{B}},\bar{\mathbf{C}}\), and \(\bar{\mathbf{D}}\) are discrete-time parameters obtained from the continuous-time parameters and \(\Delta\) using methods like zero-order hold and bilinear technique (Smith et al","x_{k+1}=\bar{A} x_k+\bar{B} u_k,\quad y_k=\bar{C} x_k+\bar{D} u_k","Discretized state space model equations with step size \(\Delta\), where \(x_k\), \(u_k\), and \(y_k\) denote the state, input, and output at discrete time step \(k\), and \(\bar{\mathbf{A}}, \bar{\mathbf{B}}, \bar{\mathbf{C}}, \bar{\mathbf{D}}\) are the discretized system matrices."
ICLR_2024_oral_45,3,"L(\theta)=\operatorname*{E}_{z_{1:T}\sim q_{\theta}}\sum_{ t=1}^{T}L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})+L^{rep}(\theta,h_{t},o_{t})+L^{dyn}(\theta,h _{t},o_{t})",,"L=E_{q_{\theta}}\left[\sum_{t=1}^{T}\log p_{\theta}(\hat{o}_{t}\mid z_{t}, h_{t})+\log p_{\theta}(\hat{r}_{t}\mid z_{t}, h_{t})+\log p_{\theta}(\hat{c}_{t}\mid z_{t}, h_{t})-KL\left(q_{\theta}(z_{t}\mid o_{t})\,\|\, p_{\theta}(z_{t}\mid h_{t})\right)\right]","The training objective maximizes the log-likelihoods of predicted observations, rewards, and continuation flags while minimizing the KL divergence between the posterior and prior distributions over the stochastic state."
ICLR_2024_oral_45,4,"L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})=-\beta_{pred}(\ln p_{\theta}(o_{t}\mid z_{t},h_{t})+\ln p_{\theta}(r_{t}\mid z_{t},h_{t})+\ln p_{\theta}(c_{t}\mid z_{t},h_{t})) || L^{dyn}(\theta,h_{t},o_{t})=\beta_{dyn}\max(1,KL[\lessdot\circ g(q_{\theta}(z_ {t}\mid o_{t}))\parallel p(z_{t}\mid h_{t})\mid)]",,"L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})=-\log p_{\theta}(o_{t}\mid h_{t},z_{t})-\log p_{\theta}(r_{t}\mid h_{t},z_{t})-\log p_{\theta}(c_{t}\mid h_{t},z_{t})","The prediction loss \(\mathcal{L}^{\text{pred}}\) is the negative log-likelihood of the observation, reward, and continuation predictions given the latent and deterministic states."
ICLR_2024_oral_45,5,"L^{rep}(\theta,h_{t},o_{t})=\beta_{rep}\max(1,KL[\quad q_{\theta}(z_{t}\mid o_ {t})\parallel\lessdot\circ g(p(z_{t}\mid h_{t}))\,])",,"L^{rep}(\theta,h_{t},o_{t})=\beta_{rep}\,KL\big[q_{\theta}(z_{t}\mid o_{t})\,\|\,p_{\theta}(z_{t}\mid h_{t})\big]","where \(\mathcal{L}^{\text{rep}}\) is the representation loss, computed as the KL divergence between the posterior and prior distributions over the stochastic state."
ICLR_2024_oral_45,6,"h_{1:T},x_{1:T}=f_{\theta}((a_{1:T},z_{1:T}),x_{0})",,\lessdot\circ g(q_{\theta}(z_{t}\mid o_{t}))=E_{q_{\theta}(z_{t}\mid o_{t})}[g(z_{t})],The operator \(\lessdot\circ g(q_{\theta}(z_{t}\mid o_{t}))\) denotes the expectation of \(g(z_{t})\) under the distribution \(q_{\theta}(z_{t}\mid o_{t})\).
ICLR_2024_oral_49,1,"e_{i}^{num}=x_{i}^{num}\cdotw_{i}^{num}+b_{i}^{num},\\e_{i}^{cat}=x_{i}^{oh}\cdotW_{i}^{cat }+b_{i}^{cat}","where \(\mathbf{w}_{i}^{\mathrm{num}},\mathbf{b}_{i}^{\mathrm{num}},\mathbf{b}_{i}^{\mathrm{cat}} \in\mathbb{R}^{1\times d}\), \(\mathbf{W}_{i}^{\mathrm{cat}}\in\mathbb{R}^{C_{i}\times d}\) are learnable parameters of the tokenizer, \(\mathbf{e}_{i}^{\mathrm{num}},\mathbf{e}_{i}^{\mathrm{cat}}\in\mathbb{R}^{1\times d}\)","h_{i}=W_{i} x_{i}^{num}+b_{i}, &if  i is numerical\\E_{i}x_{i}^{oh}, &if  i is categorical",The tokenized representation $\mathbf{h}_i$ for column $i$ is obtained by applying a linear transformation for numerical columns or an embedding lookup for categorical columns.
ICLR_2024_oral_49,2,"E=[e_{1}^{num},\cdots,e_{M_{num}}^{ num},e_{1}^{cat},\cdots,e_{M_{cat}}^{cat}]\inR^{M\times d}",,"E=[e_1^{num},\ldots,e_{M_{num}}^{num},e_1^{cat},\ldots,e_{M_{cat}}^{cat}]\inR^{M\times d}","The matrix \(\mathbf{E}\) is the concatenation of all column embeddings for a record, where \(M = M_{\mathrm{num}} + M_{\mathrm{cat}}\)."
ICLR_2024_oral_49,3,"&\hat{x}_{i}^{num}=\hat{e}_{i}^{num}\cdot\hat{w}_{i}^{num}+\hat{b}_{i}^{num},\\\hat{e}_{i}^{oh}=Softmax(\hat{e}_{i}^{cat}\cdot\hat{W}_{i}^{cat}+\hat{b}_{i}^{cat}),\\&\hat{x}=[\hat{x}_{1}^{num},\cdots,\hat{x}_{M_{num}}^{num},\hat{x}_{1}^{oh},\cdots,\hat{x }_{M_{cat}}^{oh}]","where \(\hat{\mathbf{w}}_{i}^{\mathrm{num}}\in\mathbb{R}^{d\times 1},\hat{b}_{i}^{ \mathrm{num}}\in\mathbb{R}^{1\times 1}\), \(\mathbf{W}_{i}^{\mathrm{cat}}\in\mathbb{R}^{d\times C_{i}},\hat{\mathbf{b}}_{i}^{ \mathrm{cat}}\in\mathbb{R}^{1\times C_{i}}\) are detokenizer's parameters","\hat{x}_{i}^{num}=\hat{e}_{i}^{num}\cdotw_{i}^{num,\top}+b_{i}^{num},\quad\hat{x}_{i}^{cat}=softmax\left(\hat{e}_{i}^{cat}\cdotW_{i}^{cat,\top}+b_{i}^{cat}\right)","The detokenizer reconstructs numerical and categorical column values from their recovered token representations using a linear transformation and a softmax over the embedding matrix, respectively."
ICLR_2024_oral_49,4,"L=\ell_{recon}(x,\hat{x})+\beta\ell_{kl}",,"L_{\beta-VAE}=E_{q_{\phi}(z|E)}\left[\log p_{\theta}(E|z)\right]-\beta\, D_{KL}\left(q_{\phi}(z|E)\,\|\, p(z)\right)","where \(\mathcal{L}_{\beta\text{-VAE}}\) is the loss function, \(\beta\) is the adaptive weight coefficient, and \(D_{\mathrm{KL}}\) denotes the Kullback-Leibler divergence between the approximate posterior and the prior."
ICLR_2024_oral_49,5,"z_{t}=z_{0}+\sigma(t)\varepsilon,\\varepsilon\simN(0,I), (Forward Process) || dz_{t}=-2\hat{\sigma}(t)\sigma(t)\nabla_{z_{t}}\log p(z_{t})dt+\sqrt{2\hat{\sigma}(t)\sigma(t)}d\omega_{t}, (Reverse Process)",,"q(z_t\midz_0)=N(z_t;\sqrt{\bar{\alpha}_t}z_0, (1-\bar{\alpha}_t)I)","The forward diffusion process adds Gaussian noise to the latent embedding $\mathbf{z}_0$ at each timestep $t$, where $\bar{\alpha}_t$ is the cumulative product of noise schedule coefficients."
ICLR_2024_oral_49,6,"L=E_{z_{0}\sim p(z_{0})}E_{t\sim p (t)}E_{\varepsilon\simN(0,I)}\|\varepsilon_{\theta}(z_{t},t)-\varepsilon)\|_{2}^{2},\\where\z_{t}=z_{0}+\sigma(t)\varepsilon",where \(\mathbf{\epsilon}_{\theta}\) is a neural network (named denoising function) to approximate the Gaussian noise using the perturbed data \(\mathbf{x}_{t}\) and the time \(t\),"E_{t,\,z_{0},\,\varepsilon}\left[\lambda(t)\left\|\nabla_{z_{t}}\log p_{\theta}(z_{t}|t)-\nabla_{z_{t}}\log p(z_{t}|z_{0})\right\|_{2}^{2}\right]","The denoising score matching loss, where \(\lambda(t)\) is a weighting function, \(p_{\theta}(\mathbf{z}_{t}|t)\) is the model's predicted distribution, and \(p(\mathbf{z}_{t}|\mathbf{z}_{0})\) is the true perturbed distribution at time \(t\)."
ICLR_2024_oral_52,1,"p(x(t)\midx(0))=N(x(t);x(0),\sigma^{2}(t)I)\",,"q(\tilde{x}\midx)=N(\tilde{x};\alphax,\sigma^2I)",The perturbed data distribution \(q(\tilde{\mathbf{x}} \mid \mathbf{x})\) is defined as a Gaussian with mean \(\alpha \mathbf{x}\) and covariance \(\sigma^2 \mathbf{I}\).
ICLR_2024_oral_52,2,"dx(t)=-\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt\",,\frac{dx(t)}{dt}=-\sigma(t)\nabla_{x(t)}\log p(x(t)),"This equation defines the probability flow ordinary differential equation (ODE) governing the evolution of the data point \(\mathbf{x}(t)\) in time, where the drift is proportional to the score function of the noisy data distribution."
ICLR_2024_oral_52,3,"dx(t)=\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt\",,"dx(t)=-\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt","The backward ODE describes the reverse-time denoising process, starting from noise and iteratively removing it to recover data samples."
ICLR_2024_oral_52,4,"E_{t\simU([0,T])}E_{x(0)\sim p(x (0))}E_{x(t)\sim p(x(t)|x(0))}\|S^{\theta}(x(t),\sigma(t))-\nabla_{x(t)}\log p (x(t)\midx(0))\|_{2}^{2}",,"L_{SM}=E_{x(0), t,x(t)}\left[\lambda(t)\left\| S^{\theta}(x(t),\sigma(t))-\nabla_{x(t)}\log p(x(t)\midx(0))\right\|_2^2\right]","The score-matching loss \(\mathcal{L}_{\text{SM}}\) measures the expected squared error between the neural network approximation \(S^{\theta}\) and the true score of the perturbed data distribution, weighted by a function \(\lambda(t)\)."
ICLR_2024_oral_52,5,"E_{t\simU([0,T])}E_{x(0)\sim p(x (0))}E_{x\simN(0,\sigma^{2}(t)I )}\|D^{\theta}(x(0)+\epsilon,\sigma(t))-x(0)\|_ {2}^{2}\","where we define \(S^{\theta}(\mathbf{x}(t),\sigma(t))=:(D^{\theta}(\mathbf{x}(t),\sigma(t))- \mathbf{x}(t))/\sigma^{2}(t)\)","E_{t,\,x(0),\,x(t)}\left\|S^{\theta}(x(t),\sigma(t))+\frac{x(t)-x(0)}{\sigma^2(t)}\right\|_2^2",The simplified score-matching loss expresses the expected squared error between the neural network score estimate and the exact score of the Gaussian perturbation kernel.
ICLR_2024_oral_52,6,"\nabla_{x(t)}\log p(x(t))=\nabla_{(x_{1}(t),\ldots,x_{N}(t))}\log p(x_{1}(t),\ldots,x_{N}(t))\",,"S^{\theta}(x(t),\sigma(t))\approx\nabla_{x(t)}\log p(x_{1}(t),\ldots,x_{N}(t))",The neural network \(\mathcal{S}^{\theta}\) approximates the score function of the joint distribution over all noisy sources at time \(t\).
ICLR_2024_oral_52,7,"S^{\theta}(x(t),\sigma(t)):R^{N\times D}\timesR arrowR^{N\times D}\","where \(\mathbf{x}(t)=(\mathbf{x}_{1}(t),\ldots,\mathbf{x}_{N}(t))\) denotes the sources perturbed with the Gaussian kernel in Eq","S^{\theta}(x(t),\sigma(t))\approx\nabla_{x(t)}\log p(x(t))",The neural network \(\mathcal{S}^{\theta}\) is trained to approximate the score function of the joint noisy source distribution.
ICLR_2024_oral_52,8,\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t)),,\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t)),"Gradient of the log-conditional prior with respect to the unfixed sources, given the fixed sources at time \(t\)."
ICLR_2024_oral_52,9,"\nabla_{x_{\overline{I}}(t)}\log p([x_{\overline{I}}(t),\hat{x}_{I}(t)])\","where \(\hat{\mathbf{x}}_{\mathcal{I}}\) is a sample from the forward process: \(\hat{\mathbf{x}}_{\mathcal{I}}(t)\sim\mathcal{N}(\mathbf{x}_{\mathcal{I}}(t) ;\mathbf{x}_{\mathcal{I}}(0),\sigma(t)^{2}\mathbf{I})\)","\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t))\approx\nabla_{x_{\overline{I}}(t)}\log p(x(t))=[\nabla_{x_{1}(t)}\log p(x(t)),\ldots,\nabla_{x_{N}(t)}\log p(x(t))]_{\overline{I}}",The conditional score for the unfixed sources is approximated by the corresponding components of the full prior score.
ICLR_2024_oral_52,10,"\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t))\approx S_{\overline{I}}^{\theta}([x_{\overline{I}}(t),\hat{x }_{I}(t)],\sigma(t))\",where \(S_{\overline{\mathcal{I}}}^{\theta}\) denotes the entries of the score network corresponding to the sources indexed by \(\overline{\mathcal{I}}\),"S^{\theta}([x_{\overline{I}}(t),\hat{x}_{I}(t)],\sigma(t))",The neural network score function is evaluated on the concatenation of the generated and fixed noisy sources at time \(t\) with noise level \(\sigma(t)\).
ICLR_2024_oral_52,11,\nabla_{x(t)}\log p(x(t)\midy(0))\,,\nabla_{x(t)}\log p(x(t)\midy(0)),"The gradient of the log-posterior with respect to the sources at time \(t\), conditioned on the observed mixture \(\mathbf{y}(0)\)."
ICLR_2024_oral_52,12,"p(y(t)\midx(t))=N(y(t)\mid\sum_{n=1}^{N}x_{n}(t),\gamma^{2}(t)I)",,"p(y(0)\midx(t))=N\left(y(0);\sum_{n=1}^{N}x_n(t),\sigma^2(t)I\right)",The likelihood of the observed mixture \(\mathbf{y}(0)\) given the noisy sources \(\mathbf{x}(t)\) is modeled as a Gaussian centered at the sum of the sources with variance \(\sigma^2(t)\).
ICLR_2024_oral_52,13,p(y(t)\midx(t))=1_{y(t)=\sum_{n=1}^{N}x_{ n}(t)}\,,p(y(t)\midx(t))=\delta\left(y(t)-\sum_{n=1}^{N}x_{n}(t)\right)\,where \(\delta(\cdot)\) denotes the Dirac delta function enforcing the mixture constraint.
ICLR_2024_oral_52,14,"\nabla_{x_{m}(t)}\log p(x(t)\midy(0))\approx S_{m}^{\theta}((x_{1}(t),\dots,x_{N-1}(t),y(0)-\sum_{n=1}^{N-1}x_{n}(t)),\sigma(t)) || -S_{N}^{\theta}((x_{1}(t),\dots,x_{N-1}(t),y(0)-\sum_{n=1}^{N-1}x_{n}(t)),\sigma(t))\",,"\nabla_{x(t)}\log p(x(t)\midy(0))\approx\left[S_{1}^{\theta}(x(t),\sigma(t)),\ldots,S_{N-1}^{\theta}(x(t),\sigma(t)),-\sum_{n=1}^{N-1} S_{n}^{\theta}(x(t),\sigma(t))\right]",where the last entry enforces the mixture constraint by expressing the score for \(\mathbf{x}_N\) as the negative sum of the scores for the other sources.
ICLR_2024_oral_53,1,L=L_{clip}+\lambdaL_{video},where video-paragraph contrastive loss \(\mathcal{L}_{\text{video}}\) explores the temporal correlations between the long video \(\mathbf{V}_{i}\) and its corresponding paragraph \(\mathbf{T}_{i}\) through a novel noise robust temporal optimal transport distance,L_{pretrain}=L_{itm}+\lambdaL_{mlm}+\muL_{mfm},"The overall pre-training loss \(\mathcal{L}_{\text{pretrain}}\) is a weighted sum of the image-text matching loss \(\mathcal{L}_{\text{itm}}\), the masked language modeling loss \(\mathcal{L}_{\text{mlm}}\), and the masked frame modeling loss \(\mathcal{L}_{\text{mfm}}\), with weights \(\lambda\) and \(\mu\)."
ICLR_2024_oral_53,2,"\max_{Q\inQ}&\langleQ,\S\rangle+\varepsilon H(Q)\\s.t.&Q=\{Q\inR _{+}^{n\times m}\midQ1_{m}=\mu,Q^{\top}1_{n}=\nu\}","where \(\mathbf{1}_{m}\) represents the vector of ones in dimension \(m\), \(\boldsymbol{\mu}\in\mathbb{R}^{n}\) and \(\boldsymbol{\nu}\in\mathbb{R}^{m}\) indicate the relative importance of each clip or caption","\max_{Q\inU(p,q)}\langleQ,S\rangle","where \(\mathcal{U}(\mathbf{p},\mathbf{q})\) is the set of doubly stochastic matrices with marginals \(\mathbf{p}\) and \(\mathbf{q}\), and \(\langle \mathbf{Q}, \mathbf{S} \rangle = \operatorname{tr}(\mathbf{Q}^{\top} \mathbf{S})\) denotes the total similarity between clips and captions under assignment \(\mathbf{Q}\)."
ICLR_2024_oral_53,3,"Q^{*}&=Diag(\kappa_{1})\exp(S/\varepsilon)Diag(\kappa_{2}),\\with iteratively updated \kappa_{1}& arrow\mu./(\exp(S/\varepsilon)\kappa_{2}),\\kappa_{2}arrow\nu_{.}/(\exp(S^{\top}/\varepsilon)\kappa_{1})","where \(\boldsymbol{\kappa}_{1}\in\mathbb{R}^{n}\), \(\boldsymbol{\kappa}_{2}\in\mathbb{R}^{m}\) are the non-negative left and right scaling vectors",Q^{*}=diag(u)\exp\left(\frac{S}{\varepsilon}\right)diag(v),where \(\mathbf{u}\) and \(\mathbf{v}\) are scaling vectors iteratively updated to satisfy the marginal constraints.
ICLR_2024_oral_53,4,"L_{video}=-\sum_{i=1}^{N}(\log\frac{\exp((Q_{ii},\S_{ii})/\tau)}{\sum_{j=1}^{N}\exp((Q_{ ij},\S_{ij})/\tau)}+\log\frac{\exp((Q_{ii},\S_{ii})/\tau)}{\sum_{j=1}^{N}\exp((Q_{ ji},\S_{ji})/\tau)})","where \(\mathbf{S}_{ij}\in\mathbb{R}^{n\times m}\) is the clip-caption similarity matrix between video \(\mathbf{V}_{i}\) and paragraph \(\mathbf{T}_{j}\), \(\mathbf{Q}_{ij}\) is the corresponding transport assignment of \(\mathbf{S}_{ij}\), and \(\tau\) is a learnable temperature initialized as 0","L_{video}=-\log\frac{\exp\left(OT(V_i,T_i)/\tau\right)}{\sum_{j=1}^{N}\exp\left(OT(V_i,T_j)/\tau\right)}","where \(\operatorname{OT}(\mathbf{V}_i, \mathbf{T}_j)\) denotes the optimal transport distance between video \(\mathbf{V}_i\) and paragraph \(\mathbf{T}_j\), and \(\tau\) is a temperature parameter."
ICLR_2024_oral_53,5,"[S]_{a,b}=\frac{1}{2}(\frac{1}{f}\sum_{i=1}^{f}\alpha\log(\sum_{j=1}^{w}\exp(\frac{v_{a}^{i}\cdott_{b}^{j}}{\alpha}) )+\frac{1}{w}\sum_{i=1}^{w}\alpha\log(\sum_{j=1}^{f}\exp(\frac{t_{b}^{i}\cdotv_{a}^{j}}{\alpha})))",,"[S_{fine}]_{a,b}=\frac{1}{\gamma}\log\sum_{j=1}^{f}\sum_{k=1}^{w}\exp\left(\gamma\cdot s(v_a^j,t_b^k)\right)","where \([\mathbf{S}_{\text{fine}}]_{a,b}\) denotes the fine-grained similarity between clip \(\mathbf{v}_a\) and caption \(\mathbf{t}_b\), \(s(\mathbf{v}_a^j, \mathbf{t}_b^k)\) is the similarity between frame \(j\) in clip \(a\) and word \(k\) in caption \(b\), and \(\gamma\) is a temperature parameter controlling the sharpness of the softmax."
ICLR_2024_oral_53,6,"[\bar{S}]_{a,m+1}=[\bar{S}]_{n+1,b}=[\bar{S}]_{n+1, m+1}=p,\,[\bar{S}]_{a,b}=[S]_{a,b},\\forall a\in[1,n],\b\in[1,m]",,S'=S &p\\p^\top & p,"where \(\mathbf{S}'\) is the augmented similarity matrix with the alignable prompt bucket, \(\mathbf{p}\) is a column vector of value \(p\), and \(p\) is a scalar prompt bucket value."
ICLR_2024_oral_53,7,"\max_{\hat{Q}\in\hat{Q}}\\\\langle\hat{Q},\\hat{S}\rangle+\varepsilon H(\hat{Q})\\\\s.t.\\\\hat{Q}=\{\hat{Q}\inR^{B\times B}_{+}\mid\hat{Q}1_{B}=\frac{1}{B}1_{B},\hat{Q}^{\top}1_{B}=\frac{1}{B}1_{B}\}",where the transport assignment \(\hat{\mathbf{Q}}\) attempts to realign the clips with similar captions (_i,"\hat{Q}^{*}=\arg\max_{Q\inQ}\langleQ,\hat{S}\rangle+\varepsilon H(Q)",where \(\hat{\mathbf{Q}}^{*}\) is the optimal transport assignment for the within-batch clip-caption similarity matrix \(\hat{\mathbf{S}}\).
ICLR_2024_oral_53,8,"L_{clip}=-\sum\limits_{i=1}^{B}\sum\limits_{j=1}^{B}[ T]_{i,j}(\log\frac{\exp([\hat{S}]_{i,j}/\tau)}{\sum_{k=1}^{B}\exp([\hat{S}]_{i,k}/\tau)}+\log\frac{\exp([\hat{S}]_{i,j}/\tau)}{\sum_{k=1}^{B}\exp([\hat{S}]_{i,j}/\tau)}),T=(1-\beta )\,I_{B}+\beta\hat{Q}^{*}",where \(\beta\) is a weighted parameter that balances the identity target \(\mathbf{I}_{B}\) and realigned targets \(\hat{\mathbf{Q}}^{*}\),L_{clip}=-\frac{1}{B}\sum_{i=1}^{B}\sum_{j=1}^{B}\hat{Q}^{*}_{ij}\log\frac{\exp(\hat{S}_{ij}/\tau)}{\sum_{k=1}^{B}\exp(\hat{S}_{ik}/\tau)},"where \(\hat{\mathbf{Q}}^{*}\) is the optimal transport assignment from Eq. (7), \(\hat{\mathbf{S}}_{ij}\) is the similarity between the \(i\)-th clip and \(j\)-th caption, and \(\tau\) is the temperature parameter."
ICLR_2024_oral_54,1,"\min_{S\inR^{N\times d}}D(\nabla_{\theta}\ell(S;\theta),\nabla_{\theta}\ell(B;\theta))=D( S,B;\theta)","where the function \(D(\cdot)\) is defined as a distance metric such as MSE, \(\theta\) represents the model parameters, and \(\nabla_{\theta}\ell(\cdot)\) denotes the gradient, utilizing either the big dataset \(\mathcal{B}\) or its synthetic version \(\mathcal{S}\)","L_{grad}=\sum_{c=1}^{C}\left\|\nabla_\theta\ell(f_\theta(B_c), y_c)-\nabla_\theta\ell(f_\theta(S_c), y_c)\right\|_2^2","\(\mathcal{L}_{\text{grad}}\) is the gradient matching loss that measures the squared Euclidean distance between the gradients of the loss with respect to model parameters on the real and synthetic datasets, summed over all classes \(c\)."
ICLR_2024_oral_54,2,"SarrowS-\lambda\nabla_{S}D( S,B;\theta),\quad\thetaarrow\theta-\eta\nabla_{\theta}\ell(\theta;S)","where \(\lambda\) and \(\eta\) are learning rates designated for \(\mathcal{S}\) and \(\theta\), respectively","S^{(t+1)} &=S^{(t)}-\eta_{S}\nabla_{S} D(S^{(t)},B;\theta^{(t)})\\\theta^{(t+1)} &=\theta^{(t)}-\eta_{\theta}\nabla_{\theta}\ell(S^{(t+1)};\theta^{(t)})","where \(\eta_{\mathcal{S}}\) and \(\eta_{\theta}\) are the learning rates for updating the synthetic dataset and the model parameters, respectively, and \(t\) denotes the iteration step."
ICLR_2024_oral_54,3,"\min_{S\inR^{N\times d}}D(\nabla_{\theta }\ell(S_{[1]},S_{[2]},\ldotsS_{[N]};\theta ),\nabla_{\theta}\ell(B;\theta))","where \(\mathcal{S}_{[n]}=\mathcal{S}_{\{1,2,\ldots,n\}}\subset\mathcal{S}=\mathcal{S}_ {[N]}\) represents \(n_{th}\) subset of the synthetic dataset \(\mathcal{S}\in\mathbb{R}^{N\times d}\)","\min_{S\inR^{N\times d}}\sum_{n=1}^{N}\alpha_n D(S_{[n]},B;\theta)","where \(\mathcal{S}_{[n]}\) denotes a subset of the synthetic dataset of size \(n\), and \(\alpha_n\) is a weighting coefficient for each subset size."
ICLR_2024_oral_54,4,"SarrowS-\lambda(\nabla_{S}D(S,B;\theta)+\nabla_{S_{[n]}}D(S_{[n]},B;\theta)),\hskip 14.226378ptn\in[1,N-1]","where \(\mathcal{S}=\mathcal{S}_{[N]}\) represents the condensed dataset of \(N\) images and is associated with the ""base loss""","S\leftarrowS-\lambda\nabla_{S}\left( D(\nabla_{\theta}\ell(S_{[N]};\theta),\nabla_{\theta}\ell(B;\theta))+\alpha\sum_{n=1}^{N-1} D(\nabla_{\theta}\ell(S_{[n]};\theta),\nabla_{\theta}\ell(B;\theta))\right)","where \(\alpha\) is a balancing hyperparameter for the subset loss, and the update jointly optimizes both the base loss (for the full synthetic set) and the subset losses (for all smaller subsets)."
ICLR_2024_oral_54,5,"F_{t}(S_{[n]},B)=D(f_{t}(S _{[n]}),f_{t}(B))","where \(f_{t}(\cdot)\) is the feature extraction function for \(t_{th}\) condensation iteration, and \(D(\cdot)\) is a distance metric like MSE","d_{feat}^{(t)}(S_{[n]},B)=D(f(S_{[n]};\theta^{(t)}), f(B;\theta^{(t)}))","where \(d_{feat}^{(t)}(\mathcal{S}_{[n]}, \mathcal{B})\) denotes the feature distance at iteration \(t\), \(f(\cdot; \theta^{(t)})\) is the feature extractor parameterized by \(\theta^{(t)}\), and \(D(\cdot)\) is a distance metric such as MSE."
ICLR_2024_oral_54,6,"F_{t}(S_{[p]},B)>F_{t}(S_{[q]},B),\;\;if\;\;\;1<p<q<N",,"F_{t}(S_{[p]},B)>F_{t}(S_{[q]},B),\quad 1<p<q<N",The feature distance between a smaller subset \(\mathcal{S}_{[p]}\) and the big dataset \(\mathcal{B}\) is greater than that between a larger subset \(\mathcal{S}_{[q]}\) and \(\mathcal{B}\) at iteration \(t\).
ICLR_2024_oral_54,7,"\underbrace{F_{t-\Delta t}(S_{[p]},B)>F_{t} (S_{[p]},B)}_{p},\;\;\underbrace{F_{t-\Delta t }(S_{[q]},B)>F_{t}(S_{[q]},B)}_{q}",where \(t-\Delta t\) and \(t\) are two different time points for the condensation process,"F_{t}(S_{[1]},B)>F_{t}(S_{[2]},B)>\cdots>F_{t}(S_{[N-1]},B)","where the feature distance between the smallest subset and the big dataset is the largest, and the feature distance decreases as the subset size increases"
ICLR_2024_oral_54,8,"R(S_{[n]},t)=\frac{\Delta F_{S_{[n]}}}{\Delta t}=\frac{ |F_{t}(S_{[n]},B)-F_{t-\Delta t}(S_{[n]},B)|}{\Delta t}","where \(R(\mathcal{S}_{[n]},t)\) represents the rate of change of feature distance for subset \(\mathcal{S}_{[n]}\) at the time point \(t\), and \(\Delta F_{\mathcal{S}_{[n]}}\) denotes the change in feature distance of subset \(\mathcal{S}_{[n]}\) from time \(t-\Delta t\) to \(t\)","r_{t}(S_{[n]},B)=F_{t-\Delta t}(S_{[n]},B)-F_{t}(S_{[n]},B)","where \(r_{t}(\mathcal{S}_{[n]}, \mathcal{B})\) denotes the feature distance reduction rate for subset \(\mathcal{S}_{[n]}\) at iteration \(t\)."
ICLR_2024_oral_54,9,"S_{MLS}(t)=S_{[n_{t}^{*}]}=\operatorname*{arg\, max}_{S_{[n]}}(R(S_{[n]},t))\;\; where\;\;n\in[1,N-1]",,"n^{*}=\arg\max_{n\in[1,N-1]} R(S_{[n]}, t)","where \(n^{*}\) is the index of the Most Learnable Subset (MLS) at time \(t\), selected as the subset with the highest feature distance reduction rate."
ICLR_2024_oral_54,10,{l}Using Eq.~{\ref{eq:mLS} to~{}}Update&S\\Update&S\setminusS_{MLS}(t-\Delta t)if\;S_{MLS}(t)\supsetS_{MLS}(t-\Delta t),where \(\setminus\) is the symbol for set minus,"S\leftarrowS-\lambda\left(\nabla_{S} D(S,B;\theta)+\nabla_{S_{MLS}} D(S_{MLS},B;\theta)\right), &if  n_t^*\neq n_{t-\Delta t}^*\\S-\lambda\nabla_{S} D(S,B;\theta), &otherwise","where \(n_t^*\) and \(n_{t-\Delta t}^*\) are the indices of the most learnable subset (MLS) at time \(t\) and \(t-\Delta t\), respectively, and the update includes the subset loss only when the MLS changes."
ICLR_2024_oral_55,1,"\operatorname*{arg\,max}_{\theta}\prod_{\bar{D}}p(Y_{Q}|f_ {\theta}(S,X_{Q}))",,"\theta^{*}=\arg\min_{\theta}E_{S,Q\sim\bar{D}}\left[L\left(f_{\theta}(X_{Q}), Y_{Q}\right)\right]","The optimal classifier parameters \(\theta^{*}\) are found by minimizing the expected loss on the query set, given the support and query sets sampled from the task."
ICLR_2024_oral_55,2,"\operatorname*{arg\,max}_{\alpha,\phi}\prod_{\bar{D}_{test}} p(Y_{Q}|f_{\alpha,\phi}(S,X_{Q}))",,"\operatorname*{arg\,max}_{\phi,\alpha}\prod_{\bar{D}_{test}} p\left(Y_{Q}\mid f_{\phi,\alpha}(S, X_{Q})\right)","At meta-test, the objective is to optimise the transferred and adapted parameters \(\phi\) and \(\alpha\) to maximise the likelihood of correct predictions on the query set."
ICLR_2024_oral_55,3,"g_{\phi,\phi^{\prime},\alpha}(x)=g_{\phi,\phi^{\prime}}(x)+h_{\alpha}(x)","where \(x\in\mathbb{R}^{W,H,C}\)","g_{\phi,\alpha}(x)=g_{\phi}(x)+h_{\alpha}(x)",The adapted layer output is the sum of the original layer output \(g_{\phi}(x)\) and the adapter module output \(h_{\alpha}(x)\).
ICLR_2024_oral_55,4,"g_{\phi,\phi^{\prime},\alpha}(x)=z(A_{qkv}[q\;;\;g_{\phi,\phi^{\prime}}(x)]+h _{\alpha 1})+h_{\alpha 2}",where \(x\in\mathbb{R}^{D}\) and \([\cdot\;;\;\cdot]\) denotes the concatenation operation,"A_{\phi,\phi',\alpha}(x)=A_{\phi,\phi'}(x)+h_{\alpha}(x),\quad z_{\phi,\phi',\alpha}(x)=z_{\phi,\phi'}(x)+h_{\alpha}(x)",where \(A_{qkv}\) and \(z\) are augmented with residual adapters \(h_{\alpha}\) in each decoder block.
ICLR_2024_oral_55,5,"L(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\log\frac{e^{-d_{cos}(C_{Q_{i}},f(Q_{i}))}}{\sum_{j=1}^{|C|}e^{-d_{cos}(C_{j},f(Q_{cj}))}}","where \(C_{\mathcal{Q}_{i}}\) denotes the embedding of the class centroid that corresponds to the true class of \(\mathcal{Q}_{i}\), and \(d_{cos}\) denotes the cosine distance","L(f, S, Q)=-\frac{1}{|Q|}\sum_{(x, y)\in Q}\log p\left(y\mid f(S, x)\right)","where \(Q\) is the query set, \(S\) is the support set, \(f\) is the model, and \(p(y \mid f(S, x))\) is the predicted probability of label \(y\) for query \(x\) given support \(S\)."
ICLR_2024_oral_55,6,"\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}\E_{p\sim P}E_{S,Q}\L(f^{p}_{\theta,\alpha,\phi^{\prime}},S,Q)",,"\min_{\theta,\,\alpha,\,\phi^{\prime}}\,E_{p\sim P}\,E_{(S,\,Q)\sim\bar{D}_{train}}\left[L\left(f^{p}_{\theta,\alpha,\phi^{\prime}},\,S,\,Q\right)\right]","where the expectation is over sampled paths \(p\) from the search space \(P\) and episodes \((\mathcal{S},\mathcal{Q})\) from the meta-train set."
ICLR_2024_oral_55,7,"p_{k}=\operatorname*{arg\,max}_{p\in P}E_{S,Q}A(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}},S,Q),\quads.t || \alpha^{*},\phi^{\prime*}=\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}L(f^{p} _{\theta,\alpha,\phi^{\prime}},S,S)",,"(p_{1}^{*},p_{2}^{*},...,p_{N}^{*})=\operatorname*{arg\,min}_{p_{1},...,p_{N}\in P}\sum_{i=1}^{N}E_{S,Q}L(f^{p_{i}}_{\theta,\alpha,\phi^{\prime}},S,Q)","where \((p_{1}^{*},p_{2}^{*},...,p_{N}^{*})\) denotes the optimal set of \(N\) paths (models) selected from the search space \(P\) by minimising the expected loss over episodes."
ICLR_2024_oral_55,8,"\quad\forall_{j=1,\dots,k-1}\\d_{cos}(p_{k},p_{j})\geq T",,"p^{*}=\operatorname*{arg\,max}_{p\in (p_{1},\ldots,p_{N})} A(f^{p}_{\theta,\alpha^{*},\phi^{\prime*}},S,Q)",The optimal path \(p^{*}\) at test time is selected from the pre-selected set by maximising the adaptation performance \(A\) on the given support and query sets.
ICLR_2024_oral_55,9,"A(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}[\operatorname*{arg\,min}_{j}d_{cos}(C_{Q_{j}},f(Q_{i}))=Y_ {Q_{i}}]",,"A(f^{p}_{\theta,\alpha,\phi^{\prime}},S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}I\left[\underset{l}{arg\,min}\d_{cos}(C_l, f^{p}_{\theta,\alpha,\phi^{\prime}}(Q_i))=y_{Q_i}\right]","where \(\mathbb{I}[\cdot]\) is the indicator function, \(C_l\) is the class centroid for class \(l\), and \(y_{\mathcal{Q}_i}\) is the true label of query sample \(\mathcal{Q}_i\)."
ICLR_2024_oral_55,10,"p^{*}=\operatorname*{arg\,min}_{p\in\{p_{1},...,p_{N}\}}L(f^{p}_{O_{\alpha^{*}},\phi^{\prime\prime*}},S,S),\quads.t || \alpha^{*},\phi^{\prime*}=\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}L(f^{p}_{O,\alpha,\phi^{\prime}},S,S)",,"p^{*}=\operatorname*{arg\,max}_{p\in\{p_1,\ldots, p_N\}} A(f^p_{\theta,\alpha',\phi''},S,Q)",The final path \(p^{*}\) is selected from the pre-chosen set by maximising the accuracy \(A\) on the support and query sets for each meta-test episode.
ICLR_2024_oral_56,1,"\vec{x}_{n}&=A\vec{x} _{n-1}+Bu_{n}&A\inC^{N\times N},B\inC^{N\times 1}\\y_{n}&=C\vec{x}_{n}&C\inC^{1\times N}",,\vec{x}_{n+1} &=A\vec{x}_n+B u_n\\y_n &=C\vec{x}_n+D u_n,"State Space Models (SSMs) update the hidden state vector $\vec{\mathbf{x}}_n$ and output $y_n$ at each timestep $n$ using learned matrices $\mathbf{A}$, $\mathbf{B}$, $\mathbf{C}$, and $\mathbf{D}$ applied to the previous state and current input $u_n$."
ICLR_2024_oral_56,2,A=A-PQ^{\star} || \bar{A}=(I-\Delta/2\cdotA)^{-1}(I+\Delta/2\cdotA),,K_{k}=C^{T}A^{k}B,"The kernel \(K_k\) at lag \(k\) is defined as the product of \(\mathbf{C}^{T}\), \(\mathbf{A}^{k}\), and \(\mathbf{B}\)."
ICLR_2024_oral_56,3,\bar{B}=(I-\Delta/2\cdotA)^{-1}\DeltaB\quad\bar{C}=C,,K_{k}=C^{T}A^{k}B,"The kernel \(K_k\) is defined as the product of \(\mathbf{C}^{T}\), \(\mathbf{A}\) raised to the \(k\)th power, and \(\mathbf{B}\)."
ICLR_2024_oral_56,4,K_{k}=\bar{C}^{T}\bar{A}^{k}\bar{B},"where \(\mathbf{A},\mathbf{P},\mathbf{Q},\mathbf{B},\mathbf{C},\Delta\) are learnable parameters and \(\mathbf{A}\in\text{{Diag}}(\mathbb{C}^{N\times N}),\mathbf{P},\mathbf{Q}\in\mathbb{C}^{N \times 1}\)","\bar{K}_k=\bar{C}\,\bar{A}^k\,\bar{B}","The discrete-time kernel \(\bar{K}_k\) is computed using the transformed parameters \(\mathbf{\bar{A}}, \mathbf{\bar{B}}, \mathbf{\bar{C}}\)."
ICLR_2024_oral_56,5,"\vec{x}_{n}&=A\vec{x} _{n-1}+I\,u_{n}&A\in{diag}(C^{N\times N })\\y_{n}&=C\vec{x}_{n}&C\inC^{1\times N}",where \(\mathbf{I}\) is the all-ones vector,\vec{x}_{n} &=D\vec{x}_{n-1}+E u_{n}\\y_{n} &=F\vec{x}_{n},"where \(\mathbf{D}\in\mathbb{C}^{N\times N}\) is diagonal, \(\mathbf{E}\in\mathbb{C}^{N\times 1}\), and \(\mathbf{F}\in\mathbb{C}^{1\times N}\) are learnable parameters."
ICLR_2024_oral_58,1,"\mu_{m,k}\triangleqE_{(x,y)\simG}[\upsilon_{m,k}(x) ],\\sigma_{m,k}^{2}\triangleqE_{(x,y)\simG}[(\upsilon_{m,k}(x)-\mu_{m,k})^{2}]",,"\mu_{m,k}=\frac{1}{N}\sum_{i=1}^{N}\Phi_{m,k,i}^{proj},\quad\sigma_{m,k}^2=\frac{1}{N}\sum_{i=1}^{N}\left(\Phi_{m,k,i}^{proj}-\mu_{m,k}\right)^2","The mean \(\mu_{m,k}\) and variance \(\sigma_{m,k}^2\) of the \(k^{\text{th}}\) projected feature for model \(f_m\) are computed over \(N\) samples."
ICLR_2024_oral_58,2,"\rho_{(i,j),(a,b)}\triangleqE_{(x,y)\simG}[(\upsilon_{i,a}(x)-\mu_{i,a})(\upsilon_{j,b}(x)-\mu_{j,b}) ](\sigma_{i,a}\\sigma_{j,b})^{-1}",,"\rho_{i,a;j,b}\triangleq\frac{E_{(x,y)\simG}\left[(\upsilon_{i,a}(x)-\mu_{i,a})(\upsilon_{j,b}(x)-\mu_{j,b})\right]}{\sigma_{i,a}\sigma_{j,b}}","\(\rho_{i,a;j,b}\) denotes the correlation between the \(a^{\text{th}}\) feature of model \(f_i\) and the \(b^{\text{th}}\) feature of model \(f_j\)."
ICLR_2024_oral_58,3,Acc=p_{d}(1-\frac{1}{2}\binom{t_{d}-c_{d}}{a_{d}}\\\binom{t_{d}}{a_{d}}^{+}p_{r}(1-\frac{1}{2}\binom{t_{r}-c_{r}}{c_{r}}\\\binom{t_{r}}{c_{r}}),,Acc=p_{d}\left[1-\frac{\binom{t_{d}-c_{d}}{n_{d}}}{\binom{t_{d}}{n_{d}}}\right]+p_{r}\left[1-\frac{\binom{t_{r}-c_{r}}{n_{r}}}{\binom{t_{r}}{n_{r}}}\right],"The expected accuracy is the weighted sum over dominant and rare data, where each term is one minus the probability that a model shares no features with a data point of that type."
ICLR_2024_oral_59,1,\Pr[A(D)\in R]\leq e^{\epsilon}\Pr[A(D^{\prime})\in R]+\delta,,\[\Pr[A(D)\in R]\leq e^{\epsilon}\Pr[A(D')\in R]+\delta\],"This equation defines user-level \((\epsilon, \delta)\)-differential privacy for a training algorithm \(A\), stating that the probability of any output region \(R\) does not change significantly when the data of a single user is added or removed."
ICLR_2024_oral_59,2,"\hat{\epsilon}=\max\{\log\frac{1-\delta-FPR}{FNR},\log\frac{1-\delta-FNR}{FPR}\}",,\delta=\inf_{S\subseteqR}\left\{\Pr[A(D)\in S]-e^{\epsilon}\Pr[A(D')\in S]\right\},"\(\delta\) is the minimal slack required to satisfy \((\epsilon, \delta)\)-differential privacy, expressed as the infimum over all measurable subsets \(S\) of the output space \(\mathcal{R}\)."
ICLR_2024_oral_59,3,f_{d}(t)=\frac{\Gamma(\frac{d}{2})}{\Gamma(\frac{d-1}{2})\sqrt{\pi}}(1-t^{2})^{\frac{d-3}{2}},,"f_{d}(t)=\frac{\Gamma(d/2)}{\sqrt{\pi}\,\Gamma((d-1)/2)}(1-t^{2})^{(d-3)/2},\quad t\in[-1,1]",\(f_{d}(t)\) is the probability density function of the cosine similarity between a random unit vector in \(\mathbb{R}^{d}\) and an independent nonzero vector.
ICLR_2024_oral_6,1,"\epsilon_{k}(x)\mathop{=}^{def}u_{k}(\texttt{BR}_{k},x_{-k})-u_{k}(x) where \texttt{BR}_{k}\in\operatorname*{arg\,max}_{z}u_{k}(z,x_{-k})",,"\max_{i\in N}\max_{s_i'\in S_i}\left[ u_i(s_i', s_{-i})-u_i(s_i, s_{-i})\right]",The maximum gain any player $i$ can achieve by unilaterally deviating from their current strategy $s_i$ to another strategy $s_i'$ given the strategies $s_{-i}$ of the other players.
ICLR_2024_oral_6,2,L(x)=\sum_{k}\eta_{k} || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || ^{2},"where each \(\eta_{k}>0\) represents a scalar weight, or equivalently, a step size to be explained next",L_{PGN}(x)=\sum_{k=1}^{n}\left\| P_{T\Delta^{m_k-1}}\nabla_{x_k} u_k(x)\right\|^2,$\mathcal{L}_{\text{PGN}}(\boldsymbol{x})$ is the sum over players of the squared norm of the projected gradient of each player's utility onto the tangent space of their simplex.
ICLR_2024_oral_6,3,\epsilon_{k}(x)\leq\sqrt{2} || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || ,,\epsilon_{k}(x)\leq\eta_{k}\left\|\Pi_{T\Delta}(\nabla_{x_{k}}^{k})\right\|^{2},The exploitability of player \(k\) at joint strategy \(\mathbf{x}\) is upper bounded by a constant times the squared norm of the projected gradient.
ICLR_2024_oral_6,4,\epsilon\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L(x)}\stackrel{{\tiny def}}{{=}}f(L),,\epsilon(x)\leq\sqrt{2\sum_{k}\eta_{k}^{-1}L(x)},"The exploitability \(\epsilon(\mathbf{x})\) is upper bounded by a function of the loss \(\mathcal{L}(\mathbf{x})\), weighted by the inverse step sizes \(\eta_{k}^{-1}\)."
ICLR_2024_oral_6,5,L(x)=E[\sum_{k}\eta_{k}\underbrace{(\hat{\nabla}_{x_{ k}}^{k(1)}-\frac{1}{m_{k}}(1^{\top}\hat{\nabla}_{x_{k}}^{k(1)}))}_{ projected-gradient 1})^{\top}(\underbrace{\hat{\nabla}_{x_{k}}^{k(2)}-\frac{1}{m_{k}}(1^{\top}\hat{\nabla}_{x_{k}}^{k(2)})1)}_{projected-gradient 2}),where \(\hat{\nabla}^{k(p)}_{x_{k}}\) is an unbiased estimator of player \(k\)'s gradient,"E\left[\left\langle\Pi_{T\Delta}(\nabla_{x_{k}}^{k(1)}),\Pi_{T\Delta}(\nabla_{x_{k}}^{k(2)})\right\rangle\right]=\left\|E\left[\Pi_{T\Delta}(\nabla_{x_{k}}^{k})\right]\right\|^2",The expected inner product of two independent projected-gradient estimates equals the squared norm of the expected projected-gradient.
ICLR_2024_oral_6,6,L^{\tau}(x)=\sum_{k}\eta_{k} || \Pi_{T\Delta}(\nabla^{k\tau}_{x_ {k}}) || ^{2},,L^{\tau}(x)=E\left[\sum_{k}\eta_{k}\left(\left(\hat{\nabla}_{x_{k}}^{k(1)}+\tau\frac{dS}{dx_{k}}-\frac{1}{m_{k}}\left(1^{\top}(\hat{\nabla}_{x_{k}}^{k(1)}+\tau\frac{dS}{dx_{k}})\right)\right)^{\top}\left(\hat{\nabla}_{x_{k}}^{k(2)}+\tau\frac{dS}{dx_{k}}-\frac{1}{m_{k}}\left(1^{\top}(\hat{\nabla}_{x_{k}}^{k(2)}+\tau\frac{dS}{dx_{k}})\right)\right)\right)\right],where the projected-gradient estimator for each player \(k\) is augmented with the entropy gradient \(\tau \frac{dS}{dx_{k}}\).
ICLR_2024_oral_6,7,\epsilon_{QRE}\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L^{\tau}(x)}\overset{\tiny{def}}{=}f(L^{\tau}),,\epsilon_{QRE}\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L^{\tau}(x)}\stackrel{{\tiny def}}{{=}} f(L^{\tau}),where \(\epsilon_{QRE}\) is the exploitability in the entropy-regularized game and \(\mathcal{L}^{\tau}(\mathbf{x})\) is the entropy-regularized loss.
ICLR_2024_oral_6,8,\epsilon\leq\tau\log\Big{(}\prod_{k}m_{k}\Big{)}+\sqrt{\frac{2n}{\min_{k}\eta_ {k}}}\sqrt{L^{\tau}(x)}\overset{\tiny{def}}{=} f_{\tau}(L^{\tau}),,L^{\tau}(x)\to 0\implies\epsilon(x)\to 0,"If the entropy-regularized loss \(\mathcal{L}^{\tau}(\mathbf{x})\) approaches zero, then the exploitability \(\epsilon(\mathbf{x})\) in the original game also approaches zero."
ICLR_2024_oral_6,9,\nabla_{x_{l}}L^{\tau}(x)=2\sum_{k}\eta_{k}B_{kl}^{\top}\Pi_{T\Delta}(\nabla_{x_{k}}^{kT}),,\nabla_{x_{l}}L^{\tau}(x)=2\eta_{l}\nabla_{x_{l}}^{l\tau}-\frac{2\eta_{l}}{m_{l}}1 (1^{\top}\nabla_{x_{l}}^{l\tau}),"The gradient of the entropy-regularized loss \(\mathcal{L}^{\tau}(\mathbf{x})\) with respect to player \(l\)'s strategy \(x_{l}\) is given by the above expression, where \(\nabla_{x_{l}}^{l\tau}\) is the entropy-regularized gradient for player \(l\)."
ICLR_2024_oral_6,10,\textsl{Hess}(L^{\tau})=2\big{[}\tilde{B}^{\top}\tilde{B}+T\Pi_{T\Delta}(\tilde{\nabla}^{\tau})\big{]},,"\nabla^{2}_{x_{l},x_{j}}L^{\tau}(x)=2\sum_{k}\eta_{k}\left[ B_{kl}^{\top} B_{kj}+\delta_{kj} C_{kl}\right]","where \(B_{kl}\) and \(C_{kl}\) are as defined in the context, and \(\delta_{kj}\) is the Kronecker delta."
ICLR_2024_oral_6,11,"M(x)=-\sqrt{\eta_{1}}\Pi_{T\Delta}(\frac{1}{x_{1}})&\sqrt{\eta_{1}}\Pi_{T\Delta}(H^{1}_{12})&\ldots&\sqrt{\eta_{1}}\Pi_{T\Delta}(H^{1}_{ 1n})\\\vdots&\vdots&\vdots&\vdots\\\sqrt{\eta_{n}}\Pi_{T\Delta}(H^{n}_{n1})&\ldots&\sqrt{\eta_{n}}\Pi_{T\Delta}( H^{n}_{n,n-1})&-\tau\sqrt{\eta_{n}}\Pi_{T\Delta}(\frac{1}{x_{n}})\\1_{1}^{\top}&0&\ldots&0\\\vdots&\vdots&\vdots&\vdots\\0&\ldots&0&1_{n}^{\top}",where \(\Pi_{T\Delta}(z\in\mathbb{R}^{n\times b})=[I_{a}-\frac{1}{a}\mathbf{_{1}}\mathbf{_{ 1}}^{\top}]z\) subtracts the mean from each column of \(z\) and \(\frac{1}{x_{k}}\) is shorthand for \(\texttt{diag}\big{(}\frac{1}{x_{k}}\big{)}\),\textsl{Hess}(L^{\tau})=2M^{\top}M+2T\Pi_{T\Delta}(\tilde{\nabla}^{\tau}),"The Hessian of the loss \(\mathcal{L}^{\tau}\) is given by \(2M^{\top}M+2T\Pi_{T\Delta}(\tilde{\nabla}^{\tau})\), where \(M\) augments \(\tilde{B}\) with a repeated identity matrix encoding orthogonality to the simplex."
ICLR_2024_oral_60,1,y_{i}^{\prime}=I_{\tau}(h)(x_{i}),,y_{i}^{\prime}=I_{\tau}(h)(x_{i}),Predicted output \(y_{i}^{\prime}\) is obtained by applying the interpreted rule \(I_{\tau}(h)\) to input \(x_{i}\).
ICLR_2024_oral_60,2,"a_{\tau}=\frac{1}{|D_{\tau}^{u}|}\sum_{(x,y)\inD_{\tau}}\mathbbm{1}\big{[}I_{\tau}(h)(x)=y\big{]}",,Acc_{\tau}(h)=\frac{1}{n}\sum_{i=1}^{n}I\left[y_{i}^{\prime}=y_{i}\right],Task accuracy is the fraction of unseen examples for which the induced rule's prediction matches the ground truth.
ICLR_2024_oral_60,3,c=\frac{1}{|T|}\sum_{\tau\inT}a_{\tau}\hskip 28.452756ptc_{t}=\frac{1}{|T|}\sum_{\tau\inT}\mathbbm{1}\big{[}a_{\tau}=1\big{]},,"c=\frac{1}{\sum_{\tau\inT} |D_{\tau}^{u}|}\sum_{\tau\inT}\sum_{(x, y)\inD_{\tau}^{u}}\mathbbm{1}\big[I_{\tau}(h)(x)=y\big]",Raw accuracy \(c\) is the proportion of all unseen examples across all tasks that are correctly predicted by the induced rule \(h\).
ICLR_2024_oral_60,4,"h^{t}\sim P_{LM}\big{(}\cdot\,|d^{t-1},x_{1},y_{1},...,x_{k},y_{k})",where \(d^{t-1}\) is the feedback from previous iterations and which is set to be an empty string at the initial iteration,"H^{t}=\{ h_{1}^{t}, h_{2}^{t},\ldots, h_{N}^{t}\}",$H^{t}$ denotes the set of $N$ hypotheses (rules) generated by the LM at iteration $t$.
ICLR_2024_oral_60,5,"s(h,D_{\tau}^{s})=\frac{1}{|D_{\tau}^{s}|}\sum_{(x,y)\inD_{\tau}^{s}}\mathbbm{1}\big{[}I_{\tau}(h)(x)=y\big{]}",,"s(h,D_{\tau}^{s})=\frac{1}{|D_{\tau}^{s}|}\sum_{(x, y)\inD_{\tau}^{s}}\mathbbm{1}\big[ I_{\tau}(h)(x)=y\big]","where \(s(h, \mathcal{D}_{\tau}^{s})\) is the accuracy of rule \(h\) over the seen examples \(\mathcal{D}_{\tau}^{s}\)."
ICLR_2024_oral_60,6,"h^{t^{*}}=\operatorname*{arg\,max}_{h^{\prime}\in H^{t}}s(h^{\prime}, D_{\tau}^{s})",,"h^{*}=\arg\max_{h\in H^{t}} s(h,D_{\tau}^{s})",where \(h^{*}\) is the hypothesis in \(H^{t}\) with the highest score on the seen examples.
ICLR_2024_oral_61,1,"P(a_{t:t+k}|s_{t},s^{g})=\int_{s_{t+1},\ldots,s_{t+k}}ds_{t+1}\ldots ds_{t+k}\prod_{i=t}^{t+k}P_{\phi}(a_{i}|s_{i},s^{g})P(s_{i+1}|s_{i},a_{i})",where \(s^{g}\in S\) is the goal state,"a_t\sim P_{\phi}(a_t\mid z_t, g)",The goal-conditioned policy \(P_{\phi}\) predicts the action \(a_t\) at time \(t\) given the current state embedding \(z_t\) and the goal \(g\).
ICLR_2024_oral_61,2,"L(\phi)=E_{D}[-\log P_{\phi}(a_{i}|s_{i},s^{g})]",,"L_{BC}=-E_{(s_{i}, a_{i}, s^{g})\simD}\left[\log P_{\phi}(a_{i}\mid s_{i}, s^{g})\right]",where \(\mathcal{L}_{\text{BC}}\) is the behavior cloning loss for training the goal-conditioned policy.
ICLR_2024_oral_61,3,L(\psi)=E_{D}[-\log\pi^{p}_{\psi}(a^{h}|s_{t})],,L(\psi)=E_{D}\left[-\log\pi^{p}_{\psi}(a^{h}|s)\right],where \(\pi^{p}_{\psi}(a^{h}|s)\) is the probability assigned by the goal prior model to the goal cluster index \(a^{h}\) given state \(s\).
ICLR_2024_oral_61,4,"J(\theta)=E\pi_{\theta}[\sum_{t=0}^{\infty}\gamma^{t}(\sum _{i=kt}^{(k+1)t}R(s_{i},a_{i})-\alpha D_{KL}(\pi^{p}_{\psi}(a^{h }|s_{kt})\|\pi_{\theta}(a^{h}|s_{kt})))]",where \(t\) represents the number of steps for the high-level policy and \(\alpha\) is a hyperparameter balancing the environmental rewards and the intrinsic rewards,J(\theta)=E_{\pi_{\theta}}\left[\sum_{t=0}^{T}\gamma^{t} (r_{t}+\alpha r^{intr}_{t})\right],"where \(r_{t}\) is the environment reward, \(r^{\text{intr}}_{t}\) is the intrinsic reward from the goal prior model, \(\gamma\) is the discount factor, and \(\alpha\) is a weighting coefficient for the intrinsic reward."
ICLR_2024_oral_63,1,p_{\theta}(x)\propto e^{-f_{\theta}(x)},,p_{\theta}(x)=\frac{\exp(-f_{\theta}(x))}{Z_{\theta}},"The probability density function of the EBM, where \(Z_{\theta}\) is the partition function."
ICLR_2024_oral_63,2,"x_{k+1}=x_{k}-\delta\,\nabla f_{\theta}(x_{k})+\sqrt{2\delta}\,\varepsilon_{k },\,\varepsilon_{k}\simN(0,I_{d})","where \(\nabla\) denotes the gradient of the energy function with respect to inputs, \(k\) is the sampling step, \(\delta\) is the (discretization) step size, and the noise \(\varepsilon_{k}\) is drawn from the normal distribution at each step","x_{k+1}=x_k-\frac{\lambda}{2}\nabla_x f_{\theta}(x_k)+\sqrt{\lambda}\,\epsilon_k","Here, \(x_k\) is the current sample, \(\lambda\) is the step size, and \(\epsilon_k \sim \mathcal{N}(0, I)\) is Gaussian noise."
ICLR_2024_oral_63,3,\hat{x}(y)=y+\sigma^{2}\nabla\log p(y),where \(p(y)=\int p(y|x)p(x)dx\) is the probability distribution function of the smoothed density,\hat{x}(y)=y+\sigma^2\nabla_y\log p_Y(y),"where \(\hat{x}(y)\) is the least-squares estimator of \(X\) given \(Y=y\), \(\sigma^2\) is the noise variance, and \(p_Y(y)\) is the probability density of the noisy variable \(Y\)."
ICLR_2024_oral_63,4,\hat{x}_{\phi}(y)=y+\sigma^{2}g_{\phi}(y),,\hat{x}_{\phi}(y)=y+\sigma^{2} g_{\phi}(y),where \(g_{\phi}(y)\) is a neural network approximation of the score function \(\nabla\log p(y)\).
ICLR_2024_oral_63,5,"L(\phi)=E_{x\sim p(x),y\sim p(y|x)}\|x-\hat{x}_{\phi}(y)\|^ {2}",,L(\phi)=E_{p_{X}(x)}E_{p_{\sigma}(y|x)}\left[\left\|x-\hat{x}_{\phi}(y)\right\|^{2}\right],where \(\mathcal{L}(\phi)\) is the expected squared error between the true data \(x\) and its estimate \(\hat{x}_{\phi}(y)\) under the noisy observation model.
ICLR_2024_oral_63,6,"\operatorname*{arg\,max}_{\theta}E_{y\sim p_{Y}}[\log p_{\theta}( y)]=\operatorname*{arg\,max}_{\theta}(E_{y^{-}\sim p_{Y}(y)}[f_{\theta}(y^{-})]-E_{y^{+}\sim p_{Y}}[f_{\theta}(y^{+})])",where \(y^{+}\) are noisy training data and \(y^{-}\) are noisy data sampled from the model,\max_{\theta}\;E_{y\sim p(y)}\left[\log p_{\theta}(y)\right],where \(p_{\theta}(y)\) is the model likelihood of noisy data \(y\) under parameters \(\theta\).
ICLR_2024_oral_63,7,\nabla_{\theta}\log p_{\theta}(y)=-\nabla_{\theta}f_{\theta}(y)-\nabla_{\theta}\log Z(\theta) || =-\nabla_{\theta}f_{\theta}(y)+\frac{\int\nabla_{\theta}f_{\theta}(y)e^{-f_{\theta}(y)}dy}{Z(\theta)} || =-\nabla_{\theta}f_{\theta}(y)+\int\nabla_{\theta}f_{\theta}(y)\cdot p_{\theta}(y)dy || =-\nabla_{\theta}f_{\theta}(y)+E_{y\sim p_{\theta}(y)}[\nabla_{\theta}f_{\theta}(y)],,E_{y\sim p_{Y}}[\log p_{\theta}(y)]=E_{y\sim p_{Y}}[f_{\theta}(y)]-\log Z_{\theta},where \(Z_{\theta} = \int e^{f_{\theta}(y)} dy\) is the partition function of the energy-based model.
ICLR_2024_oral_63,8,"P^{\top}argmax\,\hat{x}(y,t)=P^{\top}s",,P_{C}(x)=Proj_{C}(x)=Mx+(I-M)x_0,"where \(M\) is a binary projection matrix, \(x_0\) is a reference sequence, and \(P_{\mathcal{C}}(x)\) projects \(x\) onto the constraint set \(\mathcal{C}\) by preserving the constrained positions from \(x\) and filling unconstrained positions from \(x_0\)."
ICLR_2024_oral_63,9,\chi_{ii^{\prime}}=\frac{ || X_{i}-X_{i^{\prime}} || }{2\sqrt{d}},where \(d\) is the dimension of the data and the \(\frac{1}{2\sqrt{d}}\) scaling comes from the concentration of isotropic Gaussians in high dimensions,\chi_{ij}=E_{x\sim p(x)}\left[ (x_i-E[x_i])(x_j-E[x_j])\right],where \(\chi_{ij}\) is the covariance between the \(i\)th and \(j\)th entries of the one-hot encoded sequence \(x\).
ICLR_2024_oral_63,10,\sigma_{c}=\max_{ii^{\prime}}\chi_{ii^{\prime}},,\sigma_{c}=\min_{i\neq i'}\chi_{ii'},"where \(\sigma_{c}\) is the minimum pairwise normalized distance between data points, serving as a lower bound for the noise level."
ICLR_2024_oral_64,1,Z_{k}\subseteqR^{M}\quadand\quadZ=Z_{1}\times\dots\timesZ_{K}\subseteqR^{KM},,"Z=Z_1\timesZ_2\times\cdots\timesZ_K,\quadwhere\quadZ_k\subseteqR^M","The latent space \(\mathcal{Z}\) is the Cartesian product of \(K\) slot subspaces \(\mathcal{Z}_k\), each of dimension \(M\)."
ICLR_2024_oral_64,2,"x=f(z),\quadz\sim p_{z},\quadsupp(p_{z })=Z^{S}",,"z\simUnif(Z^{S}),\quadx=f(z)","Latent vectors \(\mathbf{z}\) are sampled uniformly from the slot-supported subset \(\mathcal{Z}^{S}\), and observations \(\mathbf{x}\) are generated by applying the generator \(\mathbf{f}\) to \(\mathbf{z}\)."
ICLR_2024_oral_64,3,"L_{rec}(X^{S})=L_{rec}\big{(}\hat {g},\hat{f},X^{S}\big{)}:=E_{x\sim p_{x }}\big{[}\big{\|}\hat{f}\big{(}\hat{g}(x)\big{)}-x\big{\|} _{2}^{2}\big{]},\quadsupp(p_{x})=X^{S}",,"\min_{\hat{f},\,\hat{g}}\;E_{x\simX^{S}}\left[\left\|x-\hat{f}\left(\hat{g}(x)\right)\right\|^{2}\right]",The autoencoder is trained by minimizing the expected squared reconstruction error over the training data space \(\mathcal{X}^{S}\).
ICLR_2024_oral_64,4,"\frac{\partialf_{n}}{\partialz_{k}}(z)\neq 0\implies\frac{\partialf_{n}}{\partialz_{j}}(z)=0,\quadfor any $k,j\in[K]$, $k\neq j$ and any $n\in[N]$.",,"\forall i\in[N],\\exists k\in[K]\such that\\frac{\partial f_{i}}{\partialz_{l}}(z)=0\quad\forall l\neq k","Each output dimension \(f_i\) of the generator \(\mathbf{f}\) depends locally on at most one latent slot \(\mathbf{z}_k\), i.e., its partial derivatives with respect to all other slots vanish."
ICLR_2024_oral_64,5,"z^{\prime}=\big{(}h_{1}(z_{\pi(1)}),\ldots,h_{K}(z_{\pi(K)})\big{)},\quadZ^{\prime}=h_{1}(Z_{\pi(1)})\times\cdots\timesh_{K}(Z_{\pi(K)})",,"Z^{\prime}:=\big\{\,(h_{1}(z_{\pi(1)}),\ldots,h_{K}(z_{\pi(K)}))\;\big|\;(z_{1},\ldots,z_{K})\inZ\,\big\}","The set \(\mathcal{Z}^{\prime}\) consists of all possible slot-wise recombinations of the inferred latent slots, where each slot is mapped by its corresponding diffeomorphism \(\mathbf{h}_{k}\) to the inferred latent space."
ICLR_2024_oral_64,6,\hat{g}\big{(}f(z)\big{)}=z^{\prime}\quadand\quad\hat{f}(z^{\prime})=f(z),,"\hat{f}\big(h_{1}(z_{\pi(1)}),\ldots,h_{K}(z_{\pi(K)})\big)=f(z)",The decoder \(\hat{\mathbf{f}}\) applied to the slot-wise transformed latent vector recovers the ground-truth generator output for any \(\mathbf{z}\in\mathcal{Z}\).
ICLR_2024_oral_64,7,"\hat{f}(z)=\sum_{k=1}^{K}\varphi_{k}(\hat{z}_{k}),\quadwhere \varphi_{k}:R^{M}\toR^{N} for any k\in[K] and \hat{z}\inR^{KM}",,\hat{f}(\hat{z})=\sum_{k=1}^{K}\hat{f}_{k}(\hat{z}_{k}),"The decoder is additive if it can be written as a sum of slot-wise functions, each depending only on the corresponding latent slot."
ICLR_2024_oral_64,8,"L_{cons}\big{(}\hat{g},\hat{f},Z^{\prime}\big{)}=E_{z^{\prime}\sim q_{z^{\prime}}}\Big{[}\big{\|}\hat{g}\big{(}\hat{f}(z^{\prime})\big{)}-z^{\prime}\big{\|} _{2}^{2}\Big{]}",,"L_{cons}(\hat{g},\hat{f}) :=E_{z^{\prime}\sim q_{z^{\prime}}}\left[\left\|\hat{g}\big(\hat{f}(z^{\prime})\big)-z^{\prime}\right\|_2^2\right]",The compositional consistency loss measures how well the encoder inverts the decoder on recombined slot latents sampled from the full recombined latent space \(\mathcal{Z}^{\prime}\).
ICLR_2024_oral_64,9,"L_{rec}\big{(}\hat{g},\hat{f},X^{S}\big{)}+\lambdaL_{cons}\big{(}\hat{g},\hat{f},Z ^{\prime}\big{)}=0,\qquadfor some \lambda>0",,"\min_{\hat{g},\hat{f}}\L_{rec}(X^{S})+\lambda\,L_{cons}(Z^{\prime})","The autoencoder parameters are optimized by minimizing the sum of the reconstruction loss on the training space and the compositional consistency loss on the recombined latent space, weighted by a hyperparameter \(\lambda\)."
ICLR_2024_oral_64,10,"\hat{f}(z)=\sum_{k=1}^{K}\tilde{m}_{k}\odotx_{k},\qquad\tilde{m}_{k}=\sigma(m)_{k},\qquad(m_{k},x_{k})=\varphi _{k}(z_{k})",where \(\odot\) is an element-wise multiplication and \(\sigma(\cdot)\) denotes the softmax function,\hat{f}(\hat{z})=\sum_{k=1}^{K}m_{k}(\hat{z}_{k})\odot\varphi_{k}(\hat{z}_{k}),"The decoder outputs a sum of slot-wise images, each modulated by a slot-specific mask."
ICLR_2024_oral_64,11,h_{k}(z_{\pi(k)})=\hat{g}_{k}\big{(}f(z)\big{)}\quadand\quadZ^{\prime}=\hat{g}_{1}(X^{S})\times\cdots\times\hat{g}_{K}(X^{S}),,"Z^{\prime}=\hat{Z}_{1}\times\cdots\times\hat{Z}_{K},\qquad\hat{Z}_{k} :=\big\{\hat{z}_{k}\mid\hat{z}=\hat{g}(x),\x\inX^{S}\big\}",where \(\hat{\mathcal{Z}}_{k}\) is the set of inferred slot values for the \(k\)-th slot over the training data.
ICLR_2024_oral_64,12,"z^{\prime}=\big{(}\hat{z}^{(\rho_{1})}_{1},\ldots,\hat{z}^{(\rho _{K})}_{K}\big{)},\quadwhere for i\in\{1,2\}\quad\hat{z}^{(i)}=\hat{g}\big{(}x^{(i)}\big{)},\,x^{(i)}\sim p_{z}",,"z^{\prime}=\big(\hat{z}^{(\rho_1)}_1,\ldots,\hat{z}^{(\rho_K)}_K\big),\qquad\rho_k\simU\{1,2\}","where \(\mathbf{z}^{\prime}\) is formed by slot-wise recombination of two inferred ID latents \(\hat{\mathbf{z}}^{(1)}\) and \(\hat{\mathbf{z}}^{(2)}\), with each slot \(k\) chosen independently from either sample."
ICLR_2024_oral_66,1,"\theta^{*}\:=\\operatorname*{arg\,min}_{\theta}\E_{(x,t,\ell(x,t),\cdot)\simH}\\Big{[}-\log p(\ell(x,t)\mid x,t,\hat{\ell}(x,t;\theta))\Big{]}",,"\theta^{*}=\arg\min_{\theta}\sum_{i=1}^{n}\left(\hat{\ell}(x_i, t_i;\theta)-\ell(x_i, t_i)\right)^2",The optimal surrogate parameters \(\theta^*\) minimize the squared error between the surrogate's predicted performance and the observed performance over all \(n\) learning curve observations.
ICLR_2024_oral_66,2,"\gamma^{*}\:=\\operatorname*{arg\,min}_{\gamma}\E_{(x,t,\cdot,c(x,t))\simH}\\Big{[}c(x,t)-\hat{c}(x,t;\gamma)\Big{]}^{2}",,"\gamma^{*} :=\operatorname*{arg\,min}_{\gamma}\E_{(x,t,\cdot,c(x,t))\simH}\\left[\left( c(x,t)-\hat{c}(x,t;\gamma)\right)^2\right]","The optimal cost estimator parameters \(\gamma^*\) minimize the expected squared error between the true cost \(c(x,t)\) and the predicted cost \(\hat{c}(x,t;\gamma)\) over the observed history \(\mathcal{H}\)."
ICLR_2024_oral_66,3,"x^{*}:=\operatorname*{arg\,max}_{x\inX}\frac{EI(x,H,\hat{\ell}(x,\tau(x)))}{\hat{c}\Big{(}x,\tau(x)\Big{)}{-}c\Big{(}x,\tau(x)-\Delta t\Big{)}}=\operatorname*{arg\,max}_{x\inX}\frac{E_{\hat{\ell}(x,\tau(x))}[\max(\ell_{\tau(x)}^{\min}-\hat{\ell}(x,\tau(x)),0)]}{\hat{c}\Big{(}x,\tau(x){-}c\Big{(}x,\tau(x){-}\Delta t\Big{)}}",,"\alpha_{EI/c}(x, t)=\frac{E\left[\max\left\{0,\ell^*-\hat{\ell}(x, t;\theta)\right\}\right]}{\hat{c}(x, t;\gamma)}","\(\alpha_{\mathrm{EI}/c}(x, t)\) is the cost-sensitive Expected Improvement acquisition function, balancing expected performance improvement and predicted cost."
ICLR_2024_oral_66,4,"\theta^{(M)} :=\\operatorname*{arg\,min}_{\theta}\E_{(x,t,\ell(x,t,d),c(x,t,d))\simH^{(M)}}\\[-\log p(\ell(x,t,d)\mid x,t,d,\hat{\ell}(x,t,d;\theta))] || \gamma^{(M)} :=\\operatorname*{arg\,min}_{\gamma}\E_{(x,t,\ell(x,t,d),c(x,t,d))\simH^{(M)}}\\(c(x,t,d)-\hat{c}(x,t,d;\gamma))^{2}",,"\theta^{*}\:=\\operatorname*{arg\,min}_{\theta}\E_{(x,t,d,\ell(x,t,d),\cdot)\simH^{(M)}}\\Big{[}-\log p(\ell(x,t,d)\mid x,t,d,\hat{\ell}(x,t,d;\theta))\Big{]}","Meta-learned surrogate parameters $\theta^*$ are obtained by minimizing the negative log-likelihood of observed validation errors across pipelines, epochs, and datasets in the meta-dataset $\mathcal{H}^{(M)}$."
ICLR_2024_oral_66,5,"M=\{m^{*}\,|\,m^{*}\in\operatorname*{arg\,max}_{m\inM _{Timm}}[f_{ImageNet}(m),\-S(m)]\}",,"M_{Pareto} :=\left\{ m\inM_{Timm}\;\middle|\;\nexists\, m'\inM_{Timm} : f_{ImageNet}(m') > f_{ImageNet}(m)\;\wedge\; S(m') < S(m)\right\}","\(\mathcal{M}_{\mathrm{Pareto}}\) denotes the set of Pareto-optimal models from the timm library, i.e., models for which no other model has both higher ImageNet accuracy and fewer parameters."
ICLR_2024_oral_68,1,P(v\middo(x))=\prod_{i:v_{i}\notinx}P(v_{i }\midpa_{v_{i}})&if $v$ consistent with $x$\\0&otherwise.,,P(V\middo(X=x))=\prod_{V_i\notinX} P(V_i\midPa_{V_i})\Big|_{X=x},"This equation gives the post-intervention joint distribution over all variables after intervening to set variables \(\mathbf{X}\) to values \(\mathbf{x}\) in a causal Bayesian network, by removing the conditional distributions for intervened variables and fixing their values."
ICLR_2024_oral_68,2,"P(v_{i}\,|pa_{i};\sigma)=\sum_{v_{i}^{\prime}:f(v_{i}^{\prime})=v_{i}}P(v_ {i}^{\prime}\,|pa_{i})",,P^{\sigma}(v_{i}\midpa_{v_{i}})=1 &if  v_{i}=f(v_{i}') for some  v_{i}'\\0 &otherwise,$P^{\sigma}(v_{i}\mid\mathbf{pa}_{v_{i}})$ is the conditional probability of $V_i$ taking value $v_i$ given its parents under the local intervention $\sigma$.
ICLR_2024_oral_7,1,"y_{i}=M(x_{i}|\Delta W,W_{0},\theta)",,y_{i}=(W_{0}+BA)x_{i},The output vector \(\mathbf{y}_{i}\) is computed by applying the adapted weight matrix \(W_{0} + BA\) to the input \(\mathbf{x}_{i}\).
ICLR_2024_oral_7,2,y_{i}=\phi(W_{i}^{T}x_{i}) || =\phi\big{(}(W_{0}^{T}\circ\Delta W_{i}^{T})x_{i}\big{)},,y_{i}=W_{i}x_{i}=\left(\Delta W_{i}\circ W_{0}\right)x_{i},The output activations \(\mathbf{y}_{i}\) for input \(\mathbf{x}_{i}\) are computed by applying the element-wise product of the example-specific adapter \(\Delta W_{i}\) and the pre-trained weights \(W_{0}\) to \(\mathbf{x}_{i}\).
ICLR_2024_oral_7,3,=\phi\big{(}(W_{0}^{T}\circ(B_{i}A_{i})^{T})x_{i}\big{)},,y_{i}=\phi\left( (W_{0}^{T}\circ (B_{i}A_{i})^{T}) x_{i}\right),"Each example's output is computed using its own low-rank adapter, where \(\Delta W_{i} = B_{i}A_{i}\) is substituted into the forward pass equation."
ICLR_2024_oral_7,4,=\phi\Big{(}A_{i}\circ\big{(}W_{0}^{T}(B_{i}\circ x_{i})\big{)}\Big{)},,=\phi\big{(}(W_{0}^{T}\circ(A_{i}^{T}B_{i}^{T}))x_{i}\big{)},"Equation 4 rewrites the previous expression by using the property \((B_{i}A_{i})^{T} = A_{i}^{T}B_{i}^{T}\), expressing the adapted weight multiplication in terms of the transposed low-rank factors."
ICLR_2024_oral_7,5,Y=\phi\Big{(}A\circ\big{(}(B\circX)W_{0}\big{)}\Big{)},,y=\phi\Big(A\circ\big(W_{0}^{T}(B\circx)\big)\Big),\(\mathbf{y}\) is the batch of output activations computed by applying the activation function \(\phi\) to the element-wise product of the adapter matrix \(\mathbf{A}\) and the transformed input \(\mathbf{x}\) via the pre-trained weights \(W_{0}\) and adapter matrix \(\mathbf{B}\).
ICLR_2024_oral_7,6,\frac{2c_{1}}{dc_{2}}+\frac{1}{r}\geq 1,,c_{2}(rbld^{2})\ll 2c_{1}(dblr)+c_{2}(bld^{2}),"The computational cost of fLoRA is much less than that of LoRA with BMM, given by the inequality above."
ICLR_2024_oral_73,1,\tilde{x}_{i}=\frac{\mu_{k}+\varepsilon\eta}{\sqrt{1+\varepsilon^{2}}},where \(\eta\) is drawn from the same distribution as the \(\mu_{k}\)'s and \(\varepsilon\) sets the within-class variability,"\tilde{x}_{i}\simN(\mu_{k}, I/D)",The content vector \(\tilde{x}_{i}\) for item \(x_{i}\) is sampled from a normal distribution with mean \(\mu_{k}\) (the class mean) and covariance \(I/D\).
ICLR_2024_oral_73,2,"v_{i}=u_{i}+V_{1}\sum_{j\leq i}p_{ij}^{(1)}u_{j},\quad w_{i}=v_{i}+V_{2}\sum_{ j\leq i}p_{ij}^{(2)}v_{j} || p_{ij}^{(\mu)}=\frac{e^{(K_{\mu}u_{j})^{T}(Q_{\mu}u_{i})}}{\sum_{k\leq i}e^{(K _{\mu}u_{k})^{T}(Q_{\mu}u_{i})}}","where

\[p_{ij}^{(\mu)}=\frac{e^{(K_{\mu}u_{j})^{T}(Q_{\mu}u_{i})}}{\sum_{k\leq i}e^{(K _{\mu}u_{k})^{T}(Q_{\mu}u_{i})}} \tag{3}\]

is the attention paid by query \(i\) on key \(j\) in the \(\mu\)th layer","v_{i} &=Attn_{1}(u_{1},\ldots, u_{i})\\w_{i} &=Attn_{2}(v_{1},\ldots, v_{i})","where \(\mathrm{Attn}_{1}\) and \(\mathrm{Attn}_{2}\) denote the first and second attention layers, respectively, each operating with a causal mask over the input sequence up to position \(i\)."
ICLR_2024_oral_73,3,"v_{i}^{(b)}=\sum_{j\leq i}q_{ij}^{(1)}u_{j}^{(c)},\quad v_{i}^{(c )}=u_{i}^{(c)} || w_{i}^{(b)}=\sum_{j\leq i}q_{ij}^{(2)}v_{j}^{(c)},\quad w_{i}^{( c)}=v_{i}^{(c)}",,"v_{i}^{(c)}=u_{i}^{(c)},\quad v_{i}^{(b)}=u_{i-1}^{(c)},\quad w_{i}^{(c)}=v_{i}^{(c)}+\beta v_{i}^{(b)},\quad w_{i}^{(b)}=v_{i}^{(b)}","where \(v_{i}^{(c)}\) and \(v_{i}^{(b)}\) are the content and buffer components after the first layer, and \(w_{i}^{(c)}\) and \(w_{i}^{(b)}\) are the content and buffer components after the second layer; \(\beta\) is a parameter controlling the transfer from buffer to content."
ICLR_2024_oral_73,4,"q_{ij}^{(1)}=\frac{e^{\beta_{1}\delta_{i-1,j}}}{\sum_{k\leq i}e^{\beta_{1}\delta_ {i-1,k}}},\quad q_{ij}^{(2)}=\frac{e^{\alpha v_{j}^{(k)},v_{i}^{(c)}+\beta_{2}\Delta_{i,j}}}{\sum_{k\leq i}e^{\alpha v_{k}^{(k)},v_{i}^{(c)}+\beta_{2}\Delta_ {i,k}}}",,"q_{ij}^{(\mu)}=\frac{e^{\beta_{\mu}\delta_{j, i-1}}}{\sum_{k\leq i} e^{\beta_{\mu}\delta_{k, i-1}}}","where \(q_{ij}^{(\mu)}\) is the attention paid by query \(i\) to key \(j\) in layer \(\mu\), controlled by parameter \(\beta_{\mu}\), and \(\delta_{j, i-1}\) is the Kronecker delta."
ICLR_2024_oral_74,1,\partial_{k}|s_{k}\rangle=\sum_{l=0}^{k-1}(-1)^{l}|s_{k-1}(l)\rangle,where \(\left|s_{k-1}(l)\right\rangle\) is the _lower_ simplex obtained by leaving out vertex \(l\) (i,\partial_{k}\left|s_{k}\right\rangle=\sum_{\ell=0}^{k}(-1)^{\ell}\left|s_{k-1}(\ell)\right\rangle,"The boundary operator \(\partial_{k}\) maps a \(k\)-simplex basis state \(\left|s_{k}\right\rangle\) to the alternating sum of its \((k-1)\)-face basis states \(\left|s_{k-1}(\ell)\right\rangle\), where each face is obtained by removing the \(\ell\)th vertex."
ICLR_2024_oral_74,2,\beta_{k}:=\dim\ker(\Delta_{k}),,\beta_{k}=\dim\ker(\Delta_{k}),The \(k\)th Betti number is the dimension of the kernel of the combinatorial Laplacian \(\Delta_{k}\).
ICLR_2024_oral_74,3,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|\leq\epsilon,"where \(|S_{k}|\) is the the number of \(k\)-simplices \(S_{k}\in\Gamma\) or \(\dim\tilde{\mathcal{H}}_{k}\), the dimension of the Hilbert space spanned by the set of \(k\)-simplices in the complex",|\chi_{k}-\beta_{k}/\dim(\tilde{H}_{k})|\leq\epsilon,"where \(\chi_{k}\) is an estimator for the normalized \(k\)th Betti number, satisfying the given accuracy and confidence parameters."
ICLR_2024_oral_74,4,"\rank(\Delta_{k})\stackrel{{\tiny{def}}}{{=}}\trace(h(\tilde{\Delta}_{k})), where h(x)=\{{ll}1& if \x>\delta\\0& otherwise",,rank(\Delta_{k})=Tr\left[ g(\tilde{\Delta}_{k})\right],The rank of the Laplacian \(\Delta_{k}\) is given by the trace of a matrix function \(g\) applied to the normalized Laplacian \(\tilde{\Delta}_{k}\).
ICLR_2024_oral_74,5,n_{v}=O(\frac{\log(1/\eta)}{\epsilon^{2}})\qquad\qquadand\qquad\qquad m>\frac{\log(1/\epsilon)}{\sqrt{\delta}},,P\left(\left|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}\right|>\epsilon\right)\leq\eta,The probability that the estimated normalized Betti number \(\chi_{k}\) deviates from the true value \(\beta_{k}/|S_{k}|\) by more than \(\epsilon\) is at most \(\eta\).
ICLR_2024_oral_74,6,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|\leq\epsilon,,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|<\epsilon,The estimated normalized Betti number \(\chi_{k}\) deviates from the true normalized Betti number \(\beta_{k}/|S_{k}|\) by less than \(\epsilon\) with probability at least \(1-\eta\).
ICLR_2024_oral_74,7,"O(\frac{1}{\epsilon^{2}}\max\{\frac{n\log(1/\epsilon)}{\sqrt{\delta} },\frac{n}{\zeta_{k}}\})",,O\left(\frac{n^{3}\log^{3}(1/\epsilon)}{\epsilon^{2}\sqrt{\delta}}\right),"The total time complexity of the NISQ-TDA algorithm is \(O\left(\frac{n^{3}\log^{3}(1/\epsilon)}{\epsilon^{2}\sqrt{\delta}}\right)\), where \(n\) is the number of data points, \(\epsilon\) is the accuracy parameter, and \(\delta\) is the spectral gap of the scaled Laplacian."
ICLR_2024_oral_82,1,LayerNorm(x)=\frac{x-E[x]}{\sqrt {Var[x]+\epsilon}}\odot\gamma+\beta,,LayerNorm(x)=\frac{x-\mu}{\sigma}\odot\gamma+\beta,"LayerNorm normalizes the input \(\mathbf{x}\) by subtracting the mean \(\mu\) and dividing by the standard deviation \(\sigma\), then applies learnable scale \(\gamma\) and bias \(\beta\)."
ICLR_2024_oral_82,2,{BiasNorm}(x)=\frac{x}{RMS[x-b]}\cdot\exp(\gamma),"where \(\mathbf{b}\) is the learnable channel-wise bias, \(\mathrm{RMS}[\mathbf{x}-\mathbf{b}]\) is the root-mean-square value taken over channels, and \(\gamma\) is a scalar",BiasNorm(x)=x+\beta,BiasNorm simply adds a learnable bias vector \(\mathbf{\beta}\) to the input \(\mathbf{x}\).
ICLR_2024_oral_82,3,Swish(x)=x\cdot(1+\exp(-x))^{-1},,Swish(x)=x\cdot\sigma(x),where \(\sigma(x)\) is the sigmoid function applied elementwise to \(x\).
ICLR_2024_oral_82,4,"\textit{SwooshR}(x)&=\log(1+\exp(x-1))-0.08x-0.313261687,\\\textit{SwooshL}(x)&=\log(1+\exp(x-4))-0.08x-0.035",,SwooshR(x)=x\cdot\sigma(x)+\alpha\cdot (1-\sigma(x)),where \(\sigma(x) = (1 + \exp(-x))^{-1}\) is the sigmoid function and \(\alpha\) is a learnable parameter.
ICLR_2024_oral_82,5,\Delta_{t}=-\alpha_{t}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon},"where \(\alpha_{t}\) is the learning rate typically specified by an external schedule, \(\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{2}}\) is the bias-correction term, and \(\epsilon=10^{-8}\)",\Delta_{t}=-\alpha\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon},where \(\alpha\) is the learning rate and \(\epsilon\) is a small constant for numerical stability.
ICLR_2024_oral_82,6,\Delta^{\prime}_{t}=-\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^ {2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon},,\Delta_{t}^{scaled}=\frac{\Delta_{t}}{r_{t-1}},"where \(r_{t-1}\) denotes the scale (e.g., norm) of the parameter at step \(t-1\)."
ICLR_2024_oral_82,7,"\Delta^{\prime}_{t,r}&=-\eta\cdot\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{2}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\odot\theta^{\prime}_{t-1}\\&=-\eta\cdot\alpha_{t}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta _{1}^{t}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\odot\theta_{t-1}","where \(\eta\) is a scaling factor on learning rate \(\alpha_{t}\), and we found that setting \(\eta=0","\Delta^{\prime}_{t,r}=-\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{t}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\odot\theta^{\prime}_{t-1}","where \(n_{t}\) and \(w_{t}\) are the first and second moments of the scale gradients, and \(\mathbf{\theta}^{\prime}_{t-1}\) is the normalized parameter tensor."
ICLR_2024_oral_82,8,"\alpha_{t}=\alpha_{base}\cdot(\frac{t^{2}+\alpha_{step }^{2}}{\alpha_{step}^{2}})^{-0.25}\cdot(\frac{e^{2}+\alpha_{epoch}^{2}}{\alpha_{epoch}^{2}})^{-0.25}\cdotlinear(\alpha_{start},t_{warmup},t)",,"Eden(t)=\alpha_{max}\cdot\min\left(1,\frac{t}{T_{warmup}}\right)\cdot\exp\left(-\frac{t}{T_{decay}}\right)","where \(\alpha_{\mathrm{max}}\) is the maximum learning rate, \(T_{\mathrm{warmup}}\) is the warm-up period, \(T_{\mathrm{decay}}\) is the decay constant, and \(t\) is the current training step."
ICML_2024_oral_1,1,"J(\pi)=\sum_{t=0}^{\infty}E_{(s_{t},a_{t})\sim\rho (\pi)}[\gamma^{t}(r(s_{t},a_{t})+\alphaH(\pi(\cdot|s_{t})))]",,"J(\pi)=E_{\pi}\left[\sum_{t=0}^{\infty}\gamma^{t}\left( r(s_t, a_t)+\alphaH(\pi(\cdot|s_t))\right)\right]",The SAC objective augments the expected discounted reward with an entropy regularization term weighted by temperature parameter \(\alpha\).
ICML_2024_oral_1,2,"r_{t}=r_{M}(B_{s\to r|a}\odots_{t},B_{a\to r|s}\odota_{t},\epsilon_{t})","where \(\mathbf{B}_{\mathbf{s}\to r|\mathbf{a}}\in\mathbb{R}^{\mathrm{dim} \mathcal{S}\times 1}\) and \(\mathbf{B}_{\mathbf{a}\to r|\mathbf{s}}\in\mathbb{R}^{\mathrm{dim}\mathcal{A} \times 1}\) are vectors that represent the graph structure 1 from \(\mathbf{s}_{t}\) to \(r_{t}\) given \(\mathbf{a}_{t}\) and from \(\mathbf{a}_{t}\) to \(r_{t}\) given \(\mathbf{s}_{t}\), respectively","r_{t}=f(s_{t},a_{t},z_{t})+\epsilon_{t}","The reward at time \(t\) is modeled as a function of the state, action, latent confounders, and noise."
ICML_2024_oral_1,3,"H_{c}(\pi(\cdot|s))&=-E_{a\inA}[\sum_{i=1}^{\dimA}B_{a_{i}\to r|s}\pi(a_{i}|s)\log\pi(a_{i}|s)],\\&a=(a_{1},\ldots,a_{\dimA})",,"H_{c}(\pi(\cdot|s_{t}))=-\sum_{i=1}^{dimA}B_{a\to r|s}^{(i)}E_{a_{i,t}\sim\pi(\cdot|s_{t})}\left[\log\pi(a_{i,t}|s_{t})\right]","where \(\mathcal{H}_{c}\) is the causality-aware entropy, \(\mathbf{B}_{\mathbf{a}\to r|\mathbf{s}}^{(i)}\) is the causal weight for action dimension \(i\), and \(\pi(a_{i,t}|\mathbf{s}_{t})\) is the marginal policy for action dimension \(i\) given state \(\mathbf{s}_{t}\)."
ICML_2024_oral_1,4,"T_{c}^{\pi}Q(s_{t},a_{t })\triangleq& r(s_{t},a_{t})+\gammaE_{s_{t+1}\sim P}[E_{a_{t}\sim\pi}[Q(s_{t+1},a_{t+1})\\&+\alphaH_{c}(\pi(a_{t+1}|s_{t+1}))]]",,"T_{c}^{\pi} Q(s,a)=r(s,a)+\gammaE_{s'\simP(\cdot|s,a)}\left[E_{a'\sim\pi(\cdot|s')}\left[ Q(s',a')+\alphaH_{c}(\pi(\cdot|s'))\right]\right]",The causality-aware Bellman operator \(\mathcal{T}_{c}^{\pi}\) updates the \(Q\)-value by incorporating the causality-aware entropy \(\mathcal{H}_{c}\) into the expected future return.
ICML_2024_oral_1,5,\frac{n_{i}^{l}(x)}{\frac{1}{N^{l}}\sum_{k\in l}n_{k}^{l}}\leq\tau,where \(\tau\) is a constant serving as a threshold to determine the gradient dormancy of neurons in each layer,n_{i}^{l} <\epsilon_{g},"where \(n_{i}^{l}\) is the L2 norm of gradients of the weights for neuron \(i\) in layer \(l\), and \(\epsilon_{g}\) is a small positive threshold."
ICML_2024_oral_1,6,\alpha_{\tau}=\frac{\sum_{l\in\phi}N_{\tau}^{l}}{\sum_{l\in\phi}N^{l}},,\alpha_{\tau}=\frac{1}{L}\sum_{l=1}^{L}\frac{N_{\tau}^{l}}{N^{l}},"where \(L\) is the total number of layers, \(N_{\tau}^{l}\) is the number of gradient-dormant neurons in layer \(l\), and \(N^{l}\) is the total number of neurons in layer \(l\)."
ICML_2024_oral_1,7,"\theta_{t}=(1-\eta)\theta_{t-1}+\eta\phi_{i},\\phi_{i}\siminitializer",,\theta\leftarrow (1-\eta)\theta+\eta\theta_{0},"where \(\theta\) denotes the current network weights, \(\theta_{0}\) are the initial weights, and \(\eta\) is the reset factor controlling the strength of the reset."
ICML_2024_oral_10,1,"attention(Q,K,V)=softmax(QK)^{T}/\sqrt{d})V",,"Attention(Q, K, V)=softmax\left(\frac{QK^\top}{\sqrt{d_k}}\right)V","The attention mechanism computes a weighted sum of values \(V\) using the softmax-normalized dot products between queries \(Q\) and keys \(K\), scaled by the square root of the key dimension \(d_k\)."
ICML_2024_oral_10,2,"d\hat{x}_{t}=f(\hat{x}_{t},t)dt+g(t)dw",,"dx=f(x, t)dt+g(t)dW","Here, \(x\) is the data variable, \(t\) is time, \(f(x, t)\) is the drift coefficient, \(g(t)\) is the diffusion coefficient, and \(dW\) denotes the standard Wiener process increment."
ICML_2024_oral_10,3,"d\hat{x}_{t}=[f(\hat{x}_{t},t)-g(t)^{2}s(\hat{x}_{t},t) ]dt+g(t)d\tilde{w}",where \(\mathbf{\tilde{w}}\) is a backward-in-time Wiener process,"d\hat{x}_{t}=\left[ f(\hat{x}_{t}, t)-g^{2}(t)\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t})\right] dt+g(t) d\bar{w}","This stochastic differential equation describes the reverse diffusion process, where \(\bar{\mathbf{w}}\) is a standard Wiener process running backward in time and \(\nabla_{\mathbf{\hat{x}}_{t}} \log p_{t}(\mathbf{\hat{x}}_{t})\) is the score function."
ICML_2024_oral_10,4,"L(\phi)=E_{t,\hat{x}_{0},\hat{x}_{t}}[\lambda (t)\|s_{\phi}(\hat{x}_{t},t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t}|\hat{x}_{0})\|_{2}^{2}]",where \(\lambda\) denotes a positive weighting function,"L_{DSM}(\phi)=E_{t,\hat{x}_{0},\hat{x}_{t}}\left[\lambda(t)\left\| s_{\phi}(\hat{x}_{t}, t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t} |\hat{x}_{0})\right\|_2^2\right]",where \(\mathcal{L}_{\text{DSM}}(\phi)\) is the denoising score-matching loss used to train the score model \(s_{\phi}\).
ICML_2024_oral_10,5,"\ell(\phi,M_{C},t,\hat{x}_{0},\hat{x}_{t})=\\(1-M_{C})\cdot(s_{\phi}^{M_{E}}(\hat{x}_{t}^{Mc}, t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t}|\hat{x}_{0}))",where \(s_{\phi}^{M_{E}}\) denotes the score model equipped with a specific attention mask \(M_{E}\),"L(\phi)=E_{t,\hat{x}_0,\hat{x}_t, M_C}\left[\lambda(t)\left\| s_\phi\left(\hat{x}_t^{M_C}, t, M_C, M_E\right)-\nabla_{\hat{x}_t}\log p_t\left(\hat{x}_t\mid\hat{x}_0\right)\right\|_2^2\right]","where \(\hat{\mathbf{x}}_t^{M_C} = (1-M_C)\cdot\hat{\mathbf{x}}_t + M_C\cdot\hat{\mathbf{x}}_0\) denotes the masked noisy sample, and \(s_\phi\) is the Simformer score network conditioned on the attention and condition masks."
ICML_2024_oral_10,6,"L(\phi)=E_{M_{C},t,\hat{x}_{0},\hat{x}_{ t}}[\|\ell(\phi,M_{C},t,\hat{x}_{0},\hat{x}_{t})\|_{2}^{2}]",,"L(\phi, M_{E})=E_{t,\hat{x}_{0},\hat{x}_{t}, M_{C}}\left[\left\|\ell(\phi, M_{C}, t,\hat{x}_{0},\hat{x}_{t})\right\|_2^2\right]","where the overall Simformer training objective averages the per-sample loss over noise levels, data, and condition masks."
ICML_2024_oral_10,7,"s(\hat{x}_{t},t|y)\approx s_{\phi}(\hat{x}_{t},t)+\nabla_{\hat{x}_{t}}\log p_{t}(y|\hat{x}_{t})",,"s_{guided}(\hat{x}_{t}, t,y)=s_{\phi}(\hat{x}_{t}, t)+\nabla_{\hat{x}_{t}}\log p(y\mid\hat{x}_{t})","where \(s_{\text{guided}}\) is the guided score, \(s_{\phi}\) is the original score model, and \(\nabla_{\hat{\mathbf{x}}_{t}} \log p(\mathbf{y} \mid \hat{\mathbf{x}}_{t})\) is the gradient of the log-likelihood of the context \(\mathbf{y}\) given the current state."
ICML_2024_oral_10,8,"s_{\phi}(\hat{x}_{t},t|c)\approx s_{\phi}(\hat{x}_{t},t)+\nabla_{\hat{x}_{t}}\log\sigma(-s(t)c(\hat{x}_{t}))",,"s(\hat{x}_{t}, t\midy)\approx s_{\phi}(\hat{x}_{t}, t)+\nabla_{\hat{x}_{t}}\log f(y,\hat{x}_{t}, t)","where \(f(\mathbf{y}, \hat{\mathbf{x}}_{t}, t)\) is a guiding function that encodes the desired conditioning, such as interval constraints."
ICML_2024_oral_101,1,"G(z)=\sum_{j_{1}=0}^{d-1}\cdots\sum_{j_{n}=0}^{d-1}p(j_{1},\ldots,j_{n})z_{1}^ {j_{1}}\cdots z_{n}^{j_{n}}",,"G(z_{1},\ldots,z_{n})=\sum_{a_{1}=0}^{d-1}\cdots\sum_{a_{n}=0}^{d-1} p(a_{1},\ldots,a_{n}) z_{1}^{a_{1}}\cdots z_{n}^{a_{n}}","The probability generating function \(G(z_{1},\ldots,z_{n})\) encodes the joint distribution of the categorical variables as a formal polynomial."
ICML_2024_oral_101,2,"f(V_{1},...,V_{n},E_{1,N(1,1)},...,E_{n,N(n,3)})=\prod_{i=1}^{n}\sum_{j\in N(i )}E_{i,j}V_{j}",,"f(V_{1},\ldots,V_{n})=\prod_{i=1}^{n}\left( V_{N(i,1)}+V_{N(i,2)}+V_{N(i,3)}\right)","The polynomial \(f(V_{1},\ldots,V_{n})\) is defined as the product over all \(u_i \in U\) of the sum of formal variables corresponding to the three neighbors of \(u_i\) in the bipartite graph \(G\)."
ICML_2024_oral_101,3,"\Pr[V_{1}=1,\ldots,V_{n}=1]=h(1,\ldots,1)=\frac{\#PM(G)}{3^{n}}",,"\Pr[V_{1}=1, V_{2}=1,\ldots, V_{n}=1]=\frac{\#PM(G)}{3^{n}}",The probability that all \(V_i = 1\) equals the number of perfect matchings in \(G\) divided by \(3^n\).
ICML_2024_oral_101,4,"f(z_{1},...,z_{n})=\sum_{s=(s_{1},\ldots,s_{n})\in\{0,1,\ldots,k-1\}^{n}}c_{s}\cdot\prod_{i=1}^{n}z_{i}^{s_{i}}",,"f(z_{1},\ldots,z_{n})=\sum_{j_{1}=0}^{k-1}\cdots\sum_{j_{n}=0}^{k-1} p(j_{1},\ldots,j_{n}) z_{1}^{j_{1}}\cdots z_{n}^{j_{n}}","The probability generating polynomial \(f(z_{1},\ldots,z_{n})\) encodes the joint distribution \(p(j_{1},\ldots,j_{n})\) of \(k\)-nary random variables \(X_{1},\ldots,X_{n}\) as a formal polynomial in variables \(z_{1},\ldots,z_{n}\)."
ICML_2024_oral_101,5,"g(x_{1},\overline{x_{1}},...,x_{n},\overline{x_{n}})=f(\frac{x_{1}}{\overline{ x_{1}}},\frac{x_{2}}{\overline{x_{2}}},...,\frac{x_{n}}{\overline{x_{n}}})\cdot\prod_{i=1}^{n}\overline{x_{i}}",,"\sum_{s_{1}\in V_{1},\ldots,s_{n}\in V_{n}}c_{s}","The sum of coefficients \(c_{s}\) over all index tuples \(s=(s_{1},\ldots,s_{n})\) with \(s_{i}\in V_{i}\) gives the selective marginal probability."
ICML_2024_oral_101,6,m^{\prime}=c_{S}\cdot(\prod_{i\in S}\frac{x_{i}}{\overline{x_{i}}})\cdot(\prod _{j=1}^{n}\overline{x_{j}})=c_{S}(\prod_{i\in S}x_{i})\cdot(\prod_{i\notin S}\overline{x_{i}}),,m'=c_{S}\cdot\prod_{i\in S} x_{i}\prod_{i\notin S}\overline{x_{i}},"\(m'\) is the corresponding monomial in \(g\) for each monomial \(m = c_{S}\prod_{i\in S}z_{i}\) in \(f\), expressed in terms of \(x_{i}\) and \(\overline{x_{i}}\)."
ICML_2024_oral_101,7,"& f(x_{1}(1+\overline{x_{1}}),x_{2}(1+\overline{x _{2}}))\cdot(1-\overline{x_{1}})(1-\overline{x_{2}})\\&=(0.6x_{1}x_{2}(1+\overline{x_{1}})(1+\overline{x_{2}})\\&\quad+0.4x_{1}(1+\overline{x_{1}}))(1-\overline{x_{1}})(1-\overline{x_{2}})\\&=0.6x_{1}x_{2}+0.4x_{1}(1-\overline{x_{2}})\+\higher degree terms",,"g(x_{1},\overline{x_{1}},x_{2},\overline{x_{2}})=0.6 x_{1} x_{2}+0.4 x_{1} (1-\overline{x_{2}})","This is the explicit polynomial computed by the nonmonotone PC after eliminating division gates for the example \(f(z_{1},z_{2})=0.6z_{1}z_{2}+0.4z_{1}\)."
ICML_2024_oral_101,8,"P=\sum_{j_{1}=0}^{d-1}\cdots\sum_{j_{n}=0}^{d-1}\Pr[X_{1}=j_{1},\ldots,X_{n}=j _{n}]z_{1,j_{1}}\cdots z_{n,j_{n}}",,"\Pr[X_{1}\in A_{1},\ldots,X_{n}\in A_{n}]=P(v_{1},\ldots,v_{n})","The probability that each \(X_{i}\) falls in the subset \(A_{i}\) is given by evaluating the set-multilinear polynomial \(P\) at the indicator vectors \(v_{i}\), where \(v_{i,\delta}=1\) if \(\delta\in A_{i}\) and \(v_{i,\delta}=0\) otherwise."
ICML_2024_oral_101,9,"e_{i,j}=1&if $j=a_{i$},\\0&otherwise",,"e_{i,\delta}=1 &if \delta=a_{i}\\0 &otherwise","\(e_{i,\delta}\) is the indicator vector selecting the value \(a_{i}\) for variable \(X_{i}\)."
ICML_2024_oral_101,10,"v_{i,j}=1&if $j\in A_{i$},\\0&otherwise",,"v_{i,j}=1 &if  j\in A_{i},\\0 &otherwise","The vector \(v\) is defined so that \(v_{i,j}=1\) if \(j\) is in the set \(A_{i}\), and \(0\) otherwise, for each variable \(X_{i}\)."
ICML_2024_oral_101,11,"P(v)=\sum_{j_{1}\in A_{1}}\cdots\sum_{j_{n}\in A_{n}}\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}]\cdot 1 || =\Pr[X_{1}\in A_{1},\ldots,X_{n}\in A_{n}]",,"P(v)=\sum_{j_{1}\in A_{1}}\cdots\sum_{j_{n}\in A_{n}}\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}]","The probability that each \(X_i\) falls in the set \(A_i\) is given by evaluating the set-multilinear polynomial \(P\) at the indicator vector \(v\), which sums the probabilities over all tuples \((j_1,\ldots,j_n)\) with \(j_i\in A_i\)."
ICML_2024_oral_101,12,"f(a)=\sum_{a\in\Delta^{|A|}}\alpha_{a}\prod_{i\in A}z_{i,a_{i}},\quad g(b)=\sum_{b\in\Delta^{|B|}}\beta_{b}\prod_{j\in B}z_{j,b_{j}}",where \(\alpha_{a}=\Pr[X_{A}=a]\) and \(\beta_{b}=\Pr[X_{b}=b]\),"f(z_{A})=\sum_{a\in\Delta^{A}}\Pr[X_{A}=a]\prod_{i\in A} z_{i, a_{i}},\qquad g(z_{B})=\sum_{b\in\Delta^{B}}\Pr[X_{B}=b]\prod_{j\in B} z_{j, b_{j}}","\(f(z_{A})\) and \(g(z_{B})\) are the set-multilinear polynomials computed by nonmonotone PCs \(C\) and \(D\), representing the joint distributions of \(X_{A}\) and \(X_{B}\), respectively."
ICML_2024_oral_101,13,"f(a,b^{\prime})= || (\sum_{a\in\Delta^{|A|}}\alpha_{a}\prod_{i\in A}z_{i,a_{i}} )\prod_{j\in B\setminus A}\frac{1}{d}(z_{j,0}+\cdots+z_{j,d-1})",,"\tilde{f}(z)=\sum_{a\in\Delta^{|A|}}\alpha_{a}\prod_{i\in A}z_{i,a_{i}}\prod_{j\in B}1","\(\tilde{f}(z)\) is the extension of \(f\) to the larger variable set \(X_{A\cup B}\) by treating variables in \(B\) as marginalized (i.e., summing over all their possible values)."
ICML_2024_oral_104,1,call-count(u)=\sum_{v\in Q(u)}(1+call-count(v)),,C(u)=\sum_{v\in Q(u)}\left( 1+C(v)\right),The recursive call count \(C(u)\) for node \(u\) is the sum over all queried neighbors \(v\) of \(u\) of one plus the recursive call count of \(v\).
ICML_2024_oral_104,2,\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots || \leq\sigma(u_{L-1})\leq\pi(u_{L-1})\leq\sigma(u_{L})\leq\pi(u_{L}),,"\sigma(u_{i})\geq\pi(u_{i-1})\quadfor all  i=1,\ldots, L","A path \((u_{0},u_{1},\ldots,u_{L})\) is a query path if and only if for each \(i=1,\ldots,L\), \(\sigma(u_{i}) \geq \pi(u_{i-1})\)."
ICML_2024_oral_104,3,"\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots || \leq\sigma(u_{L-2})\leq\pi(u_{L-2})\leq\min(\sigma(u_{L-1}),\sigma (u_{L}))",,\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots\leq\sigma(u_{L-2})\leq\pi(u_{L-2})\leq\sigma(u_{L})\leq\pi(u_{L}),"A path \((u_{0},u_{1},\ldots,u_{L})\) of length \(L\geq 2\) is an extended query path (EQ-path) if and only if the above sequence of inequalities holds."
ICML_2024_oral_104,4,\sigma(u_{0})<\sigma(u_{1}) and\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq || \cdots\leq\pi(u_{L-2})\leq\sigma(u_{L-1})=\sigma(u_{L}),,"\sigma(u_{0}) <\sigma(u_{1})\quadand\quad\sigma(u_{L-1})=\sigma(u_{L})\quadand\quad\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots\leq\sigma(u_{L-2})\leq\pi(u_{L-2})\leq\min(\sigma(u_{L-1}),\sigma(u_{L}))","An extended query path \((u_{0},u_{1},\ldots,u_{L})\) is expensive if and only if \(\sigma(u_{0}) < \sigma(u_{1})\), \(\sigma(u_{L-1}) = \sigma(u_{L})\), and the sequence of \(\sigma\) and \(\pi\) values satisfies the EQ-path condition."
ICML_2024_oral_104,5,"E_{\pi}|X|\leq 2E\Big{[}\sum_{(u,v)\in E}1 (\sigma(u)\neq\sigma(v))\Big{]}",,"E_{\pi}|X|\leq 4\,OPT","The expected number of expensive extended query paths is at most \(4\,\mathrm{OPT}\)."
ICML_2024_oral_104,6,"\Phi_{t}(a,b)=2|D_{t}(a,b)|+|Q_{t}(a,b)| || \Psi_{t}(a,b)=2|D_{t}(a,b)|+|X_{t}(a,b)|",,"Y_{t}(a,b) &=|Q_{t}(a,b)|,\\Z_{t}(a,b) &=|X_{t}(a,b)|","$Y_{t}(a,b)$ is the number of query paths and $Z_{t}(a,b)$ is the number of expensive EQ-paths that start with edge $(a,b)$ and have been created up to iteration $t$."
ICML_2024_oral_106,1,"p(u)=\prod_{i=1}^{n}p(u_{i}|u_{1},...,u_{i-1},\Theta)",,"P(u_{1},...,u_{n})=\prod_{t=1}^{n} P(u_{t}\mid u_{1},...,u_{t-1})",The joint probability of a sequence of words is factorized autoregressively as the product of conditional probabilities of each word given all previous words.
ICML_2024_oral_106,2,L=-log\;p(u),,"L_{NLL}=-\sum_{i=1}^{n}\log p(u_{i} | u_{1}, ..., u_{i-1},\Theta)","\(\mathcal{L}_{\text{NLL}}\) denotes the negative log-likelihood loss for the sequence \(u_1, ..., u_n\) given model parameters \(\Theta\)."
ICML_2024_oral_106,3,"p(x)=\prod_{i=1}^{n}p(x_{i}|x_{1},...,x_{i-1},\Theta)",,"p(X)=\prod_{i=1}^{n} p(x_{i}\mid x_{1},\ldots, x_{i-1},\Theta)",The probability of the image \(X\) is modeled as the product of conditional probabilities of each pixel \(x_{i}\) given all previous pixels and model parameters \(\Theta\).
ICML_2024_oral_106,4,L=-log\;p(x),,L=-\log p(x),\(\mathcal{L}\) denotes the negative log-likelihood loss for the image sequence \(x\).
ICML_2024_oral_106,5,"p(s)=\prod_{i=1}^{n}p(s_{i}|s_{1},...,s_{i-1},\Theta)",,"p(s)=\prod_{i=1}^{n} p(s_{i}\mid s_{1}, ..., s_{i-1},\Theta)","The probability of the sequence of clusters \(s\) is modeled autoregressively, where each cluster \(s_{i}\) is conditioned on all preceding clusters in the sequence."
ICML_2024_oral_106,6,"L_{G}=-\sum_{i=1}^{n}cosine(G(f(x_{s_{1}:s_{i-1}});\theta_{G}),f_{\phi }(x)_{s_{i}})","where \(f(\cdot)\) is the encoder, \(f_{\phi}(x)_{s_{i}}\) is the semantically enriched tokens corresponding to the cluster \(s_{i}\), \(G(\cdot;\ \theta_{G})\) is the generative decoder for autoregressive prediction, and \(cosine\) is the cosine similarity loss","p(z)=\prod_{i=1}^{n}p(z_{i}|z_{1},...,z_{i-1},\Theta)","\(z_{i}\) denotes the semantic token for the \(i\)-th cluster, and the model autoregressively predicts each semantic token conditioned on all previous tokens in the sequence."
ICML_2024_oral_106,7,"L_{D}=-\sum_{i=1}^{n}cosine(D(f(x_{s_{1}:s_{i-1}});\theta_{D}),f_{\phi}(x)_{s_{1}:s_{i-1}})","where \(D(\cdot;\ \theta_{D})\) is the discriminative decoder, tasked with predicting the semantic tokens of visible pixels","L_{V}=-\sum_{i=1}^{m} cosine(G(f(x_{s_{\pi(1)}:\pi(i-1)}});\theta_{G}), f_{\phi}(x)_{s_{\pi(i)}})","where \(m\) is the number of visible clusters, \(\pi\) is a random permutation of cluster indices, and the loss is computed over the visible clusters in the permuted sequence."
ICML_2024_oral_107,1,"L_{eval}=-\log p_{M}(<\)cc\(>\)\(|X_{l},X_{r})",,"L_{eval}=-E_{(X_{l}, X_{r}, Y, CC, label)}\left[\log p_\theta(\texttt{<cc>}\mid X_{l}, X_{r}, Y)\cdotI[label=1]\right]","\(\mathcal{L}_{eval}\) is the expected negative log-likelihood of predicting the special token \(<\)cc\(>\) given the input sequence, weighted by whether the label is true."
ICML_2024_oral_107,2,"L_{gen}=-\log p_{M}(Y|X_{l},X_{r},CC),& if label\\-\log p_{M}(Y|X_{l},X_{r}),&otherwise",,"L_{gen}=-\sum_{t=1}^{|Y|}\log p_{M}(y_t\mid X_{l}, X_{r}, [CC], y_{<t})","\(\mathcal{L}_{gen}\) is the cross-entropy loss for generating the target code tokens \(Y = (y_1, \ldots, y_{|Y|})\), conditioned on the in-file context \(X_l, X_r\), optionally the retrieved context \(CC\), and previously generated tokens."
ICML_2024_oral_107,3,"ES(\hat{Y},Y)=\frac{1-Lev(\hat{Y},Y)}{\max(|\hat{Y}|,|Y|)}",where \(Lev\) is the Levenshtein distance (Levenshtein et al,L_{total}=\lambdaL_{eval}+L_{gen},The final training loss is a weighted sum of the self-assessment loss and the code generation loss.
ICML_2024_oral_109,1,"\operatorname*{arg\,max}_{k=1,\dots,K}\,\cos(\phi(x),\psi(t_{k}))",,"\hat{y}=\arg\max_{k\in\{1,\dots, K\}}\frac{\langle\phi(x),\psi(t_k)\rangle}{\|\phi(x)\|\,\|\psi(t_k)\|}",The predicted class \(\hat{y}\) is the one whose text embedding has the highest cosine similarity with the image embedding.
ICML_2024_oral_109,2,"f_{k}(\phi,x)=\cos(\phi(x),\psi(t_{k}))=\langle\frac{\phi(x)}{\|\phi (x)\|_{2}},\frac{\psi(t_{k})}{\|\psi(t_{k})\|_{2}}\rangle",,"f_{k}(x)=\langle\phi(x),\psi(t_{k})\rangle",The logit for class \(k\) is given by the inner product between the image embedding \(\phi(x)\) and the text embedding \(\psi(t_{k})\).
ICML_2024_oral_109,3,"\operatorname*{arg\,max}_{k=1,\dots,K}\,f_{k}(\phi,z)\neq y,\quad\|z-x\|_{p}\leq\varepsilon,\quad z\in I",where \(\varepsilon\) is the perturbation size,"\|z-x\|_p\leq\epsilon\quadand\quad\operatorname*{arg\,max}_{k=1,\dots,K} f_k(\phi, z)\neq y",An adversarial image \(z\) is within an \(\ell_p\) ball of radius \(\epsilon\) around \(x\) and is misclassified by the classifier \(f\).
ICML_2024_oral_109,4,"L_{TeCoA}(y,f(\phi,x))=-\log(\frac{e^{f_{y}(\phi,x)}}{\sum_{k=1}^ {K}e^{f_{k}(\phi,x)}})",,"\min_{\phi}\;E_{(x, y)\simD}\left[\max_{\|z-x\|_{\infty}\leq\varepsilon}\;\ell_{CE}\left(f(\phi, z), y\right)\right]",where \(\ell_{\mathrm{CE}}\) denotes the cross-entropy loss and \(\mathcal{D}\) is the data distribution.
ICML_2024_oral_109,5,"\phi_{FT}=\operatorname*{arg\,min}_{\phi}\sum_{i=1}^{n}\max_{\|z-x_{i}\|_{\infty}\leq\varepsilon}L_{TeCoA}(y_{i},f(\phi,z))",where the inner problem is approximately solved with projected gradient descent (PGD) during training and \(\phi_{\mathrm{FT}}\) indicates the weights of the robust CLIP vision encoder,"\min_{\phi}\;\frac{1}{n}\sum_{i=1}^{n}\;\max_{\|z_{i}-x_{i}\|_{\infty}\leq\varepsilon} L_{TeCoA}(y_{i},f(\phi,z_{i}))",Adversarial training objective minimizing the TeCoA loss over worst-case \(\ell_{\infty}\)-bounded perturbations for each training example.
ICML_2024_oral_109,6,"L_{FARE}(\phi,x)=\max_{\|z-x\|_{\infty}\leq\varepsilon}\|\phi(z)-\phi_{Org}(x)\|_{2}^{2}",,"L_{emb}(\phi, x)=\max_{\|z-x\|_{\infty}\leq\varepsilon}\|\phi(z)-\phi_{Org}(x)\|_{2}^{2}",The embedding loss penalizes deviations of the adversarial image embedding from the original CLIP embedding for the clean image.
ICML_2024_oral_109,7,"\phi_{FT}=\operatorname*{arg\,min}_{\phi}\sum_{i=1}^{n}L_{ FARE}(\phi,x_{i})",,"\phi_{FARE}=\operatorname*{arg\,min}_{\phi}\sum_{i=1}^{n} L_{FARE}(\phi, x_{i})",where \(\phi_{\mathrm{FARE}}\) denotes the weights of the CLIP vision encoder after unsupervised adversarial fine-tuning.
ICML_2024_oral_109,8,"|\cos(\phi_{FT}(x),\psi(t))-\cos(\phi_{Org},\psi(t))| || \leq\min(\frac{2}{\|\phi_{Org}(x)\|_{2}},\frac{2}{\|\phi_{FT}(x)\|_{2}})\|\phi_{FT}(x)-\phi_{Org}(x)\|_{2}",,"\left|\cos(\phi_{FT}(x),\psi(t_{k}))-\cos(\phi_{Org}(x),\psi(t_{k}))\right|\leq\frac{2\|\phi_{FT}(x)-\phi_{Org}(x)\|_{2}}{\min\{\|\phi_{FT}(x)\|_{2},\|\phi_{Org}(x)\|_{2}\}}",The difference in cosine similarity between the fine-tuned and original image embeddings with any text embedding is bounded by the normalized \(\ell_2\)-distance between the two image embeddings.
ICML_2024_oral_110,1,F_{iso}=\{f:\Omega\subsetR^{d}\to&R^{D}:\Df^{\top}(s)Df(s)=Id\\&for all s\in\Omega\},,"F_{iso}(\Omega) :=\left\{ f\inF(\Omega) :\forall s\in\Omega,\; J_f(s)^\top J_f(s)=I_d\right\}","\(\mathcal{F}_{\mathrm{iso}}(\Omega)\) denotes the set of local isometries, i.e., functions whose Jacobian matrices are orthogonal at every point in \(\Omega\)."
ICML_2024_oral_110,2,"\Theta_{p}^{p}(f,\Omega)=\int_{\Omega}&dist(Df(s),SO(d))^{p}\\&+dist\big{(}(Df)^{-1}(s),SO(d)\big{)}^{p}\,ds",,\Theta(f)=\sup_{s\in\Omega}\| Df^{\top}(s) Df(s)-Id\|_{op},"\(\Theta(f)\) measures the maximal operator norm deviation of the local metric induced by \(f\) from the identity, quantifying how far \(f\) is from being a local isometry."
ICML_2024_oral_110,3,"\Theta_{p}^{p}(f,\Omega)=&\int_{\Omega }dist^{p}(Df(z),SO(d,T_{f(z)}M))\\&+dist^{p}\big{(}(Df)^{-1}(z),SO(T_{f(z)}M,d)\big{)}\,dz","where \(T_{f(z)}M\) denotes the tangent space of \(M\) at \(f(z)\) and \(\mathrm{SO}(d,T_{f(z)}M)\) denotes the set of orthogonal matrices \(Q\in\mathbb{R}^{D\times d}\) (i","\Theta_{p}^{p}(f,\Omega)=\int_{\Omega}dist(Df(s),St(d, D))^{p}+dist\big((Df)^{\dagger}(s),St(d, D)\big)^{p}\,ds","\(\Theta_{p}^{p}(f,\Omega)\) measures the integrated \(p\)-th power of the distance of the differential \(Df(s)\) and its Moore-Penrose pseudoinverse \((Df)^{\dagger}(s)\) to the Stiefel manifold \(\mathrm{St}(d, D)\) over the domain \(\Omega\)."
ICML_2024_oral_110,4,"MCC(\tilde{S},\tilde{S})=\max_{\pi\in S_{d}}d^{-1}\sum_{i=1}^{ d}|\rho(S_{i},\tilde{S}_{\pi(i)})|","where \(\rho(X,Y)=\operatorname{Cov}(X,Y)/(\operatorname{Var}(X)\operatorname{Var}( Y))^{1/2}\) denotes the correlation coefficient","MCC(\tilde{S}, S)=\max_{P\inP_d}\frac{1}{d}\sum_{i=1}^d |Corr(\tilde{S}_i, S_{P(i)})|",The mean correlation coefficient (MCC) between two \(d\)-dimensional random variables \(\tilde{S}\) and \(S\) is defined as the maximum average absolute correlation over all permutations \(P\) of the indices.
ICML_2024_oral_110,5,"MCC(\hat{S},S)\geq 1-C\Theta_{p}^{2}(f)",,"MCC(\hat{S},S)\geq 1-C\,\Theta_{p}(f,\Omega)^{1/p}","This inequality states that the mean correlation coefficient between the estimated sources \(\hat{S}\) and the true sources \(S\) is lower bounded by \(1\) minus a constant times the \(p\)-th root of the isometry deviation \(\Theta_{p}(f,\Omega)\)."
ICML_2024_oral_110,6,"\min_{L}&\|u-L\|_{L^{q}(\Omega)}\\&\leq C(\Omega,p)(\int_{\Omega}dist(Du(s),SO (d))^{p}\,ds)^{\frac{1}{p}}",,"MCC(\hat{S},S)\geq 1-C\Theta_{p}^{2}(f)","The mean correlation coefficient between the estimated sources \(\hat{S}\) and the true sources \(S\) is lower bounded by \(1-C\Theta_{p}^{2}(f)\), where \(C\) is a constant independent of \(f\)."
ICML_2024_oral_110,7,"M(f_{*}P)=\{&(g,Q,\Omega^{\prime}):g\inF(\Omega^{\prime}), where \\g_{*}Q=f_{*}P,\,supp(Q)=\Omega^{\prime}\}",,"M_{\varepsilon}(P)=\left\{ f :\Omega\toR^d\,\middle|\, f is a diffeomorphism,  f_{*}P\inP,\\Theta_{p}(f,\Omega)\leq\varepsilon\right\}","The set \(\mathcal{M}_{\varepsilon}(\mathbb{P})\) consists of all diffeomorphisms \(f\) from \(\Omega\) to \(\mathbb{R}^d\) such that the push-forward \(f_{*}\mathbb{P}\) belongs to \(\mathcal{P}\) and the isometry deviation \(\Theta_{p}(f,\Omega)\) is at most \(\varepsilon\)."
ICML_2024_oral_110,8,"&(g,Q,\Omega^{\prime})\in\\&\operatorname*{argmin}_{(\bar{g},\bar{Q},\Omega)\inM(f,P)}\int_{\Omega}dist((D\bar{g})^{-1}(g(s)),SO(d))^ {p}\,\bar{Q}(ds)",,"(g^{*},Q^{*},\Omega^{*})=\arg\min_{(g,Q,\Omega')\inM(f_{*}P)}\Theta_{p}(g,\Omega')","The triple \((g^{*},\mathbb{Q}^{*},\Omega^{*})\) minimizes the isometry deviation \(\Theta_{p}(g,\Omega')\) over all models generating the observed distribution."
ICML_2024_oral_110,9,"\|h\|_{P,q}\leq C_{1}\Theta_{p}(f,\Omega)",,"\|h\|_{L^{q}(\Omega)}\leq C(\Omega,p)\left(\int_{\Omega}dist(Df(s),SO(d))^{p}\,ds\right)^{1/p}","where \(h\) is the non-linear part of \(g^{-1} \circ f\) and \(C(\Omega,p)\) is a constant depending on the domain \(\Omega\) and exponent \(p\)."
ICML_2024_oral_110,10,x=f(s)=As+\eta h(s),where \(h:\mathbb{R}^{d}\to\mathbb{R}^{d}\) is a non-linear function and \(\eta\in\mathbb{R}\) is a small constant,"\|h\|_{P,q}\leq C_{1}\Theta_{p}(f,\Omega)","The function \(h\) measuring the nonlinearity of the deviation from a linear map is bounded in \(L^q(\mathbb{P})\) norm by a constant times the isometry deviation \(\Theta_{p}(f,\Omega)\)."
ICML_2024_oral_110,11,H(w)=EG(w^{\top}\Sigma_{X}^{-\frac{1}{2}}X),where \(\Sigma_{X}\) denotes the covariance matrix of \(X\) so that \(\Sigma_{X}^{-\frac{1}{2}}X\) is whitened and \(G\) is the so-called contrast function,"H(u)=\kappa_{4}(\langle u, X\rangle)",\(H(u)\) is the fourth cumulant (kurtosis) of the projection of \(X\) onto the unit vector \(u\).
ICML_2024_oral_110,12,\bar{w}_{i}=(AA^{\top})^{\frac{1}{2}}A^{-\top}e_{i},,A^{\top}\Sigma_{X}^{-\frac{1}{2}}w=e_{i},where \(e_{i}\) is the \(i\)-th standard basis vector in \(\mathbb{R}^{d}\).
ICML_2024_oral_110,13,"|G^{(k)}(x)|\leq C_{g}(1+|x|)^{\max(d_{g}-k,0)}",where \(G^{(k)}\) denotes the \(k\)-th derivative of \(G\),\bar{w}_{i}=(AA^{\top})^{\frac{1}{2}} A^{-\top} e_{i},\(\bar{w}_{i}\) is the vector such that \(\bar{w}_{i}^{\top}\Sigma_{X}^{-\frac{1}{2}}X = S_{i}\) in the linear mixing case.
ICML_2024_oral_110,14,E(|S|^{q})=M,,|S|_{L^{q}(P)}\leq M,The \(L^{q}\)-norm of the latent sources \(S\) under \(\mathbb{P}\) is bounded by \(M\).
ICML_2024_oral_110,15,E(S_{i}g(S_{i})-g^{\prime}(S_{i}))=\alpha_{i},,E\left[ G''(S_i) S_i^2+G'(S_i) S_i\right]=\alpha_i\neq 0,"where \(G'\) and \(G''\) denote the first and second derivatives of the contrast function \(G\), and \(S_i\) is the \(i\)-th latent variable."
ICML_2024_oral_111,1,"L_{sup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE} (M_{i,j}^{l},Y_{i,j}^{l})","where \(M_{i,j}^{l}\) denotes the prediction mask of Burn-In model for the \(j\)-th pixel of \(i\)-th labeled image, \(Y_{i,j}^{l}\) denotes the corresponding ground truth, \(\mathcal{L}_{BCE}\) denotes binary cross entropy loss (Csiszar, 2008)","L_{burn-in}=\frac{1}{N_l}\sum_{i=1}^{N_l}\ell\left(f_\theta(x_i^l), y_i^l\right)","The burn-in loss $\mathcal{L}_{\text{burn-in}}$ is the average supervised loss over the labeled dataset, where $f_\theta$ is the model, $x_i^l$ and $y_i^l$ are the $i$-th labeled input and label, and $\ell$ is the loss function."
ICML_2024_oral_111,2,"\theta_{t}arrow\theta,\theta_{s}arrow\theta","where \(\theta_{t},\theta_{s},\theta\) denote the parameters of the teacher, student and Burn-In model, respectively","\theta_{teacher},\theta_{student}\leftarrow\theta","where \(\theta_{teacher}\) and \(\theta_{student}\) denote the initialized parameters of the teacher and student models, respectively, both set to the pre-trained weights \(\theta\) from the Burn-In stage."
ICML_2024_oral_111,3,"L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE} (M_{i,j}^{u},\hat{M}_{i,j}^{u})","where \(M_{i,j}^{u}\) and \(\hat{M}_{i,j}^{u}\) denote the predicted mask for \(j\)-th pixel of \(i\)-th unlabeled image by student and teacher, respectively","L_{pseudo}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE}(M_{i,j}^{u},\hat{Y}_{i,j}^{u})","where \(M_{i,j}^{u}\) denotes the prediction mask of the student for the \(j\)-th pixel of the \(i\)-th unlabeled image, and \(\hat{Y}_{i,j}^{u}\) denotes the pseudo-label generated by the teacher."
ICML_2024_oral_111,4,L=\lambda_{sup}L_{sup}+\lambda_{unsup}L_{unsup},where \(\lambda_{sup}\) and \(\lambda_{unsup}\) is the hyperparameter of supervised loss \(\mathcal{L}_{sup}\) and unsupervised loss \(\mathcal{L}_{unsup}\),L_{total}=L_{sup}+\lambdaL_{unsup},where \(\lambda\) is a weighting coefficient balancing the supervised and unsupervised loss terms.
ICML_2024_oral_111,5,\theta_{t}arrow\alpha\theta_{t}+(1-\alpha)\theta_{s},"where \(\alpha\) is the decay coefficient of EMA, typically set within the small range of 0",\theta_{t}^{(k+1)}=\alpha\theta_{t}^{(k)}+(1-\alpha)\theta_{s}^{(k)},"where \(\theta_{t}^{(k+1)}\) and \(\theta_{t}^{(k)}\) denote the teacher model parameters at iteration \(k+1\) and \(k\), \(\theta_{s}^{(k)}\) denotes the student model parameters at iteration \(k\), and \(\alpha\) is the EMA decay rate."
ICML_2024_oral_111,6,"s^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i, j,k}^{u})}{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cup\widetilde{M}_{i, j,k}^{u})}","where \(\hat{M}_{i,j}^{u}\) and \(\widetilde{M}_{i,j,k}^{u}\) denote the pseudo-labels and \(k\)-th segment mask generated by SAM for \(j\)-th pixel of \(i\)-th unlabeled image \(\mathcal{I}_{i}^{u}\), respectively","IoU(A, B)=\frac{|A\cap B|}{|A\cup B|}",The Intersection over Union (IoU) between two masks \(A\) and \(B\) is defined as the ratio of the area of their intersection to the area of their union.
ICML_2024_oral_111,7,"s_{1}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{ i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u})+\epsilon}",where \(\epsilon\) is the smoothing factor to prevent a denominator of zero,"r^{k}=\frac{\sum_{j=1}^{H\times W} (\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i,j,k}^{u})}{\sum_{j=1}^{H\times W}\hat{M}_{i,j}^{u}}","where \(r^{k}\) denotes the overlap ratio between the pseudo-label \(\hat{M}_{i,j}^{u}\) and the \(k\)-th SAM segment \(\widetilde{M}_{i,j,k}^{u}\) for the \(j\)-th pixel of the \(i\)-th unlabeled image."
ICML_2024_oral_111,8,"s_{2}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M} _{i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\widetilde{M}_{i,j,k}^{u} )}",,"s_{2}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\widetilde{M}_{i,j,k}^{u})+\epsilon}","where \(s_{2}^{k}\) is the overlap ratio for over-segmentation, \(\widetilde{M}_{i,j,k}^{u}\) is the \(k\)-th SAM segment, \(\hat{M}_{i,j}^{u}\) is the pseudo-label, and \(\epsilon\) is a smoothing factor."
ICML_2024_oral_111,9,"\Psi(\hat{M}^{u}_{i,j})=\gamma-\frac{1}{\sqrt{2\pi\sigma}}\exp(-\frac{(\hat{M}^{u}_{i,j}-\mu)^{2}}{2\sigma^{2}})","where \(\gamma,\sigma^{2},\mu\) are hyperparameters, which are set to 1","w_{i,j}=\Psi(\hat{M}_{i,j}^{u})=1-4\cdot (\hat{M}_{i,j}^{u}-0.5)^2","where \(w_{i,j}\) is the weight for the \(j\)-th pixel of the \(i\)-th unlabeled image, \(\Psi\) is the mapping function, and \(\hat{M}_{i,j}^{u}\) is the pseudo-label confidence for that pixel."
ICML_2024_oral_111,10,"L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}\Psi(\hat{M}^{u} _{i,j})*L_{BCE}(M^{u}_{i,j},\hat{M}^{u}_{i,j})",,"L_{PWA}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}\Psi(\hat{M}^{u}_{i,j})\cdotL_{BCE}(M^{u}_{i,j},\hat{M}^{u}_{i,j})","where \(\mathcal{L}_{PWA}\) denotes the pixel-wise weighted adjustment loss, \(\Psi(\hat{M}^{u}_{i,j})\) is the confidence-based pixel weight, and \(\mathcal{L}_{BCE}\) is the binary cross entropy loss between the student prediction \(M^{u}_{i,j}\) and teacher pseudo-label \(\hat{M}^{u}_{i,j}\) for the \(j\)-th pixel of the \(i\)-th unlabeled image."
ICML_2024_oral_113,1,"\nabla_{\theta}J(\pi_{\theta})=\operatorname*{E}_{s\sim\rho_{d},a\sim\pi(\cdot|s)}[\nabla_{\theta}\log(\pi_{\theta}(a))\hat{A}^{\pi_{\theta}}(s,a)]","where \(\hat{A}^{\pi_{\theta}}(s,a)\) is an advantage function that estimates the contribution of the transition to the gradient","\nabla_\thetaJ(\pi_\theta)=E_{\pi_\theta}\left[\nabla_\theta\log\pi_\theta(a_t|s_t)\,\hat{A}_t\right]",The policy gradient is estimated as the expectation over trajectories of the gradient of the log-policy weighted by the advantage estimator \(\hat{A}_t\).
ICML_2024_oral_113,2,"L_{on}(\pi_{\theta})&=\operatorname*{E}_{\pi_{old}}[\min(r_{t}(\pi_{\theta}),.\\&.clip(r_{t}(\pi_{\theta}),1-\epsilon,1+\epsilon))A_{t}^{\pi_{old}}]",,"L^{PPO}(\theta)=\operatorname*{E}_{t}\left[\min\left( r_{t}(\theta)\hat{A}_{t},\clip(r_{t}(\theta), 1-\epsilon, 1+\epsilon)\hat{A}_{t}\right)\right]",where \(r_{t}(\theta) = \frac{\pi_{\theta}(a_{t}|s_{t})}{\pi_{\theta_{\text{old}}}(a_{t}|s_{t})}\) is the probability ratio and \(\epsilon\) is a hyperparameter controlling the clipping range.
ICML_2024_oral_113,3,"& L_{off}(\pi_{i};X)=\frac{1}{|X|}\sum_{j\inX}\operatorname*{E}_{(s,a)\sim\pi_{j}}[\min (r_{\pi_{i}}(s,a),..\\&..clip(r_{\pi_{i}}(s,a),\mu(1-\epsilon),\mu(1+\epsilon)))A^{\pi_{i,old}}(s,a)]","where \(r_{\pi_{i}}(s,a)=\frac{\pi_{i}(s,a)}{\pi_{j}(s,a)}\) and \(\mu\) is an off-policy correction term \(\mu=\frac{\pi_{i,old}(s,a)}{\pi_{j}(s,a)}\)","\nabla_{\theta_{i}}J(\pi_{i})=\operatorname*{E}_{s,a\sim\pi_{j}}\left[\frac{\pi_{i}(a|s)}{\pi_{j}(a|s)}\nabla_{\theta_{i}}\log\pi_{i}(a|s)\hat{A}^{\pi_{i}}(s,a)\right]","where the gradient for policy \(\pi_{i}\) is estimated using samples from policy \(\pi_{j}\), weighted by the importance ratio \(\frac{\pi_{i}(a|s)}{\pi_{j}(a|s)}\)."
ICML_2024_oral_113,4,L(\pi_{i})=L_{on}(\pi_{i})+\lambda\cdot L_{off}(\pi_{i};X),,L(\pi_{i})=\lambda_{on} L_{on}(\pi_{i})+\lambda_{off} L_{off}(\pi_{i};X),"where \(\lambda_{on}\) and \(\lambda_{off}\) are coefficients that weight the on-policy and off-policy loss terms, respectively."
ICML_2024_oral_113,5,"V^{target}_{on,\pi_{j}}(s_{t})=\sum_{k=t}^{t+2}\gamma^{k-t}r_{k}+\gamma^{3}V_{\pi_{j},old}(s_{t+3})",,G_{t}^{(n)}=\sum_{k=0}^{n-1}\gamma^{k} r_{t+k}+\gamma^{n} V(s_{t+n}),"\(G_{t}^{(n)}\) is the \(n\)-step return used as the target for the value function update, combining immediate rewards and the bootstrapped value at step \(t+n\)."
ICML_2024_oral_113,6,"V^{target}_{off,\pi_{j}}(s^{\prime}_{t})=r_{t}+\gamma V_{\pi_{j},old}(s^{\prime}_{t+1})",,"V^{target}_{off,\pi_{i},\pi_{j}}(s_{t})=r_{t}+\gamma V_{\pi_{i},old}(s_{t+1})","where \(V^{target}_{off,\pi_{i},\pi_{j}}(s_{t})\) is the 1-step return target for the critic when using off-policy data from \(\pi_{j}\) to update \(\pi_{i}\)."
ICML_2024_oral_113,7,"L^{critic}_{on}(\pi_{i})=\operatorname*{E}_{(s,a)\sim\pi_{i}}[( V_{\pi_{i}}(s)-V^{target}_{on,\pi_{i}}(s))^{2}] || L^{critic}_{off}(\pi_{i};X)=\frac{1}{|X|}\sum_{j\inX}\operatorname*{E}_{(s,a)\sim\pi_{j}}[(V_{\pi_{i}}(s)-V^{target}_{off,\pi_{i}}(s))^{2}] || L^{critic}(\pi_{i})=L^{critic}_{on}(\pi_{i})+\lambda\cdot L^{critic}_{off}(\pi_{i})",,"L_{V}=\frac{1}{|X|}\sum_{j\inX}\operatorname*{E}_{s\sim\pi_{j}}\left[\left( V_{\pi_{j}}(s)-V^{target}_{off,\pi_{j}}(s)\right)^2\right]","The critic loss \(L_{V}\) is the mean squared error between the predicted value \(V_{\pi_{j}}(s)\) and the off-policy target value \(V^{target}_{off,\pi_{j}}(s)\), averaged over all policies in \(\mathcal{X}\)."
ICML_2024_oral_117,1,"Attention(q,K,V)=softmax(\frac{qK^{T}}{\sqrt{d_{model}}})V",,v=Softmax\left(\frac{q K^\top}{\sqrt{d_{model}}}\right) V,"The output vector \(\mathbf{v}\) is computed as the scaled dot-product attention over previous policy outputs, using the query \(\mathbf{q}\), keys \(K\), and values \(V\)."
ICML_2024_oral_117,2,"FTr_{i}=\frac{AUC_{i}-AUC_{i}^{b}}{1-AUC_{i}^{ b}},\quadAUC_{i}=\frac{1}{\Delta}\int_{(i-1)\cdot\Delta}^{i\cdot\Delta}p_{i}(t)dt || AUC_{i}^{b}=\frac{1}{\Delta}\int_{0}^{\Delta}p_{i}^{b}(t)dt",,FTr_{i}=\frac{1}{\Delta}\sum_{t=1}^{\Delta}\left( p_{i}(t)-p_{i}^{b}(t)\right),The forward transfer \(\text{FTr}_{i}\) for task \(i\) is the average difference in success rate between the method and the baseline over the training timesteps for that task.
ICML_2024_oral_117,3,"RT=\frac{1}{N}\sum_{i=2}^{N}\max_{j<i}FTr(j,i)","where \(\text{FTr}(j,i)\) is the forward transfer obtained by training a model from scratch in the \(j\)-th task and fine-tuning it in the \(i\)-th task","RT_{i}=\max_{j < i}\frac{AUC_{i}^{j}-AUC_{i}^{b}}{1-AUC_{i}^{b}},\quadAUC_{i}^{j}=\frac{1}{\Delta}\int_{0}^{\Delta} p_{i}^{j}(t)dt","\(\text{RT}_{i}\) is the maximum normalized forward transfer to task \(i\) achieved by fine-tuning from any previous task \(j < i\), where \(\text{AUC}_{i}^{j}\) is the area under the learning curve for task \(i\) when initialized from task \(j\), and \(\text{AUC}_{i}^{b}\) is the area under the baseline curve."
ICML_2024_oral_121,1,"p(x;p^{m})=\sum_{i}^{N}k(x,d_{i})p_{i}^{m}",,p(x)=\sum_{i=1}^{N} p_{i}^{m}\cdot\frac{1}{2b}\exp\left(-\frac{|x-d_{i}|}{b}\right),The continuous probability density function \(p(x)\) is obtained by interpolating the discrete disparity probabilities \(p_{i}^{m}\) using a Laplacian kernel centered at each discrete disparity \(d_{i}\) with bandwidth parameter \(b\).
ICML_2024_oral_121,2,"\texttt{argmin}_{y}F(y,p^{m})=\texttt{argmin}_{y}\intL(y,x )p(x;p^{m})dx","where \(F(y,\mathbf{p}^{m})\) is called as the risk at \(y\), and \(\mathcal{L}(y,x)\) is the error function between \(y\) and \(x\)","R(y;p^{m})=\int |y-x|\, p(x;p^{m})\, dx",The expected absolute error (risk) of predicting disparity \(y\) under the interpolated probability density \(p(x;\mathbf{p}^{m})\).
ICML_2024_oral_121,3,y=\int xp(x;p^{m})dx,,"\hat{y}_{exp}=\int x\, p(x;p^{m})\, dx",The expected disparity prediction \(\hat{y}_{\text{exp}}\) is computed as the mean of the interpolated probability density \(p(x;\mathbf{p}^{m})\).
ICML_2024_oral_121,4,"\texttt{argmin}_{y}F(y,p^{m})=\texttt{argmin}_{y}\int|y-x|p(x;p^{m})dx",,"L(y,x)=|y-x|","The loss function \(\mathcal{L}(y,x)\) is defined as the \(L^1\) norm, i.e., the absolute difference between the prediction \(y\) and the ground truth \(x\)."
ICML_2024_oral_121,5,"G(y,p^{m})\triangleq\frac{\partial F(y,p^{m})} {\partial y} || =\sum_{i}p_{i}^{m}\texttt{Sign}(y-d_{i})(1-\exp-\frac{|y-d_{i}|}{\sigma})=0",,"\frac{\partial F(y,p^{m})}{\partial y}=\intsign(y-x)\, p(x;p^{m})\, dx=0","The optimal prediction \(y\) under the \(L^1\) risk is found by setting the derivative of the risk function with respect to \(y\) to zero, where the derivative involves the sign function and the interpolated probability density."
ICML_2024_oral_121,6,"dG(y,p^{m})=\frac{\partial G}{\partial y}dy+\frac{\partial G}{\partialp^{m}}dp^{m}=0",,"\frac{dy}{dp^{m}}=-\left(\frac{\partial G(y,p^{m})}{\partial y}\right)^{-1}\frac{\partial G(y,p^{m})}{\partialp^{m}}","The gradient of the optimal prediction \(y\) with respect to the discrete probability distribution \(\mathbf{p}^{m}\) is given by the negative ratio of the partial derivatives of \(G(y, \mathbf{p}^{m})\) with respect to \(y\) and \(\mathbf{p}^{m}\)."
ICML_2024_oral_121,7,"\frac{dy}{dp^{m}}=-\frac{\partial G/\partialp^{m}}{\partial G/\partial y} || =[\dots,\frac{\sigma\texttt{Sign}(d_{i}-y)(1-\exp-\frac{|y-d_{i} |}{\sigma})}{\sum_{j}p_{j}^{m}\exp-\frac{|y-d_{i}|}{\sigma}},\dots]^{T}",,\frac{dy}{dp^{m}}=-\left(\frac{\partial G}{\partial y}\right)^{-1}\frac{\partial G}{\partialp^{m}},The gradient of the optimal disparity \(y\) with respect to the discrete probability vector \(\mathbf{p}^{m}\) is given by the negative inverse of the partial derivative of \(G\) with respect to \(y\) times the partial derivative of \(G\) with respect to \(\mathbf{p}^{m}\).
ICML_2024_oral_121,8,"L(x^{\texttt{gt}},x^{\texttt{pred}})=0.5(x^{\texttt{gt}}-x^{\texttt{pred}})^{2},&if |x^{\texttt{gt}}-x^{\texttt{pred}}|<1.0\\|x^{\texttt{gt}}-x^{\texttt{pred}}|-0.5,&otherwise",,"L_{smooth}(x^{\texttt{pred}}, x^{\texttt{gt}})=0.5(x^{\texttt{pred}}-x^{\texttt{gt}})^2, &if  |x^{\texttt{pred}}-x^{\texttt{gt}}| < 1\\|x^{\texttt{pred}}-x^{\texttt{gt}}|-0.5, &otherwise","The smooth \(L^1\) loss penalizes the difference between the predicted disparity and the ground-truth disparity, being quadratic for small errors and linear for large errors."
ICML_2024_oral_122,1,"\min_{\theta}\,\sum_{i=1}^{N}(\hat{y}(x;\theta)-y_{i})^{2}",,L_{MSE}(\theta)=\frac{1}{N}\sum_{i=1}^{N}\left( y_i-\hat{y}(x_i;\theta)\right)^2,"The mean-squared error (MSE) loss for regression, measuring the average squared difference between true targets \(y_i\) and model predictions \(\hat{y}(x_i; \theta)\)."
ICML_2024_oral_122,2,"\min_{\theta}\,\sum_{i=1}^{N}\int_{Y}p(y\,|\,x_{i})\log(\hat{p}(y\,|\,x_ {i};\theta))dy",,"\min_{\theta}\,KL\left(p(y\,|\,x)\,\|\,\hat{p}(y\,|\,x;\theta)\right)","The regression objective is to minimize the Kullback-Leibler (KL) divergence between the true target distribution \(p(y\,|\,x)\) and the parameterized model distribution \(\hat{p}(y\,|\,x;\theta)\)."
ICML_2024_oral_122,3,"Z=\{\sum_{i=1}^{m}p_{i}\,\delta_{z_{i}}\,:\,p_{i}\geq 0,\sum_{i=1} ^{m}p_{i}=1\}",where \(p_{i}\) is the probability associated with location \(z_{i}\) and \(\delta_{z_{i}}\) is the Dirac delta function at location \(z_{i}\),"z_{j}=v_{min}+(j-1)\Delta,\qquad\Delta=\frac{v_{max}-v_{min}}{m-1},\qquad j=1,\ldots,m","\(z_j\) denotes the \(j\)-th discrete support point for the categorical distribution, spaced by \(\Delta\) between \(v_{\text{min}}\) and \(v_{\text{max}}\)."
ICML_2024_oral_122,4,"\boxed{TD_{MSE}(\theta)=E_{D}[((\tilde{T}Q)(S,A;\tilde{\theta})-\,Q(S,A;\theta))^{2}]} || (\tilde{T}Q)(s,a;\tilde{\theta})=R+\gamma\max_{a^{\prime}}Q(S^{\prime },a^{\prime};\tilde{\theta})\,\big{|}\,S=s,A=a\","where \(\tilde{\theta}\) is a slow moving copy of the parameters \(\theta\) that parameterize the ""target network"" and

\[(\tilde{\mathcal{T}}Q)(s,a;\tilde{\theta})=R+\gamma\max_{a^{\prime}}Q(S^{\prime },a^{\prime};\tilde{\theta})\,\big{|}\,S=s,A=a\,,\]

is the sample version of the Bellman optimality operator which defines our scalar regression target","\min_{\theta}\,E_{(S,A,R,S')\simD}\left[\left(Q(S,A;\theta)-\left(R+\gamma\,\max_{a'}Q(S',a';\theta^{-})\right)\right)^{2}\right]","where \(Q(S,A;\theta)\) is the predicted action-value, \(R\) is the observed reward, \(\gamma\) is the discount factor, \(S'\) is the next state, and \(\theta^{-}\) are the parameters of the target network."
ICML_2024_oral_122,5,"\alpha\,E_{D}[\log\big{(}\sum_{a^{\prime}}\exp(Q(S^{\prime},a^{\prime};\theta))\big{)}-Q(S,A;\theta)]",,"L_{CQL}(\theta)=\alpha\,E_{S\simD}\left[\log\sum_{a\inA}\exp(Q(S,a;\theta))-E_{A\simD}[Q(S,A;\theta)]\right]","where \(\mathcal{L}_{\text{CQL}}(\theta)\) is the conservative Q-learning regularization loss, \(\alpha\) is a scaling parameter, and the terms encourage conservative value estimates by penalizing overestimation of unseen actions."
ICML_2024_oral_122,6,"Q(s,a;\theta)=E[\,Z(s,a;\theta)\,],\Z(s,a;\theta)=\sum_{i=1}^{m}\hat{p}_{i}(s,a;\theta)\cdot\delta_{z_{i}} || \hat{p}_{i}(s,a;\theta)=\frac{\exp(l_{i}(s,a;\theta))}{\sum_{j=1} ^{m}\exp(l_{j}(s,a;\theta))}\",,"\hat{p}_{i}(s,a;\theta)=\frac{\exp(l_{i}(s,a;\theta))}{\sum_{j=1}^{m}\exp(l_{j}(s,a;\theta))}","where \(\hat{p}_{i}(s,a;\theta)\) is the probability assigned to class \(z_{i}\) for state-action pair \((s,a)\), computed via the softmax over logits \(l_{i}(s,a;\theta)\)."
ICML_2024_oral_122,7,"\boxed{TD_{CE}(\theta)=E_{D}[\sum_{i=1 }^{m}p_{i}(S,A;\tilde{\theta})\log\hat{p}_{i}(S,A;\theta)]}",,"E_{D}\left[-\sum_{i=1}^{m}p_{i}(S,A;\tilde{\theta})\log\hat{p}_{i}(S,A;\theta)\right]","where \(p_{i}(S,A;\tilde{\theta})\) are the target categorical probabilities and \(\hat{p}_{i}(S,A;\theta)\) are the predicted probabilities for each support location \(z_{i}\)."
ICML_2024_oral_122,8,"p_{i}(S,A;\tilde{\theta})=\frac{y-z_{i}}{z_{i+1}-z_{i}},\p_{i+1}(S,A;\tilde{\theta})=\frac{z_{i+1}-y}{z_{i+1}-z_{i}}\",,"p_{i}=\frac{z_{i+1}-y}{z_{i+1}-z_{i}},\quad p_{i+1}=\frac{y-z_{i}}{z_{i+1}-z_{i}}",\(p_{i}\) and \(p_{i+1}\) are the probabilities assigned to the two categorical locations \(z_{i}\) and \(z_{i+1}\) that bound the scalar target \(y\).
ICML_2024_oral_122,9,"p_{i}(S,A;\tilde{\theta})=\int_{z_{i}-\nicefrac{{\varsigma}}{{2}}}^{z_{i}+\nicefrac{{\varsigma}}{{2}}}f_{Y|S,A}(y|S,A)dy || =F_{Y|S,A}(z_{i}+\nicefrac{{\varsigma}}{{2}}|S,A)-F_{Y|S,A}(z_{i}-\nicefrac{{\varsigma}}{{2}}|S,A)",,"p_{i}(S,A;\tilde{\theta})=\int_{z_{i}-\frac{\varsigma}{2}}^{z_{i}+\frac{\varsigma}{2}} f_{Y|S,A}(y)\,dy=F_{Y|S,A}\left(z_{i}+\frac{\varsigma}{2}\right)-F_{Y|S,A}\left(z_{i}-\frac{\varsigma}{2}\right)","$p_{i}(S,A;\tilde{\theta})$ is the probability assigned to bin $i$ by integrating the target density $f_{Y|S,A}$ over the interval corresponding to bin $i$."
ICML_2024_oral_122,10,"(\widehat{T}Z)(s,a;\tilde{\theta})\overset{D}{=}\sum_{i=1}^{m}\hat{p}_{i}(S^{\prime},A^{\prime};\tilde{\theta})\cdot\delta_{R+\gamma z_{i}}\bigm{|}S=s,\,A=a\","where \(A^{\prime}=\operatorname*{arg\,max}_{a^{\prime}}Q(S^{\prime},a^{\prime}; \tilde{\theta})\)","TZ(s,a)\overset{D}{=} R(s,a)+\gamma Z(S', a'),\quad S'\sim P(\cdot|s,a),\a'\sim\pi(\cdot|S')","The distributional Bellman operator \(\mathcal{T}Z(s,a)\) defines the target return distribution as the sum of the immediate reward and the discounted return distribution from the next state-action pair, where the randomness is over the environment transition and the policy."
ICML_2024_oral_122,11,"p_{i}(S,A;\tilde{\theta})=\sum_{j=1}^{m}\hat{p}_{j}(S^{\prime},A ^{\prime};\tilde{\theta})\cdot\xi_{j}(R+\gamma z_{i}) || \xi_{j}(x)=\frac{x-z_{j}}{z_{j+1}-z_{j}}\mathds{1}\{\lfloor x\rfloor=z_{j}\}+\frac{z_{j+1}-x}{z_{j+1}-z_{j}}\mathds{1}\{\lceil x\rceil=z_ {j}\}\",,"p_{i}(S,A;\tilde{\theta})=\sum_{j=1}^{m}\hat{p}_{j}(S',A';\tilde{\theta})\cdot\left[\frac{z_{i}-(R+\gamma z_{j})}{z_{i}-z_{i-1}}\cdotI\left(z_{i-1} < R+\gamma z_{j}\leq z_{i}\right)+\frac{(R+\gamma z_{j})-z_{i}}{z_{i+1}-z_{i}}\cdotI\left(z_{i} < R+\gamma z_{j}\leq z_{i+1}\right)\right]","where \(p_{i}(S,A;\tilde{\theta})\) is the projected probability for location \(z_{i}\) obtained by distributing the probability mass from \(R+\gamma z_{j}\) to its neighboring bins according to the predicted distribution \(\hat{p}_{j}(S',A';\tilde{\theta})\)."
ICML_2024_oral_125,1,"E_{i}=L_{i}(E_{i-1}),\\i=1,...,N || \dot{y}=\texttt{Head}(e_{N}^{0})",,"E_{i+1}=L_{i+1}(E_{i}),\quad 0\leq i < N",The patch embeddings for the \((i+1)\)-th layer are obtained by applying the layer \(L_{i+1}\) to the embeddings from the \(i\)-th layer.
ICML_2024_oral_125,2,"\min_{\tilde{\Theta}}L(x;\Theta),\x\sim Q(x)",where \(\tilde{\Theta}\subseteq\Theta\) denotes the model parameters involved for updating,\Theta^{*}=\arg\min_{\Theta}\L_{TTA}(D_{test};\Theta),The optimal model parameters \(\Theta^{*}\) are obtained by minimizing the test-time adaptation loss \(\mathcal{L}_{\text{TTA}}\) over the test dataset \(\mathcal{D}_{test}\).
ICML_2024_oral_125,3,"p^{*}=\operatorname*{arg\,min}_{p}L(f_{\Theta}(p;x))","where \(\mathcal{L}(\cdot)\) is a fitness function and \(\mathbf{p}\in\mathbb{R}^{d\times N_{p}}\) consists of \(N_{p}\) prompt embeddings, each of dimension \(d\)","p^{*}=\arg\min_{p}F(x,p;\Theta),\quadx\sim Q(x)",where \(\mathbf{p}^{*}\) denotes the optimal prompt found by minimizing the unsupervised fitness function \(\mathcal{F}\) for each test sample \(\mathbf{x}\) with model parameters \(\Theta\) fixed.
ICML_2024_oral_125,4,L(f_{\Theta}(p;X_{t}))=\sum_{ x\inX_{t}}\sum_{c\inC}-\hat{y}_{c}\log\hat{y}_{c} || \qquad+\lambda\sum_{i=1}^{N}\lvert\lvert\mu_{i}(X_ {t})-\mu_{i}^{S}\rvert\rvert_{2}+\lVert\sigma_{i}(X_{t})-\sigma_{i}^{S}\rvert\rvert_{2},,L_{stat}(X_{t})=\sum_{i=0}^{N}\left(\left\|\mu_{i}(X_{t})-\mu_{i}^{S}\right\|_{2}^{2}+\left\|\sigma_{i}(X_{t})-\sigma_{i}^{S}\right\|_{2}^{2}\right),"The fitness function \(\mathcal{L}_{\text{stat}}(\mathcal{X}_{t})\) measures the sum of squared differences between the mean and standard deviation of CLS token activations for the current test batch and those of the source in-distribution samples, across all layers."
ICML_2024_oral_125,5,"p_{k}^{(t)}\simm^{(t)}+\tau^{(t)}N(0,\bm {\Sigma}^{(t)})",,"p_{k}^{(t)}\simN(m^{(t)},C^{(t)}),\quad k=1,\ldots,K","where \(\mathbf{p}_{k}^{(t)}\) denotes the \(k\)-th candidate prompt at iteration \(t\), sampled from a multivariate normal distribution with mean \(\mathbf{m}^{(t)}\) and covariance \(\mathbf{C}^{(t)}\), and \(K\) is the population size."
ICML_2024_oral_125,6,e_{N}^{0}arrowe_{N}^{0}+\gammad,where \(\mathbf{d}\) is a shifting direction and \(\gamma\) is a step size,\tilde{e}_{N}^{0}=e_{N}^{0}+\alpha\left(\mu_{N}^{S}-\mu_{N}(X_{t})\right),"where \(\tilde{\mathbf{e}}_{N}^{0}\) is the shifted CLS feature, \(\alpha\) is a step size hyperparameter, \(\mathbf{\mu}_{N}^{S}\) is the mean of source in-distribution CLS features, and \(\mathbf{\mu}_{N}(\mathcal{X}_{t})\) is the mean of CLS features for the current test batch."
ICML_2024_oral_125,7,d_{t}=\mu_{N}^{S}-\mu_{N}(t),where \(\boldsymbol{\mu}_{N}^{S}\) is the mean of the \(N\)-th final layer CLS feature \(\mathbf{e}_{N}^{0}\) and calculated over source in-distribution samples \(\mathcal{D}_{S}\) (the same one used in Eqn,d=\mu_{N}^{S}-\mu_{N}(X_{t}),where \(\mathbf{\mu}_{N}^{S}\) is the mean of source in-distribution CLS features and \(\mathbf{\mu}_{N}(\mathcal{X}_{t})\) is the mean of current testing CLS features at the \(N\)-th layer.
ICML_2024_oral_125,8,\mu_{N}(t)=\alpha\mu_{N}(X_{t})+(1-\alpha )\mu_{N}(t-1),where \(\boldsymbol{\mu}_{N}(\mathcal{X}_{t})\) is the mean of the \(N\)-th layer's CLS feature and calculated over the \(t\)-th test batch \(\mathcal{X}_{t}\),\mu_{N}(t)=\alpha\cdot\mu_{N}(t-1)+(1-\alpha)\cdot\frac{1}{|X_t|}\sum_{x\inX_t}e_N^0(x),where \(\alpha\) is the momentum coefficient and \(\mathcal{X}_t\) is the current test batch.
ICML_2024_oral_127,1,\sup_{x}\mathds{E}_{D^{j}\sim\chi}[\lfloor\frac{j}{i}\hat{f}(x )-f_{D^{j}}(x)\rceil]\geq\frac{\sqrt{k}}{4},,\sup_{x}\mathds{E}_{D\sim\chi}\left[\left\lfloor\frac{j}{i}\hat{f}(x)-f_{D^{j}}(x)\right\rfloor\right]\geq\frac{k}{2i},The expected maximum generalization error of the model after \(k\) insertions is lower bounded by \(\frac{k}{2i}\).
ICML_2024_oral_127,2,\mathds{P}_{D\sim\chi}[\|f_{\chi}-\hat{f}\|_{\infty}\geq\epsilon]\leq\varkappa_ {1}e^{-\varkappa_{2}(\frac{\epsilon}{\sqrt{n}}-1)^{2}},,\sup_{x}\mathds{E}_{D\sim\chi}\left[\left|\hat{f}(x)-f_{D}(x)\right|\right]\leqB_{n}^{X},The expected maximum error between the model's prediction and the true operation is bounded by \(\mathcal{B}_{n}^{\mathfrak{X}}\).
ICML_2024_oral_13,1,"&P\{X_{1}=x_{1}\}\\&P\{X_{2}=x_{2}|X_{1}=x_{1}\}\\&\quad\vdots\\&P\{X_{n}=x_{n}|X_{1}=x_{1},\cdots,X_{n-1}=x_{n-1 }\}",,"P(X_{1}=x_{1},\ldots,X_{n}=x_{n})=\prod_{i=1}^{n} P(X_{i}=x_{i}\mid X_{1}=x_{1},\ldots,X_{i-1}=x_{i-1})",The joint probability of a sequence of tokens is given by the product of conditional probabilities of each token given all previous tokens.
ICML_2024_oral_13,2,"&P\{X_{n}=x_{n}\}\\&P\{X_{n-1}=x_{n-1}|X_{n}=x_{n}\}\\&\quad\vdots\\&P\{X_{1}=x_{1}|X_{n}=x_{n},\cdots,X_{2}=x_{2}\}",,"&P\{X_{n}=x_{n}\}\\&P\{X_{n-1}=x_{n-1}|X_{n}=x_{n}\}\\&\quad\vdots\\&P\{X_{1}=x_{1}|X_{2}=x_{2},\cdots,X_{n}=x_{n}\}","Backward factorization of the joint probability, conditioning each token on all future tokens."
ICML_2024_oral_13,3,"\sum_{i=1}^{n}\ell_{i}^{arrow}=-\lnP_{n}^{arrow}\{X_ {1}=x_{1},\cdots,X_{n}=x_{n}\}",,"E_{(x_{1},\ldots,x_{n})\simP}\left[\sum_{i=1}^{n}\ell_{C}\left(p_{i}^{\leftarrow},x_{i}\right)\right]=KL\left(P\,\|\,P_{n}^{\leftarrow}\right)+H(P)",The expected total cross-entropy loss of the backward model equals the Kullback-Leibler divergence between the true distribution and the backward model plus the entropy of the true distribution.
ICML_2024_oral_13,4,L_{n}^{arrow}=D_{KL}(P_{n}\big{|}\big{|}P_{n}^{arrow})+H(P_{n}),where \(H\) denotes the entropy and \(\mathrm{D}_{\mathrm{KL}}\) the Kullback-Leibler divergence,"L_{n}^{\leftarrow}=-E_{(x_{1},\ldots,x_{n})\simP_{n}}\left[\lnP_{n}^{\leftarrow}\{X_{1}=x_{1},\ldots,X_{n}=x_{n}\}\right]",The expected backward cross-entropy loss equals the negative expected log-likelihood of the backward model's estimated probability over true data samples.
ICML_2024_oral_132,1,P(A(D)\in S)\leq e^{\epsilon}P(A(D^{\prime})\in S)+\delta,,\Pr[A(D)\in S]\leq e^{\epsilon}\Pr[A(D^{\prime})\in S]+\delta,"This equation defines \((\epsilon, \delta)\)-differential privacy for a randomized algorithm \(\mathcal{A}\), requiring that the probability of any output set \(S\) does not change significantly when a single data point is added or removed from the dataset."
ICML_2024_oral_132,2,\epsilon=\epsilon_{\alpha}+\log(\frac{\alpha-1}{\alpha})-\frac{\log\delta+\log\alpha}{\alpha-1},,\epsilon=\epsilon_{\alpha}+\frac{\log(1/\delta)}{\alpha-1},"Here, \(\epsilon\) is the differential privacy parameter obtained from the RDP parameter \(\epsilon_{\alpha}\), the order \(\alpha\), and the failure probability \(\delta\)."
ICML_2024_oral_132,3,"\widetilde{g}_{t}=\frac{1}{B}(\sum_{x\inB_{t}}clip_{C}(\nabla_{\theta}\ell(x;\theta_{t})+N(0,\sigma^{2}C^{2}I))","where \(\eta_{t}\) is the learning rate, \(\mathcal{B}_{t}\) is the sampled batch, \(B\) is the average batch size, \(\sigma>0\) is the noise multiplier, and \(\mathsf{clip}_{C}\) is the operation that clips the per-sample gradient norm to at most \(C>0\)","\widetilde{g}_{t}=\frac{1}{|B_t|}\sum_{i\in B_t}\left(\nabla_{\theta}\ell(\theta_t,z_i)+N(0,\sigma^2I)\right)","\(\widetilde{\mathbf{g}}_{t}\) is the privatized gradient at iteration \(t\), computed by averaging the per-sample gradients (with added Gaussian noise) over the minibatch \(B_t\)."
ICML_2024_oral_132,4,"L_{MAE}(\theta):=\frac{1}{n}\sum_{i=1}^{n}\underbrace{\xi_{ MSE}(g\circ\psi(mask(x_{i});\theta),x_{i})}_{\ell(x_{i};\theta)}","where \(n\) is the number of training samples, \(\mathbf{x}_{i}\in\mathbb{R}^{C\times H\times W}\) is the input of the \(i\)-th training image (\(C\)-number of channels, \(H\)-height, \(W\)-width), mask\((\cdot)\) is a function that mask out a fraction of the image, \(\psi:\mathbb{R}^{C\times H\times W}\rightarrow\mathbb{R}^{d}\) is the encoder and \(g:\mathbb{R}^{d}\rightarrow\mathbb{R}^{C\times H\times W}\) is the decoder",L_{MAE}(\theta)=E_{x\simD}\;E_{M}\left[\left\| f_{\theta}(M(x))-x\right\|_2^2\right],"where \(L_{\text{MAE}}(\mathbf{\theta})\) is the masked autoencoder reconstruction loss, \(\mathcal{D}\) is the data distribution, \(\mathcal{M}\) is a random masking operator, and \(f_{\mathbf{\theta}}\) is the model parameterized by \(\mathbf{\theta}\)."
ICML_2024_oral_15,1,\min_{p(T|X)}\quad I(X;T),where \(I(X;T)\) denotes the mutual information of \(X\) and \(T\),"T^*=\arg\min_{T}E_{x\sim p(x)}\left[ d(x,\hat{x}(T(x)))\right]","Here, \(\mathcal{T}^*\) denotes the optimal partitioning that minimizes the expected distortion between the original data \(x\) and its reconstruction \(\hat{x}\) under the mapping \(\mathcal{T}\)."
ICML_2024_oral_15,2,\min_{p(T|X)} I(X;T),,\min_{p(T|X)}\quad I(X;T)-\lambda I(T;Q),"where \(I(T;Q)\) denotes the mutual information between \(T\) and \(Q\), and \(\lambda\) is a trade-off parameter."
ICML_2024_oral_15,3,I(T;Q)\geq\varepsilon,where \(\varepsilon>0\) is a threshold,I(Q;T)\geq\beta,"where \(I(Q;T)\) denotes the mutual information between \(Q\) and \(T\), and \(\beta\) is a target information constraint."
ICML_2024_oral_15,4,L(p(T|X))=I(X;T)-\beta I(T;Q),where \(\beta\) is the Lagrange multiplier,L=I(X;T)-\beta I(T;Q),where \(\beta > 0\) is a Lagrange multiplier balancing index conciseness and retrieval accuracy.
ICML_2024_oral_15,5,L(p(T|X))=I(X;T)+\beta I(X;Q|T)+constant,,\max_{p(T|X)}\I(T;Q)\quads.t.\I(X;T)\leq R,where \(R\) is a constraint on the maximum allowable mutual information between \(X\) and \(T\)
ICML_2024_oral_15,6,"p^{*}(T|X)=\frac{p^{*}(T)}{Z(X,\beta)}\exp\Bigl{(}-\betaKL[p(Q|X)\\big{\|}\p(Q|T)]\Bigr{)}","where \(Z(X,\beta)\) is a probability normalization term, \(p^{*}(T)=\mathbb{E}_{X}[p^{*}(T|X)]\)","p^{*}(T|X)=\frac{p(T)}{Z(X,\beta)}\exp\left(-\beta D_{KL}(p(Q|X)\,\|\,p(Q|T))\right)","where \(Z(X,\beta)\) is a normalization constant and \(D_{\mathrm{KL}}(p(Q|X)\,\|\,p(Q|T))\) is the Kullback-Leibler divergence between \(p(Q|X)\) and \(p(Q|T)\)"
ICML_2024_oral_15,7,"p(X,Q|f)\equiv\prod_{x\inX}p^{*}\big{(}X=x\\big{|}\T=f(x)\big{)}",where \(p^{*}\) is given by Formula (5),"p(X,Q|f)=\prod_{x\inX}\prod_{q\inQ} p(q|t=f(x))","The likelihood function \(p(\mathcal{X},\mathcal{Q}|f)\) is the product over all documents \(x\) and queries \(q\) of the conditional probability \(p(q|t)\), where \(t=f(x)\) is the index assigned to \(x\) by \(f\)."
ICML_2024_oral_15,8,"I(X;T)=E_{X,T}\log\frac{p(X|T)}{p(X)} || I(X;Q|T)=E_{X,T,Q}\log\frac{p(X,Q|T)}{p(X|T)p(Q|T)}",,"I(X;T)=\sum_{x\inX}\sum_{t\inT} p(x, t)\log\frac{p(x, t)}{p(x)p(t)}","where \(p(x, t)\) is the joint probability of document \(x\) and index \(t\), and \(p(x)\), \(p(t)\) are their marginals."
ICML_2024_oral_15,9,"=E_{X,T,Q}\log\frac{p(X|Q)}{p(T|Q)}\frac{p(T)}{p(X)}",,"I(T;Q)=E_{T,Q}\log\frac{p(T,Q)}{p(T)p(Q)}",where \(I(T;Q)\) denotes the mutual information between \(T\) and \(Q\).
ICML_2024_oral_22,1,"x_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\Big{(}x_{t}-\frac{1-\alpha_{t}} {\sqrt{1-\bar{\alpha}_{t}}}\epsilon_{\theta}(x_{t},t,c)\Big{)}+\sigma_{t}\epsilon","where \(\mathbf{\epsilon}\sim\mathcal{N}(0,I)\), \(\alpha_{0}:=1\), \(\alpha_{t}\) and \(\bar{\alpha}_{t}\) define the noise schedule, \(\sigma_{t}\) is the sampling standard deviation","x_{t-1}=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_\theta(x_t, t,c)\right)+\sigma_tz,\quadz\simN(0, I)","The reverse diffusion step updates the sample from \(\mathbf{x}_t\) to \(\mathbf{x}_{t-1}\) using the neural network prediction, noise schedule parameters, and Gaussian noise."
ICML_2024_oral_22,2,"x_{T}^{*}=\arg\min_{x_{T}}L(f(x_{0}),y) || x_{0}=\texttt{Sampler}_{T}(\epsilon_{\theta},x_{T},c)",,"x_{T}^{*}=\arg\min_{x_{T}}\;L\big(f(\texttt{Sampler}_{T}(\epsilon_{\theta},x_{T},c)),y\big)",where \(\mathbf{x}_{T}^{*}\) is the optimized initial noise latent that minimizes the loss between the extracted feature of the generated sample and the target control \(\mathbf{y}\).
ICML_2024_oral_24,1,"\omega_{1}(D_{1},D_{2},J)=\frac{1}{N}\sum_{i=1}^{N}\mathds{1}\{J(q_{i},a_{i1}, a_{i2})=a_{i1}\}",,"\omega_{1}=\frac{1}{N}\sum_{i=1}^{N}I\left[J(q_{i}, a_{i1}, a_{i2})=1\right]",\(\omega_{1}\) is the proportion of questions for which the judge selects Debater \(D_{1}\)'s answer.
ICML_2024_oral_24,2,"\bar{\omega}_{1}(D_{1},D_{2},J)>\frac{1}{2}",,"\bar{\omega}_{1}(D_{1},D_{2},J)=\frac{1}{2}\left[\omega_{1}(D_{1},D_{2},J)+\omega_{1}(D_{2},D_{1},J)\right]","\(\bar{\omega}_{1}(D_{1},D_{2},J)\) is the assignment-balanced win rate for Debater \(D_{1}\) against \(D_{2}\) with Judge \(J\)."
ICML_2024_oral_24,3,"\bar{\omega}_{1}(D_{1},D_{2},J)=\frac{1}{1+10^{(E_{2}-E_{1})/400}}",,"\bar{\omega}_{1}(D_{1}, D_{2}, J)=\frac{1}{1+10^{(E_{2}-E_{1})/400}}","\(E_{1}\) and \(E_{2}\) are the aggregate Elo ratings for debaters \(D_{1}\) and \(D_{2}\), respectively."
ICML_2024_oral_24,4,"\omega_{C}(D_{1},D_{2},J)=\frac{1}{1+10^{(E^{I}_{2}-E^{C}_{1})/400}}",,"\omega_{C}(D_{1},D_{2},J)=\frac{1}{N_{C}}\sum_{i=1}^{N}\mathds{1}\{J(q_{i},a_{i1}, a_{i2})=a_{i1}\}\cdot\mathds{1}\{a_{i1}=a_{i}^{*}\}","\(\omega_{C}(D_{1},D_{2},J)\) is the win rate for \(D_{1}\) when assigned the correct answer \(a_{i}^{*}\), averaged over all such assignments."
ICML_2024_oral_25,1,"\min_{\theta}KL(p(Y|X)\|q(Y|X,\theta))",,"\min_{\theta^{(k)}}E_{(x, y)\simD}\left[\ell\left(f(x;\theta^{(k)}), y\right)\right]",Each ensemble member \(k\) learns parameters \(\mathbf{\theta}^{(k)}\) by minimizing the expected loss \(\ell\) over the data distribution \(\mathcal{D}\).
ICML_2024_oral_25,2,"H(q(Y|X))=\underbrace{I(Y;\theta| X)}_{D}+\underbrace{E_{q(\theta|D)}H(q(Y|X,\theta))}_{D}",where \(\mathcal{I}\) denotes the mutual information under the \(q\) distribution,"Var_{q(Y|X)}[Y]=E_{q(\theta|D)}\left[Var_{q(Y|X,\theta)}[Y]\right]+Var_{q(\theta|D)}\left[E_{q(Y|X,\theta)}[Y]\right]",The predictive variance is decomposed into the expected data (aleatoric) uncertainty and the variance due to model (epistemic) uncertainty.
ICML_2024_oral_25,3,H(q(Y|X))=\underbrace{I(Y;C|X)}_ {Q^{\prime}}+\underbrace{E_{q(C|X)}H( q(Y|X\oplusC))}_{Q^{\prime}},,H(q(Y|X))=\underbrace{I(Y;C|X)}_{Aleatoric}+\underbrace{E_{q(C|X)}H(q(Y|X\oplusC))}_{Residual},"where \(\mathcal{I}(\mathbf{Y};\mathbf{C}|\mathbf{X})\) denotes the mutual information between the output and the clarification given the input, quantifying the aleatoric uncertainty resolved by input clarification."
ICML_2024_oral_26,1,"&Attention(Q,K,V)=softmax(QK^{\intercal})V,\\&where Q,K,V\inR^{n\times d}",where \(n\) denotes the number of tokens and \(d\) denotes the hidden dimension of the attention,"Attention(Q, K, V)=softmax(QK^\top)V","The self-attention operation computes a weighted sum of the values \(V\), where the weights are determined by the similarity between queries \(Q\) and keys \(K\)."
ICML_2024_oral_26,2,"& o_{i}=\sum_{j=1}^{n}\frac{e^{q_{i}k_{j}^{\intercal}} }{\sum_{j^{\prime}=1}^{n}e^{q_{i}k_{j^{\prime}}^{\intercal}}v_{j}},\\&where q_{i},k_{i},v_{i}\inR^{1\times d},i=\{1,2,...,n\}",,o_{i}=\sum_{j=1}^{n}\frac{\exp(q_{i} k_{j}^{\intercal})}{\sum_{l=1}^{n}\exp(q_{i} k_{l}^{\intercal})} v_{j},"where \(o_{i}\) is the output vector for the \(i\)-th token, computed as a weighted sum over all value vectors \(v_{j}\) with weights given by the softmax of the dot products between \(q_{i}\) and each \(k_{j}\)."
ICML_2024_oral_26,3,"o_{i}=\sum_{j=1}^{n}\frac{K(q_{i},k_{j})}{\sum_{j^{\prime}=1}^{n}K( q_{i},k_{j^{\prime}})}v_{j}",,"o_{i}=\frac{\sum_{j=1}^{n} K(q_{i}, k_{j}) v_{j}}{\sum_{j'=1}^{n} K(q_{i}, k_{j'})}","where \(K(\cdot,\cdot)\) is a positive-definite kernel function measuring similarity between queries and keys."
ICML_2024_oral_26,4,o_{i}=\sum_{j=1}^{n}\frac{\phi(q_{i})\phi(k_{j})^{\intercal}}{\sum_{j^{\prime }=1}^{n}\phi(q_{i})\phi(k_{j^{\prime}})^{\intercal}}v_{j},where \(\phi(\cdot):\mathbb{R}^{d}\rightarrow\mathbb{R}^{m}\) is a projection to map the inputs into \(m\) dimension features,o_{i}=\frac{\phi(q_{i})\left(\sum_{j=1}^{n}\phi(k_{j})^{\intercal} v_{j}\right)}{\sum_{j^{\prime}=1}^{n}\phi(q_{i})\phi(k_{j^{\prime}})^{\intercal}},"where \(\phi(\cdot)\) is a feature map such that \(K(q_{i}, k_{j}) = \phi(q_{i}) \phi(k_{j})^{\intercal}\)."
ICML_2024_oral_26,5,\phi_{PRF}(x)=e^{\omega x^{\intercal}-\frac{1+x^{2}}{2}},where \(\omega\in\mathbb{R}^{m\times d}\),"\phi(x)=\frac{1}{\sqrt{m}}\exp(Wx+b),\quad W\inR^{m\times d},\b\inR^{m}",where \(\phi(x)\) denotes the positive random feature mapping parameterized by random matrix \(W\) and bias \(b\).
ICML_2024_oral_26,6,"K(x,z)=\int_{R^{d}}e^{i(x-z)^{\intercal}w}p(w)dw=E_{w\sim p(\cdot)}[ e^{iw^{\intercal}x}(e^{iw^{\intercal}z})^{\intercal}]",,"K(x, z)=\int_{R^d} p(\omega) e^{i\omega (x-z)^{\intercal}} d\omega","where \(K(x, z)\) is a continuous shift-invariant positive definite kernel and \(p(\omega)\) is its corresponding spectral measure."
ICML_2024_oral_26,7,"K(x,z)=E_{w\sim p(\cdot)}[e^{iw^{\intercal}x}(e^{iw^{\intercal}z})^{\intercal }]\approx\varphi_{p}(x)^{\intercal}\varphi_{p}^{*}(z)",where \(w_{i}\sim p(\cdot)\) are samples constructed by Monte Carlo methods,"\varphi_{p}(x) :=\frac{1}{\sqrt{m}}\left[ e^{-iw_{1}^{\intercal}x},\ldots, e^{-iw_{m}^{\intercal}x}\right]^{\intercal}","where \(w_{1},\ldots,w_{m}\) are sampled from the probability density \(p(w)\) on \(\mathbb{R}^{d}\)"
ICML_2024_oral_26,8,"K_{G}(x,y):=e^{-\frac{\|x-y\|^{2}}{2}}=e^{-\frac{\|x\|^{2}+\|y\|^{2}}{2}}e^{x ^{\intercal}y}",,"K(x,z)=\exp\left(-\frac{\|x-z\|^{2}}{2}\right)=\int_{R^{d}}e^{iw^{\intercal}(x-z)}p(w)dw","where \(p(w)\) is the standard normal distribution \(p(w)=\mathcal{N}(0,I)\)."
ICML_2024_oral_26,9,"\varphi_{PFF}(x):=\frac{e^{-\|x\|^{2}}}{\sqrt{m}}[e^{\Phi^{-1}(t_{1}) x^{\intercal}v_{1}},...,e^{\Phi^{-1}(t_{m})x^{\intercal}v_{m}}]^{\intercal}",,\phi_{PFF}(x)=e^{\omega x^{\intercal}},where \(\omega\in\mathbb{R}^{m\times d}\) is a fixed frequency matrix used for feature mapping.
ICML_2024_oral_26,10,"\varphi_{WPFF}(x):=\frac{De^{-\|x\|^{2}}}{\sqrt{m}}[e^{\Phi^{-1}(t_{1 })x^{\intercal}v_{1}},...,e^{\Phi^{-1}(t_{m})x^{\intercal}v_{m}}]^{\intercal}",,"\varphi_{WPFF}(x):=\frac{e^{-\|x\|^{2}}}{\sqrt{m}}\left[w_{1}e^{\Phi^{-1}(t_{1}) x^{\intercal}v_{1}},\ldots,w_{m}e^{\Phi^{-1}(t_{m}) x^{\intercal}v_{m}}\right]^{\intercal}","where \(w_{i}\) are positive weights associated with each feature, \(V=[v_{1},...,v_{m}]\in\mathbb{S}^{d\times m}\) is asymptotically uniformly distributed, and \(t_{i}\sim U(0,1)\)."
ICML_2024_oral_26,11,\smallC_{j_{1}j_{2}}=s_{j_{1}}s_{j_{2}}\sum_{i_{1}=0}^{n-1}\sum_{i_{2}=0 }^{d-1}\cos(\frac{\pi(2i_{1}+1)j_{1}}{2d})\cos(\frac{\pi(2i_{2}+1)j_{2}}{2d}),where \(s_{j}=\sqrt{1/d}\) if \(j=0\) and \(s_{j}=\sqrt{2/d}\) otherwise,"C_{ij}=\sqrt{\frac{2}{d}}\cos\left(\frac{\pi}{d}\left(i-\frac{1}{2}\right)(j-1)\right),\quad i,j=1,2,\ldots,d","where \(\mathcal{C}_{ij}\) denotes the \((i,j)\)-th entry of the DCT coefficient matrix for dimension \(d\)."
ICML_2024_oral_26,12,\small\phi_{WDCF}(x)=De^{TCx^{\intercal}},"where \(\mathcal{C}\in\mathbb{R}^{m\times d}\) is the DCT coefficient, \(D\in\mathbb{R}^{m}\) is a learnable weight, and \(T=\text{diag}(t_{1},\dots,t_{m})\) is a random diagonal matrix following the inverse cumulative distribution",\varphi_{WDCF}(x) :=D\cdotC\cdot x,where \(D\) is a learnable parameter and \(\mathcal{C}\) is the DCT coefficient matrix.
ICML_2024_oral_26,13,"\smallFKA(Q,K,V)=\phi_{WDCF}(Q)\phi_{WDCF}(K)^{\intercal}V,\\where Q,K,V\inR^{n\times d}",,\small o_{i}=\sum_{j=1}^{n}\frac{\phi_{WDCF}(q_{i})\phi_{WDCF}(k_{j})^{\intercal}}{\sum_{j'=1}^{n}\phi_{WDCF}(q_{i})\phi_{WDCF}(k_{j'})^{\intercal}} v_{j},where \(\phi_{\text{WDCF}}(\cdot)\) is the Weighted Discrete Cosine Features mapping defined in Equation 12.
ICML_2024_oral_28,1,f\in\operatorname*{argmin}_{f}\sup_{e\inE}R^{e}(\tilde{f}),"where the risk \(R^{e}(f)=\mathbb{E}_{(x,y)\sim P^{e}}[\ell(f(x),y)]\) measures the average loss \(\ell\) incurred by the predictor \(f\) across examples from environment \(e\), all of them drawn iid from \(P^{e}\)",f:X\toY,\(f\) is a predictor mapping inputs \(x \in \mathcal{X}\) to labels \(y \in \mathcal{Y}\).
ICML_2024_oral_28,2,(p_{y_{i}^{out}}^{out}-1/n_{classes})\cdot n_{ classes}/(n_{classes}-1),,P\left(flip  y_{i}\to y_{i}^{out}\right)=\alpha\cdotI\left[y_{i}\neq y_{i}^{out}\right],"where \(\alpha\) is a hyperparameter controlling the flip probability, and \(\mathbb{I}[\cdot]\) is the indicator function."
ICML_2024_oral_28,3,"\llbracket(y\notin\operatorname*{argmax}_{j}f^{a}(x)_{j})\,\vee\,(y\notin\operatorname*{argmax}_{j}f^{b}(x)_{j})\rrbracket","where ""\(\vee\)"" denotes logical-OR, and ""\(\llbracket\)"" is the Iverson bracket","I\left[\operatorname*{arg\,max}_{j} f^{a}(x)\neq\operatorname*{arg\,max}_{j} f^{b}(x)\right]","where \(e(x,y)\) is 1 if the two twin classifiers \(f^{a}\) and \(f^{b}\) disagree on the predicted class for input \(x\), and 0 otherwise."
ICML_2024_oral_28,4,Y\perp E\mid X_{inv},,X_{inv}\perp\!\!\!\perp Y\mid E,"where \(X_{\text{inv}}\) is the invariant feature, \(Y\) is the target, and \(E\) is the set of environments, with ""\(\perp\!\!\!\perp\)"" denoting conditional independence."
ICML_2024_oral_3,1,"\operatorname*{argmin}_{\Theta_{T},M_{T}}\frac{1}{|D|}\sum_{x,y\inD}L(x,y|\Theta_{T},M_{T})",,"\min_{\{M_t,\,R_t\}_{t=1}^T}\quad &L(\Theta;\{M_t,\,R_t\}_{t=1}^T)\\s.t.\quad &Sparsity(\Theta,M_t)\geq\gamma_t,\quad\forall t\in [1, T]\nonumber\\&TuningParams(R_t)\leq\Delta_t,\quad\forall t\in [1, T]\nonumber\\&Sparsity(\Theta,M_T)=\gamma_T\nonumber","The objective is to minimize the task loss \(\mathcal{L}\) by optimizing pruning masks \(\mathcal{M}_t\) and tuning ranks \(\mathcal{R}_t\) at each training step, subject to sparsity and parameter constraints."
ICML_2024_oral_3,2,"1-\frac{C(\Theta_{t},M_{t})}{C(\Theta_{0},M_{0})}\geq\gamma_{t} || \delta(\Theta_{t},M_{t},R_{t})\leq\Delta_{t} || \forall t\in\{0,1,\dots,T\}",,"&\frac{|\Theta_{T}\odot (1-M_{T})|}{|\Theta_{T}|}\geq\gamma_{T},\\&\frac{|\Theta_{t}\odot (1-M_{t})|}{|\Theta_{t}|}\geq\gamma_{t},\quad |R_{t}|\leq\Delta_{t},\quad\forall t\in [1, T]","The constraints enforce target sparsity at the end of training, per-step sparsity and tuning parameter limits throughout training."
ICML_2024_oral_3,3,H_{apt}(X)=m_{o}\circ(W+s\cdot W_{B}W_{A})X\circ m_{i},"where \(s\) is the constant scaling factor following LoRA's implementation, and \(\circ\) denotes the Hadamard product between the masks and their corresponding matrices",H_{apt}(X)=(m_{o}\odot W_{B})\left( (m_{i}\odot W_{A}) X\right),"\(H_{\text{apt}}(X)\) denotes the output of the APT adapter given input \(X\), with binary pruning masks \(m_{i}\) and \(m_{o}\), and dynamic-rank tuning parameters \(W_{A}\) and \(W_{B}\)."
ICML_2024_oral_3,4,"S(W_{i,j})=|W_{i,j}\cdot\frac{\partialL}{\partial W_{i,j}}|",,S_{i}=\left| W_{i}\odot\nabla_{W_{i}}L\right|,"where \(S_{i}\) is the salience score for parameter block \(i\), \(W_{i}\) is the parameter block, \(\nabla_{W_{i}} \mathcal{L}\) is the gradient of the loss with respect to \(W_{i}\), and \(\odot\) denotes element-wise multiplication."
ICML_2024_oral_3,5,"\widetilde{S}_{t}(W_{:,j})=\sum_{(x,y)\inD_{t}}\sum_{i}|\frac{\partialL (x,y|\Theta_{t},M_{t})}{\partial H_{j,i}}| || \sum_{(x,y)\inD_{t}}\sum_{i}|H_{j,i}| || \hat{S}((W_{:,j})=\widetilde{S}(W_{:,j})+(Kurt(O_{j:}))^{\frac{1}{2}}",,"\hat{S}(W_{i,j})=\left|\left(\sum_{(x, y)\inD_t} a_{i,j}(x)\right)\cdot\left(\sum_{(x, y)\inD_t}\frac{\partialL}{\partial a_{i,j}(x)}\right)\right|+\lambda\cdotKurt(a_{i,j})","where \(a_{i,j}(x)\) is the activation corresponding to parameter \(W_{i,j}\) for input \(x\), \(\operatorname{Kurt}(\cdot)\) denotes the kurtosis of the activation, and \(\lambda\) is a hyperparameter balancing the two terms."
ICML_2024_oral_3,6,C(\Theta_{t};M_{t})\approx d_{m}\sum_{i=1}^{n_{L}}(4n_{h} ^{i}\cdot d_{h}+2n_{f}^{i}),where \(d_{h}\) is the dimension per MHA head,"C(\Theta_{t},M_{t})\approx\sum_{i=1}^{n_{L}}\left( n_{h}^{i} d_{m}^{2}+n_{f}^{i} d_{m}\right)","where \(\mathcal{C}(\Theta_{t}, \mathcal{M}_{t})\) is the approximated number of LM parameters at step \(t\), \(n_{L}\) is the number of transformer layers, \(n_{h}^{i}\) is the number of MHA heads in layer \(i\), \(n_{f}^{i}\) is the number of FFN neurons in layer \(i\), and \(d_{m}\) is the hidden dimension size."
ICML_2024_oral_3,7,"L&=\muL_{ distill}+(1-\mu)L_{ft}\\L_{layer}&=\sum_{i=1}^{T}MSE(Tr(H_{s}^{\phi(i)}),H_{t}^{i})","where \(\mu\) is a moving term linearly scales from 0 to 1 during distillation to encourage the pre-pruned model vastly fit to the training data, \(\mathcal{L}_{distill}\) is the distillation objective from CoFi, and \(\mathcal{L}_{ft}\) is the supervised fine-tuning objective",L_{distill}=\lambda_{ce}L_{ce}+\lambda_{kl}L_{kl},"where \(\mathcal{L}_{\text{distill}}\) is the total distillation loss, \(\mathcal{L}_{\text{ce}}\) is the cross-entropy loss, \(\mathcal{L}_{\text{kl}}\) is the Kullback-Leibler divergence loss, and \(\lambda_{\text{ce}}, \lambda_{\text{kl}}\) are their respective weighting coefficients."
ICML_2024_oral_30,1,W^{\prime}=W_{0}+\Delta W=W_{0}+\underline{BA},"where \(W_{0}\) remains static during the fine-tuning process, and the underlined parameters are being trained",W'=W_0+BA,"Here, \(W'\) denotes the fine-tuned weight matrix, \(W_0\) is the pre-trained weight matrix, and \(BA\) is the low-rank update with \(B \in \mathbb{R}^{d \times r}\) and \(A \in \mathbb{R}^{r \times k}\)."
ICML_2024_oral_30,2,W=m\frac{V}{ || V || _{c}}= || W || _{c}\frac{W}{ || W || _{c}},"where \(m\in\mathbb{R}^{1\times k}\) is the magnitude vector, \(V\in\mathbb{R}^{d\times k}\) is the directional matrix, with \(||\cdot||_{c}\) being the vector-wise norm of a matrix across each column",W=\|W\|_F\cdot\frac{W}{\|W\|_F},"where \(\|W\|_F\) denotes the Frobenius norm of \(W\), representing the magnitude, and \(\frac{W}{\|W\|_F}\) represents the direction of the weight matrix."
ICML_2024_oral_30,3,"\Delta M_{FT}^{t}=\frac{\sum_{n=1}^{k}|m_{FT}^{n,t}-m_{0}^{n}|}{ k} || \Delta D_{FT}^{t}=\frac{\sum_{n=1}^{k}(1-\bf cos(V_{FT}^{ n,t},W_{0}^{n}))}{k}",,\Delta m_{FT} &= || W_{FT} || _{c}- || W_{0} || _{c}\\\Delta V_{FT} &=\frac{W_{FT}}{ || W_{FT} || _{c}}-\frac{W_{0}}{ || W_{0} || _{c}},"where \(\Delta m_{\text{FT}}\) and \(\Delta V_{\text{FT}}\) denote the changes in magnitude and direction, respectively, between the full fine-tuned weights and the pre-trained weights."
ICML_2024_oral_30,4,W^{\prime}=\underline{m}\frac{V+\Delta V}{ || V+\Delta V || _{c}}=\underline{m}\frac{W_{0}+\underline{BA}}{ || W_{0}+\underline{BA} || _{c}},"where \(\Delta V\) is the incremental directional update learned by multiplying two low-rank matrices \(B\) and \(A\), and the underlined parameters denote the trainable parameters",W'=\underline{m}\frac{V+\underline{BA}}{ || V+\underline{BA} || _{c}},"where \(m\) is a trainable magnitude vector, \(V\) is the frozen pre-trained directional matrix, and \(BA\) is the low-rank update to the direction, with all underlined terms being trainable."
ICML_2024_oral_30,5,\nabla_{V^{\prime}}L=\frac{m}{ || V^{\prime} || _{c}}(I-\frac{V^{\prime}V^{\primeT}}{ || V^{\prime} || _{c}^{2}})\nabla_{W^{\prime}}L || \nabla_{m}L=\frac{\nabla_{W^{\prime}}L\cdot V^{\prime}}{ || V^{\prime} || _{c}},,"\frac{\partialL}{\partial m}=\frac{\partialL}{\partial W^{\prime}}\cdot\frac{V^{\prime}}{ || V^{\prime} || _{c}},\quad\frac{\partialL}{\partial V^{\prime}}=\frac{\partialL}{\partial W^{\prime}}\cdot m\left(\frac{I}{ || V^{\prime} || _{c}}-\frac{V^{\prime}\odot || V^{\prime} || _{c}^{-3}\odot (V^{\prime})^{\top}}{1}\right)","where \(\frac{\partial \mathcal{L}}{\partial m}\) and \(\frac{\partial \mathcal{L}}{\partial V^{\prime}}\) denote the gradients of the loss with respect to the magnitude vector and the updated directional component, respectively."
ICML_2024_oral_30,6,"cos(\nabla_{w^{\prime}}L,v^{\prime})=cos(\nabla_{w^{\prime}}L,v)=\frac{\nabla_{w^{\prime}}L\cdot v}{ || \nabla_{w^{\prime}}L ||  || v || }",,"|\textbf{cos}(\nabla_{w^{\prime}}L,v)|=\frac{|\nabla_{w^{\prime}}L\cdot v|}{ || \nabla_{w^{\prime}}L || \ || v || }","The cosine similarity between the gradient of the loss with respect to the weight and the vector \(v\), quantifying their alignment."
ICML_2024_oral_30,7,"\nabla_{m_{*}}L=\frac{\nabla_{w^{\prime}}L\cdot v^{\prime }}{ || v^{\prime} || }= || \nabla_{w^{\prime}}L || \cdot cos(\nabla_{w^{\prime}}L,v)",,"\frac{\nabla_{w^{\prime}}L\cdot v}{ || \nabla_{w^{\prime}}L || \, m_{*}}",where \(m_{*}\) is the magnitude (norm) of the vector \(w^{\prime}\)
ICML_2024_oral_30,8," || \nabla_{w^{\prime}}^{S1}L || \cdot|cos(\nabla_{w^{\prime}}^{S1}L,v)|> || \nabla_{w^{\prime}}^{S2}L || \cdot|cos(\nabla_{w^{\prime}}^{S2}L,v)|",,"\frac{|\nabla_{m_{*}}^{S1}L|}{|\nabla_{m_{*}}^{S2}L|}=\frac{|\cos(\nabla_{w^{\prime}}^{S1}L, v)|}{|\cos(\nabla_{w^{\prime}}^{S2}L, v)|} > 1","where the ratio compares the magnitude of the gradients with respect to \(m_{*}\) in scenarios \(S1\) and \(S2\), reflecting that a smaller directional update yields a larger gradient for the magnitude component."
ICML_2024_oral_30,9,\nabla_{V^{\prime}}L=\frac{m}{C}\nabla_{W^{\prime}}L\text { where }C= || V^{\prime} || _{c},,\nabla_{V^{\prime}}L=\frac{m}{ || V^{\prime} || _{c}}\nabla_{W^{\prime}}L,"where the normalization term \(||V^{\prime}||_{c}\) is detached from the gradient computation, simplifying the gradient of the directional component in DoRA."
ICML_2024_oral_37,1,"P_{t}=\{W_{t},O_{t}\}",,"P_{t}=\left\{W_{t},O_{t}\right\}",The checkpoint \(\mathcal{P}_{t}\) at iteration \(t\) consists of the model weights \(\mathcal{W}_{t}\) and optimizer parameters \(\mathcal{O}_{t}\).
ICML_2024_oral_37,2,"P=\{P_{1},P_{2},\cdots,P_{t}\,\cdots,P_{T}\}",,"P=\{P_1,P_2,\ldots,P_T\}",\(\mathcal{P}\) denotes the collection of all checkpoints saved over \(T\) training iterations.
ICML_2024_oral_37,3,"O_{t}=\{v_{t},m_{t}\}",,"O_{t}=\{m_{t}, v_{t}\}","\(\mathcal{O}_{t}\) denotes the optimizer state at iteration \(t\), consisting of the first-order moment \(m_{t}\) and second-order moment \(v_{t}\) in Adam."
ICML_2024_oral_37,4,"\DeltaP_{t}=\{\DeltaW_{t},O_{t}\}=\{W_ {t}-W_{t-1},O_{t}\}",,"\DeltaP_{t}=\{W_{t}-W_{t-1},O_{t}\}","The residual checkpoint \(\Delta\mathcal{P}_{t}\) at iteration \(t\) consists of the difference between current and previous model weights, and the current optimizer momentum states."
ICML_2024_oral_37,5,"r_{w}=\frac{\alpha}{\sqrt{m_{t}}}\timesmedian(W),M _{w}(i)=\mathds{1}_{w_{t}(i)>r_{w}}",,"\theta_{w}^{(l)}=Quantile\left(\left|\DeltaW_{t}^{(l)}\right|, 1-p_{w}^{(l)}\right)","\(\theta_{w}^{(l)}\) is the pruning threshold for the weights in layer \(l\), determined by the quantile of the absolute residual weights \(\Delta\mathcal{W}_{t}^{(l)}\) at sparsity level \(p_{w}^{(l)}\)."
ICML_2024_oral_37,6,"r_{o}=\beta\timesmean(v_{t}),M_{o}(i)=\mathds{1}_{v_{t}(i)> r_{o} and M_{w}(i)=1}",,"r_{o}=\beta\timesmedian(m_{t}),\quadM_{o}(i)=\mathds{1}_{|m_{t}(i)| > r_{o}}\cdotM_{w}(i)","\(r_{o}\) is the pruning threshold for momentum, \(\beta\) is a hyperparameter, \(m_{t}\) is the first-order moment, and \(\mathcal{M}_{o}(i)\) is the momentum pruning mask at index \(i\), which is set to 1 only if the absolute value of the first-order moment exceeds the threshold and the corresponding weight is not pruned."
ICML_2024_oral_37,7,"\tilde{R}(T)\leq\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}\sqrt {T\widehat{v}_{T,i}} || +\frac{\alpha(1+\beta_{1})G_{\infty}}{(1-\beta_{ 1})\sqrt{1-\beta_{2}}(1-\gamma)^{2}}\sum_{i=1}^{d}\|g_{1,\tau,i}\|_{2} || +\frac{D_{\infty}^{2}G_{\infty}\sqrt{1-\beta_{2}}}{2\alpha}\sum_ {i=1}^{d}\sum_{t=1}^{t}\frac{\beta_{1,t}}{(1-\beta_{1,t})}\sqrt{t} || +\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}})",,\min_{t\in[T]}E\left[\left\|\nabla f_{t}(\theta_{t})\right\|^{2}\right]\leq\frac{D^{2}+\alpha G_{\infty} D_{\infty}\sqrt{T}/(1-\beta_{1})}{\alpha\sqrt{T}/(1-\beta_{1})},"The expected squared gradient norm is upper bounded, ensuring convergence of Adam with pruned moments under the stated assumptions."
ICML_2024_oral_37,8,"\Delta\tilde{R}(T)&=\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}})\\&=\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}(1-M_{o})})",,"\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}\left(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}}\right)",This term quantifies the additional regret introduced by pruning the optimizer moments with mask \(\mathcal{M}_{o}\) during checkpoint compression.
ICML_2024_oral_37,9,\lim_{Tarrow\infty}\frac{\tilde{R}(T)}{T}\leq\lim_{Tarrow\infty}\frac{R(T)+\Delta\tilde{R}(T)}{T}=0,,\lim_{T\to\infty}\frac{\tilde{R}(T)}{T}=\lim_{T\to\infty}\frac{R(T)}{T}=0,"The average regret of the pruned Adam process converges to zero as \(T\) approaches infinity, matching the original Adam optimizer."
ICML_2024_oral_37,10,\frac{R(T)}{T}=O(\frac{1}{\sqrt{T}}),,\tilde{R}(T)\leq R(T)+\Delta\tilde{R}(T),The regret bound \(\tilde{R}(T)\) of the pruned method is upper-bounded by the sum of the original Adam regret bound \(R(T)\) and the additional term \(\Delta\tilde{R}(T)\) due to pruning.
ICML_2024_oral_4,1,S_{opt_{t}}=\arg\min_{S\subseteq V_{t}}\{\textsc{Cost}(S):f(S)=f(V_{t})\}\enspace,where \(V_{t}\) denotes the set of the currently present elements after the first \(t\) updates,S_{t}^{*}=\arg\min_{S\subseteq V_{t}}\left\{\textsc{Cost}(S) : f(S)=f(V_{t})\right\},The optimal solution \(S_{t}^{*}\) at time \(t\) is the subset of \(V_{t}\) with minimum total weight such that \(f(S) = f(V_{t})\).
ICML_2024_oral_4,2,"f(S)\geq(1-\epsilon)f(V),\quadand\quad\textsc{Cost}(S)\leq c\textsc{ Cost}(S_{opt})",where \(S_{opt}\) denotes the optimal solution,f(S)\geq (1-\epsilon)f(V)\quadand\quad\textsc{Cost}(S)\leq c\cdot\textsc{OPT}_{\textsc{cost}},"A set \(S\) is a \((1-\epsilon,c)\)-bicriteria approximate solution if its submodular value is at least \((1-\epsilon)\) times the optimum and its cost is at most \(c\) times the minimum possible cost."
ICML_2024_oral_4,3,"E[\,X(r)\,]\geq 1-2\epsilon for all r\in[1,m^{*}] and || E[\,X(m^{*}+1)\,]\leq 1-\frac{\epsilon}{2}",,E\left[\frac{1}{m^{*}}\sum_{j=1}^{m^{*}}\mathds{1}\left\{X_{j}=1\right\}\right]\geq 1-\epsilon,"where \(X_{j}\) indicates whether the \(j\)-th sampled element is added to \(G_{i}\), and the expectation is over the random sampling process."
ICML_2024_oral_41,1,"\min_{\theta_{1},\theta_{2},...,\theta_{N}}[\frac{1}{N}\sum_{i=1}^{N}L_{i}(\theta_{i})]+R(\theta_{1},\theta_{2},...,\theta_{N})",,"\min_{\{\theta_{i}\}_{i=1}^{N}}\sum_{i=1}^{N} w_{i}\,E_{(x, y)\simP_{i}(x)Q_{i}(y|x)}\left[\ell\left(f_{A_{i}}(x;\theta_{i}), y\right)\right]","The global objective minimizes the weighted sum of expected local losses across all clients, where each client’s loss is computed over its own data distribution and model."
ICML_2024_oral_41,2,A_{i}\capA_{i^{\prime}}=\{B_{enc}^{(m)}|\forall m\inI_{i}\capI_{i^{\prime}}\}\cup\{B_{share}\},,"A_{i} :=\left\{B_{enc}^{(m)}\mid\forall m\inI_{i}\right\}\cup\left\{B_{share}\right\}\cup\left\{B_{dec,i}\right\}","The architecture $\mathcal{A}_{i}$ for client $i$ is composed of modality-specific encoder blocks $\mathcal{B}_{\text{enc}}^{(m)}$ for each modality $m$ in $\mathcal{I}_{i}$, a shared block $\mathcal{B}_{\text{share}}$, and a client-specific decoder block $\mathcal{B}_{\text{dec},i}$."
ICML_2024_oral_41,3,A_{i}\capA_{i^{\prime}}=\emptyset,,A_{i}\capA_{i^{\prime}}=\emptyset,The model architectures of any two clients do not overlap in the architecture-personalized MFL setting.
ICML_2024_oral_41,4,"\theta_{i}:=h(A_{i},c_{i};\phi),\\\\forall i\in[N]","where the first generative factor \(\mathcal{A}_{i}\in\mathcal{G}\) is the local neural architecture from a globally-shared _latent topology space_\(\mathcal{G}\) and the second generative factor \(\mathbf{c}_{i}\in\mathcal{T}\) represents the lo

Figure 1: (a) Local mapping functions per client in Multimodal Federated Learning (MFL)","\theta_{i}=h(z_{i},G_{i};\phi)","The local model weights $\theta_{i}$ for client $i$ are generated by the bridge function $h$ conditioned on the client-specific latent code $\mathbf{z}_{i}$ and the architecture graph $\mathcal{G}_{i}$, with shared parameters $\phi$."
ICML_2024_oral_41,5,"A_{i}:=(V_{i},E_{i},Z_{i}^{(0)})",,"A_{i}=(V_{i},E_{i})",The multimodal neural architecture for client \(i\) is represented as a directed acyclic graph with node set \(\mathcal{V}_{i}\) and edge set \(\mathcal{E}_{i}\).
ICML_2024_oral_41,6,"h(A_{i},c_{i};\phi)=\texttt{Comb}(c_{i},\texttt{Role}(A_{i};\phi_{1});\phi_{2})","where the first stage \(\texttt{Role}(\cdot;\phi_{1})\) parameterized by \(\phi_{1}\) learns the implicit roles of layers such that layers across clients share a unified _layer-role embedding_ space, and the second stage \(\texttt{Comb}(\cdot,\cdot;\phi_{2})\) parameterized by \(\phi_{2}\) aims to combine the two heterogeneity patterns and directly generates the weights","Z_{i}^{(0)}=\left[z_{i,1}^{(0)},z_{i,2}^{(0)},\ldots,z_{i,|V_i|}^{(0)}\right]^\top\inR^{|V_i|\times K}","The node feature matrix \(\mathbf{Z}_{i}^{(0)}\) stacks the \(K\)-dimensional configuration/prior information vectors \(\mathbf{z}_{i,v}^{(0)}\) for all nodes \(v\) in the architecture graph of client \(i\)."
ICML_2024_oral_41,7,"Z_{i}^{(L)}=\texttt{Role}(A_{i};\phi_{1}) || :=g_{L}\circ g_{L-1}\circ...\circ g_{1}(Z_{i}^{(0)}; V_{i},E_{i})",,"Z_{i}^{(l+1)}=\texttt{GNN}^{(l)}(Z_{i}^{(l)},E_{i}),\quad l=0, 1,\ldots, L-1",The \(l\)-th GNN layer updates the node features \(\mathbf{Z}_{i}^{(l)}\) using the edge set \(\mathcal{E}_{i}\) of the architecture graph.
ICML_2024_oral_41,8,"z_{i,v}^{(l)}=\sigma(W_{self}^{(l)}z_{i,v}^{(l-1)}+W_{in}^{(l)}\sum_{(v^{\prime},v)\inE_{i}}z_{i,v^{\prime}}^ {(l-1)} || \qquad+W_{out}^{(l)}\sum_{(v,v^{\prime})\in E_{i}}z_{i,v^{\prime}}^{(l-1)}+b^{(l)})",,"z_{i,v}^{(l)}=g_{l}\left(z_{i,v}^{(l-1)},\left\{z_{i,v'}^{(l-1)} : (v'\to v)\inE_{i}\right\};\phi_{1}\right)","At GNN layer \(l\), the embedding of node \(v\) in client \(i\)'s architecture graph is updated by aggregating its previous embedding and the embeddings of its predecessor nodes, parameterized by \(\phi_{1}\)."
ICML_2024_oral_41,9,"\theta_{i,v}:=g_{node}(c_{i}\oplusz_{i,v}^{(L)};\phi_{ 2}),\;\forall v\inV_{i}",where \(\oplus\) denotes an operation (e,"\theta_{i,v}=g_{node}(c_{i},z_{i,v}^{(L)};\phi_{2}),\qquad\forall v\inV_{i}","The weights for each parametric computational operator \(v\) in client \(i\)'s model are generated by a node-wise HyperNetwork decoder that takes as input the client-specific task embedding \(\mathbf{c}_{i}\) and the layer-role embedding \(\mathbf{z}_{i,v}^{(L)}\)."
ICML_2024_oral_41,10,\Deltac_{i}=\nabla_{c_{i}}L_{i}(\theta_{i})=\Delta\theta_{i}\cdot\nabla_{c_{i}}\theta_{i} || \Delta\phi_{2}=\frac{1}{|N_{r}|}\sum_{i\inN_{r}}(\Delta\theta_{i}\cdot\nabla_{\phi_{2}}\theta_{i}) || \Delta\phi_{1}=\frac{1}{|N_{r}|}\sum_{i\inN_{r}}(\Delta\theta_{i}\cdot\nabla_{z_{1}^{(L)}}\theta_{i}\cdot\nabla_{\phi_{i} }Z_{i}^{(L)}),,\frac{\partialL_{i}}{\partial\phi}=\frac{\partialL_{i}}{\partial\theta_{i}}\cdot\frac{\partial\theta_{i}}{\partial\phi},"The gradient of the local loss with respect to the TAHN parameters is computed by the chain rule, multiplying the gradient of the loss with respect to the client weights by the gradient of the client weights with respect to the TAHN parameters."
ICML_2024_oral_44,1,"\operatorname*{arg\,max}_{\theta\in\Theta}E_{G^{\prime}\sim D_{\theta}}[u_{\tau}(G^{\prime})]",where \(D_{\theta}\) is a parameterized distribution and \(\Theta\) represents a feasible set of real-valued parameters,\arg\max_{q_{\phi}\inQ}E_{G\sim q_{\phi}}\left[ u_{\tau}(G)\right],"Here, \(q_{\phi}\) denotes a parameterized distribution over DAGs, \(\mathcal{Q}\) is the set of feasible distributions, and \(u_{\tau}(G)\) is the utility function evaluated on graph \(G\)."
ICML_2024_oral_44,2,"\prod_{i=1}^{d}\theta_{i}&if\,(N,E\cup(\{e_{j}\}_{j=1}^{i-1}\capE)\cup\{e_{i}\})\,is a DAG,\\0&otherwise",,P(G'=G_{E}\mid\theta)=\prod_{i=1}^{d}\theta_{i}^{I[e_{i}\inE]} (1-\theta_{i})^{1-I[e_{i}\inE]},"where \(\mathbb{I}[e_{i} \in \mathcal{E}]\) is the indicator function that equals 1 if edge \(e_{i}\) is present in \(\mathcal{E}\), and 0 otherwise."
ICML_2024_oral_44,3,\nabla_{\theta}E_{G_{E}\sim D_{\theta}} [u_{\tau}(G_{E})]\approx\frac{1}{M}\sum_{i=1}^{M}\hat{u}_ {\tau}(G_{i})\nabla_{\theta}\log(p_{\theta}(G_{i})),"where \(G_{1},G_{2},\ldots,G_{N}\sim D_{\theta}\) are mutually independent and \(\hat{u}_{\tau}(G_{i})\) is an independent unbiased estimate of \(u_{\tau}(G_{i})\) for all \(i\) and some \(M\in\mathbb{N}\)",\nabla_{\theta}E_{G^{\prime}\sim D_{\theta}}[u_{\tau}(G^{\prime})]=E_{G^{\prime}\sim D_{\theta}}\left[u_{\tau}(G^{\prime})\nabla_{\theta}\log D_{\theta}(G^{\prime})\right],The gradient of the expected utility with respect to the parameters \(\theta\) is given by the expectation over sampled DAGs of the utility multiplied by the gradient of the log-probability of the sampled DAG.
ICML_2024_oral_5,1,x_{i}^{\ell+1}=x_{i}^{\ell}+\texttt{MLP}^{\ell}(x_{i}^{\ell}+\texttt{Att}^{\ell}(x_{i}^{\ell})),,x_{i}^{(l+1)}=x_{i}^{(l)}+Attn^{(l)}(x_{i}^{(l)})+MLP^{(l)}(x_{i}^{(l)}),"The residual stream at position \(i\) and layer \(l+1\) is the sum of the previous residual stream, the output of the attention mechanism, and the output of the MLP block at layer \(l\)."
ICML_2024_oral_5,2,\texttt{MLP}^{\ell}(x^{\ell})=\sigma(W_{K}^{\ell}x^{\ell})W_{V}^{\ell},"where \(W_{K}^{\ell},W_{V}^{\ell}\in\mathbb{R}^{d_{mlp}\times d}\)","\texttt{MLP}^{\ell}(x)=W_2^{\ell}\,\sigma\left(W_1^{\ell}x\right)","The MLP block at layer \(\ell\) applies a first linear transformation \(W_1^{\ell}\), a nonlinearity \(\sigma\), and a second linear transformation \(W_2^{\ell}\) to the input \(\mathbf{x}\)."
ICML_2024_oral_5,3,\texttt{MLP}^{\ell}(x^{\ell})=\sum_{i=1}^{d_{mlp}}\sigma(x^{\ell}\cdotk_{i}^{\ell})v_{i}^{\ell}=\sum_{i=1}^{d_{mlp}}m_{i} ^{\ell}v_{i}^{\ell},,\texttt{MLP}^{\ell}(x^{\ell})=\sum_{i=1}^{d_{mlp}} m_{i}^{\ell}v_{i}^{\ell},where \(m_{i}^{\ell} = \sigma\left(\mathbf{k}_{i}^{\ell} \cdot \mathbf{x}^{\ell}\right)\) are the activation coefficients for each value vector \(\mathbf{v}_{i}^{\ell}\).
ICML_2024_oral_5,4,"p\big{(}w\midx^{\ell}+m_{i}^{\ell}v_{i}^{\ell},E\big{)}\propto\exp\big{(}e_{w}\cdotx^{\ell}\big{)}\cdot\exp\big{(}e_{w}\cdot m_{i}^{\ell}v_{i}^{\ell}\big{)}",where \(\mathbf{e}_{w}\) is the embedding of \(w\),Uv_{i}^{\ell},The effect of value vector \(\mathbf{v}_{i}^{\ell}\) on the logits for each vocabulary token is given by \(U\mathbf{v}_{i}^{\ell}\).
ICML_2024_oral_5,5,\texttt{GLU}^{\ell}(x^{\ell})=(\sigma(W_{1}x^{\ell})\odot W_{ 2}x^{\ell})W_{V}^{\ell},"where \(W_{1}^{\ell},W_{2}^{\ell},W_{V}^{\ell}\in R^{d_{mlp}\times d}\)",\texttt{GLU}^{\ell}(x^{\ell})=\sigma(W_{K}^{\ell}x^{\ell})\odot (W_{V}^{\ell}x^{\ell}),"where \(\odot\) denotes element-wise multiplication, and \(W_{K}^{\ell}, W_{V}^{\ell} \in \mathbb{R}^{d_{mlp} \times d}\)."
ICML_2024_oral_5,6,"P(Toxic|\bar{x}^{L-1})=softmax(W_{Toxic}\bar{x}^{L-1}),W_{Toxic}\inR^{d}",,\hat{y}=W_{Toxic}\cdot\bar{x}^{L-1},where \(W_{\text{Toxic}}\) is the learned probe weight and \(\bar{\mathbf{x}}^{L-1}\) is the average residual stream from the last layer.
ICML_2024_oral_5,7,x^{L-1}=x^{L-1}-\alpha*W,where \(a\) is a heuristic scale value and \(W\) is one of our toxicity vectors,x^{L}\leftarrowx^{L}-\alpha\cdotv_{toxic},"where $\alpha$ is a scaling coefficient and $\mathbf{v}_{\text{toxic}}$ is a selected toxic vector (e.g., $W_{\text{Toxic}}$, MLP.$\mathbf{v}_{\text{Toxic}}$, or SVD.U$_{\text{Toxic}}$)."
ICML_2024_oral_5,8,"L_{DPO}=-E[\log\sigma(\beta\log P-\beta\log N)] || P=\frac{\pi_{\theta}(y_{+}\midw)}{\pi_{ref}(y_{+}\midw)},N=\frac{\pi_{\theta}(y_{-}\midw)}{\pi_{ref}(y_{-}\midw)}",,L_{DPO}=-\log\frac{\exp(\beta\cdot\Delta\log p)}{\exp(\beta\cdot\Delta\log p)+1},where \(\Delta \log p = \log p_{\theta}(y^+|x) - \log p_{\theta}(y^-|x)\) and \(\beta\) is a temperature hyperparameter.
ICML_2024_oral_5,9,p(y\mid a)\propto p(y)p(a\mid y),,\Deltax=\alpha\nabla_{x}\log p(a\midw),"The PPLM method perturbs the residual stream in the direction of the gradient of the log-probability of the attribute, scaled by a step size \(\alpha\)."
ICML_2024_oral_5,10,"\gamma(k_{i}^{\ell}):=\{g|g\inR^{d},\sigma(k_{i}^{\ell}\cdotg)>0\}",where \(\sigma\) is a non-linear activation,R_{i}^{\ell}=\left\{x\inR^d :\sigma(x\cdotk_{i}^{\ell}) >\tau\right\},"where \(\mathcal{R}_{i}^{\ell}\) is the activation region for key vector \(\mathbf{k}_{i}^{\ell}\) at layer \(\ell\), and \(\tau\) is a threshold for activation."
ICML_2024_oral_5,11,"\forall j<\ell,\forall i<d_{mlp}:cos(\delta_{x}^{\ell\_midmid},\delta_{MLP,v_{i}}^{j})",,"\cos\left(\delta_{x}^{\ell\_mid},\,\delta_{MLP,v}^{j}\right)=\frac{\delta_{x}^{\ell\_mid}\cdot\delta_{MLP,v}^{j}}{\|\delta_{x}^{\ell\_mid}\|\,\|\delta_{MLP,v}^{j}\|}",Cosine similarity between the shift in the residual stream at layer \(\ell\_mid\) and the shift in value vectors in the preceding layer \(j\).
ICML_2024_oral_53,1,generalization gap\leq\sqrt{\frac{CMI_{D}(A_{n})}{n}},,"\left|E_{S, A}[L(A(S))-L_S(A(S))]\right|\leq\sqrt{\frac{2 I(S; A(S))}{n}}","The expected generalization error is upper bounded by the square root of twice the conditional mutual information between the sample \(S\) and the output \(A(S)\), divided by the sample size \(n\)."
ICML_2024_oral_53,2,F_{D}(A_{n}(S_{n}))-\min_{\theta\in\Theta}F_{D}(\theta)\leq\varepsilon,,E\left[F_{D}(A_{n}(S_{n}))\right]-\min_{\theta\in\Theta}F_{D}(\theta)\leq\varepsilon,The expected excess error of the learner is at most \(\varepsilon\).
ICML_2024_oral_53,3,CMI_{D}(A_{n})\triangleq I(A_{n}(S_{n}) ;U|\tilde{Z}),,CMI_{D}(A_{n}) :=I(S_{n};A_{n}(S_{n})\mid\tilde{Z}),"The conditional mutual information (CMI) of a learning algorithm \(\mathcal{A}_{n}\) with respect to a data distribution \(\mathcal{D}\) is defined as the mutual information between the training set \(S_{n}\) and the output \(\mathcal{A}_{n}(S_{n})\), conditioned on the auxiliary array \(\tilde{\mathbf{Z}}\)."
ICML_2024_oral_53,4,E[F_{D}(A_{n}(S_{n}) )]-\min_{\theta\in\Theta}F_{D}(\theta) || \leqEGE_{D}(A_{n})+E\big{[}\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\big{]},,E\left[F_{D}(A_{n}(S_{n}))\right]-\min_{\theta\in\Theta}F_{D}(\theta)\leqEGE_{D}(A_{n})+E\left[\hat{F}_{S_{n}}(A_{n}(S_{n}))\right]-\min_{\theta\in\Theta}F_{D}(\theta),The expected excess population error is upper bounded by the sum of the expected generalization error and the expected optimization error.
ICML_2024_oral_53,5,E[F_{D}(A_{n}(S_{n}) )]-\min_{\theta\in\Theta}F_{D}(\theta) || \leq LR\sqrt{\frac{8CMI_{D}(A_{n})}{ n}}+E\big{[}\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\big{]},,"E[F_{D}(A_{n}(S_{n}))]-\min_{\theta\in\Theta}F_{D}(\theta)\leq LR\sqrt{\frac{8\,CMI_{D}(A_{n})}{n}}+E\left[\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\right]",The expected excess error is upper-bounded by a term involving the CMI-based generalization bound and the expected empirical optimization error.
ICML_2024_oral_53,6,"ISCMI_{D}(A_{n})\triangleq\sum_{i=1}^{n}I(A_{n}(S);U_{i}|Z_{0,i},Z_{1,i})",,ISCMI_{D}(A_{n})\triangleq\frac{1}{n}\sum_{i=1}^{n}I(A_{n}(S_{n});U_{i}|\tilde{Z}),"The individual sample conditional mutual information (ISCMI) is defined as the average, over all training samples, of the mutual information between the algorithm's output and the indicator variable for each sample's inclusion in the training set, conditioned on the full data array."
ICML_2024_oral_53,7,E[\sum_{i=1}^{n}\sum_{k=1}^{d}(\frac{144\varepsilon^{2}-d(\mu^{(k)})^{2}}{1-d(\mu^{(k)})^{2}})(\hat{\theta} ^{(k)})(Z_{i}^{(k)}-\mu^{(k)})] || \quad\geq 2\varepsilon-4\delta,,"E\left[\frac{1}{n}\sum_{i=1}^{n}\left\langle\hat{\theta}, Z_{i}\right\rangle\right]\geq 1-\varepsilon-2\delta",The expected average inner product between the learner's output $\hat{\theta}$ and the training samples $Z_i$ is at least $1 - \varepsilon - 2\delta$.
ICML_2024_oral_55,1,"D_{LCA}(y^{\prime},y):=f(y)-f(N_{LCA}(y,y^{\prime}))","where \(f(y)\geq f(N_{LCA}(y,y^{\prime}))\) and \(N_{LCA}(y^{\prime},y)\) denotes the lowest common ancestor class node for classes \(y\) and \(y^{\prime}\) within the hierarchy, and \(f(\cdot)\) represents a function of a node, such as the tree depth or entropy","d_{LCA}(y, y')=depth(y)+depth(y')-2\,depth(LCA(y, y'))",The LCA distance between classes \(y\) and \(y'\) is defined as the sum of their depths in the taxonomy minus twice the depth of their lowest common ancestor.
ICML_2024_oral_55,2,"D_{LCA}(model,M):=\frac{1}{n}\sum_{i=1}^{n}D_{LCA}(\widehat{y}_{i},y _{i})\iff y_{i}\neq\widehat{y}_{i}","where \(\widehat{y}_{i}\) is the predicted class for sample \(X_{i}\) using the model, \(y_{i}\) is the ground truth class for sample \(X_{i}\), and \(y_{i}\neq\widehat{y}_{i}\)",IC(y) :=-\log p(y),"where \(IC(y)\) denotes the information content of class \(y\), and \(p(y)\) is the probability of class \(y\) in the dataset."
ICML_2024_oral_58,1,"Sequence model:\hat{z}_{t},\,h_{t}=seq(z_{t-1},\,h_{t-1},\,a_{t-1}) || Multimodal encoder: z_{t}\simenc(x_{t},\,l_{t},\,h_{t}) || Multimodal decoder:\hat{x}_{t},\,\hat{l}_{t},\,\hat{r}_{t},\,\hat{c}_{t}=dec(z_{t},\,h_{t})",,"h_{t}=f_{\theta}(z_{t}, a_{t}, h_{t-1})","\(h_{t}\) is the recurrent hidden state at time \(t\), computed by function \(f_{\theta}\) given the current latent representation \(z_{t}\), action \(a_{t}\), and previous hidden state \(h_{t-1}\)."
ICML_2024_oral_58,2,"Image loss:\qquad\quadL_{x}=\|\hat{x}_{t}-x_{t}\|_{2}^{2} || Language loss:\qquad\quadL_{t}=catext(\hat {t}_{t},l_{t}) || Reward loss:\qquad\quadL_{r}=catext(\hat {r}_{t},twoot(r_{t})) || Continue loss:\qquad\quadL_{c}=binkent(\hat{c}_{t},c_{t}) || Regularizer:\qquad\quadL_{reg}=\beta_{reg}\max(1,KL\big{[}z_{t}\bigm{\|}\\sg(\hat{z}_{t})\big{]})",,"L_{repr}=catxent(x_{t},\,\hat{x}_{t})+catxent(l_{t},\,\hat{l}_{t})+catxent(z_{t},\,\hat{z}_{t})+binxent(r_{t},\,\hat{r}_{t})+binxent(c_{t},\,\hat{c}_{t})+\beta_{reg}\,catxent\big(sg[z_{t}],\,\hat{z}_{t}\big)",The representation learning loss \(\mathcal{L}_{\mathrm{repr}}\) sums the reconstruction and regularization losses over all modalities and latent variables.
ICML_2024_oral_58,3,"Prediction loss:\quadL_{pred}=\beta_{pred}\\max(1,KL\big{[}\,sg(z_{t})\bigm{\|}\hat{z}_{t}\big{]})",where the gradient around the target distribution for \(z_{t}\) is stopped since it is also a learned representation and \(\beta_{\mathrm{pred}}=0,"L_{pred}=catxent(\hat{z}_{t}, z_{t})",The future prediction loss \(\mathcal{L}_{\mathrm{pred}}\) is the categorical cross-entropy between the predicted latent representation \(\hat{z}_{t}\) and the actual latent representation \(z_{t}\).
ICML_2024_oral_58,4,"Actor net:\quad\pi(a_{t}|h_{t},z_{t})\qquadCritic net:\quadV(h_{t},z_{t})",,"Critic:\qquad & v_{t}=critic(z_{t}, h_{t})\\Actor:\qquad &\pi(a_{t}\mid z_{t}, h_{t})=actor(z_{t}, h_{t})","The critic estimates the value function \(v_{t}\) and the actor outputs the policy \(\pi(a_{t} \mid z_{t}, h_{t})\) given the latent representation and recurrent state."
ICML_2024_oral_60,1,"\min_{M}\alphaL_{in}(f(M\odot X),y) || -\betaL_{out}(f((1-M)\odot X),y)+R(M)",,L_{mask}=-\lambda_{in}\log p(y\mid x\odot m)-\lambda_{out}\log\left(1-p(y\mid x\odot (1-m))\right),"Here, $x$ is the input audio, $m$ is the mask, $y$ is the target label, $p(y \mid \cdot)$ is the model's predicted probability, and $\lambda_{\text{in}}, \lambda_{\text{out}}$ are weighting coefficients."
ICML_2024_oral_60,2,"\min_{\theta}\lambda_{in}L_{in}(\log f(M_{\theta}(h)\odot X),y) || -\lambda_{out}L_{out}(\log f((1-M_{\theta}(h))\odot X),y)+R(M_{\theta}(h))",,"\min_{\theta}\\alphaL_{in}(f(M_{\theta}(h)\odot X),y)-\betaL_{out}(f((1-M_{\theta}(h))\odot X),y)+R(M_{\theta}(h))",The objective is now optimized over the neural decoder parameters \(\theta\) that generate the mask \(M_{\theta}(h)\) from input \(h\).
ICML_2024_oral_60,3,R(M_{\theta}(h))=\lambda_{g}\|M_{\theta}(h)\odot X-X\|+\lambda_{s}\|M_{\theta} (h)\|_{1},"where \(\lambda_{g}\) and \(\lambda_{s}\) are regularization coefficients, and \(X\) represents the spectrogram of the original signal",R'(M_{\theta}(h))=R(M_{\theta}(h))+\gamma\cdotTV(M_{\theta}(h)),"The refined regularizer \(R'(M_{\theta}(h))\) augments the original regularization term with a total variation penalty weighted by \(\gamma\), encouraging spatial smoothness in the mask."
ICML_2024_oral_60,4,x_{interpretation}=ISTFT((M_{\theta}(h)\odot X)e^{jX_{ phase}}),,"\hat{x}=ISTFT(M_{\theta}(h)\odot X,\angle x)",The reconstructed audio signal \(\hat{x}\) is obtained by applying the inverse short-time Fourier transform (ISTFT) to the masked spectrogram \(M_{\theta}(h) \odot X\) using the phase \(\angle x\) of the original waveform.
ICML_2024_oral_60,5,FF_{n}:=f(X_{n})_{c}-f(X_{n}\odot(1-M_{\theta}(h)))_{c},,FF=f_{y}(X)-f_{y}((1-M_{\theta}(h))\odot X),The faithfulness score (FF) is computed as the difference between the classifier's logit for class \(y\) on the original input \(X\) and the logit for class \(y\) on the masked-out input \((1-M_{\theta}(h)) \odot X\).
ICML_2024_oral_60,6,AI:=\frac{1}{N}\sum_{n=1}^{N}1_{[f(X_{n}\odot M_{\theta}(h))>f (X_{n})_{c}]}\cdot 100,where \(\mathbf{1}_{[,AI_{n}:=f(X_{n}\odot M_{\theta}(h))_{c}-f(X_{n})_{c},"where \(\text{AI}_{n}\) measures the increase in the classifier's confidence for class \(c\) when only the masked-in portion of the input is provided, compared to the original input."
ICML_2024_oral_60,7,"AD:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n})_{c}-f(X_{n}\odot M_ {\theta}(h))_{c})}{f(X_{n})_{c}}\cdot 100",,"AD:=\frac{1}{N}\sum_{n=1}^{N}\max\left(0,\frac{f(X_{n})_{c}-f(X_{n}\odot M_{\theta}(h))}{f(X_{n})_{c}}\right)\cdot 100","where \(f(X_{n})_{c}\) is the classifier confidence for class \(c\) on input \(X_{n}\), and \(f(X_{n}\odot M_{\theta}(h))\) is the confidence after masking; AD measures the average percentage drop in confidence, with lower values indicating better faithfulness."
ICML_2024_oral_60,8,"AG:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n}\odot M_{\theta}(h))_ {c}-f(X_{n})_{c})}{1-f(X_{n})_{c}}\cdot 100",,"AG:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n}\odot M_{\theta}(h))_{c}-f(X_{n})_{c})}{f(X_{n})_{c}}\cdot 100","where AG measures the average percentage increase in classifier confidence for class \(c\) when the input is masked by \(M_{\theta}(h)\), averaged over all \(N\) examples."
ICML_2024_oral_60,9,Fid-In=\frac{1}{N}\sum_{n=1}^{N}1_{[\arg\max_{c}f(X_{n})_{c}=\arg\max_{c}f_{c}(X_{n}\odot M_{\theta}(h))]},,Fid-In :=\frac{1}{N}\sum_{n=1}^{N}1_{[\arg\max_{c} f(X_{n}\odot M_{\theta}(h))=c]},"where \(\mathbf{1}_{[.]}\) is the indicator function, \(f(\cdot)\) is the classifier, \(M_{\theta}(h)\) is the learned mask, and \(c\) is the predicted class for the original input \(X_{n}\)."
ICML_2024_oral_66,1,"cost(P,S)=\sum_{p\in P}\min_{s\in S}dist(p,s)^{ z}",,"cost(P, S)=\sum_{p\in P}\min_{s\in S}\|p-s\|^z",The cost function sums the \(z\)-th power of the distances from each point in \(P\) to its nearest center in \(S\).
ICML_2024_oral_66,2,P(M(P)\in S)\leq\exp(\varepsilon)\cdotP( M(P^{\prime})\in S)+\delta,,\Pr[M(P)\in S]\leq e^{\varepsilon}\Pr[M(P')\in S]+\delta,"A randomized mechanism $\mathcal{M}$ is $(\varepsilon,\delta)$-differentially private if, for any two neighboring datasets $P$ and $P'$, and any set of outputs $S$, the probability that $\mathcal{M}(P)$ outputs an element in $S$ is at most $e^{\varepsilon}$ times the probability for $\mathcal{M}(P')$, plus $\delta$."
ICML_2024_oral_66,3,\sum_{p\in P}\|p-\mu\|^{z}\leq 2^{z}\sum_{p\in P}\|p-\mu_{z}\|^{z},,\sum_{p\in P}\|p-\mu\|_2^z\leq 2^z\sum_{p\in P}\|p-\mu_z\|_2^z,"For any multiset \(P\) in \(\mathbb{R}^d\), the cost of using the \(L_2\) mean as center for the \((1,z)\)-clustering problem is at most \(2^z\) times the optimal \((1,z)\)-clustering cost."
ICML_2024_oral_66,4,"cost(E,\mu(E))=\sum_{p\in E}\|p\|_{2}^{2}-\frac{\|\sum_{p\in E }p\|_{2}^{2}}{|E|}",,"\sum_{p\in E}\|p-c\|_2^2=\sum_{p\in E}\|p\|_2^2-2\left\langle\sum_{p\in E} p, c\right\rangle+|E|\cdot\|c\|_2^2","For any multiset \(E\) and any center \(c\), the sum of squared distances from points in \(E\) to \(c\) equals the sum of squared norms of the points minus twice the inner product of the sum of the points and \(c\), plus the size of \(E\) times the squared norm of \(c\)."
ICML_2024_oral_72,1,"L_{mask}=\underset{X\inD,t\in[0,T]}{ E}-\sum_{i=1}^{N}m_{t,i}\cdot\log(p_{\theta}(x_{i}|X_{t},X^{p},C))",,"L_{NLL}=-E_{X,X^{p},C, t}\left[\log p_{\theta}(X_{0} |X_{t},X^{p},C)\right]","The negative log-likelihood loss for training the diffusion model to predict the original token sequence given the masked sequence, prompt, and condition."
ICML_2024_oral_72,2,"p(X_{t-\Delta t}|X_{t},X^{p},C)=\underset {X_{0}\sim p_{\theta}(X_{0}|X_{t},X^{p},C)}{E}q(X_{t-\Delta t}|\hat{X}_{0},X_{t})",,"p_{\theta}(X_{t-\Delta t}|X_{t},X^{p},C)=\prod_{i=1}^{N} p_{\theta}(x_{t-\Delta t,i}|X_{t},X^{p},C)","The reverse transition distribution factorizes over tokens, where each token at time \(t-\Delta t\) is predicted conditioned on the current masked sequence, prompt, and condition."
ICML_2024_oral_73,1,"\theta_{t+1}=\theta_{t}-\eta_{t}(\sum_{i=1}^{n}\nabla\ell(\theta_{t},z_{i})+N(0,\frac{G^{2}}{2\rho}I_{p}))",,\theta_{t+1}=\theta_{t}-\eta\left(\nablaL(\theta_{t})+\xi_{t}\right),"The Noisy Gradient Descent update rule, where \(\theta_{t}\) is the model parameter at iteration \(t\), \(\eta\) is the learning rate, \(\nabla \mathcal{L}(\theta_{t})\) is the gradient of the loss, and \(\xi_{t}\) is Gaussian noise added for differential privacy."
ICML_2024_oral_73,2,M=\sqrt{\frac{K}{K-1}}P(I_{K}-\frac{1}{K}1_{K}1_{K}^{T })\inR^{p\times K},"where \(P=[P_{1},\cdots,P_{K}]\in\mathbb{R}^{p\times K}\) is a partial orthogonal matrix such that \(P^{T}P=I_{K}\)",F\inR^{p\times K} is an ETF if  F^{\top}F=(1-\frac{K}{p})I_K+\frac{K}{p}1_K1_K^{\top},An equiangular tight frame (ETF) is a matrix \(F \in \mathbb{R}^{p \times K}\) whose columns satisfy \(F^{\top}F = (1 - \frac{K}{p})I_K + \frac{K}{p}\mathbf{1}_K\mathbf{1}_K^{\top}\).
ICML_2024_oral_73,3,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}}) || +\exp(-\frac{n}{8(\beta^{4}p^{2}+\frac{1}{3}\beta^{2} p)}),,\Pr\left[y\widehat{\theta}_{NoisyGD}^{T}x<0\right]\leq\exp\left(-\frac{n}{2\left(\beta^{4}p^{2}+\frac{1}{3}\beta^{2}p+\frac{\sigma^{2}}{n}\right)}\right),"The probability that a test point is misclassified by the NoisyGD-trained predictor is upper bounded in terms of the number of samples \(n\), feature shift parameter \(\beta\), feature dimension \(p\), and noise variance \(\sigma^{2}\)."
ICML_2024_oral_73,4,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}}) || +\exp(-\frac{n}{8(\beta^{4}p+\frac{1}{3}\beta^{2} )}),,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp\left(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}}\right)+\exp\left(-\frac{n}{8(\beta^{4}p+\frac{1}{3}\beta^{2})}\right),Upper bound on the misclassification error for NoisyGD when the feature shift vector components are independent.
ICML_2024_oral_73,5,\nablaL(\theta)=\frac{n}{2}\cdot 0.5\cdot-(-e_{1}+v)+\frac{n}{2}\cdot 0.5\cdot(e_{1}+v)=\frac{n}{2}e_{1},,\sum_{i=1}^{n} y_{i} v_{i}=0,"The sum of the class-weighted offset shift vectors is zero, i.e., \(\sum_{i=1}^{n} y_{i} v_{i} = 0\)."
ICML_2024_oral_75,1,"J(\pi)=E_{(s_{t},\tau)\inD}[E_{a_{t}=\pi} [Q^{\pi}(s_{t},a_{t},\tau)]-\etaD_{KL}[\pi,\tilde{\pi}|s_{t},\tau]]",where \(\eta\) is a hyperparameter determining the strength of the regularization towards the reference policy \(\tilde{\pi}\),"J(\pi)=E_{\pi}\left[\sum_{t=0}^{\infty}\gamma^t r(s_t, a_t)-\alpha\,KL\left(\pi(\cdot|s_t)\,\|\,\tilde{\pi}(\cdot|s_t)\right)\right]","The KL-regularized RL objective, where the expected discounted return is penalized by the KL divergence between the learned policy and a reference policy at each timestep."
ICML_2024_oral_75,2,"\pi_{imp}(a_{t}|s_{t},\tau)\propto\exp(Q^{\pi_{imp}(s_{t},a_{t},\tau)}/\eta)\tilde{\pi}(a_{t}|s_{t},\tau) || \propto\exp(A^{\pi_{imp}(s_{t},a_{t},\tau)}/\eta)\tilde{\pi}(a_{t}|s_{t},\tau)",,"\pi_{imp}(a_{t}|s_{t},\tau)\propto\tilde{\pi}(a_{t}|s_{t},\tau)\exp\left(\frac{Q^{\pi}(s_{t},a_{t},\tau)}{\eta}\right)",The improved policy \(\pi_{\text{imp}}\) is proportional to the reference policy \(\tilde{\pi}\) weighted by the exponentiated Q-value scaled by the regularization parameter \(\eta\).
ICML_2024_oral_75,3,"L^{Q}(\theta)=E\Big{[} (1-\alpha)D_{KL}[\pi_{imp},\pi_{\theta}|s_ {t},\tau,\tilde{\pi}=\pi_{\theta^{\prime}}] || +\alphaD_{KL}[b,\pi_{\theta}|s_{t},\tau] || +\betaD_{KL}[\Gamma_{\theta^{\prime}}(q|s_{t},a_{t },\tau),p_{\theta}(q|s_{t},a_{t},\tau)]\Big{]} || =-E\Big{[} (1-\alpha)\operatorname*{E}_{d^{\prime}\sim\pi_{\theta^{\prime}}}[w(a^{\prime},s_{t},\tau)\log\pi_{\theta}(a^{\prime}|s_{t},\tau)] || +\alpha\log\pi_{\theta}(a_{t}|s_{t},\tau) || +\beta\operatorname*{E}_{q\sim\Gamma_{\theta^{\prime}}}\log p_{\theta}(q|s_{t},a_{t},\tau)\Big{]}+K_{H}",,"L_{total}=\lambda_{\pi}D_{KL}[\pi_{imp},\pi_{\theta} | s_{t},\tau]+\lambda_{BC}D_{KL}[\pi_{D},\pi_{\theta} | s_{t},\tau]+\lambda_{Q}D_{KL}[\Gamma_{\theta^{\prime}}, p_{\theta} | s_{t}, a_{t},\tau]","where \(\lambda_{\pi}\), \(\lambda_{\text{BC}}\), and \(\lambda_{Q}\) are weighting coefficients for the policy imitation, behavior cloning, and Q-value distribution matching losses, respectively."
ICML_2024_oral_75,4,"N(C)=N_{0}*C^{a},\;\;\;D(C)=D_{0}*C^{b}",,C\propto N^{\alpha_N} D^{\alpha_D},"where \(C\) is the total compute, \(N\) is the number of model parameters, \(D\) is the number of tokens, and \(\alpha_N, \alpha_D\) are scaling exponents."
ICML_2024_oral_79,1,"L_{dyn}[\theta_{F,G,P}](o_{t,T},a_{t})= || -\bf cos\_sim\big{(}Q(P(T(z_{t},e_{t}))), stopgrad(P(z_{t+1}))\big{)}",,"L_{BYOL}=E_{(o_{1:T}, a_{1:T})\simD}\left[\left\|T(G(o_{1:T-1}), a_{T-1})-sg(G(o_{2:T}))\right\|_2^2\right]","The BYOL-inspired loss encourages the forward dynamics model to predict the next latent state from the current latent state and action, using a stop-gradient on the target latent state."
ICML_2024_oral_79,2,"L[\theta_{F,G,G,P,\psi}]=L_{dyn}[\theta_{F,G,P}]+\betaL_{act\_decode}[\theta_{F,G,\psi}]",,L_{pretrain}=L_{dyn}+\lambda_{act}L_{act\_decode},"The total pretraining loss is the sum of the latent dynamics loss and the action decoding loss, weighted by a hyperparameter \(\lambda_{\text{act}}\)."
ICML_2024_oral_79,3,"L_{\textbf{CE}}(\pi(stopgrad(z_{t})),\xi_{t})[\theta_{\pi}]",,L_{skill}[\theta_{\pi}]=-\frac{1}{|D|}\sum_{i=1}^{|D|}\frac{1}{H_i}\sum_{t=0}^{H_i-1}\log\pi(\xi_t^{(i)}\mid z_t^{(i)}),"The skill-token policy \(\pi\) is trained to minimize the average cross-entropy loss between the predicted skill token distribution and the expert token \(\xi_t^{(i)}\) at each timestep, conditioned on the latent state \(z_t^{(i)}\)."
ICML_2024_oral_79,4,"L_{\textbf{FT\_DECODER}}[\theta_{\pi,\psi}]=E_{\xi_{t}\sim\pi(stopgrad(z_{t}))}\Big{[}L[\theta_{\psi}](\xi_{t})\Big{]} || L[\theta_{\psi}](\xi_{t})=\sum_{i=0}^{\hat{K}}L_{ action}(\psi(stopgrad(z_{t+i}),\xi_{t}[i]),a_{t+i})","where

\[\mathcal{L}[\theta_{\psi}](\xi_{t})=\sum_{i=0}^{\hat{K}}\mathcal{L}_{\text{ action}}(\psi(\text{stopgrad}(z_{t+i}),\xi_{t}[i]),a_{t+i}) \tag{5}\]

In this equation, \(\hat{K}=\min(K,L_{\xi})\), where \(K\) is a hyperparameter, the motivation behind which is explained at the end of Section 3","L_{adapt}[\theta_{\psi}]=L_{act}(\psi(z_t, e_t), a_t)",The adaptation loss for finetuning the decoder \(\psi\) on downstream tasks is the action reconstruction loss between the decoded action and the true action.
ICML_2024_oral_79,5,"L[\theta_{\pi,\psi}]=L_{\textbf{CE}}(\pi(stopgrad(z _{t})),\xi_{t})+L_{\textbf{FT\_DECODER}}[\theta_{\pi,\psi}]",,"L_{FT}[\theta_{\pi},\theta_{\psi}]=L_{\textbf{CE}}[\theta_{\pi}]+\lambdaL_{\textbf{FT\_DECODER}}[\theta_{\pi},\theta_{\psi}]","The overall adaptation objective combines the cross-entropy loss for the skill-token policy and the decoder finetuning loss, weighted by hyperparameter \(\lambda\)."
ICML_2024_oral_84,1,\max_{\pi}E_{\hat{e}\sim\hat{p}(e)}J(\pi;\hat{e}),,"J(\pi)=E_{e\sim\hat{p}(e)}\left[ R(\pi, e)\right]",The expected return of policy \(\pi\) under the oracle environment distribution \(\hat{p}(e)\).
ICML_2024_oral_84,2,\hat{e}\sim\hat{p}(e),,\hat{e}\sim\hat{p}(e),\(\hat{e}\) denotes a sample environment drawn from the oracle distribution \(\hat{p}(e)\).
ICML_2024_oral_84,3,"E^{test}=\{\langle\hat{e}_{sim,i},r\rangle\}_{i=1,\cdots,n}",where the generated behavior \(\pi\) will be evaluated in,"E^{test}=\left\{\left(\hat{e}_{sim,i}, r\right)\mid i=1,\ldots, n\right\}",\(\mathcal{E}^{\text{test}}\) is the set of simulated sample environments paired with the task specification \(r\).
ICML_2024_oral_84,4,f:E^{ref}arrowE^{shaped},,E^{shaped}=f(E^{ref}),The shaped environment \(\mathcal{E}^{\text{shaped}}\) is defined as the result of applying a shaping transformation \(f\) to the reference environment \(\mathcal{E}^{\text{ref}}\).
ICML_2024_oral_84,5,"\max_{\pi}E_{\tau\sim\pi}[\sum_{t=0}^{T}\gamma^{t}r _{t}(s_{t},a_{t}))] || s.t.\\\s_{t+1}\sim p(s_{t},a_{t};E^{shaped })",,\max_{\pi}E_{e\simE^{shaped}}J(\pi;e),The RL objective is to maximize expected performance of policy \(\pi\) over environments sampled from the shaped environment set \(\mathcal{E}^{\text{shaped}}\).
ICML_2024_oral_84,6,H:f_{k}\times J(\pi^{\star}_{k};E^{test})\to f_{k+1},,"f^{(k+1)}=H\left(\pi^{\star(k)},E^{test}, f^{(k)}\right)","The updated shaping function \(f^{(k+1)}\) is obtained by applying the human reflection process \(\mathcal{H}\) to the current optimal policy \(\pi^{\star(k)}\), the test environment \(\mathcal{E}^{\text{test}}\), and the previous shaping function \(f^{(k)}\)."
ICML_2024_oral_84,7,"f_{k+1}=H(f_{k},J(\pi^{\star}_{k};E^{test})) || where\\\pi^{\star}_{k}=\underset{\pi}{argmax}\J(\pi;E^{shaped}_{k}) || E^{shaped}_{k}=f_{k}(E^{ref}),\f_{0}=I_{identity}",,"f_{k+1}=H\left(f_k, J(\pi^{\star}_k;E^{test})\right)",The environment shaping function is updated iteratively by applying the reflection process \(\mathcal{H}\) to the current shaping function \(f_k\) and the performance of the trained policy \(\pi^{\star}_k\) on the test environment.
ICML_2024_oral_84,8,"\max_{f\inF} J(\pi^{\star};E^{test}) || s.t.\\\\pi^{\star}\in\arg\max_{\pi}J(\pi;E^{shaped }),\\E^{shaped}=f(E^{ref})",,f^{\star}=\underset{f\inF}{argmax}\J\left(\underset{\pi}{argmax}\J(\pi; f(E^{ref}));E^{test}\right),where \(f^{\star}\) is the optimal shaping function maximizing test environment performance after RL training on the shaped environment.
ICML_2024_oral_93,1,c(\pi)=\|x_{\pi_{n}}-x_{\pi_{1}}\|_{2}+\sum_{i=1}^{n-1}\| x_{\pi_{i}}-x_{\pi_{i+1}}\|_{2},where \(\|\cdot\|_{2}\) denotes the \(\ell_{2}\) norm,c(\pi)=\sum_{i=1}^{n}\| x_{\pi_{i}}-x_{\pi_{i+1}}\|_2,"The total path length \(c(\mathbf{\pi})\) is the sum of Euclidean distances between consecutive vertices in the tour defined by permutation \(\mathbf{\pi}\), with \(x_{\pi_{n+1}} = x_{\pi_1}\) to complete the cycle."
ICML_2024_oral_93,2,"L(\theta)=E_{\pi\simS}[E_{\Phi\sim f_{\theta}(s)}[E_{\pi\sim g(s,\Phi)}[c(\bm {\pi})]]]","where \(s\) represents an instance from distribution \(\mathcal{S}\), \(\theta\) is the trainable parameters of model \(f\), \(\mathbf{\pi}\) is the solution outputed by post-hoc search algorithm \(g\) given \(\Phi\), and \(c(\mathbf{\pi})\) is calculated based on Equation 1","\max_{\pi\in S_n}\sum_{i=1}^{n}\Phi_{\pi_{i},\pi_{i+1}}",where \(S_n\) is the set of all permutations of \(n\) vertices and \(\pi_{n+1} = \pi_1\) to complete the tour.
ICML_2024_oral_93,3,"L_{\textit{surrogate}}(\theta)=E_{s\simS}[E_{\Phi\sim f_{\theta}(s)}[\ell(s,\Phi)]]",,"L_{sur}(\theta)=E_{s\simS}\left[E_{\Phi\sim f_\theta(s)}\left[\ell(s,\Phi)\right]\right]","where \(\ell(s, \Phi)\) is a differentiable surrogate loss function used in place of the original objective."
ICML_2024_oral_93,4,"p(\pi_{i}|\pi_{i-1})=\frac{Z_{\pi_{i-1},\pi_{i}}}{\sum_{l\inX_{\pi_{ i-1}}}Z_{\pi_{i-1},l}}",,"p(\pi_{i}|\pi_{i-1})=\frac{Z_{\pi_{i-1},\pi_{i}}}{\sum_{j\notin\{\pi_{1},\ldots,\pi_{i-1}\}} Z_{\pi_{i-1},j}}","where \(p(\pi_{i}|\pi_{i-1})\) is the probability of selecting vertex \(\pi_{i}\) given the previous vertex \(\pi_{i-1}\), and the denominator sums edge potentials over all unvisited vertices."
ICML_2024_oral_93,5,"\Phi_{i,j}=\frac{e^{-d_{i,j}/\tau}}{\sum_{k\neq i}e^{-d_{i,k}/\tau}}","where \(d_{i,j}=\left\|x_{i}-x_{j}\right\|_{2}\), and \(\tau\) is a parameter controlling the smoothness of the score distribution in \(\Phi\)","\Phi_{i,j}=\frac{\exp(-\lambda d_{i,j})}{\sum_{l\neq i}\exp(-\lambda d_{i,l})}","where \(d_{i,j} = \|x_i - x_j\|_2\) is the Euclidean distance between vertices \(i\) and \(j\), and \(\lambda\) is a temperature parameter controlling the sharpness of the distribution."
ICML_2024_oral_93,6,\textit{Score}=\frac{\textit{Gap}_{LKH-3}}{\textit{Gap}_{MCTS}},where \(\textit{Gap}_{\text{LKH-3}}=\frac{L_{\text{LKH-3}}}{L^{*}}-1\) and \(\textit{Gap}_{\text{MCTS}}=\frac{L_{\text{MCTS}}}{L^{*}}-1\),Score=\frac{c(\pi_{LKH-3})-c(\pi_{GT})}{c(\pi_{MCTS})-c(\pi_{GT})},"where \(c(\mathbf{\pi}_{\text{LKH-3}})\) and \(c(\mathbf{\pi}_{\text{MCTS}})\) are the tour costs found by LKH-3 and MCTS respectively, and \(c(\mathbf{\pi}_{\text{GT}})\) is the ground-truth optimal tour cost"
ICML_2024_oral_95,1,"K_{img}(i,j)=\langle f_{img}(x_{i}),f_{img}(x_{j})\rangle || K_{text}(i,j)=\langle f_{text}(y_{i}),f_{text}(y_{j})\rangle",,"K_{vision}(i, j)=\langle f_{img}(x_i), f_{img}(x_j)\rangle,\quad K_{text}(i, j)=\langle f_{text}(y_i), f_{text}(y_j)\rangle","The vision kernel \(K_{\text{vision}}(i, j)\) is the inner product between image model embeddings for images \(x_i\) and \(x_j\), and the text kernel \(K_{\text{text}}(i, j)\) is the inner product between language model embeddings for captions \(y_i\) and \(y_j\)."
ICML_2024_oral_95,2,"P_{\texttt{coor}}(x_{a},x_{b})\propto\sum_{(t,t^{\prime})\colon|t-t^{\prime}|\leq T_{\texttt{ window}}}P(X_{t}=x_{a},X_{t^{\prime}}=x_{b})",,"P_{\texttt{coor}}(x_a, x_b)=P\left(\exists\, t_1, t_2\in [1, T] : |t_1-t_2|\leq T_{\texttt{window}},\\texttt{obs}(z_{t_1})=x_a,\\texttt{obs}(z_{t_2})=x_b\right)","The cooccurrence probability \(P_{\texttt{coor}}(x_a, x_b)\) is the probability that two observations \(x_a\) and \(x_b\) both occur within a window of size \(T_{\texttt{window}}\) in the sequence of events."
ICML_2024_oral_95,3,"\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle\approx\log\frac{P(\texttt{pos}\mid x_{a},x_{b})}{ P(\texttt{neg}\mid x_{a},x_{b})}+\tilde{c}_{X}(x_{a}) || =\log\frac{P_{\texttt{coor}}(x_{a}\mid x_{b})}{P_{\texttt{coor}} (x_{a})}+c_{X}(x_{a})",,"\langle f_{X}(x_{a}), f_{X}(x_{b})\rangle\approx\log\frac{P_{\texttt{coor}}(x_{a}, x_{b})}{P_{X}(x_{a})P_{X}(x_{b})}+c","The learned representation's dot product approximates the log odds ratio of cooccurrence probability to the product of marginals, up to an additive constant."
ICML_2024_oral_95,4,"=K_{\texttt{PMI}}(x_{a},x_{b})+c_{X}(x_{a})","where \(K_{\texttt{PMI}}\) is the pointwise mutual information (PMI) kernel, and \(c_{X}(x_{a})\) is constant in \(x_{b}\)","\langle f_{X}(x_{a}), f_{X}(x_{b})\rangle\approx\log\frac{P(x_{a}, x_{b})}{P(x_{a})P(x_{b})}+c_{X}(x_{a})","The learned representation's dot product approximates the pointwise mutual information (PMI) between observations \(x_a\) and \(x_b\), up to an offset."
ICML_2024_oral_95,5,"\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle=K_{\texttt{PMI}}(x_{a},x_{b})+c_{X}",where we observed that \(c_{X}(x_{a})\) from Eq,"K_{\texttt{PMI}}(x_{a}, x_{b})=\langle f_{X}^{*}(x_{a}), f_{X}^{*}(x_{b})\rangle",The optimal representation \(f_{X}^{*}\) exactly recovers the PMI kernel via its inner product.
ICML_2024_oral_95,6,"P_{\texttt{coor}}(x_{a},x_{b})=P_{\texttt{coor}}(x_{a},x_{b}),\,K_{\texttt{PMI }}(x_{a},x_{b})=K_{\texttt{PMI}}(z_{a},z_{b})",where we use \(P_{\texttt{coor}}\) and \(K_{\texttt{PMI}}\) modality-agnostically to emphasize that different modalities share these same quantities,"K_{\texttt{PMI}}(x_{a}, x_{b})=K_{\texttt{PMI}}(z_{a}, z_{b})",The pointwise mutual information kernel between observations \(x_{a}\) and \(x_{b}\) is equal to the PMI kernel between their corresponding underlying events \(z_{a}\) and \(z_{b}\) under a bijective observation function.
ICML_2024_oral_95,7,"K_{\texttt{PMI}}(z_{a},z_{b})=\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle-c_{X} || =\langle f_{Y}(y_{a}),f_{Y}(y_{b})\rangle-c_{Y}",,"K_{\texttt{PMI}}(x_{a},x_{b})=K_{\texttt{PMI}}(y_{a},y_{b})=K_{\texttt{PMI}}(z_{a},z_{b})","The pointwise mutual information kernel is shared across all bijective, discrete modalities, so the kernel computed in any modality (\(X\), \(Y\), or the latent events \(Z\)) is the same."
ICML_2024_oral_99,1,"\min_{(\pi,\hat{\Delta})}\max_{\nu\inE_{0}}(R_{\nu}(n,\pi),\max_{1\leq j\leq M}e_{\nu}(n,\hat{\Delta}(X_{j})))",where we use the subscript \(\nu\) to denote the contextual bandit instance,"\min_{(\pi,\hat{\Delta})}\quad &\max\left\{R(n,\pi),\;\max_{1\leq j\leq M} e\left(n,\hat{\Delta}(X_j)\right)\right\}\\s.t.\quad & (\pi,\hat{\Delta}) is admissible.","The minimax multi-objective optimization problem seeks an admissible policy-estimator pair \((\pi, \hat{\Delta})\) that minimizes the maximum of the cumulative regret and the worst-case mean squared error across all features."
ICML_2024_oral_99,2,"\inf_{(\pi,\hat{\Delta}_{n})}\max_{\nu\inE_{0}}[e_{\nu}(n,\hat{\Delta}_{n})R_{\nu}(n,\pi)]\geq\Omega (M)",,"\min_{(\pi,\hat{\Delta})}\max_{\nu\inE_{0}}\left(R_{\nu}(n,\pi),\max_{1\leq j\leq M}e_{\nu}(n,\hat{\Delta}(X_{j}))\right)\geq\Omega\left(\frac{M}{R_{\nu}(n,\pi)}\right)","For any admissible policy-estimator pair, there exists a problem instance where the maximum CATE estimation error is at least order \(M/\mathcal{R}_{\nu}(n,\pi)\)."
ICML_2024_oral_99,3,"e_{\nu}(n,\hat{\Delta}_{n})=\max_{1\leq j\leq M}E[(\hat{\Delta}_{n}(X_{j})-\Delta(X_{j}))^{2}]=O(\frac{1}{ f_{\min}(n)})",,"e_{\nu}\left(n,\hat{\Delta}_{n}\right)=\Theta\left(\frac{M}{n}\right)",The mean squared error of the CATE estimator under random control trials is of order \(\Theta\left(\frac{M}{n}\right)\).
ICML_2024_oral_99,4,"R_{\nu}(n,\pi)\leqO(M\max\{f_{min}(n)^{1-\alpha},\log n\}) || e_{\nu}(n,\hat{\Delta}_{n})\leqO(\frac{1}{\max\{f_{min}(n)^{1-\alpha},\log n\}})",,"R_{\nu}(n,\pi)=O\left(M\hat{f}_{\min}^{\alpha}\right),\quad e_{\nu}(n,\hat{\Delta}_{n})=O\left(\frac{1}{\hat{f}_{\min}^{1-\alpha}}\right)",where \(\hat{f}_{\min} = \min_{1\leq j\leq M} \hat{f}_j\) is the estimated minimum feature occurrence from the first phase.
ICML_2024_oral_99,5,"e_{\nu}(n,\hat{\Delta}_{n})R_{\nu}(n,\pi)\leqO(M)",,"R_{\nu}(n,\pi)\cdot e_{\nu}(n,\hat{\Delta}_{n})\leqO(M)",The product of regret and estimation error is upper bounded by order \(M\).
ICML_2024_oral_99,6,O((\log n_{j}+\log\log(1/\Delta(X_{j})))(\frac{ 1}{\Delta(X_{j})^{2}}+\frac{1}{\varepsilon\Delta(X_{j})})),,O\left(\frac{\log n}{\Delta^{2}}+\frac{\log^{2} n}{\varepsilon\Delta}\right),"The number of times the suboptimal arm is pulled for any feature \(X_j\) in the first half periods under DP-ConSE, with probability at least \(1-\frac{1}{n}\)."
ICML_2024_oral_99,7,"e(n,\hat{\Delta})=O(\frac{1}{\max\{f_{min}(n)^{1-\alpha},\frac{\log n}{\varepsilon}\}})",,"e_{\nu}(n,\hat{\Delta}_{n})\leqO\left(\frac{1}{\max\{f_{\min}(n)^{1-\alpha},\log n\}}\right)","The mean squared error of the CATE estimator under DP-ConSE is upper bounded by the inverse of the minimum feature frequency to the power \(1-\alpha\) or \(\log n\), whichever is larger."
naacl_2024_short_14,1,p_{lm}(x_{t}|c)=f\circg\circenc(c),"where \(f\) is the last linear layer with softmax activation, \(g\) is the two-layer MLP network with a residual connection in the last Transformer layer, and \(\mathrm{enc}\) includes the earlier layers of the model","P(x_t\mid c)=P(x_t\mid x_1, x_2,\ldots, x_{t-1})","The probability of the next token \(x_t\) given the context tokens \(x_1, x_2, \ldots, x_{t-1}\)."
naacl_2024_short_14,2,p_{knnlm}(x_{t}|c)=\lambda p_{lm}(x_{t}|c)+(1-\lambda)p_{\text {knn}}(x_{t}|c),where \(\lambda\) is a hyperparameter for interpolation,"p(x_{t}|c)=\lambda\, p_{knn}(x_{t}|c)+(1-\lambda)\, p_{lm}(x_{t}|c)",where \(\lambda\) is a hyperparameter that interpolates between the \(k\)NN distribution and the LM distribution.
naacl_2024_short_14,3,"z^{*}\in\operatorname*{arg\,min}_{z\inR^{d}}KL[f(z)\|p_{knnlm}]",where \(f\) is the last layer of the model with its trained parameters fixed (definition in Eq 1),"\min_{q\inQ}KL(p_{knnlm}(\cdot|c)\,\|\, q)",where \(\mathcal{Q}\) is the set of distributions that the last layer of the LM can generate.
naacl_2024_short_16,1,"g(x)=\operatorname*{arg\,max}_{c\inY}P_{x\sim\phi(x,m)}(f(M(x,s))=c)",,"g(x)=E_{s\sim\phi(x, m)}\left[ f(M(x,s))\right]",The smoothed model \(g(\mathbf{x})\) is defined as the expected output of the original LLM \(f(\cdot)\) over randomly masked versions of the input \(\mathbf{x}\).
naacl_2024_short_16,2,"g^{\prime}(x)=\operatorname*{arg\,max}_{e\inY}P_{s \sim\phi(x,m)}(f(D(M(x,s)))=c)",,"f(M(x,s))\rightarrow f(D(M(x,s)))","The denoiser \(D(\cdot)\) fills the masked tokens in the masked input \(\mathcal{M}(\mathbf{x},\mathbf{s})\) before it is processed by the base LLM \(f(\cdot)\)."
naacl_2024_short_22,1,"R_{LM}(X,\tau,a^{*})=LM(a^{*}|X,\tau)",,"R_{LM}(X,\tau, a^*)=1 &if LM(X,\tau)=a^*\\0 &otherwise","\(R_{LM}(X, \tau, a^*)\) is a sparse reward function that assigns a reward of 1 if the language model's prediction given state description \(X\) and task \(\tau\) matches the target action \(a^*\), and 0 otherwise."
naacl_2024_short_22,2,"L(X,S,\tau,a^{*})=\\\sum_{t=0}^{|X|}(V_{\theta}(X_{:t},\tau)-\gamma^{|X|-t}R_{LM}( X,\tau,a^{*}))^{2}",,"L(X,\tau, a^*)=-R_{LM}(X,\tau, a^*)","The loss function \(\mathcal{L}(X, \tau, a^*)\) is defined as the negative reward assigned by \(R_{LM}\) for the state description \(X\), task \(\tau\), and target action \(a^*\)."
naacl_2024_short_22,3,"L_{V_{\theta}}=\underset{{c}S,\tau,a^{*}\sim D\\X\sim\pi|S,\tau}{E}[L(X,S,\tau,a^{*})+\phi]","where \(\gamma\) is a discount factor and \(\phi\) is a Kullback-Leibler penalty for normalizing \(V_{\theta}\), common when finetuning LMs with RL (Stiennon et al","L_{total}=E_{(S,\tau, a^*)\sim D}\left[E_{X\simX(S)}\left[L(X, S,\tau, a^*)\right]\right]",The total loss is the expected single-description loss over sampled trajectories and state descriptions.
naacl_2024_short_23,1,"\hat{C}_{m},\hat{S}_{m},\hat{F}_{m}=\textsc{attributePredictor}(m,M) || \hat{E}=\textsc{CandidateGenerator}(m,E) || f(m|T,M,E)=\textsc{Constrainer}(\hat{E},\hat{C}_{m},\hat{S}_{m},\hat{F}_{ m})",,"\hat{e}=\arg\min_{e\incandidates(m, E)}\;violations(e;predicted attributes(m, T))",\(\hat{e}\) is the candidate entry for mention \(m\) that minimizes the number of constraint violations based on the predicted attributes.
naacl_2024_short_23,2,"Z=\textsc{transformer}(\textsc{Toinput}(m,M)) || \hat{C}_{m}=softmax(Z_{c}W_{c}) || \hat{S}_{m}=softmax(Z_{s}W_{s}) || \hat{F}_{m}=softmax(Z_{f}W_{f})",,"\hat{y}_{m}^{(a)}=\arg\max_{y\inY^{(a)}} P(y\mid m, M)","\(\hat{y}_{m}^{(a)}\) is the predicted attribute \(a\) (country, state, or feature class) for mention \(m\), selected as the most probable label from the set of possible attribute values \(\mathcal{Y}^{(a)}\) given the mention \(m\) and all mentions \(M\)."
naacl_2024_short_23,3,L=C_{m}log(\hat{C}_{m})+S_{m}log(\hat{S}_{m})+F_{m}log(\hat{F}_{m}),"where \(C_{m}\), \(S_{m}\), and \(F_{m}\) are one-hot vectors of size \(N\) representing the true country, state, and feature class for mention \(m\)",L=-\sum_{i=1}^{|M|}\left(\log\hat{C}_{m_i}[c_i]+\log\hat{S}_{m_i}[s_i]+\log\hat{F}_{m_i}[f_i]\right),"\(\mathcal{L}\) is the total cross-entropy loss over all mentions, where \(\hat{C}_{m_i}[c_i]\), \(\hat{S}_{m_i}[s_i]\), and \(\hat{F}_{m_i}[f_i]\) are the predicted probabilities for the true country, state, and feature class labels for mention \(m_i\)."
naacl_2024_short_25,1,"f(q,d_{i})=\frac{\exp(s_{i,1})}{\exp(s_{i,1})+\exp(s_{i,0})}",,"f(q, d_{i})=\frac{\exp(s_{i,1})}{\exp(s_{i,1})+\exp(s_{i,0})}","The ranking score \(f(q, d_{i})\) is the softmax probability of the LLM answering ""Yes"" for the query-document pair \((q, d_{i})\), based on the log-likelihood scores \(s_{i,1}\) and \(s_{i,0}\)."
naacl_2024_short_25,2,"s_{i,k}=LLM(l_{k}|q,d_{i})",,"s_{i,j}=LLM(l_j\mid q, d_i),\quad j\in\{0, 1, 2\}","$s_{i,j}$ is the log-likelihood score assigned by the LLM to label $l_j$ for the query-document pair $(q, d_i)$."
naacl_2024_short_25,3,"f(q,d_{i})=\sum p_{i,k}\cdot y_{k} || where p_{i,k}=\frac{\exp(s_{i,k})}{\sum_{k^{\prime}}\exp(s_{i,k^{\prime}})}",,"E[y]=\sum_{k=0}^{2} y_{k}\cdot\frac{\exp(s_{i,k})}{\sum_{j=0}^{2}\exp(s_{i,j})}","The expected relevance value \(\mathbb{E}[y]\) for a query-document pair is computed as the weighted sum of assigned relevance values \(y_k\), weighted by the softmax-normalized log-likelihoods \(s_{i,k}\) for each relevance label."
naacl_2024_short_25,4,"f(q,d_{i})=s_{i,k^{*}}",,"f(q,d_{i})=p_{i,k^{*}}",Ranking score is the probability assigned to the highest relevance label for document \(d_i\) given query \(q\).
naacl_2024_short_26,1,"f(x,t,k;\theta)=y",,"y=f(x, t, k;\theta)","The stance label \(y\) is predicted by a model \(f\) given the text \(x\), target \(t\), knowledge \(k\), and model parameters \(\theta\)."
naacl_2024_short_26,2,"L_{gen}=-\sum_{i=1}^{|u|}\log p(u_{i}|,u_{< i},h(x,t,k);\theta)","where \(p(u_{i}|,\boldsymbol{u}_{<i},h(x,t,k);\theta)\) is the probability to select a token \(u_{i}\) at step \(i\) given the input \(h(x,t,k)\) and previously generated tokens \(\boldsymbol{u}_{<i}\)","L(\theta)=\sum_{i=1}^{N}\log P_{\theta}(u_i\mid h(x_i, t_i, k_i))","The training objective is to maximize the log-likelihood of the output sequence \(\mathbf{u}_i\) given the combined input \(h(x_i, t_i, k_i)\) over all \(N\) training examples."
naacl_2024_short_26,3,v_{c}arrowNormalize(\betav_{c}+(1-\beta)v_{c}^{\prime}),"where \(\beta\) is a momentum coefficient, \(\text{Normalize}(\cdot)\) is the normalization function, and \(\boldsymbol{v}_{c}^{\prime}\) is the centroid of embeddings belonging to class \(c\) in the batch",v_c\leftarrow m\cdotv_c+(1-m)\cdot\frac{1}{N_c}\sum_{i=1}^{N_c}\hat{z}_i,"where \(\boldsymbol{v}_c\) is the prototype for class \(c\), \(m\) is the momentum coefficient, \(N_c\) is the number of samples in class \(c\) in the current batch, and \(\boldsymbol{\hat{z}}_i\) are the projected stance embeddings for class \(c\)."
naacl_2024_short_26,4,L_{con}=-\sum_{c=1}^{C}y_{c}\log\frac{exp(\frac{s_{c}}{\gamma})}{\sum_{j=1}^{C}exp(\frac{s_{j}}{\gamma})},where \(\gamma\) is a scalar temperature parameter and \(\boldsymbol{y}\) is the one-hot label for the current sample,L_{con}=-\log\frac{\exp(s_{y}/\tau)}{\sum_{j=1}^{|S|}\exp(s_{j}/\tau)},"where \(s_{j} = \langle \boldsymbol{\hat{z}}, \boldsymbol{v}_{j} \rangle\) is the cosine similarity between the projected stance embedding and the prototype of class \(j\), \(y\) is the ground-truth class, \(\tau\) is a temperature hyperparameter, and \(|S|\) is the number of stance classes."
naacl_2024_short_26,5,L=\lambda_{l}\cdotL_{gen}+(1-\lambda_{l})\cdotL _{con},where \(\lambda_{l}\) is involved to balance the optimization,L=L_{gen}+\lambdaL_{con},where \(\lambda\) is a hyperparameter that balances the generative loss and the contrastive loss.
naacl_2024_short_27,1,"[sim_{A}^{j},sim_{B}^{j}]=X_{i}\cdot[X_{A}^{j},X_{B}^{j}]",,"sim(X_i, A_j)=h_{X_i}\cdot h_{A_j}",The similarity between example \(X_i\) and attribute \(A_j\) is computed as the dot product of their representations \(h_{X_i}\) and \(h_{A_j}\).
naacl_2024_short_27,2,"d_{sim}^{j}=\sigma(sim_{A}^{j},sim_{B}^{j})",,"[p_{A}^{j}, p_{B}^{j}]=\sigma(sim_{A}^{j}, sim_{B}^{j})=\left[\frac{e^{sim_{A}^{j}}}{e^{sim_{A}^{j}}+e^{sim_{B}^{j}}},\frac{e^{sim_{B}^{j}}}{e^{sim_{A}^{j}}+e^{sim_{B}^{j}}}\right]","Here, \(p_{A}^{j}\) and \(p_{B}^{j}\) represent the normalized similarity scores between example \(X_{i}\) and attribute representations \(X_{A}^{j}\) and \(X_{B}^{j}\), respectively."
naacl_2024_short_27,3,"L_{kl}=\sum_{j=1}^{K}D_{KL}(d_{sim}^{j},d_{uni})",,L_{KL}=\frac{1}{N}\sum_{j=1}^{N} D_{KL}(d_{sim}^{j}\parallel d_{uni}),"Here, \(\mathcal{L}_{KL}\) denotes the average Kullback-Leibler divergence between the similarity distributions \(d_{sim}^{j}\) and the uniform distribution \(d_{uni}\) across all \(N\) pairs."
naacl_2024_short_27,4,L_{total}=L_{ce}+\lambda L_{kl},where \(L_{ce}\) is the usual cross-entropy loss,L=L_{ce}+\lambda L_{kl},Total loss is the sum of the cross-entropy loss \(L_{ce}\) and the KL loss \(L_{kl}\) weighted by hyperparameter \(\lambda\).
naacl_2024_short_28,1,"S(y)=-\frac{1}{|H(x)|}\sum_{y^{\prime}\in H(x)}L(y^{\prime},y)",,"s(y')=-E_{y\sim P(\cdot|x)} [L(y',y)]",The score \(s(\mathbf{y}')\) is defined as the negative expected loss between candidate translation \(\mathbf{y}'\) and samples \(\mathbf{y}\) from the model distribution.
naacl_2024_short_28,2,"y^{*}=\operatorname*{arg\,max}_{y\in H(x)}S(y)",,y^{MBR}=\arg\max_{y\in H(x)} S(y),The MBR hypothesis \(\mathbf{y}^{\text{MBR}}\) is the translation in \(H(\mathbf{x})\) that maximizes the score \(S(\mathbf{y})\).
naacl_2024_short_28,3,"\max_{\pi_{\theta}}E_{x\sim D,y\sim\pi_{\theta}( y|x)}[r_{\phi}(x,y)] || -\betaD_{KL}[\pi_{\theta}(y|x)\parallel\pi_{ref}(y|x)]",,"E_{(x,y^+,y^-)\simD}\left[\log\frac{\exp(\beta r(x,y^+))}{\exp(\beta r(x,y^+))+\exp(\beta r(x,y^-))}\right]","The expected log-probability that the model assigns a higher reward to the preferred output \(\mathbf{y}^+\) over the dispreferred output \(\mathbf{y}^-\), scaled by a parameter \(\beta\)."
naacl_2024_short_28,4,"L_{DPO}=-E_{(x,y_{w},y_{l})\sim D}[log\sigma(M(y_{w},y_{l},x,\theta))] || \beta(log\frac{\pi_{\theta}(y_{w}|x)}{\pi_{ref}(y_{w}|x)}-log\frac{\pi_{\theta}( y_{l}|x)}{\pi_{ref}(y_{l}|x)})","where the reward margin \(M(\mathbf{y}_{w},\mathbf{y}_{l},\mathbf{x},\theta)\) is

\[\beta\left(\text{log}\frac{\pi_{\theta}(\mathbf{y}_{w}|\mathbf{x})}{\pi_{ \text{ref}}(\mathbf{y}_{w}|\mathbf{x})}-\text{log}\frac{\pi_{\theta}(\mathbf{ y}_{l}|\mathbf{x})}{\pi_{\text{ref}}(\mathbf{y}_{l}|\mathbf{x})}\right) \tag{5}\]

### Related Work in Translation

Previous work has explored the effectiveness of enhancing the translation performance of LLMs via Reinforcement Learning (RL) algorithms or supervised fine-tuning","E_{(x,y_{w},y_{l})\sim D}\left[\log\sigma\left(\beta\left(\log\frac{\pi_{\theta}(y_{w}|x)}{\pi_{ref}(y_{w}|x)}-\log\frac{\pi_{\theta}(y_{l}|x)}{\pi_{ref}(y_{l}|x)}\right)\right)\right]","DPO maximizes the expected log-sigmoid of the scaled reward margin between preferred and dispreferred responses, where rewards are approximated by the log-likelihood ratio between the trained and reference models."
naacl_2024_short_32,1,"y^{*}=\operatorname*{arg\,max}_{y\inY}E_{r\sim P_{ human}(\cdot|x)}[u(y,r)]",,"\hat{y}=\arg\max_{y\inY}E_{r\sim p(r)}[u(y, r)]",\(\hat{y}\) is the candidate translation from \(\mathcal{Y}\) that maximizes the expected utility with respect to the reference distribution \(p(r)\).
naacl_2024_short_32,2,"y^{*}=\operatorname*{arg\,max}_{y\inY}\frac{1}{|R^{\prime}|}\sum_{r^{\prime}\inR^{\prime}}u(y,r^{\prime})",,"y^{*}=\operatorname*{arg\,max}_{y\inY}\frac{1}{K}\sum_{k=1}^{K} u(y, r_k^{\prime})",\(r_k^{\prime}\) denotes the \(k\)-th pseudo-reference sampled from the model distribution \(P_{\mathrm{model}}(\cdot|x)\).
naacl_2024_short_33,1,"\min_{P_{n},v_{n}}-\sum_{x_{n},y_{n}}\log p(y_{n}|x_{n},P^{\prime}_{n},\theta)-\sum_{x_{n}}\cos(x_{n},v_{n})",,"L_{n}=L_{CE}(P_{n}, v_{n})-\lambda\cos(x_{n}, v_{n})","The training objective \(\mathcal{L}_{n}\) for the \(n^{\text{th}}\) task combines the cross-entropy loss and a cosine similarity term between the task feature vector and input embeddings, weighted by \(\lambda\)."
naacl_2024_short_33,2,"FWT=\frac{1}{N-1}\sum_{j=2}^{N}(a_{i,i}-\tilde{a}_{i})","where \(N\) is the number of tasks in the continual learning sequence, \(a_{i,i}\) denotes the performance evaluated on the \(i\)-th task after incremental learning on the first \(i\) tasks, \(\tilde{a}_{i}\) is the task performance of a randomly initialized reference model trained with dataset \(D_{i}\)","FWT=\frac{1}{N-1}\sum_{k=1}^{N-1}\left(\frac{1}{N-k}\sum_{l=k+1}^{N}\left( a_{l,k}-a_{k,k}\right)\right)","The forward transfer (FWT) score is defined as the average difference between the accuracy of the model on task $k$ after learning task $l$ ($a_{l,k}$) and the accuracy on task $k$ after learning only task $k$ ($a_{k,k}$), averaged over all tasks and subsequent tasks."
naacl_2024_short_34,1,x_{k}&=A_{k}x_{k-1}+Bu_{k}\\y_{k}&=h(x_{k}),,h_t=f(A_t h_{t-1}+B_t x_t),The hidden state \(h_t\) at time \(t\) is computed by applying a function \(f\) to the sum of the transformed previous hidden state \(A_t h_{t-1}\) and the transformed current input \(B_t x_t\).
naacl_2024_short_34,2,x_{k}=Ax_{k-1}+Bu_{k},,x_{k}=A x_{k-1}+B u_{k},"\(x_{k}\) is the hidden state at time step \(k\), \(A\) is the input-independent transition matrix, \(B\) is the input matrix, and \(u_{k}\) is the input at time step \(k\)."
naacl_2024_short_34,3,"x_{0-1}&=A^{3}z+A^{2}u_{0}+Au_{-}+u_{ 1},\\for ""0-1""\\x_{1-0}&=A^{3}z+A^{2}u_{1}+Au_{-}+u_{0},\\for ""1-0""",,x_{2}^{(1)} &=A(Az+Bu_{0})+Bu_{-}\\x_{2}^{(2)} &=A(Az+Bu_{1})+Bu_{-},"\(x_{2}^{(1)}\) and \(x_{2}^{(2)}\) are the state vectors after processing the sequences ""0-1"" and ""1-0"", respectively, under the input-independent LRNN recurrence."
naacl_2024_short_34,4,A^{2}u_{0}+Au_{-}+u_{1}\neq A^{2}u_{1}+Au_{-}+u_{0},,A^{2}u_{0}+u_{1}\neq A^{2}u_{1}+u_{0},"The condition that must hold for the LRNN state representations to distinguish between the sequences ""0-1"" and ""1-0""."
naacl_2024_short_34,5,x_{0-0-1}&=A^{3}x_{0-}+A^{2}u_{0}+Au_ {-}+u_{1}\\x_{0-1-0}&=A^{3}x_{0-}+A^{2}u_{1}+Au_{-}+u_{0},,"x_{0-0-1} &=A^{4}z+A^{3}u_{0}+A^{2}u_{-}+Au_{0}+u_{-}+u_{1},\\for ""0-0-1""\\x_{0-1-0} &=A^{4}z+A^{3}u_{0}+A^{2}u_{-}+Au_{1}+u_{-}+u_{0},\\for ""0-1-0""","These equations give the state representations for the input sequences ""0-0-1"" and ""0-1-0"" under the input-independent LRNN recurrence."
naacl_2024_short_34,6,A^{2}u_{0}+Au_{-}+u_{1}=A^{2}u_{1}+Au_{-}+u_{0},,A^{2}u_{0}+Au_{-}+u_{1}=A^{2}u_{1}+Au_{-}+u_{0},"This equation states that, under the assumption \(x_{0-0-1}=x_{0-1-0}\), the linear recurrence must satisfy \(A^{2}u_{0}+Au_{-}+u_{1}=A^{2}u_{1}+Au_{-}+u_{0}\)."
naacl_2024_short_34,7,x_{k}=diag(v_{k})x_{k-1}+Bu_{k},where \(v_{k}=f(u_{k})\) is a vector that depends on \(u_{k}\),x_{k}=A_{k}x_{k-1}+Bu_{k},"The state update equation for a diagonal input-dependent LRNN, where the transition matrix \(A_{k}\) depends on the current input \(u_{k}\)."
naacl_2024_short_34,8,x_{k}&=Ax_{k-1}+(Bu_{k})\odot x_{k-1}+Bu_{k}\\&=(A+diag(Bu_{k}))x_{k-1}+Bu_{k},where \(\odot\) denotes the Hadamard product and \(\text{diag}(w)\) constructs a diagonal matrix from \(w\),x_{k}=A_{k}x_{k-1}+B_{k}u_{k},where both \(A_{k}\) and \(B_{k}\) are input-dependent matrices at each timestep \(k\).
naacl_2024_short_34,9,x_{k}=A_{k}x_{k-1}+Bu_{k},where \(A_{k}=g(u_{k})\) is a block diagonal matrix in practice for the sake of efficiency,x_{k}=A_{k}x_{k-1}+Bu_{k},"where \(A_{k}=g(u_{k})\) is a block-diagonal, input-dependent transition matrix."
naacl_2024_short_34,10,"& A_{k}=diag(A_{k}^{(1)},...,A_{k}^{(h)} )\inR^{bh\timesbh}\\& A_{k}^{(i)}=[v_{k}^{(i,1)}\quad\ldots\quad v_{k}^{(i,b)} ]\inR^{b\times b}\\&\|v_{k}^{(i,j)}\|_{p}\leq 1,\\i\in[1,...,h],\\j\in[1,...,b]","where \(\|\cdot\|_{p}\) denotes the vector p-norm and \(v_{k}^{(i,j)}\) is a column vector that depends on \(u_{k}\)",\|A_{k}\|_{1}=1,The matrix \(A_{k}\) is constrained such that its maximum absolute column sum (the induced 1-norm) equals 1.
naacl_2024_short_34,11,&[\|v^{(1)}\|_{1}\quad\ldots\quad\|v^{(b)}\|_{1} ]=1^{\top}|A_{k+1}^{(i)}A_{k}^{(i)}|\\&\leq1^{\top}|A_{k+1}^{(i)} || A_{k}^{(i)} |\leq1^{\top}|A_{k}^{(i)}|\leq1^{\top},,"\|v^{(j)}\|_{1}\leq 1,\quad\forall j\in [1, ..., b]",The 1-norm of each column \(v^{(j)}\) of the product \(A_{k+1}^{(i)}A_{k}^{(i)}\) is at most 1 for all \(j\).
naacl_2024_short_38,1,"f(C,P,N_{1},N_{2})=1&if s(C,P)>s(C,N_{1} )\\&and s(C,P)>s(C,N_{2} )\\0&otherwise",where \(s(,"f\left(C,P,N_{1},N_{2}\right)=1, &if the VLM retrieves P given C\\0, &otherwise","The evaluation metric \(f\) returns 1 if the VLM retrieves the correct image \(\mathcal{P}\) for the compound noun prompt \(\mathcal{C}\), and 0 otherwise."
naacl_2024_short_38,2,"Mean Similarity=\frac{1}{n}\sum_{i=1}^{5}s(c,p_{i})","where \(p_{i}\in P\) denotes the generated prompts, \(s(","S(c, T)=\frac{1}{5}\sum_{i=1}^{5} s(c, T_i)","\(S(c, T)\) denotes the mean cosine similarity between image \(c\) and the set of 5 generated text prompts \(T = \{T_1, T_2, ..., T_5\}\)."
naacl_2024_short_39,1,"\underset{\theta_{P}}{\max}\underset{i}{\sum}\log p_{\theta,\theta_{P}}(y_{i}|[P;x_{i}])",,\max_{\Theta}\sum_{i=1}^{N}\log p_{\Theta}(y_{i}\mid x_{i}),"The objective maximizes the sum of the log-likelihoods of the output sequences \(y_i\) given the input texts \(x_i\) over all \(N\) training examples, with respect to model parameters \(\Theta\)."
naacl_2024_short_39,2,\frac{(Zero-shot\correct)\cap(PoT\incorrect)}{Zero-shot\correct},"where _Zero-shot correct_ is the case of correct responses in a zero-shot setting, and _PoT incorrect_ is the case of incorrect answers after prompt transfer in the target task",CF=\frac{1}{N}\sum_{i=1}^{N}\left( S_{before}^{(i)}-S_{after}^{(i)}\right),"CF denotes catastrophic forgetting, calculated as the average decrease in source task score before and after prompt transfer across N source tasks."
naacl_2024_short_43,1,"I_{c,i}\sim f(c_{\ell})",,x_{i}=f(c_{\ell}),The \(i\)-th generated image \(x_{i}\) is obtained by applying the multilingual T2I model \(f\) to the concept phrase \(c_{\ell}\) in language \(\ell\).
naacl_2024_short_43,2,"X_{c}=\frac{1}{n^{2}}\sum_{i=0}^{n}\sum_{j=0}^{n}SIM_{F}(I_{c_{\ell}, i},I_{c_{\ell_{s}},j})","where we sample \(n\) images per-concept per-language (we use 9), and \(\mathrm{SIM}_{F}(\cdot,\cdot)\) measures the cosine similarity in feature space by image feature extractor \(F\)","X_{c}(f, c_{\ell}, c_{\ell_{s}})=sim(f(c_{\ell}), f(c_{\ell_{s}}))","The cross-consistency score \(X_{c}(f, c_{\ell}, c_{\ell_{s}})\) measures the similarity between images generated from the concept in language \(\ell\) and its source language \(\ell_{s}\)."
naacl_2024_short_43,3,"\Delta X_{c}(c,\ell)=X_{c}(f,c^{\prime}_{\ell},c_{\ell_{s}})-X_{c}(f,c_{\ell}, c_{\ell_{s}})",,"\Delta X_{c}=X_{c}(f, c'_{\ell}, c_{\ell_{s}})-X_{c}(f, c_{\ell}, c_{\ell_{s}})",where \(\Delta X_{c}\) is the change in cross-consistency score for concept \(c\) when replacing the original translation \(c_{\ell}\) with the corrected translation \(c'_{\ell}\).
naacl_2024_short_43,4,"\DeltaSEM=SIM_{Ft}(c_{\ell_{s}},c^{\prime}_{\ell})- SIM_{Ft}(c_{\ell_{s}},c_{\ell})",,"\DeltaSEM(c_{\ell_{s}},c_{\ell},c^{\prime}_{\ell})=SIM(F_{t}(c_{\ell_{s}}), F_{t}(c^{\prime}_{\ell}))-SIM(F_{t}(c_{\ell_{s}}), F_{t}(c_{\ell}))","where \(F_{t}\) is a text feature extractor and \(\mathrm{SIM}(\cdot,\cdot)\) computes cosine similarity between feature vectors."
naacl_2024_short_45,1,\ell=softmax(affine(ReLU(u_{s}))) || \ell_{i}=softmax(affine(ReLU(u_{i}))) || \nabla_{i}=\ell-\ell_{i},,r_{i}=p(\hat{y}\midu_{s})-p(\hat{y}\midu_{i}),The relevance score \(r_{i}\) for token \(x_{i}\) is defined as the difference in predicted probability for label \(\mathbf{\hat{y}}\) between the full input and the input with \(x_{i}\) removed.
naacl_2024_short_45,2,L_{dialect-classifier}=-\sum_{i}\log\ell[y_{i}^{*}],where \(y_{i}^{*}\) is the correct label for instance \(i\),L=-\sum_{j=1}^{N}\log\ell_{y_j}^{(j)},"The loss \(\mathcal{L}\) is the negative log probability of the true label \(y_j\) under the predicted label distribution \(\ell^{(j)}\), summed over all \(N\) training instances."
naacl_2024_short_45,3,s_{j}=softmax(affine(ReLU(u_{s})-ReLU(u_{j}))) || loss=L_{{{dialect-classifier}}}+\alpha_{1}L_{{{LII}}},,\ell_{j}=softmax(affine(ReLU(u_{s}-u_{j}))),where \(\mathbf{u}_{j}\) is the MLM representation of feature \(x_{i}\)
naacl_2024_short_45,4,r_{j}=[\ell]_{y_{i}^{*}}-[s_{j}]_{y_{i}^{*}},"where higher \(r_{j}\) signifies more relevant features to the prediction, serving as better explanations",r_{i}=\ell[y^{*}]-\ell_{i}[y^{*}],"where \(r_{i}\) is the relevance score for feature \(x_{i}\), \(\boldsymbol{\ell}[y^{*}]\) is the probability of the correct label with all features, and \(\boldsymbol{\ell_{i}}[y^{*}]\) is the probability with \(x_{i}\) removed."
naacl_2024_short_45,5,E^{\prime}=\{e\in E\midisCorrect(e)\landisUnique(e)\},,E^{\prime}=\{ e_{k}\in E\midprediction(e_{k})=y_{k}^{*}\\wedge\unique(e_{k})\},\(E^{\prime}\) is the set of sentence-level explanations that are both from correct predictions and unique to a specific language variety.
naacl_2024_short_45,6,"TF-IDF(t,d,D)=TF(t,d)\timesIDF(t,D)",,"TFIDF(t, d, D)=tf(t, d)\times\log\left(\frac{|D|}{|\{d'\in D : t\in d'\}|}\right)",The TF-IDF score quantifies the importance of term \(t\) in document \(d\) relative to the corpus \(D\).
naacl_2024_short_45,7,"F=\{TF-IDF(t,d,E^{\prime})\mid t\in d,d\in E^{\prime}\}",,"F=\underset{t\in V}{argmax_k}\;TF-IDF(t, E', D)","where \(V\) is the vocabulary, \(E'\) is the filtered set of explanations, \(D\) is the corpus, and the top \(k\) terms with highest TF-IDF scores are selected as features \(F\)"
naacl_2024_short_46,1,"[x^{i},Q^{k}]=BERT([x^{i},Q^{k}])","where \(\mathbf{x}^{i}\) and \(\mathbf{Q}^{k}\) are the representations of \(x^{i}\) and \(\mathcal{Q}^{k}\), respectively",h^{i}=BERT([x^{i};Q^{k}]),\(h^{i}\) denotes the contextual representation of input \(x^{i}\) combined with the accumulated prompts \(\mathcal{Q}^{k}\) as computed by a frozen BERT model.
naacl_2024_short_46,2,"Z^{i}_{t}=Linear(FFN([x^{i}_{m},x^{i}_{n}]))","where \(\overline{\mathbf{x}}^{i}_{t}=\text{FFN}([\mathbf{x}^{i}_{m},\mathbf{x}^{i}_{ n}])\) is the span representation, \(m\) and \(n\) denote the start and end index of the span, respectively","z^{i}_{t}=FFN([x^{i}_{t,start};x^{i}_{t,end}])","\(\mathbf{z}^{i}_{t}\) is the span representation for the \(t\)-th span in the \(i\)-th example, obtained by concatenating the start and end token representations and passing them through a feed-forward network."
naacl_2024_short_46,3,"L_{new}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\in D^{k}_{train}}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})",,L_{ce}=-\log\left(\frac{\exp(Z^{i}_{t}[y])+\exp(Z_{q}[y])}{\sum_{c=1}^{|Q^{k}|}\exp(Z^{i}_{t}[c])+\exp(Z_{q}[c])}\right),"where \(y\) is the ground-truth event type index for the span, and \(\mathcal{L}_{\text{ce}}\) is the cross-entropy loss combining logits from both span and prompt representations."
naacl_2024_short_46,4,"L_{mem}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\in M}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})",,"L_{mem}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inM}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})","where \(\mathcal{M}\) is the memory module containing replay examples, and the loss is computed analogously to Eq. 3."
naacl_2024_short_46,5,"L_{sim}=\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inD^ {k}_{train}}\sum_{e_{t}\inE^{k-1}}\max(0,g(\overline {x}^{i}_{t},e_{t})-m_{1})","where \(\mathcal{E}^{k-1}\) is the prototype set of previous \(k-1\) tasks, \(g(,)\) is the similarity function (cosine similarity) and \(m_{1}\) is the margin for \(\mathcal{L}_{\text{sim}}\)","L_{margin}=\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inD^{k}_{train}}\sum_{c\inC^{1:k-1}}\max\left(0, m+sim(\overline{x}^{i}_{t},p_c)\right)","where \(m\) is the margin hyperparameter, \(\text{sim}(\cdot, \cdot)\) denotes a similarity function, and \(\mathbf{p}_c\) is the prototype of event type \(c\) from previous tasks."
naacl_2024_short_46,6,"L_{cal}=-\sum_{(\overline{x}_{t}^{i},\overline{x}_{t}^{i})\inM}\log\frac{\exp g(\overline{x}_{t}^{i},e_{t}) }{\sum_{j=1}^{|e^{k-1}|}\exp g(\overline{x}_{t}^{i}, e_{j})}",where \(\mathbf{e}_{t}\) is the prototype of \(y_{t}^{i}\),"L_{cal}=\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inM}\max(0, m_{2}-g(\overline{x}^{i}_{t},e_{y^{i}_{t}}))","where \(g(,)\) is the similarity function (cosine similarity), \(\mathbf{e}_{y^{i}_{t}}\) is the prototype of class \(y^{i}_{t}\), and \(m_{2}\) is the margin for \(\mathcal{L}_{\text{cal}}\)"
naacl_2024_short_46,7,L_{total}=L_{new}+\lambda_{1}L_{sim}+\lambda_{2}(L_{mem}+L_{cal}),where \(\lambda_{1}\) and \(\lambda_{2}\) are loss weights,L=L_{new}+\lambda_{mem}L_{mem}+\lambda_{sim}L_{sim}+\lambda_{cal}L_{cal},"where \(\lambda_{\text{mem}}, \lambda_{\text{sim}}, \lambda_{\text{cal}}\) are hyperparameters controlling the weights of the memory, separation, and calibration losses, respectively"
naacl_2024_short_46,8,"e_{j}=\frac{1}{|M_{e_{j}}|}\sum_{(\overline{x}_{t}^{i},\overline{x}_{t}^{i})\inM_{e_{j}}}\overline{x}_{t}^{i}","where \(\mathcal{M}_{e_{j}}=\{(\overline{x}_{t}^{i},y_{t}^{i})|(\overline{x}_{t}^{i}, y_{t}^{i})\in\mathcal{M},y_{t}^{i}=e_{j}\}\)","e_{j}=\frac{1}{|M_{e_{j}}|}\sum_{(\overline{x}_{t}^{i}, y_{t}^{i})\inM_{e_{j}}}\overline{x}_{t}^{i}","where \(\mathcal{M}_{e_{j}}\) is the set of memory samples with label \(e_{j}\), and \(\overline{\mathbf{x}}_{t}^{i}\) is the span representation of sample \((\overline{x}_{t}^{i}, y_{t}^{i})\)."
naacl_2024_short_5,1,"L^{unsup}_{simce}=-\log\frac{e^{sim(h_{i},h_{i}^{\prime})/\tau}}{\sum_{j=1}^{N}e^{ sim(h_{i},h_{j}^{\prime})/\tau}} || L^{unsup}_{skice}=-\log\frac{e^{sim(h_{i},h_{i}^{ski})/\tau}}{\sum_{j=1}^{N}e^{sim(h_{i},h_{j}^{ski})/\tau}}",,"L_{ski}=-\log\frac{\exp(sim(h,h^{ski})/\tau)}{\exp(sim(h,h^{ski})/\tau)+\exp(sim(h,h^{\prime})/\tau)}","\(\mathcal{L}_{\text{ski}}\) is the SKICSE unsupervised loss that encourages the embedding of \(x\) to be closer to its SKI variant than to its dropout-augmented variant, using a temperature-scaled similarity."
naacl_2024_short_5,2,L^{unsup}=(1-\lambda)L^{unsup}_{ simce}+\lambdaL^{unsup}_{skice},where the weight \(\lambda\) is a balanced hyperparameter and reflects the importance of SKI,L^{unsup}=\lambdaL^{unsup}_{simce}+(1-\lambda)L^{unsup}_{skice},"The final unsupervised SKICSE loss is a weighted sum of the simce and skice losses, controlled by the hyperparameter \(\lambda\)."
naacl_2024_short_5,3,"L^{sup}_{simce}=-\log\frac{e^{sim(h_{i},h_{i}^{+})/\tau}}{\sum_{j=1}^{N}(e^{ sim(h_{i},h_{j}^{+})/\tau}+e^{sim(h_{i},h_{j}^{-})/\tau})} || L^{sup}_{skice_{1}}=-\log\frac{e^{sim(h_{i}^{ski},h_{i}^{+})/\tau}}{\sum_{j=1}^{N} (e^{sim(h_{i}^{ski},h_{j}^{+})/\tau}+e^{sim(h_{i}^{ski},h_{j}^{-})/\tau})} || L^{sup}_{skice_{2}}=-\log\frac{e^{sim(h_{i},h_{i}^{ski})/\tau}}{\sum_{j=1}^{N}(e ^{sim(h_{i},h_{j}^{+})/\tau}+e^{sim (h_{i},h_{j}^{-})/\tau})}",,"L^{sup}_{nli}=-\log\frac{e^{sim(h,h^{+})/\tau}}{e^{sim(h,h^{+})/\tau}+e^{sim(h,h^{-})/\tau}}",The supervised NLI loss encourages the embedding of the premise to be closer to its entailment hypothesis than to its contradiction.
naacl_2024_short_5,4,L^{sup}=(1-\lambda_{1}-\lambda_{2})L^{sup}_{simce}+\lambda_{1}L^{sup}_{skice_{1}}+\lambda_ {2}L^{sup}_{skice_{2}},,L^{sup}=(1-\lambda)L^{sup}_{simce}+\frac{\lambda}{2}\left(L^{sup}_{skice_{1}}+L^{sup}_{skice_{2}}\right),"The final supervised SKICSE objective is a weighted combination of the supervised SIMCE and SKICE losses, with SKICE losses averaged and weighted by \(\lambda\)."
naacl_2024_short_51,1,"R_{d}(w)=\frac{tf(w,d)}{\sum_{d^{\prime}}tf(w,d ^{\prime})}\cdot\log\frac{N}{df(w)}","where \(\operatorname{tf}(w,d)\) is the number of times the word \(w\) occurs in the day \(d\), \(\operatorname{df}(w)\) is the number of days in which the word \(w\) occurs, and \(N\) is the total number of days in the dataset",R_{d}(w)=TF_{d}(w)\timesIDF_{d}(w),\(R_{d}(w)\) denotes the TF-IDF relevance score of token \(w\) for articles on day \(d\).
naacl_2024_short_51,2,"sim(x,x^{\prime})=\frac{\sum_{w\in x^{\prime}x^{\prime}}R_{d}(w)}{max(\hat{R}_{d}(x),\hat{R}_{d}(x^{\prime}))}",,"S(x, y)=\frac{\sum_{w\in x\cap y} R_{d}(w)}{\max\left(\hat{R}_{d}(x),\hat{R}_{d}(y)\right)}","where \(S(x, y)\) is the similarity between articles \(x\) and \(y\), \(R_{d}(w)\) is the TF-IDF relevance of word \(w\) on day \(d\), and \(\hat{R}_{d}(x)\), \(\hat{R}_{d}(y)\) are the total relevance scores for articles \(x\) and \(y\), respectively."
naacl_2024_short_52,1,"& L_{discrete}(y_{i}=t;y_{<i},x)=-\log p(y_{i}=t\midy_{<i},x)\\&\quad=-\langleE(t),h\rangle+\log\sum_{t^{\prime}\in V }\exp\langleE(t^{\prime}),h\rangle","where \(t\) is a token index, \(V\) is the vocabulary, \(\mathbf{E}:V\rightarrow\mathbb{R}^{d}\) is an embedding lookup, and \(\mathbf{h}\) is a transformer hidden state calculated in terms of \(\mathbf{x}\) and the output prefix \(\mathbf{y}_{<i}\)","L_{NLL}=-\sum_{t=1}^{n}\log p(y_t\midy_{<t},x)",\(\mathcal{L}_{\text{NLL}}\) is the negative log-likelihood loss for predicting the target sequence \(\mathbf{y}\) given the source sequence \(\mathbf{x}\).
naacl_2024_short_52,2,"L_{cos}(y_{i}=t;y_{<i},x)=1-\cos(E(t),h)",,"L_{cont}(e;y_{<i},x)=\|e-h\|^2",where \(\mathbf{e}\) is a continuous target embedding and \(\mathbf{h}\) is the predicted hidden state.
naacl_2024_short_52,3,"E(y_{i})=u_{i}/\|u_{i}\|;\quadu_{i}\simNormal( 0,I_{d})",,"E(y_{i})=\frac{z}{\|z\|},\quadz\simN(0,I_d)",\(\mathbf{E}(y_{i})\) is a random embedding for token \(y_{i}\) obtained by normalizing a standard normal vector \(\mathbf{z}\) in \(\mathbb{R}^d\).
naacl_2024_short_52,4,E(y_{i})=r_{i}/\sqrt{d};\quadr_{i}\simRademacher(d),,E(y_{i})=\frac{1}{\sqrt{d}}r_{i};\quadr_{i}\simRademacher(\pm 1)^{d},where \(\mathbf{r}_{i}\) is a vector of independent Rademacher random variables (each entry is \(\pm 1\) with equal probability) and the scaling ensures unit norm in expectation.
naacl_2024_short_52,5,E_{cmb}(y_{i})=\frac{\alphaE_{pre}(y_{i})+(1-\alpha)E_{rand}(y_{i})}{\|\alphaE_{pre}(y_{i})+(1-\alpha)\bm {E}_{rand}(y_{i})\|},,"E_{comb}(y_{i})=\alpha\,E_{pre}(y_{i})+(1-\alpha)\,E_{rand}(y_{i})","where \(\mathbf{E}_{\text{comb}}(y_{i})\) is the combined embedding for token \(y_{i}\), \(\mathbf{E}_{\text{pre}}(y_{i})\) is the pre-trained embedding, \(\mathbf{E}_{\text{rand}}(y_{i})\) is a random embedding, and \(\alpha \in [0,1]\) is a mixing coefficient."
naacl_2024_short_53,1,"S(y,\bar{y};x)>S(y,\hat{y};x)",where \(\mathbf{y}\) is the reference sequence,\bar{y}=f(e_{1:L}+\delta_{1:L};\phi_{d}),The perturbed output sequence \(\bar{\mathbf{y}}\) is generated by passing the encoder embeddings plus a perturbation \(\mathbf{\delta}_{1:L}\) through the decoder.
naacl_2024_short_53,2,\delta_{i}=\alpha|e_{i}|\bigg{|}\frac{\partial f(e_{1:L};\phi_{nap})}{\partiale_{i}}\bigg{|}^{-1}\frac{\partial f(e_{1:L};\phi_{nap})}{\partiale_{i}},"where \(i=1,\ldots,L\)",\delta_{1:L}=\arg\max_{\delta} f(e_{1:L}+\delta;\phi_{nap}),where \(\mathbf{\delta}_{1:L}\) is the perturbation to the encoder outputs that maximizes the NAP-approximated score for a given sample.
naacl_2024_short_56,1,X_{all}=L\[SEP]\X_{ori}\[SEP]\P_{C}\[SEP]\P_{L},,X_{input}=[L]\; [SEP]\; X_{ori}\; [SEP]\; P_{C}\; [SEP]\; P_{L},"$X_{\text{input}}$ denotes the final input instance formed by concatenating the label, original sentence, context prompt, and label prompt with [SEP] tokens."
naacl_2024_short_56,2,L_{MLM}=-{\sum}_{n=1}^{M}\log P(x_{n}),where \(M\) is the number of masked tokens and \(P(x_{n})\) is the predicted probability of token \(x_{n}\) over the vocabulary size,L_{MLM}=-\sum_{t\in T_{mask}}\log P(x_t=w_t\mid X_{all}^{\backslash t}),The prompt MLM loss sums the negative log-likelihood of predicting the masked tokens \(w_t\) at positions \(t\) given the input \(X_{\text{all}}\) with those tokens masked.
naacl_2024_short_56,3,"L_{s}=\frac{1}{N}\sum_{p=1}^{N}-\frac{1}{N_{y_{p}}-1}\sum_{q=1}^{N_ {y_{p}}}\log\frac{e^{sim(h_{p},h_{q}^{+})/\tau}}{\sum_{k=1}^{N}1_{p\neq k}e^{sim(h_{p},h_{k})/\tau}}",where \(N\) is the total number of examples in the batch and \(N_{y_{p}}\) is the number of positive pairs in the batch,"L_{SCL}=-\frac{1}{N}\sum_{p=1}^{N}\frac{1}{|P(p)|}\sum_{h_p^+\in P(p)}\log\frac{\exp(sim(h_p, h_p^+)/\tau)}{\sum_{h_n\in A(p)}\exp(sim(h_p, h_n)/\tau)}","where \(N\) is the batch size, \(P(p)\) is the set of positive samples for anchor \(h_p\), \(A(p)\) is the set of all samples except \(h_p\), \(\mathrm{sim}(\cdot, \cdot)\) denotes the similarity function (e.g., cosine similarity), and \(\tau\) is the temperature parameter."
naacl_2024_short_56,4,L_{final}=\alphaL_{s}+(1-\alpha)L_{MLM},,L=\alphaL_{MLM}+(1-\alpha)L_{s},where \(\alpha\) is a weighting hyperparameter balancing the prompt MLM loss and the supervised contrastive loss.
naacl_2024_short_62,1,"P_{ATTN}(n_{i}|Q,A)=softmax(\sum_{t=1}^{T}\alpha_{t} || v_{t} || _{2})",where \(T\) represents the total token count in \(n_{i}\),\alpha_{i}=\frac{\exp\left(\lambda\cdot\|v_{i}\|\right)}{\sum_{j=1}^{k}\exp\left(\lambda\cdot\|v_{j}\|\right)},"\(\alpha_{i}\) denotes the normalized attention score for document \(n_{i}\) in the set of question-relevant documents \(D_{n}\), where \(\mathbf{v}_{i}\) is the value vector corresponding to \(n_{i}\) and \(\lambda\) is a scaling parameter."
naacl_2024_short_62,2,"P_{RETR}(n_{i}|Q)=\frac{exp(s(n_{i},Q)/\theta)}{\sum_{k=1}^{K}exp(s(n_{k},Q)/\theta)}","where \(s\) denotes the dot-product between the representation vectors of the input question \(Q\) and document candidate \(n_{i}\), and \(\theta\) is the temperature hyper-parameter","p_{RETR}(n_{i}|Q)=\frac{\exp(s(Q, n_{i}))}{\sum_{j=1}^{k}\exp(s(Q, n_{j}))}","where \(s(Q, n_{i})\) denotes the retriever's relevance score between question \(Q\) and document \(n_{i}\)."
naacl_2024_short_66,1,"y_{t}\sim p_{\theta}(y_{t}\midc,x,y_{ct}) || \propto\explogit_{\theta}(y_{t}\midc,x,y _{ct})",,"P_\theta(y\midx,c)",The probability of generating response \(\mathbf{y}\) given query \(\mathbf{x}\) and context \(\mathbf{c}\) under model \(\theta\).
naacl_2024_short_66,2,"y_{t}\sim\tilde{p}_{\theta}(y_{t}\midc,x,y_{ct}) || \propto p_{\theta}(y_{t}\midc,x,y_{ct})\bigg{(}\frac{p_{\theta}(y_{t}\midc,x,y_{ct})}{p_{\theta}(y_{t}\mid\bm {x},y_{ct})}\bigg{)}^{\alpha}",,"p_{PMI}(y_{t}\midc,x,y_{ct})\propto\frac{p_{\theta}(y_{t}\midc,x,y_{ct})}{p_{\theta}(y_{t}\midx,y_{ct})}","PMI-adjusted probability for token \(y_t\) given context \(\mathbf{c}\), query \(\mathbf{x}\), and previous tokens \(\mathbf{y}_{ct}\), defined as the ratio of the model's probability with and without the context."
naacl_2024_short_66,3,"y_{t}\simsoftmax[(1+\alpha)\,logit_{\theta}(y_{t}\midc,x,y_{ct}) || \qquad\qquad-\alpha\,logit_{\theta}(y_{t}\midx,y _{ct})]",,"\tilde{p}_{\theta}(y_{t}\midc,x,y_{ct})=\frac{p_{\theta}(y_{t}\midc,x,y_{ct})^{1+\alpha}}{p_{\theta}(y_{t}\midx,y_{ct})^{\alpha}}\Bigg/\sum_{y'_{t}}\frac{p_{\theta}(y'_{t}\midc,x,y_{ct})^{1+\alpha}}{p_{\theta}(y'_{t}\midx,y_{ct})^{\alpha}}","The normalized context-aware decoding distribution, which reweights the model's output probabilities by contrastively factoring out prior knowledge and normalizes over all possible next tokens."
naacl_2024_short_67,1,"h_{0}^{x},h_{1}^{x},...,h_{n}^{x}=\textbf{BERT}(w_{0}^{x},w_{1}^{x},...,w_{n}^{x}) || x^{c}=h_{0}^{x},x^{h}=h_{[E_{h}]}^{x},x^{t}=h_{[E_{t}]}^{x}",,"h_{h},h_{t},h_{c}=Encoder(x)","\(\mathbf{h}_{h}\), \(\mathbf{h}_{t}\), and \(\mathbf{h}_{c}\) denote the hidden representations of the head entity, tail entity, and context, respectively, obtained from the encoder."
naacl_2024_short_67,2,x^{vec}=x^{c}\oplus x^{h}\oplus x^{t},where \(d\) is the hidden dimension of the encoder and \(\oplus\) denotes the concatenation operator,x^{vec}=[x^{c}; x^{h}; x^{t}],"The comprehensive representation \(x^{vec}\) is formed by concatenating the contextual, head entity, and tail entity representations."
naacl_2024_short_67,3,"h_{0}^{d},h_{1}^{d},...,h_{n}^{d}=\textbf{BERT}(w_{0}^{d},w_{1}^{d},...,w_{n}^ {d}) || d^{c}=h_{0}^{d} || d^{h}=\textit{WeightPooling}_{1}(h_{1}^{d},...,h_{n}^{d}) || d^{t}=\textit{WeightPooling}_{2}(h_{1}^{d},...,h_{n}^{d}) || d^{vec}=d^{c}\oplus d^{h}\oplus d^{t}",,d^{vec}=d^{c}\oplus d^{h}\oplus d^{t},"where \(d^{c}\), \(d^{h}\), and \(d^{t}\) are the contextual, virtual head entity, and virtual tail entity representations of the relation description, respectively, and \(\oplus\) denotes concatenation."
naacl_2024_short_67,4,"H=(h_{1}^{d},...,h_{n}^{d}) || A=\textit{softmax}(HW+b) || d^{*}=AH",,"\textit{WeightPooling}(h_{1},...,h_{n})=\sum_{i=1}^{n}\alpha_{i} h_{i},\quad\alpha_{i}=\frac{\exp(w^{\top}\tanh(h_{i}))}{\sum_{j=1}^{n}\exp(w^{\top}\tanh(h_{j}))}",where \(w\) is a learnable parameter vector and \(\alpha_{i}\) denotes the attention weight for the \(i\)-th token.
naacl_2024_short_67,5,"L_{i}=-\log\frac{e^{sim(x_{i}^{vec},d_{i}^{vec})/\tau}}{\sum_ {j=1}^{N}e^{sim(x_{i}^{vec},d_{j}^{vec})/\tau}}",where \(\tau\) is a temperature hyperparameter and \(\text{sim}(\cdot)\) is the cosine similarity,"L_{con}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{\exp(sim(x_{i}^{vec}, d_{i}^{vec})/\tau)}{\sum_{j=1}^{N}\exp(sim(x_{i}^{vec}, d_{j}^{vec})/\tau)}","where \(\text{sim}(\cdot, \cdot)\) denotes cosine similarity and \(\tau\) is a temperature hyperparameter."
naacl_2024_short_67,6,O_{i}=\textit{Pooling}(BERT(\langle x\oplus d_{j}\rangle)) || \hat{y}=\textit{MLP}(O_{0}\oplus O_{1}\oplus...O_{k}) || L_{c}=-log(\frac{e^{\hat{y}_{+}}}{\sum_{i=1}^{k}e^{\hat{y}_{i}}}),,"P(d_{i}|x,D)=\frac{\exp(f(x,d_{i}))}{\sum_{j=1}^{k}\exp(f(x,d_{j}))}","where \(f(x,d_{i})\) denotes the matching score between input instance \(x\) and relation description \(d_{i}\)."
naacl_2024_short_69,1,ATE=E[Y^{a=1}-Y^{a=0}],,ATE=E[Y^{a=1}]-E[Y^{a=0}],The average treatment effect (ATE) is defined as the difference in expected outcomes under treatment (\(A=1\)) and control (\(A=0\)).
naacl_2024_short_69,2,A=a\\Rightarrow\Y^{a}=Y,,Y=Y^{a}\quadif  A=a,Consistency: the observed outcome equals the counterfactual outcome under the received treatment.
naacl_2024_short_69,3,"Y^{a}\perp A\mid C\quad\forall a\in\{0,1\}",,Y^{a}\perp\!\!\!\perp A\mid C,Conditional exchangeability states that the counterfactual outcome \(Y^a\) is independent of the treatment \(A\) given the confounders \(C\).
naacl_2024_short_69,4,"E[Y^{a}]=\sum_{C}E[Y^{a}\mid C]P(C) || \overset{\eqref{eq:constraint}}{=}\sum_{C}E[Y^{a}\mid A=a,C]P(C)",,"E[Y^{a}]=E_{C}\left[E[Y\mid A=a, C]\right]",The expected counterfactual outcome under treatment \(a\) is the expectation over confounders \(C\) of the conditional expectation of \(Y\) given \(A=a\) and \(C\).
naacl_2024_short_69,5,"\overset{\eqref{eq:constraint}}{=}\sum_{C}E[Y\mid A=a,C]P(C)",,"E[Y^{a}]=\sum_{C}E[Y\mid A=a, C]P(C)","Counterfactual mean outcome under treatment \(a\) is computed as the expectation of \(Y\) given \(A=a\) and \(C\), averaged over the distribution of \(C\)."
naacl_2024_short_69,6,E[Y^{a}]=\frac{1}{N}\sum_{i\in[N]}Y_{i}\frac{\mathds{1}(A_{i}=a)}{P(A_{i}=a\mid T)},,E[Y^{a}]=\frac{1}{N}\sum_{i=1}^{N}\frac{I(A_i=a) Y_i}{P(A_i=a\mid T_i)},"The expected counterfactual outcome under treatment \(a\) is estimated using inverse propensity of treatment weighting (IPTW), where each observed outcome is weighted by the inverse probability of receiving the observed treatment given the text representation."
naacl_2024_short_7,1,"\underset{\theta}{min}\,E_{S^{i}}[\frac{1}{k+1}\sum_{i=0}^{k}l( M_{\theta}(S^{i}),f(x_{i+1}))]",,"L=E_{x_{1:i+1}\simD_x,\, f\simF}\left[\left( M_{\theta}(S^i)-f(x_{i+1})\right)^2\right]","The loss $\mathcal{L}$ is the expected squared error between the model prediction $M_{\theta}(S^i)$ and the ground-truth $f(x_{i+1})$, averaged over samples from the input distribution and function class."
naacl_2024_short_7,2,"f(x)=\varphi(\langle x,w\rangle)",,"f(x)=h(\langle w, x\rangle)","Here, \(f(x)\) is defined as a single-index function where \(h\) is a nonlinear function and \(w\) is a weight vector."
naacl_2024_short_7,3,\varphi_{linear}(t)=t || \varphi_{quadratic}(t)=\frac{1}{\sqrt{2}}(t+\frac{1}{\sqrt{2}}(t^{2}-1)) || \varphi_{cubic}(t)=\frac{1}{\sqrt{3}}(t+\frac{1}{\sqrt{ 2}}(t^{2}-1)+\frac{1}{\sqrt{6}}(t^{3}-3t)),,\varphi_{linear}(t) &=t\\\varphi_{quadratic}(t) &=\frac{1}{\sqrt{2}}(t^2-1)\\\varphi_{cubic}(t) &=\frac{1}{\sqrt{6}}(t^3-3t),"Definitions of the linear, quadratic, and cubic normalized probabilist's Hermite polynomial functions used as function classes."
naacl_2024_short_7,4,f\simF_{1}&1\leq t<\frac{T}{3}\\F_{2}&\frac{T}{3}\leq t<\frac{2T}{3}\\F_{3}&\frac{2T}{3}\leq t<T,,I_k=\left\{ t\;\middle|\;\left\lfloor\frac{(k-1)T}{K}\right\rfloor < t\leq\left\lfloor\frac{kT}{K}\right\rfloor\right\},\(\mathcal{I}_k\) denotes the set of training steps allocated to the \(k\)-th function class in the sequential curriculum.
naacl_2024_short_7,5,f\simF_{1}&1\leq t<\frac{T}{3}\\\sum_{s=1}^{2}1(\xi=s)F_{s}&\frac{T}{3}\leq t<\frac{2T}{3}\\\sum_{s=1}^{3}1(\zeta=s)F_{s}&\frac{2T}{3}\leq t<T,,f\simF_{\xi} & 1\leq t <\frac{2T}{3}\\F_{\zeta} &\frac{2T}{3}\leq t < T,"In the mixed curriculum, for the first two-thirds of training, the function class is randomly chosen from the first two classes, and for the final third, it is randomly chosen from all three classes."
naacl_2024_short_7,6,"f\sim\sum_{s=1}^{3}1(\zeta=s)F_{s},\quad 1\leq t<T",,f\sim\sum_{k=1}^{K}\frac{1}{K}F_{k},"At each training step, the function class \(f\) is sampled uniformly at random from the \(K\) available function classes \(\mathcal{F}_k\)."
naacl_2024_short_8,1,"s_{m}(q,d)=T_{\texttt{[CLS]}}W+b","where \(T_{\texttt{[CLS]}}\in\mathbf{R}^{D}\) is the [CLS] representation on the final layer, and \(W\in\mathbf{R}^{D\times 1}\) and \(b\in\mathbf{R}\) are the weight and bias for classification","s_{q,d}=w^\toph_{[CLS]}","The relevance score \(s_{q,d}\) is computed as the dot product between a learned weight vector \(\mathbf{w}\) and the [CLS] token representation \(\mathbf{h}_{\text{[CLS]}}\) from the final BERT layer."
naacl_2024_short_8,2,"s_{m}(q,d)=\frac{1}{n}\sum_{i}^{n}(T_{tok_{i}}W+b)","where \(T_{tok_{i}}\) is the final-layer representation of the \(i\)-th token, and \(n\) is the total number of tokens in the input sequence","s_{m}^{mean}(q,d)=\frac{1}{L}\sum_{i=1}^{L} T_i W+b","where \(T_i \in \mathbf{R}^D\) is the representation of the \(i\)-th token in the final layer, \(L\) is the total number of tokens, and \(W\) and \(b\) are the weight and bias for classification as in Eq. (1)."
naacl_2024_short_8,3,v_{q_{i}}=T_{q_{i}}W+b;\quad v_{d_{j}}=T_{d_{j}}W+b,"where \(q_{i}\) and \(d_{j}\) represent the \(i\)-th token of query \(q\) and the \(j\)-th token of document \(d\), respectively","h_{q_{i}}, h_{d_{j}}=BERT(q, d)","where \(h_{q_{i}}\) and \(h_{d_{j}}\) are the final-layer representations of the \(i\)-th query token and the \(j\)-th document token, respectively, obtained from BERT."
naacl_2024_short_8,4,"s_{l}(q,d)=\sum_{q_{i}}\max_{d_{j}}(v_{q_{i}}^{T}v_{d_{j}})",,"s_{l}(q,d)=\sum_{i=1}^{|q|}\max_{j=1,\ldots,|d|}(v_{q_{i}}^{\top}v_{d_{j}})","where \(|q|\) and \(|d|\) are the number of tokens in the query and document, respectively, and \(v_{q_{i}}\) and \(v_{d_{j}}\) are the projected representations of the \(i\)-th query token and \(j\)-th document token."
naacl_2024_short_8,5,"L=lce(s_{m}(q,d^{+}),s_{m}(q,d_{1}^{-}),...,s_{m}(q,d_{n}^ {-})) || +lce(s_{l}(q,d^{+}),s_{l}(q,d_{1}^{-}),...,s_{l}(q,d_{n}^ {-}))",,"L_{LCE}=-\log\frac{\exp(s(q, d^+))}{\exp(s(q, d^+))+\sum_{d^-}\exp(s(q, d^-))}","where \(s(q, d^+)\) is the score for the positive document and \(s(q, d^-)\) are the scores for negative documents."
naacl_2024_short_9,1,"L_{ir}(q,p_{i})=-\log(\frac{e^{q\cdot p_{t}}}{\sum_{i=1}^{N}e^{q\cdot p_{ i}}})",,L=-\log\frac{\exp(q\cdot p_{t})}{\sum_{i=1}^{N}\exp(q\cdot p_{i})},"\(\mathcal{L}\) is the negative log-likelihood loss for a query and its gold passage, where \(q\) is the query embedding, \(p_t\) is the gold passage embedding, and \(p_i\) are the embeddings of all passages in the batch."
naacl_2024_short_9,2,"L_{c}(q_{s},q_{t})=-\log(\frac{e^{q_{s}\cdot q_{t}}}{\sum_{j=1}^{N}e^{q_ {s}\cdot q_{j}}})",,"L_{c}(q_{s}, q_{j})=-\log\left(\frac{e^{q_{s}\cdot q_{t}}}{\sum_{j=1}^{N} e^{q_{s}\cdot q_{j}}}\right)",Contrastive loss aligning the English query embedding \(q_{s}\) with its code-mixed counterpart \(q_{t}\) among all code-mixed queries \(q_{j}\) in the batch.
naacl_2024_short_9,3,L=L_{ir}+wL_{c},where \(w\) is a hyperparameter for weighting the contrastive loss,L=L_{ir}+\lambda L_{c},"The total training loss \(L\) is the sum of the IR loss \(L_{ir}\) and the contrastive loss \(L_{c}\), weighted by a hyperparameter \(\lambda\)."
neurips_2024_oral_10,1,"q(x_{1:T}|x_{0})\coloneqq\prod_{t=1}^{T}q(x_{t}|x_{t-1}) || q(x_{t}|x_{t-1})\coloneqqN(x_{t};\sqrt{1-\beta_{t}}x _{t-1},\beta_{t}I)",,"x_t=\sqrt{\alpha_t}x_0+\sqrt{1-\alpha_t}\epsilon,\quad\epsilon\simN(0,I)",$\mathbf{x}_t$ denotes the noisy feature at timestep $t$ obtained by adding Gaussian noise $\mathbf{\epsilon}$ to the clean feature $\mathbf{x}_0$ with variance controlled by $\alpha_t$.
neurips_2024_oral_10,2,"p_{\theta}(x_{0:T})\coloneqq p(x_{T})\prod_{t=1}^{T}p_{\theta}(x_{t-1}|x_{t}) || p_{\theta}(x_{t-1}|x_{t})\coloneqqN(x_{t-1};\mu_{\theta}(x_{t },t),\Sigma_{\theta}(x_{t},t))",,p_{\theta}(x_{0:T})=p(x_T)\prod_{t=1}^{T} p_{\theta}(x_{t-1}|x_t),"The reverse process models the denoising of features through a parameterized Markov chain, starting from pure noise and iteratively reconstructing cleaner features."
neurips_2024_oral_10,3,"X_{t-1}=\frac{1}{\sqrt{a_{t}}}(X_{t}-\frac{1-a_{t}}{\sqrt{1-\tilde{a_{t}}}}D_{\theta}(X_{t},t))+\sigma_{t}z","where \(a_{t}=1-\beta_{t}\), \(D_{\theta}\) are the parameters of the prediction noise network",W_{fused}=W_{embed}+W_{denoise},The fused weight matrix $\mathbf{W}_{\text{fused}}$ is obtained by summing the embedding layer weights $\mathbf{W}_{\text{embed}}$ and the denoising layer weights $\mathbf{W}_{\text{denoise}}$.
neurips_2024_oral_10,4,Y&=WX+b\\\frac{1}{\sqrt{a_{t}}}X_{t}-X_{t-1}&=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}D_{\theta}X_{t}-\sigma_{t}z\\\frac{1}{\sqrt{a_{t}}}Y_{t}-Y_{t-1}&=\frac{1-a_{t} }{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}D_{\theta}Y_{t}-\sigma_{t}z,,W_{fused}=W_{embed}+W_{denoise},"where \(W_{\text{embed}}\) and \(W_{\text{denoise}}\) are the weight matrices of the embedding and denoising layers, respectively, and \(W_{\text{fused}}\) is the fused weight matrix used during inference."
neurips_2024_oral_10,5,"Y_{t-1}=[W-C_{1}(t)WW_{D}]X_{t}+WC_{2}(t)C_{3}+b\\C_{1}(t)=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}\qquad C _{2}(t)=\frac{1-a_{t-1}^{-}}{1-\tilde{a_{t}}}\beta_{t}\qquad C_{3}=Z\sim N(0,I)","where \(W_{D}\) denotes the parameters of \(D_{\theta}(X_{t},t)\), \(X_{t}\) denotes the input of this linear layer, \(Y_{t}\) denotes the output of this linear layer, and \(Y_{t-1}\) denotes the result after denoising in one step of \(Y_{t}\)",\frac{1}{\sqrt{a_{t}}}(WX_{t}+b)-Y_{t-1}=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}D_{\theta}(WX_{t}+b)-\sigma_{t}z,This equation expresses the denoising update in the fused feature space after applying the linear transformation \(W\) and bias \(b\).
neurips_2024_oral_10,6,\frac{1}{\sqrt{a_{t}}}Y_{t}-Y_{t-1}=C_{1}(t)D_{\theta}Y_{t}-\sigma_{t}z || \frac{1}{\sqrt{a_{t-1}}}Y_{t-1}-Y_{t-2}=C_{1}(t-1)D_{\theta}Y_{t-1}-\sigma_{t-1}z,,Y_{t-2}=[W-C_1(t) W W_D-C_1(t-1) W W_D] X_t+W [C_2(t) C_3+C_2(t-1) C_3']+b,"where \(C_1(t)\), \(C_2(t)\), and \(C_3\) are as defined previously, and \(C_3'\) is an independent noise sample drawn from \(N(0, I)\) for the second denoising step."
neurips_2024_oral_10,7,Y_{t-2}=W^{\prime\prime}X_{t}+C^{\prime\prime}\\W^{\prime\prime}=\frac{1}{\sqrt{a_{t}-1}}\{\frac{W}{\sqrt{a_{t} }}-[C_{1}(t)+C_{1}(t-1)]WW_{D}+\sqrt{a_{t}}C_{1}(t-1)C_{1}(t)WW_{D}W_{D}\}\\C^{\prime\prime}=\frac{1}{\sqrt{a_{t}-1}}[WC_{2}(t)+\sqrt{a_{t}}WC_{ 2}(t-1)-\sqrt{a_{t}}C_{1}(t-1)C_{2}(t)WW_{D}]Z+b,,Y_{t-2}=[W-C_{1}(t) W W_{D}-C_{1}(t-1) W W_{D}] X_{t}+W [C_{2}(t) C_{3}+C_{2}(t-1) C_{3}']+b,"where \(C_{3}' = Z' \sim N(0, I)\) is an independent standard normal noise for the second denoising step."
neurips_2024_oral_10,8,"Loss_{p}=\sum_{i=1}^{N}|\epsilon_{i}-D_{\theta_{i}}(X_{t_{i}},t_{i})|","where \(\epsilon\) denotes the sampled noise, \(N\) denotes the number of denoising layers, \(X_{t}\) denotes the noise sample, \(t\) denotes the diffusion step, and \(D_{\theta}(X_{t},t)\) denotes the noise predicted by the denoising layer","L_{p}=E_{t,x_0,z}\left[\left\|z-D_{\theta}(\sqrt{\bar{a}_t}x_0+\sqrt{1-\bar{a}_t}z, t)\right\|^2\right]",The denoising loss $\mathcal{L}_{p}$ measures the mean squared error between the true noise $\mathbf{z}$ and the predicted noise by $D_{\theta}$ at each diffusion timestep $t$.
neurips_2024_oral_10,9,Loss=(1-\lambda)Loss_{l}+\lambda Loss_{p},,Loss=Loss_{p}+\lambda Loss_{l},"The total loss combines the unsupervised denoising loss \(Loss_{p}\) and the supervised task-specific loss \(Loss_{l}\), balanced by the trade-off parameter \(\lambda\)."
neurips_2024_oral_11,1,"sim(f,g)=\int_{x\in D(f)}\frac{\mathds{1}[f(x)=g(x)]}{|D(f)|}\\\approx\sum_{x\in X|X\sim D(f)}\frac{\mathds{1}[f(x)=g(x)]}{|X|}",,"sim(f, g)=E_{x\sim D(f)}\left[I\left( f(x)=g(x)\right)\right]",The similarity between functions \(f\) and \(g\) is defined as the expected indicator of their outputs being identical over the input domain.
neurips_2024_oral_11,2,"f^{*}=\textsc{FunConsensus}(F)=\operatorname*{arg\,max}_{f_{(i)}\in F}\sum_{ f_{(j)}\in F\setminus\{f_{(i)}\}}sim(f_{(i)},f_{(j)})",,"f^{*}=\arg\max_{f\in F}\sum_{g\in F,\, g\neq f} sim(f, g)",The consensus function \(f^{*}\) is the one that maximizes the sum of similarities with all other candidate functions in the set \(F\).
neurips_2024_oral_12,1,"P(X_{1},\ldots,X_{d})=\prod_{i=1}^{d}P(X_{i}\midPA_{i})",,"P(X_{1},\ldots, X_{d})=\prod_{j=1}^{d} P(X_{j}\midPA_{j})",The joint distribution over observed variables factorizes as the product of conditional distributions of each variable given its parents in the causal graph.
neurips_2024_oral_12,2,"P(X_{1},\ldots,X_{d}|do(X=x))=\prod_{i:X_{i}\not\inX }P(X_{i}|PA_{i})\big{|}_{X=x}","where \(|_{\mathbf{X}=\mathbf{x}}\) enforces \(X_{1},\ldots,X_{d}\) to be consistent with realizations of \(\mathbf{X}\) else Eq",P(y\mid do(x))=\sum_{z}\prod_{i=1}^{d} P(x_i\midpa_i),The interventional distribution \(P(\mathbf{y} \mid do(\mathbf{x}))\) is computed by replacing the structural assignments for \(\mathbf{X}\) with fixed values \(\mathbf{x}\) and summing over the remaining variables.
neurips_2024_oral_12,3,"P(X_{\sigma(1)},\ldots,X_{\sigma(N)})=P(X_{1},\ldots,X_{N})",,"P(X_{1}, X_{2},\ldots, X_{N})=P(X_{\sigma(1)}, X_{\sigma(2)},\ldots, X_{\sigma(N)})","where \(\sigma\) is any finite permutation of the indices \(\{1,\ldots,N\}\)."
neurips_2024_oral_12,4,"P(X_{::[N]}=x_{:,[N]})=\int\int\prod_{n=1}^{N}\prod_{i=1}^{ d}p(x_{i;n}\mida_{i;n}^{G},\theta_{i})d\nu_{1}(\theta_{1})\ldots d\nu_{d}(\theta_{d})",,"P(X_{::1},\ldots,X_{::N})=\int\prod_{n=1}^{N}\prod_{i=1}^{d} P(X_{i;[n]}\midPA_{i;[n]},\theta_{i})\, dP(\theta_{1},\ldots,\theta_{d})",where \(\theta_{i}\) are latent parameters governing the causal mechanisms for each variable \(X_{i}\).
neurips_2024_oral_12,5,"P(Y=y|do(X=x))=p(y|x,\psi_{0})=P(Y=y|x),\psi_{0}\inR",,"P(X,Y|do(X=x))=\int p(y|\psi)\, d\nu(\psi)","This equation expresses the post-intervention distribution of \(Y\) after setting \(X=x\) in an i.i.d. generative process, integrating over the parameter \(\psi\) with respect to its measure \(\nu\)."
neurips_2024_oral_12,6,"P(Y=y|do(X=x))=\int p(y|x,\psi)p(\psi)d\psi=P(Y=y|x)",,"P(Y_{n}=y\mid do(X_{n}=x))=\int p(y\mid x,\psi)\, d\nu(\psi)","The causal effect of intervening on \(X_{n}\) in an ICM generative process is given by integrating the conditional density \(p(y\mid x, \psi)\) over the mixing measure \(\nu(\psi)\)."
neurips_2024_oral_12,7,"\textbf{i.i.d. generative process}:P(X_{1},Y_{1},\ldots,X_{N},Y_{N})\stackrel{{ ind}}{{=}}\prod_{n=1}^{N}P(X_{n},Y_{n})\stackrel{{ idc}}{{=}}[P(X,Y)]^{N}",,"P((Y_{1},\ldots,Y_{N})=(y_{1},\ldots,y_{N})\mid do((X_{1},\ldots,X_{N})=(x_{1},\ldots,x_{N})))=\int\prod_{n=1}^{N} p(y_{n}\mid x_{n},\psi) p(\psi) d\psi","The joint interventional distribution of the sequence \((Y_{1},\ldots,Y_{N})\) given interventions on \((X_{1},\ldots,X_{N})\) in an ICM generative process is obtained by integrating over the causal de Finetti parameter \(\psi\)."
neurips_2024_oral_12,8,"\textbf{ICM gen. process}:P(x_{1},y_{1},\ldots,x_{N},y_{N})=\int\int\prod_{n=1} ^{N}p(y_{n}|x_{n},\psi)p(x_{n}|\theta)d\mu(\theta)d\nu(\psi)",,"\textbf{ICM generative process}: P(X_{1}, Y_{1},\ldots, X_{N}, Y_{N})=\int\int\prod_{n=1}^{N} p(x_{n}\mid\theta) p(y_{n}\mid x_{n},\psi) d\nu_{1}(\theta) d\nu_{2}(\psi)","The joint distribution of a sequence of bivariate observations under an ICM generative process is represented as a mixture over latent parameters, with each observation generated conditionally independently given these parameters."
neurips_2024_oral_12,9,"P(X_{J;n}\mid do(X_{I;n}=x))=P(X_{J;m}\mid do (X_{I;m}=x)),\forall n\neq m",,"P(X_{J;n}\mid do(X_{I;n}=x_{I}))=P(X_{J;m}\mid do(X_{I;m}=x_{I})),\quad\forall n\neq m",The marginal post-interventional distribution of any subset of variables at position \(n\) is identical to that at position \(m\) under identical interventions in an ICM generative process.
neurips_2024_oral_12,10,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=P(y_{1}|\hat{x})P(y_{2}|x_{2})P(x _{2})1_{x_{1}=\hat{x}}",,"P(X_{1},Y_{1},X_{2},Y_{2}\mid do(X_{1}=\hat{x}))=\delta(X_{1}=\hat{x})\int\int p(y_{1}\mid x_{1},\psi)p(x_{2}\mid\theta)p(y_{2}\mid x_{2},\psi)d\mu(\theta)d\nu(\psi)",The post-interventional joint distribution under an ICM generative process after intervening on \(X_{1}\) by setting it to \(\hat{x}\).
neurips_2024_oral_12,11,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=\int p(y_{1}|\hat{x},\psi)p(y_{2 }|x_{2},\psi)p(\psi)d\psi p(x_{2})1_{x_{1}=\hat{x}}",,"P(x_{1},y_{1},x_{2},y_{2}\mid do(X_{1}=\hat{x}))=\int\int p(y_{1}\mid\hat{x},\psi) p(y_{2}\mid x_{2},\psi) p(x_{2}\mid\theta) d\mu(\theta) d\nu(\psi)\,1_{x_{1}=\hat{x}}","where the post-interventional joint distribution in the ICM generative process is computed by integrating over the causal de Finetti parameters \(\theta\) and \(\psi\), with the intervention enforced by the indicator \(\mathbb{1}_{x_{1}=\hat{x}}\)."
neurips_2024_oral_12,12,"p(x_{:,1},\ldots,x_{:,N}|do(X=\hat{x}))=\prod_{i\in I_{X}}p(x_{i;[-N_{i}]}|pa_{i;[-N_{i}]}^{G})\prod_{i\not\in I_{ X}}p(x_{i;[N]}|pa_{i;[N]}^{G})\big{|}_{X=\hat{x}}",,"p(x_{1},\ldots,x_{N}\mid do(X_{I;n}=\hat{x}))=\int\prod_{n=1}^{N}\left[\prod_{i\notinI} p(x_{i;n}\mida_{i;n}^{G},\theta_i)\right]\prod_{i\inI}1_{x_{i;n}=\hat{x}_{i;n}}\prod_{i=1}^{d} d\nu_{i}(\theta_i)","where \(\mathbf{I}\) is the set of intervened variable indices, \(\hat{\mathbf{x}}\) is the set of intervention values, \(\boldsymbol{a}_{i;n}^{\mathcal{G}}\) denotes the parents of \(X_{i;n}\) in graph \(\mathcal{G}\), and \(\nu_{i}\) is the measure over the de Finetti parameter \(\boldsymbol{\theta}_i\)."
neurips_2024_oral_12,13,"P(X_{\negI;n}|do(X_{I;n}=\hat{x} ),X_{\negS})=\prod_{i\not\inI}P(X_{i;n}|X_{i;S},PA_{i;S\cup\{n\}})|_{ X_{I;n}=\hat{x}}",,"P(X_{[\negI];n}\mid do(X_{I;n}=x),X_{:;S})=P(X_{[\negI];n}\midX_{I;n}=x,X_{:;S})",The conditional post-interventional distribution of non-intervened variables at position \(n\) given an intervention on variables \(\mathbf{X}_{\mathbf{I};n}\) and observations at positions \(\mathbf{S}\) equals the corresponding observational conditional distribution.
neurips_2024_oral_12,14,"\int\int\prod_{n}p(y_{n}\mid x_{n},\psi)p(x_{n}\mid\theta)p(\theta)p(\psi)d\theta d\psi","where \(p(\theta),p(\psi)\) are Beta distributions and \(p(y_{n}\mid x_{n},\psi),p(x_{n}\mid\theta)\) are Bernoulli distributions","P(x_{1},y_{1},\ldots,x_{n},y_{n})=\int\int\prod_{i=1}^{n} p(y_{i}|x_{i},\psi) p(x_{i}|\theta) d\mu(\theta) d\nu(\psi)","The joint distribution of the observed sequence in the causal Polya urn model is represented as a mixture over latent parameters, with each observation generated conditionally independently given these parameters."
neurips_2024_oral_13,1,"X_{q}=clamp(\,\lfloor\frac{X}{\Delta}\rceil\!+\!z,0,2^{b}-1),where \Delta=\frac{\max(X)-\min(X)}{2^{b}-1},z=-\lfloor\frac{\min(X)}{\Delta}\rfloor",,X_{q}=round\left(\frac{X}{s}\right),\(\mathbf{X}_{q}\) is the quantized integer tensor obtained by dividing the FP16 tensor \(\mathbf{X}\) by the quantization scale \(s\) and rounding to the nearest integer.
neurips_2024_oral_13,2,"R^{1}=E_{d^{(1)}}\hat{R}QE_{d^{(1)}},\qquadQ=1&Q\\O&Q^{\prime}\!",,\hat{R}=I-2uu^{\top},"\(\hat{\mathbf{R}}\) is the constructed Householder reflection matrix, where \(\mathbf{u}\) is a unit vector designed to reflect the feature dimension with the largest outlier."
neurips_2024_oral_13,3,"\hat{R}= BlockDiag(\hat{R}_{b_{1}},...,\hat{R}_{b_{K}})","where \(\hat{\mathbf{R}}_{b_{i}}\in\mathbb{R}^{2^{n}\times 2^{n}}\) denotes a square matrix of the \(i\)-th block, which is constructed following the three steps mentioned above","\hat{R}\approxdiag(R_1,R_2,\ldots,R_K)",The approximated rotation matrix \(\hat{\mathbf{R}}\) is represented as a block-diagonal matrix composed of smaller orthogonal blocks \(\mathbf{R}_k\).
neurips_2024_oral_13,4,"Var([M_{b_{1}},M_{b_{2}},...,M_{b_{K}}])",,"Var=\frac{1}{K}\sum_{i=1}^{K} (M_{b_{i}}-\bar{M})^{2},\qquad\bar{M}=\frac{1}{K}\sum_{i=1}^{K} M_{b_{i}}","where \(M_{b_{i}}\) is the mean of the largest outlier magnitudes in block \(i\), and \(\bar{M}\) is the average of these means across all \(K\) blocks."
neurips_2024_oral_13,5,Y=X\cdotW=[(X\cdot\underbrace{A^ {-1}}_{G})\hat{R}_{(1)}\cdotP\cdot\hat{R }_{(2)}]\cdot[\underbrace{\hat{R}_{(2)}^{\top}\cdotP^{\top}\cdot\hat{R}_{(1)}^{\top}(A}_{G^{-1}}\cdotW)],"where the notation \(\mathbf{P}\) denotes the orthogonal permutation matrix learned via the zigzag manner, the \(\hat{\mathbf{R}}_{(1)}\) and \(\hat{\mathbf{R}}_{(2)}\) represent the first and second block-diagonal rotation matrix, respectively",Y=\left(\left(X\Lambda^{-1}\hat{R}P\hat{R}\right)\cdot\left(\hat{R}^{\top}P^{\top}\hat{R}^{\top}\LambdaW\right)\right),"The DuQuant linear layer applies, in sequence, smoothing (\(\mathbf{\Lambda}\)), block-diagonal rotation (\(\hat{\mathbf{R}}\)), zigzag permutation (\(\mathbf{P}\)), and a second rotation (\(\hat{\mathbf{R}}\)), to both activations and weights for outlier mitigation."
neurips_2024_oral_13,6,\max_{1\leq j\leq 2^{n}}\O_{j}(X_{b_{i}}\hat{R}_{b_{i}})\leq\max_{1\leq j\leq 2^{n}}\O_{j}(X_{b_{i}}),,\max_{j} O_{j}(X\hat{R}_{b_{i}})\leq\max_{j} O_{j}(X),The maximum outlier in each block after applying the constructed rotation matrix \(\hat{\mathbf{R}}_{b_{i}}\) is no greater than the maximum outlier before rotation.
neurips_2024_oral_13,7,"M_{b_{i}}\leq O^{(1)}+\frac{(2^{n}K-1)(2^{n-1}-1)}{2^{n}}\delta,\qquad i=1,2, 3,...,K",,\max_{1\leq i\leq K}\M_{b_{i}}-\min_{1\leq i\leq K}\M_{b_{i}}\leq\delta,"where \(\delta\) is the maximum difference between consecutive reordered outliers, and \(M_{b_{i}}\) is the mean outlier value in the \(i\)-th block after zigzag permutation."
neurips_2024_oral_15,1,"\forall x\inX\colonP[c_{x }=1]=\frac{1}{1+\exp(-2ax^{\top}\theta^{*})},\\E[c_{x}]=\tanh(ax^{\top}\theta^{*})\\V[c_{x}]=1-\tanh^{2}(ax^{\top}\theta^{*}),\\E[t_{x}]=\frac{a}{x^{\top}\theta^{*}}\tanh(ax^ {\top}\theta^{*})&if x^{\top}\theta^{*}\neq 0\\a^{2}&if x^{\top}\theta^{*}=0",,"P(c_{x}=1) &=\frac{1-\exp\left(-2a\, x^{\top}\theta^{*}\right)}{1-\exp\left(-2a\, x^{\top}\theta^{*}\right)+\exp\left(-2a\, x^{\top}\theta^{*}\right)}\\E[c_{x}] &=\tanh\left(a\, x^{\top}\theta^{*}\right)\\Var(c_{x}) &=1-\tanh^{2}\left(a\, x^{\top}\theta^{*}\right)\\E[t_{x}] &=\frac{a}{x^{\top}\theta^{*}}\tanh\left(a\, x^{\top}\theta^{*}\right)","These equations give the choice probability, expected choice, choice variance, and expected decision time under the difference-based EZ-Diffusion Model for a query \(x\)."
neurips_2024_oral_15,2,\forall x\inX\colon x^{\top}\frac{\theta^{*}}{a}=\frac{E [c_{x}]}{E[t_{x}]},,"\forall x\inX:\quadE[c_{x}]=\tanh(a x^{\top}\theta^{*}),\quadE[t_{x}]=\frac{a}{x^{\top}\theta^{*}}\tanh(a x^{\top}\theta^{*})\for\x^{\top}\theta^{*}\neq 0","The expected choice and expected decision time for query \(x\) are given by the hyperbolic tangent of the scaled utility difference and its ratio to the utility difference, respectively."
neurips_2024_oral_15,3,"\widehat{\theta}_{CH,DT}\coloneqq(\sum_{x\inX_{ sample}}n_{x}\;xx^{\top})^{-1}\sum_{x\inX_{sample}}n_{x}\;x\;\frac{\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}",,"\widehat{\theta}_{CH,DT}=\arg\min_{\vartheta\inR^d}\sum_{x\inX_{sample}} n_x\left( x^\top\vartheta-\frac{\overline{c}_x}{\overline{t}_x}\right)^2","\(\widehat{\theta}_{\text{CH,DT}}\) is the ordinary least squares estimator of \(\theta^*/a\) using the empirical means of choices \(\overline{c}_x\) and decision times \(\overline{t}_x\) for each query \(x\)."
neurips_2024_oral_15,4,"\widehat{\theta}_{CH}\coloneqq\operatorname*{arg\,max}_{\theta\inR^{d}}\sum_{x\inX_{sample}}\sum_{i=1}^{n_{x}}\log\mu(c_{x,s_{x,i}}\,x^{\top}\theta)",where \(\mu(y)\coloneqq 1/[1+\exp(-y)]\) is the standard logistic function,"\widehat{\theta}_{CH}\coloneqq\arg\max_{\theta\inR^{d}}\sum_{x\inX_{sample}}\sum_{i=1}^{n_{x}}\log\left(\frac{1}{1+\exp(-2a\,x^{\top}\theta)}\right)^{\frac{c_{x,s_{x,i}}+1}{2}}\left(\frac{\exp(-2a\,x^{\top}\theta)}{1+\exp(-2a\,x^{\top}\theta)}\right)^{\frac{1-c_{x,s_{x,i}}}{2}}","\(\widehat{\theta}_{\text{CH}}\) is the maximum likelihood estimate of \(2a\theta^{*}\) based only on observed choices, obtained by logistic regression."
neurips_2024_oral_15,5,"\sqrt{n}\;y^{\top}(\widehat{\theta}_{CHD,n}-\theta^{*}/a)\overset{D}{\longrightarrow}N(0,\zeta^{2}/a^{2})",,"\sqrt{n}\left(y^{\top}\widehat{\theta}_{CH,DT}-y^{\top}\frac{\theta^{*}}{a}\right)\xrightarrow{d}N\left(0,\;y^{\top}\Sigma_{CH,DT}y\right)","The asymptotic distribution of the projected estimation error for the choice-decision-time estimator is normal with mean zero and variance \(y^{\top}\Sigma_{\mathrm{CH,DT}}y\)."
neurips_2024_oral_15,6,\zeta^{2}\leq\|y\|_{(\sum_{x\inX_{sample}} [\min_{x^{\prime}\inX_{sample}}E[t_{x^{\prime}}]]\cdot xx^{\top})^{-1}}^{-1},,"\zeta^{2}\leq\frac{y^{\top}\left(\sum_{x\inX_{sample}}xx^{\top}\right)^{-1}y}{\left(\sum_{x\inX_{sample}}y^{\top}x\,\frac{E[c_{x}]}{E[t_{x}]}\right)^{2}}\sum_{x\inX_{sample}} (y^{\top}x)^{2}\frac{V[c_{x}]}{E[t_{x}]^{2}}","where \(\zeta^{2}\) is the asymptotic variance of the choice-decision-time estimator, upper bounded in terms of the query features, expected choices, expected decision times, and choice variances."
neurips_2024_oral_15,7,"\sqrt{n}y^{\top}(\widehat{\theta}_{CH,n}-2a\theta^{*})\overset{D}{\longrightarrow}N(0,4a^{2}\|y\|_{(\sum_{x\inX_{sample}}[a^{2}\,V[c_{x}] ]\cdot xx^{\top})^{-1}}^{-1})",,"\sqrt{n}\;y^{\top}(\widehat{\theta}_{CH,n}-2a\theta^{*})\overset{D}{\longrightarrow}N(0,\xi^{2})",Asymptotic normality of the choice-only estimator: the scaled error in the direction \(y\) converges in distribution to a normal distribution with variance \(\xi^{2}\).
neurips_2024_oral_15,8,"\widehat{u}_{x,CH,DT}\coloneqq\frac{\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}",,"\widehat{u}_{x,CH,DT}\coloneqq\frac{\sum_{i=1}^{n_{x}}c_{x,s_{x},i}}{\sum_{i=1}^{n_{x}}t_{x,s_{x},i}}","where \(\widehat{u}_{x,\text{CH,DT}}\) is the choice-decision-time estimator for the scaled utility difference \(u_{x}/a\) using the empirical sums of choices and decision times for query \(x\)."
neurips_2024_oral_15,9,"\widehat{u}_{x,CH}\coloneqq\mu^{-1}(\frac{1}{n_{x}}\sum_{i=1}^{n _{x}}\frac{c_{x,s_{x,i}}+1}{2})","where \((c_{x,s_{x,i}}+1)/2\) is the binary choice coded as 0 or 1, and \(\mu^{-1}(p)\coloneqq\log\left(p/(1-p)\right)\) is the logit function (inverse of \(\mu\) introduced in eq","\widehat{u}_{x,CH}\coloneqq\frac{1}{2a}\cdot\operatorname*{arg\,max}_{u\inR}\sum_{i=1}^{n_x}\log\mu(c_{x,s_{x,i}}\, u)",where \(\mu(y) = 1/[1+\exp(-y)]\) is the standard logistic function.
neurips_2024_oral_15,10,"P(|\widehat{u}_{x,CH,DT}-\frac{u_{x}}{a}|>\epsilon)\leq 4\exp(-[m_{CH,DT}^{non-axym}(x^{\top}\theta^{*})]^{2}\,n_{x}\,[\epsilon\cdot a]^{2} )",,"P\left[\left|\widehat{u}_{x,CH,DT}-\frac{u_{x}}{a}\right|\geq\epsilon\right]\leq 4\exp\left(-\frac{n_{x}\epsilon^{2}E[t_{x}]^{2}}{8a^{2}E[t_{x}^{2}]}\right)","A non-asymptotic concentration inequality for the choice-decision-time estimator, bounding the probability that the estimator deviates from the true scaled utility difference by more than \(\epsilon\)."
neurips_2024_oral_15,11,"P(|\widehat{u}_{x,CH}-2au_{x}|>\epsilon)\leq 6\exp(-[m_{CH}^{non-asym}(x^{\top}\theta^{*} )]^{2}\,n_{x}\,[\epsilon/(2a)]^{2})",,"P\left(\left|\widehat{u}_{x,CH}-2au_{x}\right|>\epsilon\right)\leq 3\exp\left(-m_{CH}^{non-axym}(x^{\top}\theta^{*})\,n_{x}\,\epsilon^{2}\right)",where \(m_{\text{CH}}^{\text{non-axym}}(x^{\top}\theta^{*})\coloneqq \dot{\mu}(2au_{x})/9\) and \(\dot{\mu}(y)=\frac{e^{-y}}{(1+e^{-y})^{2}}\) is the derivative of the logistic function.
neurips_2024_oral_16,1,"H=GNN(A,X)=\tilde{A}XW^{\prime},h_{i}=\sum_{j\inN_{i}}\alpha_{ij}x_{j}\cdotW^{\prime}=\sum_{j\inN_{i}}\frac{1}{d_{ i}}x_{j}\cdotW^{\prime}","where \(\mathbf{W}^{\prime}=\xi(\mathbf{W}),\mathbf{W}\in\mathbb{R}^{D\times K}\) with \(\xi\) being an activation function like ReLU [22] for ease of understanding, \(\mathcal{N}_{i}\) denotes the set of first-order neighbors of node \(v_{i}\), inclusive of \(v_{i}\) itself",H=\sigma(\hat{A}XW),"The node representation matrix \(\mathbf{H}\) is obtained by applying a nonlinearity \(\sigma\) to the product of the normalized adjacency matrix \(\hat{\mathbf{A}}\), the feature matrix \(\mathbf{X}\), and the learnable weight matrix \(\mathbf{W}\)."
neurips_2024_oral_16,2,"E[h_{i}]&=E [\sum_{j\inN(i)}\alpha_{ij}x_{j}\cdotW^{\prime}]=\sum_{j\inN(i)}\alpha_{ij}E[x_{j}]\cdotW^{\prime}=\sum_{j\inN(i)}\alpha_{ij}\mu_{i}\cdotW^{\prime},\\Var(h_{i})&=Var(\sum_{ j\inN(i)}\alpha_{ij}x_{j}\cdotW^{\prime})=\sum_{j\inN(i)}\alpha_{ij}Var(x_{j})\cdotW ^{\prime 2}=\sigma_{i}^{2}\sum_{j\inN(i)}\alpha_{ij}^{2}\cdotW^{\prime 2}",,"\mu_{i}^{\prime}=E[h_{i}]=\frac{1}{d_{i}}\sum_{j\inN_{i}}\mu_{i},\quad (\sigma_{i}^{\prime})^{2}=Var[h_{i}]=\frac{1}{d_{i}^{2}}\sum_{j\inN_{i}}\sigma_{i}^{2}","where \(\mu_{i}^{\prime}\) and \((\sigma_{i}^{\prime})^{2}\) denote the mean and variance of the aggregated representation \(\mathbf{h}_{i}\) after GNN message passing, respectively."
neurips_2024_oral_16,3,"\tilde{h}_{i}=Trans_{R^{d}\toS^{k}}(h_{i})=\frac{h_{i}}{Max(\|h_{i}\|_{2},\varepsilon)},\quadS^{k}=\{\tilde{h}_{i}:\|\tilde{h }_{i}\|_{2}=1\}","where \(\mathbf{h}_{i}\) is representation for node \(v_{i}\in\mathcal{V}\), generated by the target encoder, \(\|\tilde{\mathbf{h}}_{i}\|_{2}=(\sum_{j=1}^{k}\tilde{\mathbf{h}}_{ij}^{2})^{ \frac{1}{2}}\), and \(\epsilon\) is a small value to avoid division by zero",h_{i}^{S^{k}}=Trans(h_{i})=\frac{h_{i}}{\|h_{i}\|_{2}},where \(\mathbf{h}_{i}^{\mathbb{S}^{k}}\) denotes the representation of node \(v_{i}\) after being transformed into the subspace \(\mathbb{S}^{k}\) via row-wise \(\ell_{2}\) normalization.
neurips_2024_oral_16,4,"L_{scattering}=-\frac{1}{n}\sum\nolimits_{i=1}^{n}\|\tilde{h}_{i}-c\|_{2}^{2},\quadc=\frac{1}{n}\sum\nolimits _{i=1}^{n}\tilde{h}_{i}",,"L_{scattering}=\frac{1}{n}\sum_{i=1}^{n}sim(\tilde{h}_{i},c)","where \(\text{sim}(\cdot, \cdot)\) denotes the cosine similarity, \(\tilde{\mathbf{h}}_{i}\) is the normalized representation of node \(v_{i}\), \(\mathbf{c}\) is the scattered center, and \(n\) is the number of nodes."
neurips_2024_oral_16,5,H_{online}^{topology}=\hat{A}^{k}H_{online}+H_{online},where k represents the order of neighbors and \(\hat{\mathbf{A}}=\mathbf{A}+\mathbf{I}\) is the adjacency matrix with self-loops,H_{online}^{topology}=H_{online}+\hat{A}^{k}H_{online},"where \(\mathbf{H}_{\text{online}}\) is the representation matrix from the online encoder, \(\hat{\mathbf{A}}^{k}\) is the k-th power of the normalized adjacency matrix, and \(\mathbf{H}_{\text{online}}^{\text{topology}}\) is the topology-augmented representation."
neurips_2024_oral_16,6,"L_{alignment}=-\frac{1}{N}\sum_{i=1}^{N}\frac{Z_{(online,i)}^{\top}H_{(target,i)}}{\|Z_{(\text {online},i)}\|\|H_{(target,i)}\|}","where \(\mathbf{Z}_{\text{online}}\) and \(\mathbf{H}_{\text{target}}\) represent the predicted and scattered representations, respectively",L_{alignment}=\frac{1}{n}\sum_{i=1}^{n}\left\|z_{i}^{online}-\tilde{h}_{i}^{target}\right\|_{2}^{2},where \(\mathbf{z}_{i}^{\text{online}}\) is the predicted topology representation for node \(v_{i}\) and \(\tilde{\mathbf{h}}_{i}^{\text{target}}\) is the scattered target representation for node \(v_{i}\).
neurips_2024_oral_16,7,\phiarrow\tau\phi+(1-\tau)\theta,"where \(\tau\) is a target decay rate and \(\tau\in[0,1]\)",\phi\leftarrow\tau\phi+(1-\tau)\theta,"where \(\tau\) is the momentum coefficient, \(\phi\) and \(\theta\) are the parameters of the target and online encoders, respectively, and \(\leftarrow\) denotes parameter update via Exponential Moving Average."
neurips_2024_oral_17,1,"L_{cons}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}H\Big{(}p_{m}(y\mid f_{\theta}(\alpha(x))),p_{m}(y\mid f_{\theta}(A(x)))\Big{)}",,"L_{cons}=E_{x\simD_u}\left[I\left(\max(p_T(x^w))\geq\tau\right)\cdot\ell\left(p_S(x^s),\hat{y}_T(x^w)\right)\right]","The consistency loss $\mathcal{L}_{\text{cons}}$ is computed over unlabeled data $\mathcal{D}_u$, where the student model's prediction on a strongly-augmented sample $x^s$ is supervised by the teacher's pseudo label $\hat{y}_T(x^w)$ for a weakly-augmented sample $x^w$, only if the teacher's confidence exceeds threshold $\tau$."
neurips_2024_oral_17,2,"L_{cons}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}d\Big{(}p_{m}(y\mid f_{\theta}(\alpha(x ))-\Delta\Re),p_{m}(y\mid f_{\theta}(A(x)) )\Big{)}",,\min_{\theta}\E_{x\simD_{U}}\left[\left\|f_{\theta}(\alpha(x))-f_{\theta}(A(x))\right\|_2^2\right],Minimize the expected squared $\ell_2$ distance between teacher and student representations over unlabeled data.
neurips_2024_oral_17,3,"E(\xi;X)=\frac{1}{2}\xi^{\top}\xi-\rm{lse}(X^{\top}\xi,\beta)+c,\quadwith \rm{lse}(v,\beta):=\beta^{-1}\log(\sum_{i=1}^{N}\exp(v_{i}))",,"E(\xi;X)=-\frac{1}{\beta}\log\sum_{i=1}^{N}\exp\left(\beta\,x_i^\top\xi\right)",The energy function \(E(\mathbf{\xi};\mathbf{X})\) quantifies the alignment between a query pattern \(\mathbf{\xi}\) and a set of stored patterns \(\mathbf{X}\) using a softmax-based similarity measure controlled by inverse temperature \(\beta\).
neurips_2024_oral_17,4,\xiarrow\xi-\eta\nabla_{\xi}E(\xi;X)=\xi-\rm{sm}(\beta\xi^{\top}X)X^{\top},,\xi\leftarrow\xi-\nabla_{\xi} E(\xi;X)=\xi-\left(\xi-\sum_{i=1}^{N} p_{i}x_{i}\right)=\sum_{i=1}^{N} p_{i}x_{i},"The state pattern \(\mathbf{\xi}\) is updated by moving it toward the weighted sum of stored patterns \(\mathbf{x}_i\), where the weights \(p_i\) are determined by the similarity between \(\mathbf{\xi}\) and each \(\mathbf{x}_i\)."
neurips_2024_oral_17,5,"E(Q_{s};K_{t})=\frac{\alpha}{2}diag(K_{t}K_{t}^{T})-\sum_{i=1}^{N}\rm{lse}(Q_{s}k_{t,i}^{T},\beta)+c || E(K_{t})=\rm{lse}(\frac{1}{2}diag(K_{t}K_{t}^{T}),1)=\log\sum_{i=1}^{N}\exp(\frac{ 1}{2}k_{t,i}k_{t,i}^{T})+c",,"E(Q_{s};K_{t})=\frac{1}{2}Q_{s}^{\top}Q_{s}-lse(K_{t}^{\top}Q_{s},\beta)+c",The energy function \(E(\mathbf{Q}_{s};\mathbf{K}_{t})\) quantifies the alignment between student queries \(\mathbf{Q}_{s}\) and teacher keys \(\mathbf{K}_{t}\) using a Hopfield-inspired formulation.
neurips_2024_oral_17,6,p(K_{t}|Q_{s})=\frac{p(Q_{s}|K_{t})p(K_{t})}{p(Q_{s})},,K_{t}^{*}=\arg\max_{K_{t}}\log p(K_{t}\midQ_{s})=\arg\min_{K_{t}}\left[ E(Q_{s};K_{t})-\log p(K_{t})\right],The MAP estimate of teacher keys \(\mathbf{K}_{t}\) is obtained by minimizing the sum of the energy function and the negative log prior over \(\mathbf{K}_{t}\) given student queries \(\mathbf{Q}_{s}\).
neurips_2024_oral_17,7,\nabla_{K_{t}}\log p(K_{t}|Q_{s})&=-(\nabla_{K_{t}}E(Q_{s};K_{t})+\nabla_{K_{t}}E(K_{t}))\\&=sm(\betaQ_{s}K_{t}^{T})Q_ {s}-(\alphaI+D(sm(\frac{1}{2}diag(K_{t}K_{t}^{T}))))K_{t},,\nabla_{K_{t}}\log p(K_{t}|Q_{s})=-\nabla_{K_{t}} E(Q_{s};K_{t})-\nabla_{K_{t}} E(K_{t}),The gradient of the log posterior with respect to teacher keys \(\mathbf{K}_{t}\) is given by the negative gradients of the energy functions for the student-teacher interaction and the teacher prior.
neurips_2024_oral_17,8,"K_{t}^{update}=K_{t}+\gamma_{update}[\,(sm(\betaKQ^{T})QW_{K}^{T})-\gamma_{reg }(\alphaI+D(sm(\frac{1}{2}diag (KK^{T})))KW_{K}^{T})\, ]",,K_{t}\leftarrowK_{t}+\eta\left[ sm(\betaQ_{s}K_{t}^{T})Q_{s}-(\alphaI+D(sm(\tfrac{1}{2}diag(K_{t}K_{t}^{T}))))K_{t}\right],The teacher key matrix \(\mathbf{K}_{t}\) is updated by a gradient ascent step that aligns it with student queries while regularizing its energy.
neurips_2024_oral_17,9,L_{rep}^{s}=\frac{1}{|B^{\prime}|}\sum_{i\inB^{\prime}}\frac{1}{|N_{i}|}\sum_{q\inN_{i}}-\log\frac{\exp(z_{i}^{T}z_{q}^{\prime}/\tau_{c})}{\sum_{i^{\prime}\neq i }\exp(z_{i}^{T}z_{i^{\prime}}^{\prime}/\tau_{c})} || L_{rep}^{u}=\frac{1}{|B|}\sum_{i\inB}-\log\frac{\exp(z_{i}^{T}z_{i}^{\prime}/\tau_{u} )}{\sum_{i^{\prime}\neq i}\exp(z_{i}^{T}z_{i^{\prime}}^{\prime}/\tau_ {u})},,"L_{con}=-\frac{1}{|B|}\sum_{i\inB}\log\frac{\exp(sim(z_i,z_i')/\tau)}{\sum_{j\inB}\exp(sim(z_i,z_j')/\tau)}","\(\mathcal{L}_{\text{con}}\) is the contrastive loss, where \(\mathbf{z}_i\) and \(\mathbf{z}_i'\) are representations of two augmented views of the same image, \(\mathrm{sim}(\cdot,\cdot)\) denotes a similarity function (e.g., cosine similarity), and \(\tau\) is a temperature parameter."
neurips_2024_oral_17,10,"L_{cons}=\frac{1}{|B|}\sum_{i\inB }\ell(q^{\prime}_{i},p_{i})-\varepsilon H(\bar{p})&for unlabeled,\\\frac{1}{|B|}\sum_{i\inB}\ell(y_{i},p_{i})&for labeled.",,"\ell(q', p)=-\sum_{k} q'(k)\log p(k)",The cross-entropy loss between the target distribution \(q'\) (pseudo-labels or ground-truth) and the predicted distribution \(p\).
neurips_2024_oral_18,1,G(x)=\exp(-\frac{1}{2}(x-\mu_{0})^{T}\Sigma_{0}^{-1}(x-\mu_{0})),"where \(\Sigma_{0}\) can be factorized as \(\Sigma_{0}=R_{0}S_{0}S_{0}^{T}R_{0}^{T}\), in which \(R_{0}\) is a rotation matrix represented by a quaternion vector \(r_{0}\in\mathbb{R}^{4}\), and \(S_{0}\) is a a diagonal scaling matrix characterized by a 3D vector \(s_{0}\in\mathbb{R}^{3}\)","p=(\mu_{0},\Sigma_{0},\sigma, c)","\(\mathbf{p}\) denotes a 3D Gaussian point parameterized by its center \(\mu_{0}\), covariance \(\Sigma_{0}\), density \(\sigma\), and color \(c\)."
neurips_2024_oral_18,2,"I(u)=\sum_{i\in N}T_{i}\alpha_{i}c_{i},\qquad A(u)=\sum_{i\in N}T_{i}\alpha_{i },\qquad D(u)=\sum_{i\in N}T_{i}\alpha_{i}d_{i}","where \(T_{i}=\prod_{j=1}^{i-1}(1-\alpha_{j})\) is the accumulated transmittance, \(\alpha_{i}\) is the probability of termination at point \(i\), and \(d_{i}\) is the depth of the Gaussian point at the specific view",D(u)=\sum_{i=1}^{N}\alpha_i(u) d_i,"where \(\alpha_i(u)\) is the alpha (opacity) contribution of the \(i\)-th Gaussian at pixel \(u\), and \(d_i\) is the depth value of the \(i\)-th Gaussian."
neurips_2024_oral_18,3,"\mu(t)=\mu_{0}+\sum_{i=1}^{N_{m}}w_{i}(\mu_{0},t)d\mu_{i}(t),\qquad s(t)=s_{0}+\sum_{i=1}^{N_{m}}w_{i}(\mu_{0},t)ds_{i}(t)",,"\mu(t)=\mu_{0}+\sum_{i=1}^{N_{m}} w_{i}(\mu_{0}, t)\, d\mu_{i}(t),\qquad s(t)=s_{0}+\sum_{i=1}^{N_{m}} w_{i}(\mu_{0}, t)\, ds_{i}(t)","where \(\mu(t)\) and \(s(t)\) are the deformed position and scale at time \(t\), \(\mu_{0}\) and \(s_{0}\) are the canonical position and scale, \(w_{i}(\mu_{0}, t)\) are the motion coefficients, and \(d\mu_{i}(t)\), \(ds_{i}(t)\) are the deformation bases for position and scale, respectively."
neurips_2024_oral_18,4,"L_{gs}=L_{1}(I,\tilde{I})+\lambda_{1}L_{ssim}(I,\tilde{I})+\lambda_{2}L_{1}(s(t))",where \(\lambda_{1}\) and \(\lambda_{2}\) are balancing hyperparameters,"L=\lambda_{1}\|I-\tilde{I}\|_{1}+\lambda_{2}\left(1-SSIM(I,\tilde{I})\right)+\lambda_{3}\|s-\tilde{s}\|_{1}","where \(\lambda_{1}\), \(\lambda_{2}\), and \(\lambda_{3}\) are weighting coefficients, \(I\) and \(\tilde{I}\) are the rendered and ground truth images, \(s\) and \(\tilde{s}\) are the predicted and ground truth scale attributes, and SSIM denotes the Structural Similarity Index Measure."
neurips_2024_oral_18,5,"P_{\tilde{P}}=\{(\tilde{p},s_{\Delta x},\sigma_{F})\}","where \(\tilde{p}\in\tilde{P}\), \(s_{\Delta x}=\Delta x/2^{n_{u}}\), and \(\sigma_{F}=F[Discretize(\tilde{p})]\) (we neglect \(t\) in the notation for simplicity)","P(t)=\{(p_{i}(t),s_{i}(t),\sigma_{i}(t))\}_{i=1}^{N_{p}}","where \(p_{i}(t)\) is the position, \(s_{i}(t)\) is the scale, and \(\sigma_{i}(t)\) is the density of the \(i\)-th continuum particle at time \(t\), and \(N_{p}\) is the total number of particles."
neurips_2024_oral_18,6,"L_{ppe}=\frac{1}{m}\sum_{i=1}^{m}[L_{CD}(S(t_{i}),\tilde{S} (t_{i}))+\frac{1}{n}\sum_{j=1}^{n}L_{1}(A_{j}(t_{i}),\bar{A}_{j}(t_{ i}))]","where \(\mathcal{L}_{CD}\) and \(\mathcal{L}_{1}\) are chamfer distance and L1 norm respectively, \(S(t_{i})\) denotes the simulated surface at time \(t_{i}\), \(A_{j}(t_{i})\) is the rendered mask at view \(j\), and \(\bar{A}_{j}(t_{i})\) represents the object mask of the image extracted from video \(V_{j}\) at time \(t_{i}\)","L_{sim}=\sum_{t=1}^{T}\left[\lambda_{3}\cdotL_{mask}(M_{sim}(t), M_{gt}(t))+\lambda_{4}\cdotL_{surf}(S_{sim}(t),\tilde{S}(t))\right]","where \(M_{sim}(t)\) and \(M_{gt}(t)\) are the simulated and ground truth masks at time \(t\), \(S_{sim}(t)\) and \(\tilde{S}(t)\) are the simulated and extracted surfaces, and \(\lambda_{3}\), \(\lambda_{4}\) are weighting hyperparameters."
neurips_2024_oral_2,1,"\operatorname*{minimize}_{\theta}L(\theta;D_{SFT})=-E_{(x,y)\simD_{SFT}}[\log\pi_{\theta}(y|x)]",,L_{SFT}(\theta)=-\frac{1}{N}\sum_{i=1}^{N}\log\pi_{\theta}^{SFT}(y^{(i)}\midx^{(i)}),The supervised fine-tuning loss is the average negative log-likelihood of the target answers given the inputs over the SFT dataset.
neurips_2024_oral_2,2,"\pi^{\prime}(y_{c}|x)=\sum_{y_{k}}\mu_{\phi}(y_{c}|y_{k},x)\pi_{\theta}(y_{k}|x)\geqslant\mu_{\phi} (y_{c}|y_{o},x)\pi_{\theta}(y_{o}|x)",where \(\mathbf{y}_{k}\) is a possible answer generated by upstream LLM \(\pi_{\mathbf{\theta}}\),"\pi_{\theta}^{Align}(y_c|x)=\int\mu_{\phi}(y_c|y_o,x)\,\pi_{\theta}(y_o|x)\, dy_o","The aligned answer distribution is obtained by marginalizing over the original answers, where the Aligner model transforms the original answer distribution into the corrected answer distribution conditioned on the input."
neurips_2024_oral_2,3,"-E_{M}[\log\pi^{\prime}(y_{c}|x)]\leqslant-E_{M}[\log\mu_{\phi}(y_{c}|y_{o},x)]-E_{M}[\log\pi_{\theta}(y_{o}|x)]",,"L(\phi;M)=-E_{(x,y_{o},y_{c})\simM}\left[\log\mu_{\phi}(y_{c} |y_{o},x)\right]",where \(\mathcal{L}(\mathbf{\phi};\mathcal{M})\) is the negative log-likelihood loss for training the Aligner model on dataset \(\mathcal{M}\).
neurips_2024_oral_2,4,"\operatorname*{minimize}_{\phi}L_{Aligner}(\phi,M)=-E_{M}[\log\mu_{\phi}(y_{c} |y_{o},x)]",,"\operatorname*{minimize}_{\phi}\;-E_{M}[\log\mu_{\phi}(y_{c}|y_{o},x)]","where \(\mu_{\mathbf{\phi}}(\mathbf{y}_{c}|\mathbf{y}_{o},\mathbf{x})\) is the conditional probability of generating the corrected answer given the original answer and the query, parameterized by \(\mathbf{\phi}\)."
neurips_2024_oral_21,1,"q(X_{V}^{t}\midX_{V}^{t-1})=Cat(X_{V}^{t};p=X_{V}^{t-1}Q_{V}^{t}),\\q(X_{E}^{t}\midX_{E}^{t-1})=Cat(X_{E}^ {t};p=X_{E}^{t-1}Q_{E}^{t})",where \(\mathrm{Cat}(\mathbf{X};\mathbf{p})\) denotes sampling from a categorical distribution with probability \(\mathbf{p}\),"q(G^{t}\mid G^{t-1})=\prod_{i=1}^{N}Q_{V}(x_{V,i}^{t}\mid x_{V,i}^{t-1})\prod_{j=1}^{M}Q_{E}(x_{E,j}^{t}\mid x_{E,j}^{t-1})",The transition probability for the graph at step \(t\) is given by the product of node and edge transition probabilities using the respective transition matrices.
neurips_2024_oral_21,2,p_{\theta}(\tilde{G}^{0}\mid G^{t})=\prod_{v\in V}p_{\theta}(v^{t-1}\mid G^{t})\prod_{e\in E}p_{\theta}(e^{t-1}\mid G^{t}),,"p_{\theta}(\tilde{G}^{0}\mid G^{t})=\prod_{v\in V} p_{\theta}(X_{V,v}^{0}\mid G^{t})\prod_{e\in E} p_{\theta}(X_{E,e}^{0}\mid G^{t})","where \(p_{\theta}(\tilde{G}^{0}\mid G^{t})\) is the model's predicted probability of the original graph given the noisy graph at step \(t\), factorized over all nodes and edges."
neurips_2024_oral_21,3,"p_{\theta}(v^{t-1}\mid G^{t})=\sum_{\tilde{v}\in\tilde{x}_{v}}q(v^{t-1 }\mid\tilde{v},G^{t})p_{\theta}(\tilde{v}\mid G^{t})",,"p_{\theta}(v^{t-1}\mid G^{t})=\sum_{\tilde{v}\in\tilde{x}_{v}} q(v^{t-1}\mid v^{t},\tilde{v})\, p_{\theta}(\tilde{v}\mid G^{t})","The probability of node state \(v^{t-1}\) given \(G^{t}\) is computed by marginalizing over all possible predicted node types \(\tilde{v}\), weighted by the reverse transition probability and the neural network prediction."
neurips_2024_oral_21,4,L=E_{q(G^{0})}E_{q(G^{t}|G^{0})}[-E_{x\in G^{0}}\log p_{\theta}(x\mid G^{t})],,L_{NLL}=-E_{q(G^{0:T})}\left[\log p_{\theta}(G^{0:T})\right],\(\mathcal{L}_{\mathrm{NLL}}\) denotes the negative log-likelihood loss for training the diffusion model.
neurips_2024_oral_21,5,Q_{G}=Q_{V}&1_{N}^{\prime}\otimesQ_{VE}\\1_{N}\otimesQ_{EV}&1_{N\times N}\otimesQ_{ E},"where \(\otimes\) denotes the Kronecker product, \(\mathbf{1}_{N}\), \(\mathbf{1}_{N}^{\prime}\), and \(\mathbf{1}_{N\times N}\) represent the column vector, row vector, and matrix with all 1 elements, respectively",Q_{G}=Q_{V} &Q_{VE}\\Q_{EV} &Q_{E},"\(\mathbf{Q}_{G}\) is the joint transition matrix for graph tokens, constructed from node and edge transition matrices and their cross-dependencies."
neurips_2024_oral_21,6,q(X_{G}^{t}\midX_{G}^{t-1})=\widetilde{Cat}(X_{G}^{t};\tilde{p}=X_{G}^{t-1}Q_{G}^{t} ),"where \(\tilde{\mathbf{p}}\) is the unnormalized probability and \(\widetilde{\mathrm{Cat}}\) denotes categorical sampling: The first \(F_{V}\) columns of \(\tilde{\mathbf{p}}\) are normalized to sample \(\mathbf{X}_{V}^{t}\), while the remaining \(N\cdot E\) dimensions are reshaped and normalized to sample edges \(\mathbf{X}_{E}^{t}\)","q(X_{G}^{t}\midX_{G}^{t-1})=Cat(X_{G}^{t};\,p=X_{G}^{t-1}Q_{G}^{t})","where \(\mathbf{X}_{G}^{t}\) is the graph token matrix at step \(t\), and \(\mathbf{Q}_{G}^{t}\) is the joint transition matrix for nodes and edges at step \(t\)"
neurips_2024_oral_21,7,"\hat{p}_{\theta}(G^{t-1}\mid G^{t},C)=\log p_{\theta}(G^{t-1}\mid G^{ t})+s(\log p_{\theta}(G^{t-1}\mid G^{t},C)-\log p_{\theta}(G^{t-1}\mid G^{t}))",where \(s\) denotes the scale of conditional guidance,"\log\hat{p}_{\theta}(G^{t-1}\mid G^{t},C)=(1+s)\log p_{\theta}(G^{t-1}\mid G^{t},C)-s\log p_{\theta}(G^{t-1}\mid G^{t})","where \(s\) is a guidance scale hyperparameter, and \(p_{\theta}(G^{t-1} \mid G^{t}, \mathcal{C})\) and \(p_{\theta}(G^{t-1} \mid G^{t})\) are the conditional and unconditional reverse process probabilities, respectively"
neurips_2024_oral_21,8,"AdaLN(h,c)=\gamma_{\theta}(c)\odot\frac{h-\mu(h)}{\sigma(h )}+\beta_{\theta}(c)",where \(\mu(\cdot)\) and \(\sigma(\cdot)\) are mean and variance values,"AdaLN(h,c)=s(c)\odot\frac{h-\mu(h)}{\sigma(h)}+b(c)","where $\mathbf{s}(\mathbf{c})$ and $\mathbf{b}(\mathbf{c})$ are scale and bias vectors generated from the condition representation $\mathbf{c}$, and $\boldsymbol{\mu}(\mathbf{h})$, $\boldsymbol{\sigma}(\mathbf{h})$ are the mean and standard deviation of $\mathbf{h}$, respectively"
neurips_2024_oral_21,9,"AdaLN_{gate}(h,c)=\alpha_{\theta}(c)\odotAdaLN(h,c)",,"AdaLN_{gate}(h,c)=g_{\theta}(c)\odot\left(\gamma_{\theta}(c)\odot\frac{h-\mu(h)}{\sigma(h)}+\beta_{\theta}(c)\right)",where \(\mathbf{g}_{\theta}(\cdot)\) is a gating neural network module controlling the residual scaling
neurips_2024_oral_21,10,"\tilde{X}_{G}^{0}=AdaLN(MLP(H),c)",,"\tilde{X}_{V}^{0},\,\tilde{X}_{E}^{0}=MLP(H)",where $\mathrm{MLP}$ denotes a multi-layer perceptron that outputs the predicted node and edge probabilities at $t=0$ from the hidden states $\mathbf{H}$
neurips_2024_oral_22,1,"dx_{\sigma}\,=\,-\sigma\nabla_{x_{\sigma}}\!\log p (x_{\sigma};\sigma)\;d\sigma",,"\frac{dx}{d\sigma}=f(x,\sigma)","\(\mathbf{x}\) is the data sample, \(\sigma\) is the noise level, and \(\mathbf{f}(\mathbf{x}, \sigma)\) is the drift function describing the probability flow in the denoising diffusion process."
neurips_2024_oral_22,2,"\theta\,=\,\arg\min_{\theta}E_{y\sim p_{data},\sigma\sim p_{train},n\simN(0,\sigma^{2}I)}\|D_{\theta}(y+n;\sigma)-y\|_{2}^ {2}",where \(p_{\text{train}}\) controls the noise level distribution during training,D_{\theta}(x;\sigma)\approx\nabla_{x}\log p(x;\sigma),\(D_{\theta}(\mathbf{x};\sigma)\) is a neural network approximation of the score function \(\nabla_{\mathbf{x}}\log p(\mathbf{x};\sigma)\) for a sample \(\mathbf{x}\) at noise level \(\sigma\).
neurips_2024_oral_22,3,"D_{w}(x;\sigma,c)\,=\,wD_{1}(x;\sigma,c)+( 1-w)D_{0}(x;\sigma,c)",,"D_{w}(x;\sigma,c)=(1+w) D_{1}(x;\sigma,c)-w D_{0}(x;\sigma,c)","where \(D_{w}(\mathbf{x};\sigma,\mathbf{c})\) is the guided denoiser output, \(D_{1}\) is the conditional denoiser, \(D_{0}\) is the unconditional denoiser, and \(w\) is the guidance strength."
neurips_2024_oral_22,4,"D_{w}(x;\sigma,c)\approxx+\sigma^{2}\nabla_{x}\log\underbrace{(p_ {0}(x|c;\sigma)[\frac{p_{1}(x|c;\sigma)}{p_{0}(x|c;\sigma)}]^{w})}_{\propto:\p_{w}(x|c;\sigma)}",,"\nabla_{x}\log p_{w}(x|c;\sigma)\;\approx\;\frac{D_{w}(x;\sigma,c)-x}{\sigma^{2}}",where \(p_{w}(\mathbf{x}|\mathbf{c};\sigma)\) denotes the guided conditional distribution and the right-hand side provides an approximate score function under classifier-free guidance.
neurips_2024_oral_22,5,\nabla_{x}\log p_{w}(x|c;\sigma)=\nabla_{x}\log p_{1}(x|c;\sigma)+(w-1)\nabla_{x}\log\frac{p_{1}(x|c;\sigma)}{p_{0}(x|c;\sigma)},,\nabla_{x}\log p_{w}(x|c;\sigma)=w\nabla_{x}\log p_{1}(x|c;\sigma)+(1-w)\nabla_{x}\log p_{0}(x|c;\sigma),"where \(p_{0}\) and \(p_{1}\) are the unconditional and conditional densities, respectively, and \(w\) is the guidance weight."
neurips_2024_oral_23,1,"|Cov(f(X),Y\mid X\in S)|\leq\alpha",,\left|E[Y\mid X\in S]-E[f(X)\mid X\in S]\right|\leq\alpha,"A set \(S\) is \(\alpha\)-indistinguishable if, for all \(f\in\mathcal{F}\), the difference between the expected value of \(Y\) and the expected prediction \(f(X)\) conditioned on \(X \in S\) is at most \(\alpha\)."
neurips_2024_oral_23,2,"\gamma^{*},\beta^{*}\in\operatorname*{arg\,min}_{\gamma\inR^{K},\beta\inR^{K}}\;E[(Y-\gamma_{J(X)}+\beta_{J(X)}\hat{Y})^{2}]",,"\gamma^{*}_{k},\beta^{*}_{k} :=\arg\min_{\gamma,\beta\inR}E_{k}\left[(Y-(\gamma+\beta\hat{Y}))^{2}\right]","\(\gamma^{*}_{k}, \beta^{*}_{k}\) are the coefficients of the best linear predictor of \(Y\) from \(\hat{Y}\) within subset \(S_{k}\), minimizing mean squared error."
neurips_2024_oral_23,3,"E_{k}[(Y-\gamma_{k}^{*}-\beta_{k}^{*}\hat{Y})^{2} ]+4Cov_{k}(Y,\hat{Y})^{2}\leqE_{k}[(Y-f(X) )^{2}]+2\alpha",,E_{k}\left[(Y-\gamma^{*}_{k}+\beta^{*}_{k}\hat{Y})^{2}\right]\leqE_{k}\left[(Y-f(X))^{2}\right]+2\alpha,"Within each subset \(S_k\), the expected squared error of the best linear predictor of \(Y\) using \(\hat{Y}\) is at most the expected squared error of any \(f\in\mathcal{F}\) plus \(2\alpha\)."
neurips_2024_oral_23,4,E_{S}[(Y-g(H))^{2}]\leqE_{S}[(Y-\gamma-\beta g(H))^{2}]+\eta,,\left|E_{S}[Y-g(H)]\right|\leq\eta,"The function \(g:\mathcal{H}\to[0,1]\) is approximately calibrated on subset \(S\) if its expected prediction error is at most \(\eta\)."
neurips_2024_oral_23,5,"E_{S}[(Y-g(H))^{2}]+4Cov_{S}(Y,g(H))^{2}\leqE_ {S}[(Y-f(X))^{2}]+2\alpha+\eta",,E_{S}[(Y-g(H))^{2}]\leqE_{S}[(Y-f(X))^{2}]+2\alpha+\eta,The expected squared error of predicting \(Y\) using the function \(g(H)\) on subset \(S\) is at most the expected squared error of any \(f\in\mathcal{F}\) plus \(2\alpha+\eta\).
neurips_2024_oral_23,6,"|Cov_{k}(Y,\hat{Y})|\leq\sqrt{\frac{\alpha}{2}}",,"Cov_{k}(Y,\hat{Y})=0",The conditional covariance between \(Y\) and \(\hat{Y}\) within subset \(S_k\) is zero when \(Y\) and \(\hat{Y}\) are conditionally independent given \(\tilde{f}_k(X)\) and \(X \in S_k\).
neurips_2024_oral_24,1,y^{\prime}=y+\Delta y=W_{0}x+BAx,where \(y\in R\)d is the output and the \(x\in R\)k denotes the input,y=W_{0}x+BAx,"Here, \(y\) is the output, \(x\) is the input, \(W_{0}\) is the frozen pre-trained weight matrix, and \(A\) and \(B\) are the trainable low-rank adaptation matrices."
neurips_2024_oral_24,2,"W&=\,W_{0}+\Delta\,W\\&=\,W_{0}+\sum_{i=1}^{N}\omega_{i}\cdot B_{i}A",,y'=y+\Delta y=W_0 x+\sum_{i=1}^{n} B_i A x,where \(B_i\) is the \(i\)-th domain-specific matrix and \(A\) is the shared matrix across all \(n\) domains.
neurips_2024_oral_24,3,y=W_{0}x+\sum_{i=1}^{N}\omega_{i}E_{i}Ax\quad(MoE),"where \(N\) denotes the number of experts, i",\Delta W=\sum_{i=1}^{N}\alpha_{i}\cdot B_{i}A,where \(\alpha_{i}\) is the gating score assigned by the MoE router to expert \(i\) for a given input.
neurips_2024_oral_24,4,\omega_{i}=softmax(W_{g}^{T}x)\quad(Router),,\omega_{i}=softmax\left((W_{g} x)_i\right),"where \(\omega_{i}\) is the gating score for expert \(i\), computed by applying a softmax to the output of the transformation matrix \(\mathit{W}_{g}\) acting on input \(x\)."
neurips_2024_oral_25,1,"{l}X=Y\beta_{Y\to X}+G^{\intercal}\gamma_{X}+\varepsilon_{X},\\Y=X\beta_{X\to Y}+G^{\intercal}\gamma_{Y}+\varepsilon_{Y}",where \(\beta_{Y\to X}\) is the causal effect of \(Y\) on \(X\) and \(\beta_{X\to Y}\) is that of \(X\) on \(Y\),X_{i} &=\alpha_{X} Y_{i}+\gamma_{X}^{\intercal}G_{i}+\varepsilon_{X_{i}}\\Y_{i} &=\alpha_{Y} X_{i}+\gamma_{Y}^{\intercal}G_{i}+\varepsilon_{Y_{i}},"The bi-directional linear structural equations for phenotypes \(X_i\) and \(Y_i\) as functions of each other, genetic variants, and error terms."
neurips_2024_oral_25,2,"{l}X=(G^{\intercal}\gamma_{X}+G ^{\intercal}\gamma_{Y}\beta_{Y\to X}+\varepsilon_{X}+\varepsilon_{Y}\beta_{Y\to X})\Delta,\\Y=(G^{\intercal}\gamma_{X}\beta_{X\to Y}+G^{\intercal}\gamma_{Y}+\varepsilon_{X}\beta_{X\to Y}+\varepsilon_{Y})\Delta",,"{l} X=\Delta\left(G^{\intercal}\gamma_X+\beta_{Y\to X}G^{\intercal}\gamma_Y+\varepsilon_X+\beta_{Y\to X}\varepsilon_Y\right),\\Y=\Delta\left(G^{\intercal}\gamma_Y+\beta_{X\to Y}G^{\intercal}\gamma_X+\varepsilon_Y+\beta_{X\to Y}\varepsilon_X\right)",where \(\Delta = 1/(1-\beta_{X\to Y}\beta_{Y\to X})\) is a normalization factor to resolve the recursive system.
neurips_2024_oral_25,3,\hat{\beta}_{X\to Y}=[X^{\intercal}PX]^{-1}X^{\intercal}PY=\beta_{X\to Y},,"\beta_{X\to Y}=\frac{Cov(Y,G_{V}^{X\to Y})}{Cov(X,G_{V}^{X\to Y})}",where \(\mathbf{G}_{\mathcal{V}}^{X\to Y}\) denotes the set of valid instrumental variables for the causal direction \(X\to Y\).
neurips_2024_oral_25,4,\hat{\beta}_{X\to Y}=[X^{\intercal}\tilde{P}X]^{-1}X^{\intercal}\tilde{P}Y=\beta_{X\to Y}+\underbrace{[X^{\intercal}\tilde{P}X ]^{-1}X^{\intercal}\tilde{P}(G^{\intercal}\gamma_{Y}+\varepsilon_{Y})}_{\beta_{bias}},,\hat{\beta}_{X\to Y}^{I}=[X^{\intercal}P_{I}X]^{-1}X^{\intercal}P_{I}Y,where \(\mathbf{P}_{\mathcal{I}}=(\mathbf{G}_{\mathcal{I}}^{X\to Y})^{\intercal}\left[\mathbf{G}_{\mathcal{I}}^{X\to Y}(\mathbf{G}_{\mathcal{I}}^{X\to Y})^{\intercal}\right]^{-1}\mathbf{G}_{\mathcal{I}}^{X\to Y}\) is the projection matrix onto the invalid IV set.
neurips_2024_oral_25,5,"corr(Y-X\omega_{\{G_{3}\}},G_{1})=0,\qquadcorr(Y-X\omega_{\{ G_{1}\}},G_{3})=0","where \(\mathrm{corr}(\cdot)\) denotes the Pearson's correlation coefficient between two random variables, and \(\omega_{\{G_{i}\}}=\mathrm{TSLS}(X,Y,\{G_{i}\})\) with \(i\in\{1,3\}\)","E[X\mid G_{1}, G_{3}] &=\gamma_{X,1} G_{1}+\gamma_{X,3} G_{3},\\E[Y\mid G_{1}, G_{3}] &=\beta_{X\to Y}E[X\mid G_{1}, G_{3}]","Conditional on valid IVs, the mean of \(X\) is a linear function of their direct effects, and the mean of \(Y\) is proportional to that of \(X\) via the causal effect."
neurips_2024_oral_25,6,"corr(Y-X\omega_{\{G_{4},G_{5}\}},G_{2})\neq 0,corr(Y-X\omega_{\{ G_{2},G_{5}\}},G_{4})\neq 0,corr(Y-X\omega_{\{G_{2},G_{4}\}},G_{5})\neq 0","where \(\omega_{\{G_{i},G_{j}\}}=\mathrm{TSLS}(X,Y,\{G_{i},G_{j}\})\) with \(i\neq j\) and \(i,j\in\{2,4,5\}\)","corr(Y-X\omega_{\{G_{2},G_{4},G_{5}\}},G_{2})\neq 0,\qquadcorr(Y-X\omega_{\{G_{2},G_{4},G_{5}\}},G_{4})\neq 0,\qquadcorr(Y-X\omega_{\{G_{2},G_{4},G_{5}\}},G_{5})\neq 0","For an invalid IV set, the residuals from regressing \(Y\) on \(X\) using the TSLS estimator with \(\{G_{2}, G_{4}, G_{5}\}\) remain correlated with each of the invalid IVs."
neurips_2024_oral_25,7,"PR_{(X,Y\,|\,G)}:=Y-X\omega_{G}",,"R_{Y|X,G}=Y-X\,TSLS(X,Y,G)","\(R_{Y|X,\mathbb{G}}\) denotes the pseudo-residual of \(Y\) given \(X\) and a set of genetic variants \(\mathbb{G}\)."
neurips_2024_oral_25,8,"corr(PR_{\langle X,Y\,|\,\{G_{j}\}\rangle},G_{j })\neq 0",,"corr(PR_{(X,Y\,|\,G\setminus\{G_{j}\})}, G_{j})\neq 0","where \(\mathcal{PR}_{(X,Y\,|\,\mathbb{G}\setminus\{G_{j}\})}\) is the pseudo-residual of \(\{X,Y\}\) relative to the set \(\mathbb{G}\) with \(G_j\) removed, and \(\mathrm{corr}(\cdot,\cdot)\) denotes the Pearson's correlation coefficient."
neurips_2024_oral_25,9,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=0",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2})=0",where \(\mathrm{corr}(\cdot)\) denotes the Pearson's correlation coefficient between the pseudo-residual and genetic variant \(G_{2}\).
neurips_2024_oral_25,10,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle}),G_{ 2})=0",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2})=0",Pearson's correlation between the pseudo-residual using \(G_1\) and the variant \(G_2\) is zero.
neurips_2024_oral_25,11,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=\frac{\gamma_{Y,1}\gamma_{X,2}-\gamma_{Y,2}\gamma_{X,1}}{\beta_{Y\to X }\gamma_{Y,2}+\gamma_{X,2}}",,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1})=0","The correlation between the pseudo-residual of \((X,Y)\) with respect to \(G_2\) and \(G_1\) is zero in subgraph (b)."
neurips_2024_oral_25,12,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2} )=\frac{\gamma_{Y,2}\gamma_{X,1}-\gamma_{Y,1}\gamma_{X,2}}{\beta_{Y\to X }\gamma_{Y,1}+\gamma_{X,1}}",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2})=\frac{\gamma_{Y,2}\gamma_{X,1}-\gamma_{Y,1}\gamma_{X,2}}{\beta_{Y\to X}\gamma_{Y,1}+\gamma_{X,1}}","where \(\gamma_{X,1}, \gamma_{X,2}, \gamma_{Y,1}, \gamma_{Y,2}\) are the direct effects of \(G_1\) and \(G_2\) on \(X\) and \(Y\), respectively, and \(\beta_{Y\to X}\) is the causal effect of \(Y\) on \(X\)."
neurips_2024_oral_25,13,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=0,\qquadcorr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle },G_{2})=0",,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1})=corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2})=0","the correlations between the pseudo-residuals and the other genetic variant both vanish when \(\gamma_{X,1}\gamma_{Y,2}=\gamma_{Y,1}\gamma_{X,2}\)"
neurips_2024_oral_25,14,"corr(PR_{(X,Y\midG\setminus G_{j})},G_{j})=0",,"corr(PR_{\langle X,Y\,|\,\{G_{j}\}\rangle},G_{j})=0,\quad\forall G_{j}\inG","where \(\mathbb{G}\) is a subset of candidate genetic variants and \(\mathcal{PR}_{\langle X,Y\,|\,\{G_{j}\}\rangle}\) is the pseudo-residual of \((X,Y)\) relative to \(\{G_{j}\}\)."
neurips_2024_oral_26,1,"s_{real}(x_{t},t)=\nabla_{x_{t}}\log p_{real,t}(x_{t})=-\frac{x_ {t}-\alpha_{t}\mu_{real}(x_{t},t)}{\sigma_{t}^{2}}",,"\nabla_{x_{t}}\log p_{real,t}(x_{t})","The score function of the diffused data distribution at timestep \(t\), representing the gradient of the log-likelihood with respect to \(x_t\)."
neurips_2024_oral_26,2,"\nablaL_{BMD}=E_{t}(\nabla_{\theta}KL( p_{fake,t}\|p_{real,t}))=-E_{t}(\int(s_{real}(F(G_{\theta}(z),t),t)-s_{fake}(F(G_{\theta}(z),t),t) )\frac{dG_{\theta}(z)}{d\theta}\,dz)","where \(z\sim\mathcal{N}(0,\mathbf{I})\) is a random Gaussian noise input, \(\theta\) are the generator parameters, \(F\) is the forward diffusion process (i","\nabla_{\theta}E_{t}\left[KL\left(p_{real,t}\| p_{fake,t}\right)\right]=E_{t, x_{t}\sim p_{real,t}}\left[ s_{real}(x_{t}, t)-s_{fake}(x_{t}, t)\right]",The gradient of the expected KL divergence between the real and fake diffused distributions with respect to generator parameters equals the expected difference of their score functions.
neurips_2024_oral_26,3,"L_{reg}=E_{(z,y)}d(G_{\theta}(z),y)","where \(d\) is a distance function, such as LPIPS [54] in their implementation","L_{reg}=E_{z\simN(0,I)}\left[\left\| G_{\theta}(z)-y(z)\right\|^2\right]",where \(y(z)\) is the image generated by the teacher diffusion model using deterministic sampling from the same noise input \(z\).
neurips_2024_oral_26,4,"L_{GAN}=E_{x\sim p_{noise},t\sim[0,T]}[\log D (F(x,t))]+E_{z\sim p_{noise},t\sim[0,T]}[-\log(D(F(G_{\theta}(z ),t)))]","where \(D\) is the discriminator, and \(F\) is the forward diffusion process (i","L_{GAN}=E_{x\sim p_{real}}\left[\log D(x)\right]+E_{z\simN(0,I)}\left[\log (1-D(G_{\theta}(z)))\right]","where \(D\) is the discriminator, \(x\) is a real image sampled from \(p_{\text{real}}\), and \(G_{\theta}(z)\) is a generated image from noise \(z\)."
neurips_2024_oral_27,1,"\langle S,A,O,I,T,R,\gamma,\Theta\rangle","where \(S\), \(A\) and \(O\) are the sets of states, actions, and observations, respectively","M=(S,A,T,O,R,\gamma)","Here, $\mathcal{M}$ denotes the UPOMDP defined by the state space $\mathcal{S}$, action space $\mathcal{A}$, transition function $\mathcal{T}$, observation space $\mathcal{O}$, reward function $\mathcal{R}$, and discount factor $\gamma$."
neurips_2024_oral_27,2,"PVL^{\theta}(\pi)=\frac{1}{T}\sum_{t=0}^{T}\max(\sum_{k=t}^{T}(\gamma\lambda)^{k-t}\delta_{k}^{\theta},0)","where \(\lambda\) and \(T\) are the GAE discount factor and MDP horizon, respectively",PVL^{\theta}(\pi)=E_{\pi}\left[\sum_{t=0}^{T}\left(\hat{A}_t\right)_{+}\right],"where \(\hat{A}_t\) is the GAE advantage estimate at time \(t\), and \((x)_{+} = \max(x, 0)\)."
neurips_2024_oral_27,3,"P(\Gamma\mid\lambda_{\Gamma})=\prod_{j=1}^{J}\sum_{k=1}^{K}\alpha_{k}N (x_{j}\mid\mu_{k},\Sigma_{k})",where \(x_{j}\) is a state-action pair sample from \(\Gamma\),"p(\Gamma\mid\lambda_{\Gamma})=\prod_{x\in\Gamma}\sum_{k=1}^{K}\alpha_{k}\,N(x\mid\mu_{k},\Sigma_{k})","The likelihood of the state-action coverage buffer \(\Gamma\) under the GMM parameters \(\lambda_{\Gamma}\), where each \(x\) is a state-action pair and \(\mathcal{N}(x \mid \mu_{k}, \Sigma_{k})\) denotes the multivariate Gaussian density for component \(k\)."
neurips_2024_oral_27,4,\textsc{Novelty}_{l_{\theta}}=-\frac{1}{|X_{\theta}|}\logL(X_{\theta}\mid\lambda_{\Gamma})=-\frac{1}{|X_{\theta}|}\sum_{t=1}^{T}\log p(x_{t}\mid\lambda_{\Gamma}),where \(x_{t}\) is a sample state-action pair from \(X_{\theta}\),"Novelty(l_{\theta})=-\frac{1}{|X_{\theta}|}\sum_{x\in X_{\theta}}\log\left(\sum_{k=1}^{K}\alpha_kN(x\mid\mu_k,\Sigma_k)\right)",The novelty score of level \(l_{\theta}\) is defined as the negative average log-likelihood of its state-action pairs under the fitted GMM.
neurips_2024_oral_27,5,P_{S}=\frac{h(S_{i})^{\beta}}{\sum_{j}h(S_{j})^{\beta}},where \(h\) is a prioritization function (e,P_{S}(l_{\theta})=\frac{\exp(\beta S(l_{\theta}))}{\sum_{l'\in L}\exp(\beta S(l'))},"where \(S(l_{\theta})\) is the score (e.g., novelty or regret) for level \(l_{\theta}\), \(\beta\) is a temperature parameter, and \(L\) is the set of candidate levels."
neurips_2024_oral_27,6,P_{replay}=\alpha\cdot P_{N}+(1-\alpha)\cdot P_{R},"where \(P_{N}\) and \(P_{R}\) are the novelty-prioritized probability and regret-prioritized probability respectively, and \(\alpha\) allows us to adjust the weightage of each probability",P_{S}=\frac{h(Novelty_{i})^{\beta_{nov}}\cdot h(Regret_{i})^{\beta_{reg}}}{\sum_{j} h(Novelty_{j})^{\beta_{nov}}\cdot h(Regret_{j})^{\beta_{reg}}},"where \(\beta_{\text{nov}}\) and \(\beta_{\text{reg}}\) are temperature parameters for novelty and regret prioritization, respectively."
neurips_2024_oral_31,1,y^{*}=y-f_{\theta}(y)\nabla f_{\theta}(y),"where, by definition, \(f_{\theta}(\mathbf{y})\) is the distance between \(\mathbf{y}\) and \(\mathbf{y}^{*}\), and the gradient \(\nabla f_{\theta}(\mathbf{y})\) points in the opposite direction of the shortest path from \(\mathbf{y}\) to the surface of the object and is unit-norm",y^{*}=y-f_{\theta}(y)\cdot\nabla_{y} f_{\theta}(y),"\(\mathbf{y}^{*}\) is the closest point on the object surface to \(\mathbf{y}\), computed using the SDF and its gradient."
neurips_2024_oral_31,2,c^{j}_{ik}=n_{ik}-d^{j}_{ik}T_{j}\Big{(}\nabla f_{\theta_{j}}(T^{-1}_{j}(n_{ik}))\Big{)},,c^{j}_{ik}=T_{j}\left(T^{-1}_{j}(n_{ik})-d^{j}_{ik}\nabla f_{\theta_{j}}(T^{-1}_{j}(n_{ik}))\right),"\(\mathbf{c}^{j}_{ik}\) is the closest point on the surface of object \(O_{j}\) to node \(\mathbf{n}_{ik}\) from object \(O_{i}\), computed using the SDF of \(O_{j}\) and appropriate coordinate transformations."
neurips_2024_oral_34,1,"x_{0}\simN(0,I)\quadand\quadx_{t+1}=a_{t}x_{t}+\mu(x_{t},t)+\sigma_{t}\epsilon_{t}\quadfor\quad t=0,1,\dots,T-1","where \(\epsilon_{t}\sim\mathcal{N}(0,I)\) and \(\mu(\mathbf{x},t)\) is the output of a neural network","x_{t-1}=f_{\theta}(x_t, t),\quad t=T, T-1,\dots, 1","Here, \(\mathbf{x}_t\) denotes the sample at timestep \(t\), and \(f_{\theta}\) is a parameterized function modeling the reverse process in the diffusion model."
neurips_2024_oral_34,2,"q(x)=\frac{1}{Z}\exp(-E(x)/\tau),\quad E:X\toR","where \(\tau>0\) is temperature, \(\mathcal{X}\) is the compact domain of data, and \(Z=\int_{\mathcal{X}}\exp(-E(\mathbf{x})/\tau)d\mathbf{x}<\infty\) is the normalization constant",q(x)=\frac{1}{Z}\exp(-E(x)),where \(E(\mathbf{x})\) is the energy function and \(Z\) is the normalizing constant (partition function).
neurips_2024_oral_34,3,\min_{\pi\in\Pi}KL(\pi(x) || p(x))=\max_{\pi\in\Pi}E _{\pi}[\log p(x)]+H(\pi(x)),"where \(\Pi\) is the set of feasible \(\pi(\mathbf{x})\)'s, and \(\mathcal{H}(\pi)=-\int\pi(\mathbf{x})\log\pi(\mathbf{x})d\mathbf{x}\) is the differential entropy",\min_{\pi} KL(\pi || p)=\min_{\pi}\int_{X}\pi(x)\log\frac{\pi(x)}{p(x)} dx,The objective is to minimize the reverse KL divergence between the diffusion model distribution \(\pi(\mathbf{x})\) and the data distribution \(p(\mathbf{x})\).
neurips_2024_oral_34,4,\min_{\pi\in\Pi}KL(\pi(x) || q(x))\quadand\quad\min_{ q\inQ}KL(p(x) || q(x)),where \(\mathcal{Q}\) is the feasible set of EBMs,\min_{q} KL(p(x) || q(x))=\min_{q}E_{p}[\log p(x)-\log q(x)],where the expectation is over the data distribution \(p(\mathbf{x})\) and \(q(\mathbf{x})\) is the energy-based model defined in Eq. (2)
neurips_2024_oral_34,5,\min_{q\inQ}\max_{\pi\in\Pi}KL(p(x) || q(x))-KL(\pi(x) || q(x)),,\min_{q\inQ}\max_{\pi\in\Pi}E_{p}[\log q(x)]-E_{\pi}[\log q(x)]+H(\pi(x)),"The DxMI objective is a minimax problem where the EBM \(q(\mathbf{x})\) is trained to maximize the log-likelihood on data and minimize it on diffusion samples, while the diffusion model \(\pi(\mathbf{x})\) maximizes entropy and the log-likelihood under \(q(\mathbf{x})\)."
neurips_2024_oral_34,6,KL(\pi_{\phi}(x_{T}) || q_{\theta}(x_{T}))\leq KL(\pi_{\phi}(x_{0:T}) || q_{\theta}(x_{T})\tilde{q}(x_{0:T-1}|x_{T})),,KL(\pi_{\phi}(x_{T}) || q_{\theta}(x_{T}))\leq KL(\pi_{\phi}(x_{0:T}) || q_{\theta}(x_{0:T})),The KL divergence between the marginal distributions at time \(T\) is upper-bounded by the KL divergence between the joint trajectory distributions from time \(0\) to \(T\).
neurips_2024_oral_34,7,"\tilde{q}(x_{0:T-1}|x_{T})=\prod_{t=0}^{T-1}\tilde{q}(x_{t}|x_{t+1}), where \tilde{q}(x_{t}|x_{t+1})=N(x_{t+1},s_{t}^{2}I),\quad s_{t}>0",,\tilde{q}(x_{0:T-1}|x_{T})=\prod_{t=0}^{T-1}\tilde{q}(x_t|x_{t+1}),where each \(\tilde{q}(\mathbf{x}_t|\mathbf{x}_{t+1})\) is a conditional Gaussian distribution.
neurips_2024_oral_34,8,\min_{\phi}\mathop{E}_{\pi_{\phi}(x_{0:T})}[E_{\theta}(x_{T})+\tau\sum_{t=0}^{T-1}\log\pi_{\phi}(x_{t+1}|x _{t})+\tau\sum_{t=0}^{T-1}\frac{1}{2s_{t}^{2}} || x_{t+1}-x_ {t} || ^{2}],,\min_{\phi}E_{\pi_{\phi}(x_{0:T})}\left[E_{\theta}(x_{T})+\tau\sum_{t=0}^{T-1}\frac{1}{2s_{t}^{2}}\|x_{t+1}-x_{t}\|^{2}\right],The objective is to minimize the expected terminal energy and a weighted sum of squared transition differences under the diffusion model trajectory distribution.
neurips_2024_oral_34,9,V_{\psi}^{t}(x_{t})=E_{\pi}[E_{\theta}(x_{T})+\tau\sum_{t^{\prime}=t}^{T-1}\log\pi_{\phi}(x_{t^{\prime}+1}| x_{t^{\prime}})+\sum_{t^{\prime}=t}^{T-1}\frac{\tau}{2s_{t^{\prime}}^{2}} || x_{t^{\prime}+1}-x_{t^{\prime}} || ^{2}\bigg{|}x_{t} ],,"V_{\psi}^{t}(x_{t})=E_{\pi_{\phi}}\left[ E_{\theta}(x_{T})+\tau\sum_{k=t}^{T-1}\log\pi_{\phi}(x_{k+1}|x_{k})+\tau\sum_{k=t}^{T-1}\frac{1}{2s_{k}^{2}}\|x_{k+1}-x_{k}\|^{2}\,\Big|\,x_{t}\right]","The value function \(V_{\psi}^{t}(\mathbf{x}_{t})\) gives the expected sum of future terminal and running costs, starting from state \(\mathbf{x}_{t}\) at time \(t\), under the diffusion policy \(\pi_{\phi}\)."
neurips_2024_oral_34,10,"\min_{\psi}E_{x_{t},x_{t+1}\sim\pi}[(sg[V_{\psi}^{t+1}(x_{t+1})]+\tau\log\pi_{\phi}(x_{t+1}|x _{t})+\frac{\tau}{2s_{t}^{2}} || x_{t}-x_{t+1} || ^{2}-V_{\psi}^ {t}(x_{t}))^{2}]",where \(\text{sg}[\cdot]\) denotes a stop-gradient operator indicating that gradient is not computed for the term,\min_{\psi}E_{\pi_{\phi}(x_{0:T})}\left[\sum_{t=0}^{T-1}\left(V_{\psi}^{t}(x_{t})-\left(\tau\log\pi_{\phi}(x_{t+1}|x_{t})+\frac{\tau}{2s_{t}^{2}}\|x_{t+1}-x_{t}\|^{2}+V_{\psi}^{t+1}(x_{t+1})\right)\right)^{2}\right],The value function parameters $\psi$ are updated by minimizing the squared Bellman residual over trajectories sampled from the current diffusion model.
neurips_2024_oral_34,11,\min_{\phi}E_{\pi_{\phi}(x_{t+1}|x_{t})}[V_{\psi}^{t+1}(x_{t+1})+\tau\log\pi_{\phi}(x_{t+1}|x _{t})+\frac{\tau}{2s_{t}^{2}} || x_{t}-x_{t+1} || ^{2}\bigg{|}x_{t}],,\min_{\phi}E_{x_{t}\sim\pi}\left[E_{x_{t+1}\sim\pi_{\phi}(\cdot|x_{t})}\left[sg[V_{\psi}^{t+1}(x_{t+1})]+\tau\log\pi_{\phi}(x_{t+1}|x_{t})+\frac{\tau}{2s_{t}^{2}}\|x_{t+1}-x_{t}\|^{2}\right]\right],"The diffusion model parameters $\phi$ are updated by minimizing the expected sum of the next-state value function and the running costs, conditioned on the current state $\mathbf{x}_{t}$."
neurips_2024_oral_34,12,"\min_{\psi}E_{x_{t},x_{t+1}\sim\pi}[(sg[V_{\psi}(x_{t+1})]+R(t)-V_{\psi}(x_{t}))^{2}]",,"\min_{\psi}E_{x_{t},x_{t+1}\sim\pi}\left[\left(sg[V_{\psi}(x_{t+1})]+R(t)-V_{\psi}(x_{t})\right)^{2}\right]",where \(R(t)\) is a time-dependent running cost function used in place of the original running costs for image generation experiments.
neurips_2024_oral_35,1,"varrowCrossAttention(Q=\{v\},K=\{p_{i}^{v}\}_{i=1}^{m}+\{v\},V=\{ p_{i}^{v}\}_{i=1}^{m}+\{v\})","Where \(v\) denotes a 3D voxel feature, and \(p_{i}^{v}\) denotes its projected 2D pixel feature from view \(i\), which is a concatenation of the RGB feature \(f_{i}^{v}\), the normal feature \(g_{i}^{v}\), and the RGB and normal values \(c_{i}^{v}\) and \(n_{i}^{v}\), respectively","f_v'=CrossAttn\left(q_v,\left\{k_v,k_{v,1},\ldots,k_{v,m}\right\},\left\{v_v,v_{v,1},\ldots,v_{v,m}\right\}\right)","The updated 3D voxel feature $\mathbf{f}_v'$ is computed by projection-aware cross-attention, where the query $\mathbf{q}_v$ is derived from the 3D voxel feature, and the keys and values are formed from the voxel feature and its $m$ projected 2D features."
neurips_2024_oral_35,2,L=\lambda_{1}L_{MSE}^{color}+\lambda_{2 }L_{LPIPS}^{color}+\lambda_{3}L_{MSE}^{normal}+\lambda_{4}L_{LPIPS}^{normal}+\lambda_{5}L_{occ}+\lambda_{6}L _{SDF},"where \(L_{\mathrm{occ}}\) and \(L_{\mathrm{SDF}}\) are MSE losses for occupancy and SDF volumes, and \(\lambda_{i}\) denotes the weight of each loss term",L_{total}=\lambda_{SDF}L_{SDF}+\lambda_{RGB}L_{RGB}+\lambda_{normal}L_{normal}+\lambda_{perc}L_{perc},"The total training loss \(\mathcal{L}_{\text{total}}\) is a weighted sum of the SDF loss, RGB rendering loss, normal rendering loss, and perceptual loss, with weights \(\lambda_{\text{SDF}}, \lambda_{\text{RGB}}, \lambda_{\text{normal}}, \lambda_{\text{perc}}\), respectively."
neurips_2024_oral_40,1,"m_{Ada}(\varepsilon,\delta)=O\Bigg{(}\frac{d\ln(\frac{d}{\varepsilon\gamma})\ln(\frac{1}{\varepsilon\gamma})}{\gamma^{2}\varepsilon}+\frac{\ln(1/\delta)}{\varepsilon}\Bigg{)}",,"m_{Ada}(\varepsilon,\delta)=O\left(\frac{d\log(1/\varepsilon)+\log(1/\delta)}{\varepsilon\gamma^2}\right)","The sample complexity of AdaBoost, denoted \(m_{\mathrm{Ada}}(\varepsilon, \delta)\), is upper bounded in terms of the VC-dimension \(d\), target error \(\varepsilon\), confidence parameter \(\delta\), and weak learning advantage \(\gamma\)."
neurips_2024_oral_40,2,L_{D}(f)=O\bigg{(}\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},,"L_{D}(f)\leq\varepsilon_{Ada}(m,\delta)=O\left(\sqrt{\frac{d\ln(m/d)\ln m+\ln(1/\delta)}{m\gamma^2}}\right)","The loss of the output classifier \(f\) is upper bounded by \(\varepsilon_{\mathrm{Ada}}(m, \delta)\), which depends on the number of samples \(m\), the VC-dimension \(d\), the weak learner advantage \(\gamma\), and the confidence parameter \(\delta\)."
neurips_2024_oral_40,3,p=O\bigg{(}\frac{\ln m}{\gamma^{2}R}\bigg{)}\qquadand\qquad t=e^{O(dR)}\cdot\ln\frac{\ln m}{\delta\gamma^{2}},,"(p, t)=\left( O\left(\frac{\gamma^{-2}\ln m}{R}\right),\\exp\left( O(d R^2)\right)\ln(1/\gamma)\right)","The parallel complexity \((p, t)\) of Algorithm 1 is given in terms of the margin parameter \(\gamma\), the sample size \(m\), the VC-dimension \(d\), and a tunable parameter \(R\)."
neurips_2024_oral_40,4,L_{D}(A_{R}(S))=O\bigg{(}\frac {d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},,L_{D}(f)=O\bigg{(}\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},"The expected loss of the output hypothesis \(f\) is bounded by the stated expression, matching the sample complexity of AdaBoost up to logarithmic factors."
neurips_2024_oral_40,5,p\ln t=O\bigg{(}\frac{d\ln m}{\gamma^{2}}\bigg{)},,p\cdot\ln t=O\left(\frac{d\ln(m)\ln(m/d)}{\gamma^{2}}\right),The product of the number of rounds and the logarithm of the parallelism per round matches the optimal tradeoff up to logarithmic factors.
neurips_2024_oral_40,6,"p\geq\frac{4\ln m}{\gamma^{2}R},\qquadand\qquad t\geq e^{16C_{ a}dR}\cdot R\ln\frac{pR}{\delta}",,p\ln t=\Omega(\gamma^{-2}d\ln m),The lower bound states that the product of the number of rounds and the logarithm of the parallel queries per round must be at least proportional to \(\gamma^{-2}d\ln m\).
neurips_2024_oral_40,7,L_{D}(sign(g))\leq C\cdot\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m},,L_{D}(sign(g))\leq C\cdot\frac{d\ln(m/d)+\ln(1/\delta)}{m\gamma^2},"The generalization error of the voting classifier \(\operatorname{sign}(g)\) is bounded in terms of the VC-dimension \(d\), sample size \(m\), margin \(\gamma\), and confidence parameter \(\delta\)."
neurips_2024_oral_40,8,|L_{D}(h)-L_{T}(h)|\leq\varepsilon,where \(\mathcal{L}_{T}(h)\coloneqq\mathcal{L}_{\mathrm{Uniform}(T)}(h)\) is the empirical loss of \(h\) on \(T\),\left|\frac{1}{|T|}\sum_{x\in T}I[h(x)\neq c(x)]-L_{D}(h)\right|\leq\varepsilon,"An $\varepsilon$-approximation is a multiset $T$ such that, for all $h \in \mathcal{H}$, the empirical error of $h$ on $T$ approximates its true error under $\mathcal{D}$ within $\varepsilon$."
neurips_2024_oral_40,9,"D_{\infty}(D_{r},D_{0})\coloneqq\ln\bigl{(}\sup_{x\inX}D_{ r}(x)/D_{0}(x)\bigr{)}",,"D_{\infty}(P, Q)\coloneqq\max_{x\inX}\left|\ln\frac{P(x)}{Q(x)}\right|","where \(D_{\infty}(P, Q)\) is the max-divergence between distributions \(P\) and \(Q\)."
neurips_2024_oral_40,10,KL(D_{r}\parallel D_{0})\coloneqq\sum_{x\inX}D_{r}(x)\ln\frac{D_{r}(x)}{D_{0}(x)},,"KL(D_{r}\,\|\,D_{0})\coloneqq\sum_{x\inX} D_{r}(x)\ln\frac{D_{r}(x)}{D_{0}(x)}","where \(\mathrm{KL}(D_{r}\,\|\,D_{0})\) denotes the Kullback-Leibler divergence from \(D_{0}\) to \(D_{r}\)."
neurips_2024_oral_40,11,\lnE_{P}\big{[}e^{X}\big{]}\geqE_{Q}[X]-KL(Q\parallel P),,E_{P}[X]\leqKL(P\parallel Q)+\lnE_{Q}[e^{X}],"For any real-valued random variable \(\mathbf{X}\) and probability distributions \(P\) and \(Q\) with the same support, the expected value of \(\mathbf{X}\) under \(P\) is bounded by the KL divergence between \(P\) and \(Q\) plus the logarithm of the moment generating function of \(\mathbf{X}\) under \(Q\)."
neurips_2024_oral_40,12,KL(D\parallel\tilde{D})\leq 4\gamma^{2}R,,KL(D\parallel\tilde{D})\leq\frac{\gamma^2 n}{32}-C_{n} d\ln\left(\frac{2e n}{d\gamma}\right),"If the KL divergence between \(D\) and \(\tilde{D}\) is at most \(\frac{\gamma^2 n}{32} - C_{\mathrm{n}} d \ln\left(\frac{2e n}{d \gamma}\right)\), then with high probability, a random sample of size \(n\) from \(\tilde{D}\) is a \(\gamma/2\)-approximation for \(D\), \(c\), and \(\mathcal{H}\)."
neurips_2024_oral_40,13,\Pr_{T\sim\tilde{D}^{n}}[T\inG]\geq\exp(-16C_{n}dR),,\Pr_{T\sim\tilde{D}^{n}}[T\inG]\geq 1-\exp(-2R),"The probability that a sample \(\mathbf{T}\) drawn from \(\tilde{D}^{n}\) is a \(\gamma/2\)-approximation for \(D\), \(c\), and \(\mathcal{H}\) is at least \(1-\exp(-2R)\), provided the KL divergence between \(D\) and \(\tilde{D}\) is at most \(4\gamma^{2}R\) and \(n\) is sufficiently large."
neurips_2024_oral_40,14,\prod_{r=1}^{R}Z_{kR+r}<\exp(-\gamma^{2}R/2),,\prod_{r=1}^{R}Z_{kR+r}\leq\exp(-\alpha\gamma R/2),The product of the normalization factors over \(R\) boosting steps is at most \(\exp(-\alpha\gamma R/2)\).
neurips_2024_oral_41,1,\min_{x\inR^{d}_{c}}\phi(x),where \(\phi:\mathbb{R}^{d}\rightarrow\mathbb{R}\) is a differentiable function bounded from below (e,\min_{x\inR^d}\;\phi(x),"Here, \(x \in \mathbb{R}^d\) is the optimization variable and \(\phi(x)\) is the objective (loss) function to be minimized."
neurips_2024_oral_41,2,x_{i}=x_{j}\quad\Leftrightarrow\quad\exists k\;:\;i\in P_{k} and j\in P_{k},,"P_{j}(x) :=\{ i\in\{1,\ldots, d\} : x_{i}=v_{j}\},\quad j=1,\ldots, c",where \(v_{j}\) are the \(c\) distinct values taken by the entries of \(x\).
neurips_2024_oral_41,3,"M_{P}(x)=M_{P,\phi}(x):=\arg\min_{y\inR^{d}}\{\phi(y)\,:\,P(y)\sqsupseteq P (x)\}",,V^{*}(x) :=\arg\min_{v\inR^{c}}\phi\left(\sum_{k=1}^{c} v_{k}1_{P_{k}(x)}\right),"\(V^{*}(x)\) denotes the optimal assignment of values to the \(c\) clusters (partitions) defined by \(P(x)\), minimizing \(\phi\) over all possible values \(v\in\mathbb{R}^{c}\)."
neurips_2024_oral_41,4,"M_{V}(y)=M_{V,\phi}(y):=\arg\min_{x\inR^{d}}\{\phi(x)\,:\,V(x)\subseteq V (y)\}",,"M_{V}(y)=M_{V,\phi}(y):=\arg\min_{x\inR^{d}_{c}}\{\phi(x)\,:\,V(x)=V(y)\}","Given \(y\in\mathbb{R}^{d}_{c}\), \(M_{V}(y)\) is the minimizer of \(\phi\) over all vectors in \(\mathbb{R}^{d}_{c}\) that share the same set of unique values as \(y\)."
neurips_2024_oral_41,5,"\phi(x)\approx\widetilde{\phi}_{y}(x):=\phi(y)+\langle\nabla\phi(y),x-y\rangle+\tfrac{L}{2}\norm{x-y}^{2}",where \(L>0\) is a sufficiently large constant,\phi(x)\approx\phi(y)+\nabla\phi(y)^{\top}(x-y)+\frac{1}{2}(x-y)^{\top} H(y) (x-y),where \(\nabla \phi(y)\) is the gradient and \(H(y)\) is the Hessian of \(\phi\) evaluated at \(y\).
neurips_2024_oral_41,6,"M_{V,\phi}(y)\overset{\eqref{eq:v_def}}{\approx}M_{V,\widetilde{\phi}_{y}}(y )\overset{\eqref{eq:v_def}}{=}\arg\min_{x\inR^{d}}\{\widetilde{\phi}_{y}(x)\:\V(x)\subseteq V(y)\}",,M_{V}^{lin}(y) :=\arg\min_{x\inR^d}\left\{\widetilde{\phi}_y(x) : V(x)\subseteq V(y)\right\},The linearized V step mapping \(M_{V}^{\text{lin}}(y)\) minimizes the quadratic approximation \(\widetilde{\phi}_y(x)\) over all \(x\) whose unique values are a subset of those in \(y\).
neurips_2024_oral_41,7,\widehat{\phi}_{y}(x):=\norm{x-(y-\tfrac{1}{L}\nabla\phi(y))}^{2}=\norm{x-y^{+}}^{2}=\sum\limits_{i=1}^{d}(x_{i}-y_{i}^{+})^{2},,"\widehat{\phi}_{y}(x):=\norm{x-y^{+}}^{2},\quadwhere\quad y^{+}:=y-\frac{1}{L}\nabla\phi(y)",\(\widehat{\phi}_{y}(x)\) is the squared Euclidean distance from \(x\) to the gradient step \(y^{+}\) taken from \(y\) with step size \(1/L\).
neurips_2024_oral_41,8,"x:=M_{V,\phi}(y)\approx M_{V,\widehat{\phi}_{y}}(y):=\hat{x}",,"x^{+}=M_{V,\widehat{\phi}_{y}}(y)=\arg\min_{x\inR^{d}}\left\{\norm{x-y^{+}}^{2}:V(x)\subseteq V(y)\right\}",\(x^{+}\) is the minimizer of the squared distance to \(y^{+}\) over all \(x\) whose unique values are a subset of those in \(y\).
neurips_2024_oral_41,9,"\phi(x)\leq\phi(y)+\langle\nabla\phi(y),x-y\rangle+\tfrac{L}{2}\norm{x-y}^{2},\qquad\forall x,y\inR^{d}_{\leq c}",,"\|\nabla\phi(x)-\nabla\phi(y)\|\leq L\|x-y\|\quadfor all x,y\inR^{d}_{\leq c}",where \(L > 0\) is the smoothness constant of \(\phi\) on \(\mathbb{R}^{d}_{\leq c}\).
neurips_2024_oral_41,10,"x^{+}:=M_{V,\widehat{\phi}_{y,S^{k}}}(y):=\operatorname*{arg\,min} _{x\inR^{d}}\{\widehat{\phi}_{y,S^{k}}(x)\:\V(x)\subseteq V(y)\} || where\quad\widehat{\phi}_{y,S^{k}}(x):=\|x-(y-\frac {1}{L_{S^{k}}}Z^{k}(\nabla\phi(y)))\|^{2}",,"\widehat{\phi}_{y,S^{k}}(x):=\left\|x-\left(y-\frac{1}{L}Z^{k}\left(\nabla\phi(y)\right)\right)\right\|^{2}","where \(\widehat{\phi}_{y,\mathcal{S}^{k}}(x)\) is the squared distance between \(x\) and the point obtained by taking a gradient step from \(y\) only in the coordinates indexed by \(\mathcal{S}^{k}\)."
neurips_2024_oral_42,1,"\min_{Q}\max_{\pi}\alpha(E_{\hat{s}\simD_{img},\alpha\sim\pi(a|\hat{s})}[Q(\hat{s},a)]-E_{\hat{s},\hat{a}\simD_{img}}[Q(\hat{s},\hat{a})]+R(\pi)) || +E_{\hat{s},\hat{a}\simD_{img}}[(Q(\hat{s},\hat{a})-\hat{B}^{\pi}\hat{Q}(\hat{s},\hat{a}))^{2}]",,"L_{CQL}=E_{(s, a)\simD_{img}}\left[ Q(s, a)-\log\sum_{a'}\exp(Q(s, a'))\right]",The CQL loss $\mathcal{L}_{\mathrm{CQL}}$ encourages conservative Q-values by penalizing overestimation on unseen actions in the offline dataset $\mathcal{D}_{\mathrm{img}}$.
neurips_2024_oral_42,2,"\hat{B}_{T}^{\pi}\hat{Q}(\hat{s},\hat{a}):=\hat{r}-\eta_{R }R_{R}(\hat{s},\hat{a})-\eta_{T}R_{T}(\hat{s},\hat{a})+\gammaE_{\hat{s}^{\prime}\simD_{img},a^{\prime}\sim\pi_{k}(a^{\prime}|\hat{s}^{\prime})}[Q(\hat{s}^{\prime},a^{\prime})]","where \(\hat{s}^{\prime}\sim\mathcal{D}_{\mathrm{img}}\) is to sample the next state given \(\hat{s},\hat{a}\), \(\eta_{R}\) and \(\eta_{T}\) are two hyper-parameters to control the weighting of the uncertainty terms","\hat{Q}^{k+1}(\hat{s},\hat{a})=\hat{r}(\hat{s},\hat{a})-R_{R}(\hat{s},\hat{a})+\gammaE_{\hat{s}'\sim\hat{P}(\cdot|\hat{s},\hat{a})}\left[\max_{a'}\hat{Q}^{k}(\hat{s}', a')-R_{T}(\hat{s}', a')\right]",The Q-value update incorporates reward and transition uncertainty regularization terms \(\mathcal{R}_{R}\) and \(\mathcal{R}_{T}\) during the backup step.
neurips_2024_oral_48,1,"x_{0}=x,\quadx_{\ell}=\sigma_{\ell}(W _{\ell}x_{\ell-1}+b_{\ell}),\quad u_{G,\theta}(x)=x_{L}","where \(L\): the number of layers, \(\mathbf{W}_{i}\in\mathbb{R}^{d_{\ell}\times d_{\ell-1}}\): the weights of the NN, \(\mathbf{b}_{i}\in\mathbb{R}^{d_{\ell}}\): the biases of the NN, \(d_{0}=d_{\text{in}}\), \(d_{L}=d_{\text{out}}\), \(\sigma_{\ell}:\mathbb{R}\to\mathbb{R}\) activation functions applied element-wise","u_{G,\theta}(x)=W_L\sigma\left(W_{L-1}\cdots\sigma\left(W_1x\right)\cdots\right)",A feedforward neural network function applying a sequence of linear transformations and nonlinearities to input \(\mathbf{x}\).
neurips_2024_oral_48,2,"W_{\ell}^{\prime}=P_{\ell}W_{\ell}P_{\ell-1}^{-1},\,b_{\ell}^{\prime}=P_{\ell}b_{\ell}\Longrightarrow(W_{\ell}^{\prime},b_{\ell}^{\prime})_ {\ell=1}^{L}=\theta^{\prime}\simeq\theta=(W_ {\ell},b_{\ell})_{\ell=1}^{L}","where \(\ell\in\{1,\ldots,L\}\), \(\mathbf{P}_{0}=\mathbf{P}_{L}=\mathbf{I}\) and \(\mathbf{P}_{\ell}\in\mathbb{R}^{d_{\ell}\times d_{\ell}}\) are arbitrary permutation matrices","u_{G,\theta}(x)=u_{G,\,\psi(\theta)}(x),\quad\forall\psi\in\Psi_{perm},\\forallx\inX",where \(\Psi_{\text{perm}}\) is the set of all hidden neuron permutation symmetries for the fixed computational graph \(G\).
neurips_2024_oral_48,3,"h_{V}^{0}(i)=INIT_{V}(x_{V}(i )),\quadh_{E}^{0}(i,j)=INIT_{E}(x_{ E}(i,j))",,"h_i^{(t+1)}=\phi_{node}\left(h_i^{(t)},\,\square_{j\inN(i)}\,\phi_{edge}\left(h_i^{(t)},\,h_j^{(t)},\,e_{ji}\right)\right)","where \(\mathbf{h}_i^{(t)}\) is the feature of node \(i\) at iteration \(t\), \(\mathbf{e}_{ji}\) is the feature of edge \((j,i)\), \(\mathcal{N}(i)\) is the set of neighbors of \(i\), \(\phi_{\text{node}}\) and \(\phi_{\text{edge}}\) are learnable functions, and \(\square\) is a permutation-invariant aggregation operator."
neurips_2024_oral_48,4,"m_{V}^{t}(i)=\bigoplus_{j\inN(i)}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!where\(h_{V}^{i},h_{E}^{i}\) are vertex and edge representations at iteration\(t\) and\(h_{G}\) is the overall graph (NN) representation. INIT, MSG, UPD are general function approximators (e.g. MLPs), while READ is a permutation invariant aggregator (e.g. DeepSets [81]). The above equations have appeared with several variations in the literature, e.g. in some cases the edge representations are not updated or the readout input involve edge representations as well. Another frequent strategy is to use _positional encodings_\(p_{V},p_{E}\) to break undesired symmetries. In FFNNs, Eq. (2) reveals that input and output vertices are not permutable, while vertices cannot be permuted across layers. Therefore, vertices (or edges) that are permutable share the same positional encoding (see Appendix A.1.2 for more details).**Remark:**Although, typically, the neighbourhood\(N(i)\) contains both incoming and outgoing edges, in Section 5 we will illustrate our method using only incoming edges: _forward neighbourhood_\(N_{FW}(i)=\{j\inV\midlayer\,(i)- layer\,(j)=1\}\) and _backward_ where layer\((i)\) gives the layer neuron\(i\) belongs. Backward neighbourhoods\(N_{BW}(i)\) are defined defined similarly. In Appendix A.2, we show a more elaborate _bidirectional version_ of our method, with both neighbourhoods considered. ## 4 Scaling symmetries in Feedforward Neural Networks**Scaling symmetries (activation functions).**Intuitively, permutation symmetries stem from the _graph structure_ of neural networks, or put differently, from the fact that hidden neurons do not possess any inherent ordering. Apart from the affine layers\(W_{\ell}\) that give rise to the graph structure, it is frequently the case that**activation functions**\(\sigma_{\ell}\) have inherent symmetries that are bestowed to the NN. Let us dive into certain illustrative examples: for the ReLU activation\(\sigma(x)=\max(x,0)\) it holds that\(\sigma(ax)=\max(ax,0)=a\max(x,0),\\forall a>0\). For the tanh and sine activations\(\sigma(x)=\tanh(x)\),\(\sigma(x)=\sin(x)\) respectively, it holds that\(\sigma(ax)=a\sigma(x),\\forall a\in\{-1,1\}\). In a slightly more complex example, polynomial activations\(\sigma(x)=x^{k}\), we have\(\sigma(ax)=a^{d}\sigma(x)\), i.e. the multiplier differs between input and output. In general, we will be talking about _scaling symmetries_ whenever there exist pairs\((a,b)\) for which it holds that\(\sigma(ax)=b\sigma(x)\). To see how such properties affect NN symmetries, let us focus on FFNNs (see Appendix A.3 for CNNs): for a neuron\(i\) (we omit layer subscripts) we have\(\sigma\big{(}aW(i,:)x+ab(i)\big{)}=\textit{b}\big{(}W(i,:)x+b(i)\big{)}\), i.e. _multiplying its bias and all incoming weights with a constant a results in scaling its output with a corresponding constant\(b\)_. Generalising this to linear transformations, we may ask the following: which are the pairs of matrices\((A,B)\) for which we have\(\sigma\big{(}AWx+Ab\big{)}=B\sigma\big{(}Wx+b\big{)}\)? Godfrey et al. [25] provide an answer for _any activation that respects certain conditions_. We restate here their most important results:**Proposition 4.1**(Lemma 3.1. and Theorem E.14 from [25]).: _Consider an activation function\(\sigma:R\toR\). Under mild conditions,5 the following hold:_ Footnote 5: See Appendix A.7.1 for the precise statement and more details about\(\phi_{\sigma,d}\).*_For any_\(d\inN^{+}\)_, there exists a (non-empty) group of invertible matrices defined as:_\(I_{\sigma,d}=\{A\inR^{d\times d}: invertible\mid\exists\B\inR^{d\times d} invertible, such that: \sigma(Ax)=B\sigma(x)\}\) _(_intertwiner group_)_, and a mapping function_\(\phi_{\sigma,d}\) _such that_\(B=\phi_{\sigma,d}(A)\)_._*_Every_\(A\in I_{\sigma,d}\) _is of the form_\(PQ\)_, where_\(P\)_: permutation matrix and_\(Q=\textit{diag}\big{(}q_{1},\ldots q_{d}\big{)}\) _diagonal, with_\(q_{i}\in D_{\sigma}=\{a\inR\setminus\{0\}\mid\sigma(ax)=\phi_{\sigma,1}(a)\sigma(x)\}\)_: the 1-dimensional group, and_\(\phi_{\sigma,d}(A)=P\textit{diag}\big{(}\phi_{\sigma,1}(q_{1} ),\ldots\phi_{\sigma,1}(q_{d})\big{)}\)_._ This is a powerful result that completely answers the question above for most practical activation functions. Importantly, not only does it recover permutation symmetries, but also reveals symmetries to diagonal matrix groups, which can be identified by solely examining\(\phi_{\sigma,1}\), i.e. the one-dimensional case and the set\(D_{\sigma}\) (easily proved to be a group) we have already discussed in our examples above. Using this statement, Godfrey et al. [25] characterised various activation functions (or recovered existing results), e.g. ReLU:\(I_{\sigma,d}\) contains**generalised permutation matrices with positive entries**of the form\(PQ\),\(Q=diag(q_{1},\ldots,q_{d})\),\(q_{i}>0\) and\(\phi_{\sigma,d}(PQ)=PQ\)[56]. Additionally, here we characterise the intertwiner group of sine (used in the popular SIREN architecture [70] for INRs). Not surprisingly, it has the same intertwiner group with tanh [11, 21] (we also recover this here using Proposition 4.1). Formally, (proof in Appendix A.7.1):**Corollary 4.2**.: _Hyperbolic tangent\(\sigma(x)=\tanh(x)\) and sine activation\(\sigma(x)=\sin(\omega x)\), satisfy the conditions of Proposition 4.1, when (for the latter)\(\omega\neq k\pi,k\inZ\). Additionally,\(I_{\sigma,d}\) contains**signed permutation matrices**of the form\(PQ\), with\(Q=diag(q_{1},\ldots,q_{d})\),\(q_{i}=\pm 1\) and\(\phi_{\sigma_{d}}(PQ)=PQ\)._It is straightforward to see that the symmetries of Proposition 4.1, induce equivalent parameterisations for FNNs. In particular, it follows directly from Proposition 3.4. in [25], that for activation functions\(\sigma_{\ell}\) satisfying the conditions of Proposition 4.1 and when\(\phi_{\sigma,\ell}(Q)=Q\), we have that:\[W^{\prime}_{\ell}=P_{\ell}Q_{\ell}W_{\ell}Q_{\ell-1}^{-1}P_{\ell-1}^{-1},\;b^{\prime}_{\ell}=P_{\ell}Q_{\ell}b_{\ell}\implies(W^{\prime }_{\ell},b^{\prime}_{\ell})_{\ell=1}^{L}=\theta^{\prime}\simeq\theta=(W_{\ell},b_{\ell})_{\ell=1}^{L}","where again \(\ell\in\{1,\ldots,L\}\), \(\mathbf{P}_{0}=\mathbf{Q}_{0}=\mathbf{P}_{L}=\mathbf{Q}_{L}=\mathbf{I}\)","h_{V}^{t+1}(i)=UPD_{V}\left(h_{V}^{t}(i),\left\{h_{E}^{t}(i,j),h_{V}^{t}(j)\right\}_{j\inN(i)}\right),\quadh_{E}^{t+1}(i,j)=UPD_{E}\left(h_{E}^{t}(i,j),h_{V}^{t}(i),h_{V}^{t}(j)\right)","where \(\mathrm{UPD}_{V}\) and \(\mathrm{UPD}_{E}\) are update functions for vertex and edge features, and \(\mathcal{N}(i)\) denotes the neighbors of vertex \(i\)."
neurips_2024_oral_48,5,"h^{\prime}_{V}(i)=q_{\ell}(\pi_{\ell}(i))h_{V} (\pi_{\ell}(i)),\quad\ell=layer(i)\in\{1,\ldots,L-1\} || h^{\prime}_{E}(i,j)=q_{\ell}(\pi_{\ell}(i))h_{E} (\pi_{\ell}(i),\pi_{\ell-1}(j))q_{\ell-1}^{-1}(\pi_{\ell-1}(j)),\;\ell=layer(i)\in\{2,\ldots,L-1\}",,"h_{V}^{\prime}(i)=q_{i}\,h_{V}(P^{-1}(i)),\quadh_{E}^{\prime}(i,j)=q_{i}\,h_{E}(P^{-1}(i),P^{-1}(j))",where \(P\) is the permutation and \(q_{i}\) is the scaling factor associated with neuron \(i\).
neurips_2024_oral_48,6,"g_{i}\big{(}q_{1}x_{1},\ldots,q_{n}x_{n}\big{)}=q_{i}g_{i}(x_{1},\ldots,x_{n}\big{)},\forall q_{i}\in D_{i},i\in\{1,\ldots,n\}",where \(D_{i}\) a 1-dimensional scaling group as defined in Proposition 4,"f(h_{V}(i))=f(q_{\ell}(i)h_{V}(i))=f(h_{V}(i)),\quad\forall q_{\ell}(i)\in D_{\sigma}",where \(f\) is a function that is invariant to scaling of the vertex representation \(\mathbf{h}_{V}(i)\) by any \(q_{\ell}(i)\) in the group \(D_{\sigma}\).
neurips_2024_oral_48,7,"ScaleInv^{k}(X)=\rho^{k}(\tilde{x }_{1},\ldots,\tilde{x}_{n})",,f(x)=A\cdot h(x),where \(h(\mathbf{x})\) is a scale-invariant function and \(\mathbf{A}\) is a learnable linear transformation.
neurips_2024_oral_48,8,"ScaleEq=f^{K}\circ\cdots\circf^{1},\;f^{k}(X)=\big{(}\Gamma^{k}_{1}x_{1},\ldots,\Gamma^{k}_{n}x_{n}\big{)}\odotScalelInv^{k }(X)",,ScaleEquiv^{k}(X)=ScaleInv^{k}(X)\odotX,where \(\odot\) denotes elementwise multiplication and \(\mathsf{ScaleInv}^{k}\) is a scale-invariant function as defined previously.
neurips_2024_oral_48,9,"g\big{(}q_{1}x_{1},\ldots q_{n}x_{n}\big{)}=g(x_{1},\ldotsx_{n})\prod_{i=1}^{n}q_{i},\forall q_{i}\in D_{i}",,"g\big(q_{1}x_{1},\ldots,q_{n}x_{n}\big)=q_{o}g(x_{1},\ldots,x_{n}),\quad\forall q_{i}\in D_{i},\,q_{o}\in D_{o}","where \(D_{i}, D_{o}\) are scaling groups for the inputs and output, respectively, and \(g\) is equivariant to input scalings mapping to an output scaling by \(q_{o}\)."
neurips_2024_oral_48,10,"ReScaleEq(x_{1},\ldotsx_{n})=ScaleEq\big{(}vec(\textbf{X}_{n})\big{)}",,"RescaleEq(x_1,\ldots,x_n)=\rho\left(x_1\otimes\cdots\otimesx_n\right)","where \(\rho\) is a universal approximator (e.g., an MLP) acting on the outer product tensor of the input vectors."
neurips_2024_oral_48,11,"MSG_{V}(x,y,e)=ScaleEq ([x,ReScaleEq(y,e) ])","where \([\cdot,\cdot]\) denotes concatenation, \(\mathsf{ReScaleEq}(q_{y}\mathbf{y},q_{x}q_{y}^{-1}\mathbf{e})=q_{x}\mathsf{ ReScaleEq}(\mathbf{y},\mathbf{e})\)","MSG_{V}(x,y,e)=ReScaleEq\big(x,e\odoty\big)",The message function is defined as a rescale equivariant network applied to the central vertex features and the elementwise product of the edge and neighbor features.
neurips_2024_oral_48,12,"UPD_{V}(x,m)=ScaleEq( [x,m])",,"UPD_{V}(x,m)=ScaleEq([x,m])",The vertex update function is implemented as a scale equivariant network applied to the concatenation of the current vertex representation \(\mathbf{x}\) and the aggregated message \(\mathbf{m}\).
neurips_2024_oral_48,13,"READ_{V}(X):=DeepSets(\tilde{x}_{1},\ldots,\tilde{x}_{n}),\quad\tilde{x}_{ i}=canon_{i}(x_{i}) or \tilde{x}_{i}=symm_{i}(x_{i})",,"READ(\{x_{i}\}_{i=1}^{n})=\rho(canon(x_1),\ldots,canon(x_n))",The readout function aggregates canonicalised (or symmetrised) vertex representations using a permutation-invariant function \(\rho\).
neurips_2024_oral_54,1,"V^{\pi}(s):=E[\sum_{t=0}^{\infty}\gamma^{t}r(s_{t},a_{t})| s_{0}=s];\quad Q^{\pi}(s,a):=E[\sum_{t=0}^{\infty}\gamma^{t}r (s_{t},a_{t})|s_{0}=s,a_{0}=a]","where \(a_{t}\sim\pi(\cdot|s_{t})\) and \(s_{t+1}\sim P(\,\cdot\,|s_{t},a_{t})\) for all \(t\geq 0\)","V^{\pi}(s)=E_{\pi}\left[\sum_{t=0}^{\infty}\gamma^t r(s_t, a_t)\mid s_0=s\right],\qquad Q^{\pi}(s,a)=E_{\pi}\left[\sum_{t=0}^{\infty}\gamma^t r(s_t, a_t)\mid s_0=s, a_0=a\right]","\(V^{\pi}(s)\) is the expected discounted cumulative reward when starting from state \(s\) and following policy \(\pi\); \(Q^{\pi}(s,a)\) is the expected discounted cumulative reward when starting from state \(s\), taking action \(a\), and then following policy \(\pi\)."
neurips_2024_oral_54,2,"(TQ)(s,a)=r(s,a)+\gamma\cdotE_{s^{\prime}\sim P(\cdot|s,a) }[\max_{a^{\prime}\inA}Q(s^{\prime},a^{\prime})]",,"TQ(s,a) :=r(s,a)+\gamma\sum_{s'\inS} P(s'|s,a)\max_{a'\inA} Q(s',a')",where \(\mathcal{T}\) is the Bellman optimality operator acting on any function \(Q:\mathcal{S}\times\mathcal{A}\to\mathbb{R}\).
neurips_2024_oral_54,3,"(T_{Z}Q)(s,a)=r(s,a)+\gamma V(Z(s,a))","where \(V(s^{\prime})=\max_{a^{\prime}\in\mathcal{A}}Q(s^{\prime},a^{\prime})\)","(T_{Z}Q)(s,a)=r(s,a)+\gamma\max_{a'\inA} Q(Z_{s,a}, a')","The random Bellman operator \(\mathcal{T}_{Z}\) applies the reward and discounted maximum Q-value at a next state \(Z_{s,a}\) sampled from \(P(\cdot|s,a)\)."
neurips_2024_oral_54,4,"ER(A;N,M):=\sup_{M=(P,r)}E[\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty }]",where the expectation is taken over the samples and any randomness in the algorithm,"ER(A;N,M):=\sup_{M}E\left[\left\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\right\|_{\infty}\right]",where the supremum is over all MDPs \(\mathcal{M}\) and the expectation is over the randomness of the samples and the algorithm.
neurips_2024_oral_54,5,"SC(A;\varepsilon,M):=|S || A|\cdot\min\{N\inN:ER(A;N,M)\leq\varepsilon\}",,"SC(A;\varepsilon,M):=\min\left\{N\inN:ER(A;N,M)\leq\varepsilon\right\}",the minimum number of samples per agent required so that the minimax error rate is at most \(\varepsilon\)
neurips_2024_oral_54,6,"SC(A;\varepsilon,M,\delta):=|S || A|\cdot\min\{N\inN:\Pr(\sup_{M}\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty}\leq\varepsilon)\geq 1-\delta\}",,"SC_{hp}(A;\varepsilon,\delta,M):=|S || A|\cdot\min\left\{N\inN:\sup_{M=(P,r)}P\left(\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty}>\varepsilon\right)\leq\delta\right\}",High-probability sample complexity: the minimum number of samples per state-action pair per agent required so that the estimated Q-function is within \(\varepsilon\) of optimal with probability at least \(1-\delta\).
neurips_2024_oral_54,7,CC_{round}(A;N):=\frac{1}{M}\sum_{m=1}^{M}C^{m}_{round}(A;N);\quadCC_{bit}(A;N ):=\frac{1}{M}\sum_{m=1}^{M}C^{m}_{bit}(A;N),,"CC_{round}(A;N,M):=\sum_{m=1}^{M}C^{m}_{round}(A;N),\quadCC_{bit}(A;N,M):=\sum_{m=1}^{M}C^{m}_{bit}(A;N)","where \(\mathsf{CC}_{\mathsf{round}}(\mathscr{A};N,M)\) is the total number of communication rounds and \(\mathsf{CC}_{\mathsf{bit}}(\mathscr{A};N,M)\) is the total number of bits uploaded by all agents under algorithm \(\mathscr{A}\) with \(N\) samples per agent."
neurips_2024_oral_54,8,Q_{t-\frac{1}{2}}^{m}=(1-\eta_{t})Q_{t-1}^{m}+\frac{\eta_{t}}{B}\sum_{b=1}^{B}T_{Zs}(Q_{t-1}^{m}),,Q_{t}^{m}=(1-\eta_{t}) Q_{t-1}^{m}+\frac{\eta_{t}}{B}\sum_{b=1}^{B}\widehat{T}_{Zs}(Q_{t-1}^{m}),"where \(Q_{t}^{m}\) is the updated Q-function estimate for agent \(m\) at iteration \(t\), \(\eta_{t}\) is the step size, \(B\) is the minibatch size, and \(\widehat{\mathcal{T}}_{\text{Zs}}(Q_{t-1}^{m})\) denotes the sample Bellman operator applied to the previous estimate."
neurips_2024_oral_54,9,"Q_{t}^{m}=\frac{1}{M}\sum_{j=1}^{M}Q_{t-\frac{1}{2}}^{j}& if t\inC,\\Q_{t-\frac{1}{2}}^{m}& otherwise.",,Q_{t}^{m}=\frac{1}{M}\sum_{m'=1}^{M} Q_{t-\frac{1}{2}}^{m'} &if  t\inC\\Q_{t-\frac{1}{2}}^{m} &otherwise,"where \(Q_{t}^{m}\) is the updated Q-function estimate for agent \(m\) at iteration \(t\), and \(\mathcal{C}\) is the set of communication rounds."
neurips_2024_oral_54,10,R=\textsf{CC}_{\textsf{round}}(A;N)\leq\frac{c_{0}}{(1-\gamma)\log ^{2}N}; or\textsf{CC}_{\textsf{left}}(A;N)\leq\frac{c_{1}|S || A|}{(1-\gamma)\log^{2}N},,N=BT,"where \(N\) is the total number of samples taken, \(B\) is the batch size, and \(T\) is the total number of updates."
neurips_2024_oral_54,11,"\textsf{ER}(A;N,M)\geq\frac{C_{\gamma}}{\log^{3}N\sqrt{N}}",,"ER(A;N,M)\geq\frac{1}{32(1-\gamma)}",The minimax error of any Federated Q-learning algorithm with intermittent communication is lower bounded by \(\frac{1}{32(1-\gamma)}\) under the stated conditions.
neurips_2024_oral_56,1,"B_{Acc=K_{1}}(t|m)=\sup_{d}\{d|Acc(t|d,m)\leq K_{1}\}","where \(Acc(t|d,m)\) represents the accuracy of the model's accuracy on task \(t\) with difficulty \(d\)","RB(m, t)=\max\left\{ d\midAcc(m, t, d)\geq K_{1}\right\}","The reasoning boundary \(\operatorname{RB}(m, t)\) is the maximum problem difficulty \(d\) where the accuracy of model \(m\) on task \(t\) remains above threshold \(K_{1}\)."
neurips_2024_oral_56,2,"B_{Acc=K_{1}}(t_{1},t_{2},\dots,t_{n}|m)\approx\frac{1}{\sum _{i=1}^{n}\frac{N_{i}}{B_{Acc=K_{1}}(t_{i}|m)-b_{i}}}",where \(\mathcal{B}_{\text{Acc}=K_{1}}(t_{i}|m)\) denotes the reasoning boundary of model \(m\) for task \(t_{i}\),"B_{Acc=K_{1}}(t_{1}, t_{2},\dots, t_{n} | m)=\min_{i=1,\dots,n}B_{Acc=K_{1}}(t_{i} | m)",The unified reasoning boundary for multiple tasks is determined by the minimum reasoning boundary among all individual tasks for a given model.
neurips_2024_oral_56,3,"B^{\texttt{CGT}}(c,p)=\frac{1}{\frac{N_{1}}{(B(c)-b_{1})}+\frac{N_{2}}{(B(p)-b_{2})}}",,"B(p, c)\approx\frac{1}{\frac{1}{B(p)}+\frac{1}{B(c)}}",The combined reasoning boundary for planning and calculation tasks is given by the harmonic mean of the individual planning boundary \(\mathcal{B}(p)\) and calculation boundary \(\mathcal{B}(c)\).
neurips_2024_oral_56,4,"B^{Tool}(c,p)=\lim_{B(c)arrow+\infty}\frac{ 1}{\frac{N_{1}}{(B(c)-b_{1})}+\frac{N_{2}}{(B(p)-b_{2})}}=\frac{B(p)-b_{2}}{N_{2}}",,"B^{\texttt{Tool}}(c,p)=\frac{1}{\frac{N_{2}}{(B(p)-b_{2})}}","where \(\mathcal{B}^{\texttt{Tool}}(c,p)\) denotes the combined reasoning boundary when calculation RB is boosted to infinity by tool usage, reducing the harmonic mean to depend solely on the planning RB."
neurips_2024_oral_57,1,"E_{t\simU[1,T],\;X^{0},C\sim q( X^{0},C)}(\|X^{0}-H(X^{t},t,C)\|^{2})","where \(t\) denotes the time step, \(\mathbf{X}^{0}=\mathbf{X}\) is the raw motion latent sequence, and \(\mathbf{X}^{t}\) is the noisy inputs generated by the diffusion forward process \(q(\mathbf{X}^{t}|\mathbf{X}^{t-1})=\mathcal{N}(\mathbf{X}^{t};\sqrt{1-\beta_{ t}}\mathbf{X}^{t-1},\beta_{t}\text{I})\)","L_{diff}=E_{X,\epsilon\simN(0,I), t}\left[\left\|\epsilon-\epsilon_\theta(X_t, t,A)\right\|_2^2\right]","The diffusion loss is the expected squared error between the true noise and the predicted noise at timestep \(t\), conditioned on the noisy motion sequence and audio features."
neurips_2024_oral_57,2,"\hat{X}^{0}=(1+\sum_{e\inC}\lambda_{e})\cdotH(X^{t},t,C)-\sum_{e\inC}\lambda_{c}\cdotH(X^{t},t,C|_{e=\emptyset})",,"C=[X^{pre},\,A^{pre};\,A,\,g,\, d,\,e]","where \(\mathbf{C}\) is the full condition vector composed of previous motion frames \(\mathbf{X}^{pre}\), previous audio features \(\mathbf{A}^{pre}\), current audio features \(\mathbf{A}\), gaze direction \(\mathbf{g}\), head distance \(d\), and emotion offset \(\mathbf{e}\)."
neurips_2024_oral_58,1,"p(x_{1},x_{2},\dots,x_{T})=\prod_{t=1}^{T}p(x_{t}\mid x_{1},x_{2},\dots,x_{t-1 })",,"p(x)=\prod_{t=1}^{T} p(x_t\mid x_{1}, x_{2},\dots, x_{t-1})",The probability of the sequence \(x\) is factorized as the product of conditional probabilities of each token given its prefix.
neurips_2024_oral_58,2,"f=E(im),\\\\\q=Q(f)","where \(im\) denotes the raw image, \(\mathcal{E}(\cdot)\) a encoder, and \(\mathcal{Q}(\cdot)\) a quantizer",q=Quantize(f),"Here, \(q\) denotes the discrete token map obtained by quantizing the image feature map \(f\)."
neurips_2024_oral_58,3,"q^{(i,j)}=(\operatorname*{arg\,min}_{v\in[V]}\|lookup(Z,v)-f^{(i,j)}\|_{2})\in[V]","where \(\text{lookup}(Z,v)\) means taking the \(v\)-th vector in codebook \(Z\)","q^{(i,j)}=\arg\min_{k\in [V]}\left\| f^{(i,j)}-Z_k\right\|_2^2","\(q^{(i,j)}\) is the code index assigned to feature vector \(f^{(i,j)}\) by finding the nearest codebook vector \(Z_k\) in Euclidean distance."
neurips_2024_oral_58,4,"\hat{f}=lookup(Z,q),\\\\\\\\\hat{im}=D(\hat{f}) || L=\|im-\hat{im}\|_{2}+\|f-\hat{f}\|_{2}+\lambda_{P}L_{P}(\hat{im})+\lambda_{G}L_{G}(\hat{im})",,L=\|im-\hat{im}\|_2^2+\lambda\|f-\hat{f}\|_2^2,"where \(\hat{f} = \text{lookup}(Z, q)\), \(\hat{im} = \mathcal{D}(\hat{f})\), and \(\lambda\) is a weighting hyperparameter."
neurips_2024_oral_58,5,"p(r_{1},r_{2},\dots,r_{K})=\prod_{k=1}^{K}p(r_{k}\mid r_{1},r_{2},\dots,r_{k-1 })","where each autoregressive unit \(r_{k}\in[V]^{h_{k}\times w_{k}}\) is the token map at scale \(k\) containing \(h_{k}\times w_{k}\) tokens, and the sequence \((r_{1},r_{2},\dots,r_{k-1})\) serves as the the ""prefix"" for \(r_{k}\)","p(r_{1},r_{2},\dots,r_{K})=\prod_{k=1}^{K} p(r_{k}\mid r_{1}, r_{2},\dots, r_{k-1})","where \(r_{k}\) denotes the token map at scale \(k\), and the likelihood is factorized over scales in a coarse-to-fine manner."
neurips_2024_oral_58,6,"w=64d,\qquad h=d,\qquad dr=0.1\cdot d/24",,"w=w_{0}+\alpha_{w}\cdot d,\\\\h=h_{0}+\alpha_{h}\cdot d,\\\\dr=dr_{0}+\alpha_{dr}\cdot d","where \(w\) is the model width, \(h\) is the number of attention heads, \(dr\) is the dropout rate, \(d\) is the model depth, and \(w_{0}, h_{0}, dr_{0}, \alpha_{w}, \alpha_{h}, \alpha_{dr}\) are scaling hyperparameters."
neurips_2024_oral_58,7,"N(d)=\underbrace{d\cdot 4w^{2}}_{self-attention}+\underbrace{d\cdot 8w^{2}} _{feed-forward}+\underbrace{d\cdot 6w^{2}}_{adaptive layernorm}=18\,dw^{2}=73728\,d^{3}",,N\approx 24 d w^{2},"where \(N\) is the total number of parameters, \(d\) is the transformer depth, and \(w\) is the model width."
neurips_2024_oral_59,1,"c^{(t+1)}(v)\gets f^{(t+1)}(c^{(t)}(v),g^{(t+1)}(\{\{c ^{(t)}(u)\mid u\inN(v)\}\}))",,"c_v^{(t+1)}=UPDATE\left(c_v^{(t)},AGGREGATE\left(\{c_u^{(t)} : u\in N(v)\}\right)\right)",The color (embedding) of node \(v\) at iteration \(t+1\) is updated by combining its current color and an aggregation of its neighbors' colors.
neurips_2024_oral_59,2,c^{(t)}(G)\coloneqq h(\{\{c^{(t)}(v)\mid v\in V(G)\}\} ),,h^{(t)}(G)=READOUT\left(\left\{c^{(t)}(v)\mid v\in V(G)\right\}\right),"\(h^{(t)}(G)\) denotes the graph-level representation after \(t\) message passing iterations, computed by applying a READOUT function to the set of node colors."
neurips_2024_oral_59,3,"N_{r}(v)\coloneqq\{p\midp simple path of length r,\,p_{1},p_{r+1}\inN(v),v\notinp\}\",,"N_{r}(v)\coloneqq\left\{ u\in V(G)\mid\exists\,p=(p_1,\ldots, p_{r+1}) simple path in  G,\, p_1=v,\, p_{r+1}=u\right\}",\(\mathcal{N}_{r}(v)\) denotes the set of nodes reachable from \(v\) via a simple path of length \(r\).
neurips_2024_oral_59,4,"c_{r}^{(t+1)}(v)arrowHASH_{r}(c_{r}^{(t)}(v),\{\{c _{r}^{(t)}(p)\midp\inN_{0}(v)\}\},\ldots,\{\{c_{r}^{(t)}(p)\midp\inN_{r}(v )\}\})",,"c_{r-\ellWL}^{(t+1)}(v)\gets f^{(t+1)}\left( c_{r-\ellWL}^{(t)}(v),\, g^{(t+1)}\left(\left\{\left\{ c_{r-\ellWL}^{(t)}(p)\midp\inN_r(v)\right\}\right\}\right)\right)",The color of node \(v\) at iteration \(t+1\) in the \(r\)-loop Weisfeiler-Leman algorithm is updated based on its previous color and the multiset of colors of all simple paths of length \(r\) in its \(r\)-neighborhood.
neurips_2024_oral_59,5,c_{r}^{(t)}(G)=HASH_{r}(\{\{c_{r}^{(t)}(v)\mid v\in V(G)\}\}\}),,c_{r}^{(t)}(G)\coloneqq h_{r}(\{\{c_{r}^{(t)}(v)\mid v\in V(G)\}\})\,"\(c_{r}^{(t)}(G)\) is the graph-level output after \(t\) iterations of the \(r\)-\(\ell\)WL algorithm, obtained by aggregating the node colors using a function \(h_{r}\)."
neurips_2024_oral_59,6,"m_{k}^{(t+1)}(v)&=f_{k}^{(t+1)}(\{\{c_{k}^{(t)}(p)\midp\inN_{k}(v)\}\}),\\c_{r}^{(t+1)}(v)&=g^{(t+1)}(c_{r}^{(t)}(v),\,m_{0 }^{(t+1)}(v),\ldots,m_{r}^{(t+1)}(v))",,"h_{r}^{(t+1)}(v)\gets f_{r}^{(t+1)}\Big(h_{r}^{(t)}(v),\; g_{r,0}^{(t+1)}\big(\{\{h_{r}^{(t)}(p)\midp\inN_{0}(v)\}\}\big),\;\ldots,\; g_{r,r}^{(t+1)}\big(\{\{h_{r}^{(t)}(p)\midp\inN_{r}(v)\}\}\big)\Big)","The node representation \(h_{r}^{(t+1)}(v)\) at iteration \(t+1\) is updated by aggregating information from all \(k\)-neighborhoods (\(k=0,\ldots,r\)) of node \(v\) via functions \(g_{r,k}^{(t+1)}\), and combining them with the previous representation using \(f_{r}^{(t+1)}\)."
neurips_2024_oral_59,7,f_{k}^{(t+1)}(\{\{c_{k}^{(t)}(p)\midp\inN_{k}(v)\}\}):=f(\sum_{p\inN_{k}(v)}g(p)),,\sum_{p\inN_{k}(v)}\phi_{k}^{(t)}\left(c_{k}^{(t)}(p)\right),"The sum aggregates transformed colorings of all simple paths \(\mathbf{p}\) in the \(k\)-neighborhood \(\mathcal{N}_{k}(v)\) of node \(v\) at iteration \(t\), using a learnable function \(\phi_{k}^{(t)}\)."
neurips_2024_oral_59,8,x_{r}^{(t+1)}(v):=MLP(x_{r}^{(t)}(v)+(1+\varepsilon_{0})\sum_{u\inN_{0}(v)}x_{r}^{(t)}(u)+\sum_{k=1}^{r}(1+\varepsilon_{k})\sum_{p\inN_{k}(v)}GIN_{k}(p)),,f_{k}^{(t+1)}(\{\{c_{k}^{(t)}(p)\midp\inN_{k}(v)\}\}):=MLP\left(\sum_{p\inN_{k}(v)}GIN(p)\right),The message function in \(r\)-\(\ell\)GIN aggregates GIN-encoded path features via summation and applies an MLP for update.
neurips_2024_oral_6,1,"f_{z}(a_{1},a_{2})=E_{i\simS(z)\,,\,A_{1}\simB(a_{1})\,,\,A_{2}\simB(a_{2})}\Big{[}g_{i}(A_{1},A_{2 })\Big{]}=\sum_{i=0}^{15}\frac{\exp(z_{i})}{\sum_{j}\exp(z_{j})}\cdot g_{i}(a_ {1},a_{2})\",,"DLG(a_1, a_2;z)=\sum_{k=0}^{15}softmax(z)_k\cdot g_k(a_1, a_2)","The differentiable logic gate (DLG) output is the weighted sum over all 16 logic gate outputs, where weights are given by the softmax of the trainable parameter vector $\mathbf{z}$."
neurips_2024_oral_6,2,"f_{3}(\,f_{1}(a_{1},a_{2}),f_{2}(a_{3},a_{4})\,)",,"f_{tree}(a_{1}, a_{2}, a_{3}, a_{4})=f_{z_1}\left(f_{z_2}(a_{1}, a_{2}),\; f_{z_3}(a_{3}, a_{4})\right)","The output of a depth-2 logic gate tree kernel applied to inputs \(a_{1}, a_{2}, a_{3}, a_{4}\), where each internal node is a differentiable logic gate parameterized by \(\mathbf{z}_1, \mathbf{z}_2, \mathbf{z}_3\)."
neurips_2024_oral_6,3,"A^{\prime}[k,i,j]=f_{3}^{k}\big{(}f_{1}^{k}\big{(}A\big{[}C_{M}[k,\!1]\!,C_{H}[k,\!1]\!+\!i,C_{W}[k,\!1]\!+\! j\big{]},A\big{[}C_{M}[k,\!2]\!,C_{H}[k,\!2]\!+\!i,C_{W}[k,\!2]\!+\!j\big{]}\big{)} || \qquad\qquad\qquad f_{2}^{k}\big{(}A\big{[}C_{M} [k,\!3]\!,C_{H}[k,\!3]\!+\!i,C_{W}[k,\!3]\!+\!j\big{]},A\big{[}C_{M}[k,\!4]\!,C_{H}[k,\!4]\!+\!i,C _{W}[k,\!4]\!+\!j\big{]}\big{)}\big{)}",,"Y_{k,i,j}=f_{3}\Big( f_{1}\big(A_{C_{M}[k,1],\,i+C_{H}[k,1],\,j+C_{W}[k,1]},\;A_{C_{M}[k,2],\,i+C_{H}[k,2],\,j+C_{W}[k,2]}\big),\; f_{2}\big(A_{C_{M}[k,3],\,i+C_{H}[k,3],\,j+C_{W}[k,3]},\;A_{C_{M}[k,4],\,i+C_{H}[k,4],\,j+C_{W}[k,4]}\big)\Big)","The output activation at channel \(k\) and spatial position \((i,j)\) is computed by applying the logic tree kernel to the selected input activations according to the connection indices."
neurips_2024_oral_60,1,Y^{l}=ESA(LN(X^{l}))+X^{l} || X^{l+1}=SwiGLU(LN(Y^{l}))+Y^{l},,X^{\nicefrac{L}{2}}=SelfDecoder(X^{0}),The intermediate vector representation \(X^{\nicefrac{L}{2}}\) is computed by applying the self-decoder to the input embeddings \(X^{0}\).
neurips_2024_oral_60,2,"\hat{K}=LN(X^{\nicefrac{{L}}{{2}}})W_{K},\quad\hat{V}=LN(X^ {\nicefrac{{L}}{{2}}})W_{V}","where \(W_{K},W_{V}\in\mathbb{R}^{d\times d}\) are learnable","\hat{K},\hat{V}=Linear(X^{\nicefrac{L}{2}})",\(\hat{K}\) and \(\hat{V}\) are the global key and value caches generated by applying a linear transformation to the output of the self-decoder \(X^{\nicefrac{L}{2}}\).
neurips_2024_oral_60,3,"Q^{l}=LN(X^{l})W_{Q}^{l} || Y^{l}=Attention(Q^{l},\hat{K},\hat{V})+X^{l} || X^{l+1}=SwiGLU(LN(Y^{l}))+Y^{l}",,"Y^{l}=ESA(LN(X^{l}),\hat{K},\hat{V})+X^{l}","where \(Y^{l}\) is the output of the \(l\)-th cross-decoder layer, computed using efficient self-attention with global KV caches \(\hat{K}, \hat{V}\)."
neurips_2024_oral_60,4,"Q=XW_{Q},\quad K=XW_{K},\quad V=XW_{V}\\head_{i}=softmax(Q_{[i]}K_{[i]}^{\intercal}+B)V,\quad B_{ij}=0,&i-C<j\leq i\\-\infty,&otherwise\\SWA(X)=Concat(head_{1},\cdots,head_{h})W_ {O}","where \(W_{Q},W_{K},W_{V},W_{O}\in\mathbb{R}^{d\times d}\) are learnable matrices, and the window causal mask \(B\) controls each query only attends to the previous keys whose distances are less than \(C\)","SWAttn(Q, K, V)=Softmax\left(\frac{QK^{\top}}{\sqrt{d}}+M_{sw}\right)V",where \(M_{\text{sw}}\) is the sliding-window causal mask that restricts attention to a fixed window size \(C\).
neurips_2024_oral_60,5,"Q=(XW_{Q})\odot\Theta,\quad K=(XW_{K})\odot\overline{\Theta},\quad V=XW_{V},\quad\Theta_{n}=e^{in\theta}\\\gamma=sigmoid(XW_{\gamma})^{1/\tau},\quad D_{nm}=\prod\nolimits_{i=m+1}^{n}\gamma_{i},&n\geq m\\0,&n<m\\gRet(X)=(QK^{\intercal}\odot D)V","where \(W_{Q},W_{K},W_{V}\in\mathbb{R}^{d\times d}\) and \(W_{\gamma}\in\mathbb{R}^{d\times 1}\) are learnable weights, and the temperature term \(\tau\) encourages \(\gamma\) to 1 for better memorization [46]","R &=Retention(X, W_{Q}, W_{K}, W_{V})\\G &=\sigma(LN(X) W_{G})\\gRet(X) &=G\odot R","where \(R\) is the retention output, \(G\) is the data-dependent gate, \(W_{G}\) is a learnable matrix, \(\sigma\) is the sigmoid function, and \(\odot\) denotes element-wise multiplication."
neurips_2024_oral_60,6,"S_{n}=\gamma_{n}S_{n-1}+K_{n}^{\intercal}V_{n}\\gRet(X_{n})=Q_{n}S_{n},\quad n=1,\cdots,|x|","where \(Q,K,V,\gamma\) are the same as in Equation (5)",h_{n}=\gamma_{n} h_{n-1}+(Q_{n} K_{n}^{\intercal}) V_{n},"where \(h_{n}\) is the output at timestep \(n\), \(\gamma_{n}\) is the data-controlled decay, and \(Q_{n}, K_{n}, V_{n}\) are the projected query, key, and value at timestep \(n\)."
neurips_2024_oral_60,7,"\beta_{(i-1)B+j}&=\prod\limits_{k=(i-1)B+1}^{(i-1)B+j}\gamma_{k},\quad D_{[i]}(j,k)=\frac{\beta_{(i-1)B+k}}{\beta_{ (i-1)B+j}}\\if\\j\leq k\\else\\0\\R_{i}&=K_{[i]}^{\intercal}(V_{[i]}\odot\frac{\beta_{iB}}{\beta_{[i]}})+\beta_{iB}R_{i-1},\\\beta_{[i]}(j,k)=\beta_{(i-1)B+j}\\gRet(X)&=\underbrace{(Q_{[i]}K_{[i]}^{\intercal}\odot D_{[i]})V_{[i]}}_{Inner-Chunk}+\underbrace{(Q_{[i]}R_{i-1})\odot\beta_{[i]}}_{Cross-Chunk}","where \(R_{i}\) is the intermediate state of the \(i\)-th chunk, and \(\beta\) summarizes the data-controlled decay \(\gamma\)","S_{[i],n} &=\gamma_{[i],n} S_{[i],n-1}+K_{[i],n}^{\intercal} V_{[i],n},\quad n=1,\cdots,B\\gRet(X_{[i]}) &=Q_{[i]} S_{[i]},\\S_{[i]} &=S_{[i],B}+\prod_{j=1}^{B}\gamma_{[i],j} S_{[i-1]}","where \(S_{[i],n}\) is the intermediate state at position \(n\) within chunk \(i\), \(S_{[i]}\) is the final state for chunk \(i\), and \(S_{[i-1]}\) is the state from the previous chunk."
neurips_2024_oral_60,8,"head_{i}=gRet(X) || Y=GroupNorm_{h}(Concat(head_{1},\cdots,head_{n})) || MHGR(X)=(swish(XW_{G})\odot Y)W_{O}",,"MH-gRet(X)=Concat(gRet_1(X),\ldots,gRet_h(X)) W_O",where \(\mathrm{gRet}_i(X)\) denotes the gated retention output for the \(i\)-th head and \(W_O\) is a learnable output projection.
neurips_2024_oral_8,1,w_{i}^{t}=\alpha^{t}W^{t-1}+(1-\alpha^{t})\hat{w}_{i}^{t},where \(\alpha^{t}\) is the fusion factor used to control the quality of the fused global model \(\mathcal{W}^{t-1}\),w_{i}^{t}=\lambda\hat{w}_{i}^{t}+(1-\lambda)W^{t-1},"The fused local model \(\mathbf{w}_{i}^{t}\) is a convex combination of the fine-tuned local model \(\hat{\mathbf{w}}_{i}^{t}\) and the global model \(\mathcal{W}^{t-1}\), controlled by the fusion coefficient \(\lambda\)."
neurips_2024_oral_8,2,"\alpha^{t}=\max\{(1-\epsilon)^{t-1}\alpha_{0},\alpha_{min}\}",,"\alpha^{t}=\max\left(\alpha_{0}-\epsilon\cdot (t-1),\\alpha_{min}\right)","where \(\alpha_{0}\) is the initial fusion factor, \(\epsilon\) is the sensitivity factor controlling the decay rate, \(t\) is the current communication round, and \(\alpha_{min}\) is the minimum allowed value for the fusion factor."
neurips_2024_oral_8,3,L^{DAR}_{i}= || g_{e}(w_{e}\odotM_{e};x_{i}) || _{2}^{2},,L^{DAR}=\frac{1}{N}\sum_{i=1}^{N}\left\| z_{i}-\bar{z}\right\|_{2}^{2},"where \(z_{i}\) is the representation of the \(i\)-th sample, \(\bar{z}\) is the mean representation over the local batch, and \(N\) is the batch size."
neurips_2024_oral_8,4,"L^{CE}_{i}=-\frac{1}{|K_{i}|}\sum_{k\inK_{i}}y_{ i,k}\log(\hat{y}_{i,k})","where \(\mathcal{K}_{i}\) denotes the set of possible labels on the client \(i\), \(\hat{y}_{i,k}\) denotes predicting label, and \(y_{i,k}\) denotes ground-truth label","L^{CE}_{i}=-\sum_{(x_{i}, y_{i})\inD_{i}} y_{i}\log\left( g_{p}(w_{p}\odotM_{p};\g_{e}(w_{e}\odotM_{e}; x_{i}))\right)",where \(\mathcal{L}^{CE}_{i}\) is the cross-entropy loss for client \(i\) computed over its local dataset \(\mathcal{D}_{i}\).
neurips_2024_oral_8,5,L_{i}=L^{CE}_{i}+\gammaL^{DAR}_{i},where the \(\gamma\) is a pre-defined coefficient controlling the importance of \(\mathcal{L}^{DAR}_{i}\) relative to \(\mathcal{L}^{CE}_{i}\),L_{i}=L^{CE}_{i}+\lambdaL^{DAR}_{i},where \(\lambda\) is a hyperparameter that balances the cross-entropy loss and the domain adaptive regularization term for client \(i\).
neurips_2024_oral_8,6,w^{t}_{i}:=\underbrace{w^{t}_{i}\odotM^{t}_{i}}_{local knowledge}+\underbrace{W^{t-1}\odot\overline{M}^{t}_{i}}_{global knowledge},"where \(\mathcal{W}^{t-1}\) is the global model aggregated at the \((t-1)\)-th round, and \(\overline{\mathbf{M}}^{t}_{i}\) denotes the logical NOT operation applied to \(\mathbf{M}^{t}_{i}\)",\tilde{w}_{i}^{t}=w_{i}^{t}\odotM_{i}^{t}+(1-M_{i}^{t})\odotW^{t-1},The recovered local model $\tilde{\mathbf{w}}_{i}^{t}$ is constructed by combining the pruned local model $\mathbf{w}_{i}^{t} \odot \mathbf{M}_{i}^{t}$ with the corresponding parameters from the previous global model $\mathcal{W}^{t-1}$ for the pruned positions.
neurips_2024_oral_8,7,W^{t}=\sum_{i\inC}\frac{|D_{i}|}{|D|}w_{i}^{t},"where \(|\mathcal{D}_{i}|\) is the sample number in the local dataset on client \(i\), and \(|\mathcal{D}|\) is the total number of samples in the entire FL system",W^{t}=\frac{1}{|C|}\sum_{i\inC}w^{t}_{i},"where \(\mathcal{C}\) denotes the set of participating clients in round \(t\), and \(\mathbf{w}^{t}_{i}\) is the recovered local model of client \(i\)."
neurips_2024_oral_9,1,"lh_{Q}=(Q_{i}^{d},subqs^{i})(i=1,2,...,K)",,"sim(Q, Q_i^d)=\frac{h_Q\cdoth_{Q_i^d}}{\|h_Q\|\|h_{Q_i^d}\|}",The cosine similarity between the representation vectors of the input question \(Q\) and a demonstration question \(Q_i^d\).
neurips_2024_oral_9,2,"\{q_{t+1}^{j},j=1,...,J\}\gets Decompose(p_{\theta},\;h_{1},\;lh_{Q},\;q_ {t})",,Prompt_{decompose}=h_{1}\oplus lh_{Q}\oplus q_{t},"The decomposition prompt is constructed by concatenating the prompt head \(h_{1}\), the logic heuristics \(lh_{Q}\), and the current sub-question \(q_{t}\)."
neurips_2024_oral_9,3,"r_{t+1}^{j}\gets Solve(p_{\theta},\;h_{2},\;q_{t+1}^{j})",,"r_{t+1}^{j}\gets Analyze(p_{\theta},\;h_{2},\;q_{t+1}^{j})",The essential rationale \(r_{t+1}^{j}\) for each sub-question \(q_{t+1}^{j}\) is generated by prompting the LLM with the analysis prompt head \(h_{2}\).
neurips_2024_oral_9,4,"\hat{r}_{t+1}^{j}\gets Self\_Check(p_{\theta},\;h_{3},\;q_{t+1}^{j},\;r_{t+1}^{j})",,"\hat{r}_{t+1}^{j}\gets SelfCheck(p_{\theta},\;h_{3},\;q_{t+1}^{j},\;r_{t+1}^{j})",The corrected rationale \(\hat{r}_{t+1}^{j}\) for sub-question \(q_{t+1}^{j}\) is obtained by prompting the LLM with a self-check procedure using the original rationale \(r_{t+1}^{j}\).
neurips_2024_oral_9,5,"s_{t+1}^{j}\gets Score(p_{\theta},\;h_{4},\;q_{t+1}^{j},\;\hat{r}_{t+1}^{j })",,"s_{t+1}^{j}\gets Coherence\_Score(p_{\theta},\;h_{4},\;q_{t+1}^{j},\;\hat{r}_{t+1}^{j})",\(s_{t+1}^{j}\) denotes the coherence score between the refined rationale \(\hat{r}_{t+1}^{j}\) and the sub-question \(q_{t+1}^{j}\).
neurips_2024_oral_9,6,"n_{t+1}^{j}=(q_{t+1}^{j},\hat{r}_{t+1}^{j},s_{t+1}^{j})",where \(s_{t+1}^{j}\) can support the current or subsequent cycles in _Rethink_ (4,"n_{t+1}^{j}=(q_{t+1}^{j},\;\hat{r}_{t+1}^{j},\;s_{t+1}^{j})","Each node at level \(t+1\) contains the sub-question, its refined rationale, and the coherence score."
neurips_2024_oral_9,7,"L_{k}\gets Extract(p_{\theta},\h_{5},\L,q_{t+1}^{j}),\L_{k}\subseteq L",where \(h_{5}\) is a prompt head (_Appendix_ A,"L_{k}=Select\_Related(p_{\theta},\; h_{5},\; q_{t+1}^{j},\; L)","\(L_{k}\) denotes the subset of \(k\) most related nodes to \(q_{t+1}^{j}\), selected from the set of ancestor nodes \(L\) using the LLM with prompt head \(h_{5}\)."
neurips_2024_oral_9,8,"r^{\prime}\gets Update(p_{\theta},\h_{6},\n_{e}(q,r,s),\\hat{r}_{t+1}^{j})",,"r_{e}^{new}\gets Update(p_{\theta},\h_{6},\n_{e},\\hat{r}_{t+1}^{j})",where \(h_{6}\) is a prompt head and \(r_{e}^{\text{new}}\) denotes the updated rationale for node \(n_{e}\) using information from \(\hat{r}_{t+1}^{j}\).
neurips_2024_oral_9,9,"n_{e}(q,r^{\prime},s)\gets n_{e}(q,r,s)",,"n_{e}^{\prime}=(q, r^{\prime}, s)",where \(n_{e}^{\prime}\) denotes the updated node with the revised rationale \(r^{\prime}\) and original question \(q\) and score \(s\).
