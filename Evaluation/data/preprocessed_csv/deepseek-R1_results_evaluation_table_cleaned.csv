paper_id,equation_id,ground_truth_eq,ground_truth_description,generated_equation,generated_description
2024.acl-short.12,1,ECE=\sum_{i=1}^{B}\frac{n_{b_{i}}}{N}|acc(b_{i})-conf(b_{i})|,"where \(i\) denotes \(i\)-th bin, \(N\) is the total instance count of the dataset, \(acc(b_{i})\) and \(conf(b_{i})\) represent the accuracy and confidence of the bin \(b_{i}\), and \(n_{b_{i}}\) is the instance number of the bin \(b_{i}\)",ECE=\sum_{m=1}^{M}\frac{|B_m|}{n}\left|acc(B_m)-conf(B_m)\right|,"Here $M$ is the number of confidence bins, $B_m$ is the set of samples in bin $m$, $n$ is the total number of samples, $\text{acc}(B_m)$ is the accuracy within bin $B_m$, and $\text{conf}(B_m)$ is the average predicted confidence in bin $B_m$."
2024.acl-short.12,2,"GECE=\frac{|M(pred,ref)-\frac{1}{n}\sum_{i=1}^{n}p(t_{i})|}{\alpha\cdot[E(\bigtriangledown_{ins})\cdot\bigtriangledown_{ins}]}","where \(pred\) and \(ref\) represent the generated text and the referenced ground truth, respectively",GECE=\sum_{i=1}^{B}\frac{n_{b_{i}}}{N}\left|METEOR(b_{i})-AvgProb(b_{i})\right|\cdot\left(\alpha\cdotAWF(b_i)+\beta\cdotAGD(b_i)\right),"where \(i\) denotes \(i\)-th bin, \(B\) is the total bin count, \(n_{b_i}\) is the instance count in bin \(b_i\), \(N\) is the total instance count, \(\text{METEOR}(b_i)\) and \(\text{AvgProb}(b_i)\) are the average METEOR score and average token probability in bin \(b_i\) respectively, \(\text{AWF}(b_i)\) is the average word frequency in bin \(b_i\), \(\text{AGD}(b_i)\) is the average of the dot product between the mean gradient of the dataset and the gradient of each instance in bin \(b_i\), and \(\alpha\), \(\beta\) are coefficients."
2024.acl-short.14,1,"P(cot,T|KG) || =P((s_{1},t_{1}),\cdots,(s_{n},t_{n}),T|KG) || =\prod_{i=1}^{n}P((s_{i},t_{i})|(s_{1},t_{1}),\cdots,(s_{i-1},t_ {i-1}),KG)\cdot || P(T|(s_{1},t_{1}),\cdots,(s_{n},t_{n}),KG) || =\prod_{i=1}^{n}P(t_{i}|(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}),KG)\cdot || \prod_{i=1}^{n}P(s_{i})|t_{i},(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}),KG)\cdot || P(T|(s_{1},t_{1}),\cdots,(s_{n},t_{n}),KG)",,"p(s |G)=\prod_{i=1}^{N} p(s_i | s_{<i},G)",The probability of generating the sequence of sentences $\mathbf{s}$ given the knowledge graph $\mathcal{G}$ is the product of the conditional probability of each sentence $s_i$ given the previous sentences $s_{<i}$ and $\mathcal{G}$.
2024.acl-short.14,2,"L_{seq}=-logP((s_{1},t_{1}),\cdots,(s_{n},t_{n}),T|KG) || =-\sum_{i=1}^{n}logP(t_{i}|(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}) || KG)-\sum_{i=1}^{n}logP(s_{i})|t_{i},(s_{1},t_{1 }),\cdots,(s_{i-1} || t_{i-1}),KG)-\sum_{i=1}^{n}logP(T|(s_{1},t_{1 }),\cdots,(s_{n} || t_{n}),KG)",,"L(\theta)=-\log P(cot, T\midKG;\theta)",The cross-entropy loss function for optimizing the model parameters \(\theta\).
2024.acl-short.14,3,"L_{re}=-\textbf{log}P(r|h,t,T) || =-\textbf{log}\prod_{i=1}^{m}P(r_{i}|r_{<i},h,t,T)",,"L_{backward}=-\sum_{j=1}^{M}\log P( A_j | h_j, t_j, T )","The backward relation extraction loss, where M is the number of sampled triples, A_j is the target answer text for the j-th triple, h_j and t_j are the head and tail entities of the j-th triple, and T is the generated text for the entire KG."
2024.acl-short.14,4,L=\alpha_{1}L_{seq}+\alpha_{2}L_{re},where \(\alpha_{1}\) and \(\alpha_{2}\) are parameters to tune,L_{total}=L_{seq}+L_{re},The total loss function combines the sequential sentence-level generation loss and the backward relation extraction loss.
2024.acl-short.15,1,"(o^{I},o^{S})=f(x)",where \(f(\cdot)\) is the joint model; \(\mathbf{o}^{I}\) and \(\mathbf{o}^{S}\) denotes an intent label and a slot sequence,"P(y^{intent},y^{slot}\midx)",The joint probability of the intent \(y^{\text{intent}}\) and slot sequence \(\mathbf{y}^{\text{slot}}\) given the input sentence \(\mathbf{x}\).
2024.acl-short.15,2,"\hat{Q}_{[i,j]}=norm(Q_{[i,j]})","where \(\mathrm{norm}(\cdot)\) denotes row normalization, which constrains the values to lie between 0 and 1","\hat{Q}=\arg\min_{Q\inU(a,b)}L_{C}","where \(\mathbf{\hat{Q}}\) is the optimal transport alignment matrix, \(\mathbf{U}(\mathbf{a}, \mathbf{b})\) is the set of coupling matrices with marginals \(\mathbf{a}\) and \(\mathbf{b}\), and \(\mathcal{L}_{\mathbf{C}}\) is the transport cost."
2024.acl-short.15,3,"L_{RLA}=-\sum_{[i,j]}\hat{Q}_{[i,j]}\log(\sigma(1-C_{[i,j]}))","where \(\sigma\) denotes the sigmoid function, and \(1-\mathbf{C}_{[i,j]}\) denotes the cosine similarity between \(\mathbf{h}_{i}\) and \(\mathbf{h}^{\prime}_{j}\)","L_{align}=\sum_{i=1}^{n}\sum_{j=1}^{m}\hat{Q}_{[i,j]}\cdot\left(1-\frac{h_i^\toph^{\prime}_j}{\|h_i\|\|h^{\prime}_j\|}\right)","\(\mathcal{L}_{\text{align}}\) is the representation alignment loss, computed as the weighted sum of cosine distances between original and code-switched token representations using the alignment matrix \(\hat{\mathbf{Q}}\) as weights."
2024.acl-short.15,4,P^{I}_{x}=softmax(W^{I}h_{CLS}+b^{I}) || P^{I}_{x^{\prime}}=softmax(W^{I}h^{\prime}_{CLS}+b^{I}),,"o^{I}=decoder^{I}(h_{CLS}),\quado^{\prime I}=decoder^{I}(h^{\prime}_{CLS})","\(\mathbf{o}^{I}\) and \(\mathbf{o}^{\prime I}\) are the intent predictions for the original sentence and the code-switched sentence, respectively."
2024.acl-short.15,5,P^{S}_{x}=softmax(W^{S}h_{[1:-1]}+b^{ S}) || P^{S}_{x^{\prime}}=softmax(W^{S}h^{\prime}_{[1:-1]}+b^{S}),,"P^{S}_{x} &=softmax(W^{S}h_{[1:-1]}+b^{S}),\\P^{S}_{x^{\prime}} &=softmax(W^{S}h^{\prime}_{[1:-1]}+b^{S})","where \(\mathbf{P}^{S}_{\mathbf{x}}\) and \(\mathbf{P}^{S}_{\mathbf{x}^{\prime}}\) denote the slot label distributions for the original and code-switched sentences, respectively; \(\mathbf{W}^{S}\) and \(\mathbf{b}^{S}\) are the weight matrix and bias for the slot filling decoder."
2024.acl-short.15,6,"L_{I}=CE(P^{I}_{x},P^{I}) || L_{S}=\frac{1}{L}\sum_{i=1}^{L}CE(P^{S}_{[x,i]},P^{S}_{i})",,"L_{I}=-\logP^{I}_{x, y^{I}}","where \(y^{I}\) is the ground truth intent label, and \(y^{S}_{t}\) is the ground truth slot label for the \(t\)-th token in the input sequence."
2024.acl-short.15,7,L_{PLA}=\underbrace{KL(P^{I}_{x^{\prime}} || P^{I}_{x})}_{Intent PLA}+\underbrace{KL(P^{S}_{x^{\prime}} || P^{S}_{x}) }_{Slot PLA},"where \(\mathrm{KL}(\cdot)\) denotes Kullback-Leibler divergence (Kullback and Leibler, 1951) to measure the difference between two distributions","L_{PLA}^{I} &=\frac{1}{2}\left[ D_{KL}\left(P^{I}_{x}\parallelP^{I}_{x^{\prime}}\right)+D_{KL}\left(P^{I}_{x^{\prime}}\parallelP^{I}_{x}\right)\right]\\L_{PLA}^{S} &=\frac{1}{2L}\sum_{i=1}^{L}\left[ D_{KL}\left(P^{S}_{[x,i]}\parallelP^{S}_{[x^{\prime},i]}\right)+D_{KL}\left(P^{S}_{[x^{\prime},i]}\parallelP^{S}_{[x,i]}\right)\right]\\L_{PLA} &=L_{PLA}^{I}+L_{PLA}^{S}","where \(\mathcal{L}_{\text{PLA}}^{I}\) and \(\mathcal{L}_{\text{PLA}}^{S}\) are the prediction-level alignment losses for intent detection and slot filling, respectively, computed as the symmetric KL divergence between the original and code-switched predictions, and \(\mathcal{L}_{\text{PLA}}\) is their sum."
2024.acl-short.15,8,"L_{SD}=\underbrace{KL(P^{[I,t-1]}_{ kT} || P^{[I,t]}_{latent SD})}_{Intent SD}+\underbrace{\frac{1}{L}\sum_{i=1}^{L}KL(P^{[S,t-1]}_{[x,i]} || P^{[S,t]}_{[x,i]}) }_{Slot SD}","where \(\mathbf{P}^{[I,t]}_{\mathbf{x}}\) denotes the probability distribution of intent, \(\mathbf{P}^{[S,t]}_{[\mathbf{x},i]}\) of slot at \(i\)-th token","L_{SD}=\underbrace{KL\left(P^{I,t}_{x}\parallelP^{I,t-1}_{x}\right)}_{Intent SD}+\underbrace{\frac{1}{L}\sum_{i=1}^{L}KL\left(P^{S,t}_{x,i}\parallelP^{S,t-1}_{x,i}\right)}_{Slot SD}",The self-distillation loss \(\mathcal{L}_{\text{SD}}\) is the sum of the KL divergence between the current and previous epoch's intent predictions and the average per-token KL divergence for slot predictions.
2024.acl-short.15,9,L=L_{I}+L_{S}+L_{RLA}+L _{PLA}+L_{SD},,L_{total}=L_{RLA}+L_{I}+L_{S}+L_{PLA}+L_{SD},"The total loss \(\mathcal{L}_{\text{total}}\) combines representation-level alignment, intent detection, slot filling, prediction-level alignment, and self-distillation losses."
2024.acl-short.16,1,Y=W_{0}^{l}X+\Lambda_{b}^{l}B^{l}\Lambda_{d}^{l}A^{l}X,,Y=s_b\odot lora_B\left( s_d\odot lora_A(X)\right),"The output \(Y\) of the AFLoRA module for input \(X\) is computed by sequentially applying the down-projection \(lora_A\), element-wise scaling by \(s_d\), the up-projection \(lora_B\), and element-wise scaling by \(s_b\)."
2024.acl-short.16,2,"I_{A^{l}}=|\nablaL(\theta)|,\overline{T}^{(t)}_{A^{l }}=\beta_{1}\overline{T}^{(t-1)}_{A^{l}}+(1-\beta_{1})I^{(t)}_{A^{l}} || U^{(t)}_{A^{l}}=|I^{(t)}_{A^{l}}-\overline{I}^{(t)}_{A^{l}}|,\overline{U}^{(t)}_{A^{l}}=\beta_{2}\overline{U}^{(t-1)}_{A^{l}}+(1-\beta_{2} )U^{(t)}_{A^{l}} || s^{(t)}_{A^{l}}=mean(\overline{T}^{(t)}_{A^{l}}\circ\overline{U}^{(t)}_{A^{l}})",,S(A^{l})=\left\|\frac{\partialL}{\partial A^{l}}\right\|_F,The freezing score \( S(A^{l}) \) for the low-rank tensor \( A^{l} \) is defined as the Frobenius norm of the gradient of the loss \( \mathcal{L} \) with respect to \( A^{l} \).
2024.acl-short.16,3,r(t)=\{{ll}0&0\leq t<t_{i}\\1-(1-\frac{t-t_{i}}{T-t_{i}-t_{f}})^{3}&t_{i}\leq t<T-t_{f}\\1&otherwise,"where \(t\) refers to current #step, \(T\) is the total number of fine-tuning steps","U^{(t)}_{A^{l}}=|I^{(t)}_{A^{l}}-\overline{T}^{(t)}_{A^{l}}|,\overline{U}^{(t)}_{A^{l}}=\beta_{2}\overline{U}^{(t-1)}_{A^{l}}+(1-\beta_{2})U^{(t)}_{A^{l}}","This equation computes the uncertainty tensor for the low-rank tensor \(A^{l}\) at iteration \(t\), defined as the absolute difference between the current gradient and its moving average, and updates the smoothed uncertainty tensor using an exponential moving average with parameter \(\beta_{2}\)."
2024.acl-short.20,1,"E(h,r,t)=\sum_{i=1}^{k}w_{i}(q)M_{i}(h,r,t)","where \(\mathtt{E}(\mathtt{h},\mathbf{r},\mathbf{t})\) is the ensemble score for \(\mathbf{t}\) given query \(\mathtt{q}=(\mathbf{h},\mathbf{r},?)\)","E(h,r,t)=\sum_{i=1}^{k} w_i\cdotM_{i}(h,r,t)","The ensemble score for triple \((\mathbf{h}, \mathbf{r}, \mathbf{t})\) is computed as a weighted sum of scores from \(k\) individual KGC models."
2024.acl-short.20,2,"M_{i}(h,r,t)\getsM_ {i}(h,r,t)-\min_{t^{\prime}\inE}M_{i}(h,r,t^{\prime}) || M_{i}(h,r,t)arrow\frac{M_{i}(h,r,t)}{\max_{t^{\prime}\inE}M_{i}(h,r,t^{\prime})}",,"\hat{M}_{i}(h,r,t)=\frac{M_{i}(h,r,t)-\min_{t'\inE}M_{i}(h,r,t')}{\max_{t'\inE}M_{i}(h,r,t')-\min_{t'\inE}M_{i}(h,r,t')}","where \(\hat{\mathtt{M}}_{\mathtt{i}}(\mathbf{h},\mathbf{r},\mathbf{t})\) is the max-min normalized score from model \(\mathtt{M}_{\mathtt{i}}\) for candidate tail \(\mathbf{t}\) given query \(\mathbf{q}=(\mathbf{h},\mathbf{r},?)\)."
2024.acl-short.20,3,"f(M_{i},q)=\underset{t^{\prime}\inE}{mean}(M_{i}(h,r,t^{\prime})) || \underset{t^{\prime}\inE}{ var}(M_{i}(h,r,t^{\prime}))",,Entropy_i(q)=-\sum_{t\inE} p_i(t)\log p_i(t),"The entropy of the score distribution for model \(\mathtt{M}_{\mathtt{i}}\) on query \(\mathbf{q}\), where \(p_i(\mathbf{t})\) is the normalized probability distribution over candidate tails."
2024.acl-short.20,4,"w_{1}(q)=MLP_{1}(f(M_{1},q) || f(M_{2},q) ||  || f(M_ {k},q))",,"w_{i}(q)=MLP_{i}\left(\left[f(M_{1},q);f(M_{2},q);\ldots;f(M_{k},q)\right]\right)",The ensemble weight \(\mathbf{w}_{i}(\mathbf{q})\) for model \(\mathtt{M}_{i}\) is computed by a model-specific 2-layer MLP applied to the concatenated feature vector of all models for query \(\mathbf{q}\).
2024.acl-short.20,5,"L=\sum_{t\inN}\max(E(h,r,t)-E(h,r,t^{*})+m,0)",where \(\mathtt{m}\) is the margin hyperparameter,"L(q)=\sum_{t\inN}\max\left(0,E(h,r,t)-E(h,r,t^{*})+\gamma\right)",The loss function \( \mathcal{L} \) for query \( \mathtt{q} \) is defined as the sum over negative samples \( \mathbf{t} \in \mathtt{N} \) of the margin loss between the ensemble score of the gold entity \( \mathtt{t^{*}} \) and the ensemble score of the negative sample \( \mathbf{t} \).
2024.acl-short.25,1,"s_{i}=\sigma(\frac{1}{\beta_{i}}(log\frac{\mu_{i}}{1-\mu_{i}}+\textit{log}\alpha_{i})) || m_{i}=min(1,max(0,s_{i}(\zeta-\gamma)+\gamma))",,"m_i\simHardConcrete(\log\alpha_i,\beta_i)",The mask \(m_i\) for neuron \(i\) is sampled from a hard concrete distribution with location parameter \(\alpha_i\) and temperature \(\beta_i\).
2024.acl-short.25,2,"min(1,max(0,\sigma(log\alpha_{i})(\zeta-\gamma)+\gamma))",,"m_{i}=\min\left(1,\max\left(0,\sigma\left(\frac{\log\alpha_{i}}{\beta_{i}}\right) (\zeta-\gamma)+\gamma\right)\right)","The deterministic mask for neuron \(i\) during inference, calculated via the hard concrete gate using learned parameter \(\alpha_i\) without stochastic sampling."
2024.acl-short.25,3,"L_{m}(f(m\odot\theta),x)=\sum_{i=1}^{I}log(P(x_{p+i}|x_{<p+i}))",,L_{adv}=-\sum_{i=p}^{p+I}\log P(x_i |x_{<i}),The adversarial loss maximizes the negative log-likelihood of the PII token sequences.
2024.acl-short.25,4,"L_{adv}(f(m\odot\theta),x)=-\sum_{t=1}^{T}log(P(x_{t}|x_{<t}))",,"L_{adv}(f(m\odot\theta),x)=-\sum_{t=1}^{T}\log P(x_t | x_{<t})",The adversarial loss \(\mathcal{L}_{adv}\) is the negative log-likelihood of the entire token sequence to preserve the original language modeling ability.
2024.acl-short.25,5,R(m)=-\frac{1}{|m|}\sum_{i=1}^{|m|}\sigma(log\alpha_{i}-\beta_{i}log \frac{-\gamma}{\zeta}),,R(m)=\sum_{i}\sigma\left(\beta\log\left(-\frac{\gamma}{\zeta}\right)-\log\alpha_{i}\right),The regularization term penalizes the expected number of non-zero masks to minimize the number of localized neurons.
2024.acl-short.3,1,"\Delta(G_{1},G_{2})=\min_{ops}\sum_{i=1}^{n}w(op_{i})",,"\Delta(G_1, G_2)",The tree edit distance between the predicted code's AST \(G_1\) and the ground truth AST \(G_2\).
2024.acl-short.3,2,"TSED=\max\{1-\frac{\delta}{MaxNodes(G_{1},G_{2})},0\}",,"TSED(G_1, G_2)=\min\left(\frac{\Delta(G_1, G_2)}{\max(|G_1|, |G_2|, 1)}, 1\right)",The normalized tree edit distance TSED is defined as the minimum of the ratio of the raw tree edit distance to the maximum number of nodes in either the predicted or ground-truth AST (with a minimum denominator of 1) and 1.
2024.acl-short.39,1,"Bio(m,co(m))=f_{gen}(m,co(m))",where biography is generated by the model \(f_{gen}\) given the personal attribute of interest (\(m\)) and the co-occurring attributes (\(co(m)\)),f:X\rightarrowY,This equation formulates the biography generation task as a function \( f \) mapping from the set of infoboxes \( \mathcal{X} \) to the set of biographies \( \mathcal{Y} \).
2024.acl-short.39,2,"Bio(\phi,co(m))=f_{gen}(\phi,co(m))",,Bio_{masked}(co(m))=f_{gen}(co(m)),"Biography generated by the model without the personal attribute of interest (m), using only the co-occurring attributes (co(m))."
2024.acl-short.39,3,"Bio(f,co(m))=f_{gen}(f,co(m)),do(m\to f)","where \(do(m\to f)\) denotes the do operator (Pearl, 2009), e","Bio(m',co(m))=f_{gen}(m',co(m))",The counterfactual biography generated by the model \(f_{\text{gen}}\) when the personal attribute of interest is changed to \(m'\) while keeping the co-occurring attributes \(\text{co}(m)\) unchanged.
2024.acl-short.40,1,"L_{e}=\frac{1}{N}\sum_{i=1}^{N}(\cos(S_{1,i},S_{2,i})-\cos(E_{1,i},E_{2,i}))^{2}","where \(N\) is the batch size, and \(S\) and \(E\) contain the target text SEM vectors and the predicted output SEM vectors respectively",L_{MSE}=\frac{1}{d}\|u-v\|_2^2,The mean squared error loss between the embeddings $\mathbf{u}$ and $\mathbf{v}$ from the twin subnetworks.
2024.acl-short.40,2,"L_{o}=CE(T,O)=-\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{M} (T_{ij}\cdot\log(O_{ij}))","where \(N\) is the batch size, \(M\) the vocabulary size, \(T\) is the target text and \(O\) is the output text","L_{ce}=-\frac{1}{N}\sum_{i=1}^{N}\frac{1}{T_i}\sum_{t=1}^{T_i}\log P(y_{i,t}\mid y_{i,<t},s_i)","where \(N\) is the batch size, \(T_i\) is the length of the target text sequence for the \(i\)-th example, \(y_{i,t}\) is the true token at position \(t\) of the \(i\)-th target sequence, \(\mathbf{s}_i\) is the input SEM vector for the \(i\)-th example, and \(P(y_{i,t} \mid y_{i,<t}, \mathbf{s}_i)\) is the predicted probability of the true token \(y_{i,t}\) given the previous tokens and the SEM vector."
2024.acl-short.41,1,E(y)=h(\beta+\sum_{j=1}^{J}f_{j}(x_{j})),"where \(h(\cdot)\) is the activation function used in the output layer, e",\hat{y}=g\left(\beta_0+\sum_{j=1}^{m} f_j(x_j)\right),"The general form of a Neural Additive Model (NAM) where $\hat{y}$ is the predicted target variable, $g$ is a link function, $\beta_0$ is the bias term, $x_j$ are input features including both topic proportions and additional tabular variables, and $f_j$ are feature-specific neural networks."
2024.acl-short.41,2,h(E[y])=\beta+\sum_{j=1}^{J}f_{j}(x_{j(tab)})+\sum_{k=1}^{ K}f_{k}(x_{k(top)}),,E(y)=h\left(\beta+\sum_{j=1}^{J} f_j(x_{j}^{(tab)})+\sum_{k=1}^{K} g_k(x_{k}^{(top)})\right),The expected value of the target variable \(y\) is modeled using an activation function \(h\) applied to an intercept \(\beta\) plus the sum of shape functions for each tabular feature and the sum of shape functions for each topic prevalence feature.
2024.acl-short.43,1,P(c|s)=\frac{\exp(b_{c}\cdot\frac{1}{T}\sum_{t=1}^{T}x_{t})}{\sum_{c^{\prime}=1}^{N}\exp(b_{c^{\prime}}\cdot\frac{1}{T}\sum_{t=1}^ {T}x_{t})},,P(c | s)=\frac{\exp\left(\frac{1}{T}\sum_{i=1}^Tw_c^\topx_i+b_c\right) }{\sum_{c'=1}^{N}\exp\left(\frac{1}{T}\sum_{i=1}^Tw_{c'}^\topx_i+b_{c'}\right) },"The posterior probability \( P(c | s) \) of sentence \( s \) belonging to language \( c \), where \( T \) is the number of features, \( \mathbf{x}_i \) is the embedding of the \( i \)-th feature, \( \mathbf{w}_c \) and \( b_c \) are the weight vector and bias for language \( c \), and \( N \) is the number of languages."
2024.acl-short.43,2,"V_{c,t}(s)=b_{c}\cdotx_{t}",,"V_{c,t}(s)=b_{c}\cdotx_{t}","The element \(\mathbf{V}_{c,t}(s)\) represents the logit score for language \(c\) and word-level feature \(\mathbf{x}_{t}\) in sentence \(s\), computed as the dot product of the language weight vector \(\mathbf{b}_c\) and the word embedding \(\mathbf{x}_t\)."
2024.acl-short.49,1,CEF=\frac{\sum_{i=0}^{n}(I_{i}-\overline{I} )(M_{i}-\overline{M})}{\sqrt{\sum_{i=1}^ {n}(I_{i}-\overline{I})^{2}}\sqrt{\sum_{i=1}^ {n}(M_{i}-\overline{M})^{2}}},where \(\overline{x}=\frac{1}{n}\sum_{i=1}^{n}x_{i}\) (the sample mean),"CEF=\rho(I,M)=\frac{cov(I,M)}{\sigma_{I}\sigma_{M}}",The Correlational Explanatory Faithfulness (CEF) metric is defined as the Pearson correlation coefficient between prediction impact \(\mathcal{I}\) and mention importance \(\mathcal{M}\).
2024.acl-short.49,2,"TVD(P,Q)=\frac{1}{2}\sum_{x}|P(x)-Q(x)|",where P and Q are probability distributions over discrete classes,I=\frac{1}{2}\sum_{c\inC}\left| P(y=c\midx)-P(y=c\midx')\right|,"\(\mathcal{I}\) is the prediction impact for an intervention, measured as the total variation distance between the model's original prediction distribution and the prediction distribution after the intervention."
2024.acl-short.49,3,CCT=\frac{E_{M}(TVD)-E_{-M}(TVD)}{STD(TVD)}\sqrt{\frac{|M || \neg M|}{|M\cup\neg M|^{2}}},"where \(M\) indicates that the explanation mentions the IA, and \(|M|\) indicates the number of examples with explanation mentions",CCT=\frac{\sum_{i=1}^{n}(I_{i}-\overline{I})(M_{i}-\overline{M})}{\sqrt{\sum_{i=1}^{n}(I_{i}-\overline{I})^{2}}\sqrt{\sum_{i=1}^{n}(M_{i}-\overline{M})^{2}}},"where \(\mathcal{I}_i\) is the prediction impact (TVD) for the \(i\)-th intervention, \(\mathcal{M}_i\) is the binary mention importance (1 if mentioned, 0 otherwise), and \(\overline{\mathcal{I}}\) and \(\overline{\mathcal{M}}\) are their sample means."
2024.acl-short.5,1,"s_{ori}(x_{i}|x_{<i})= || \{{ll}\log P_{M_{e}}(x_{i}|x_{<i})-\log P_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{ori,i}^{\alpha}\\-\infty,&x_{i}\notinV_{ori,i}^{\alpha}\\s_{imp}(x_{i}|x_{<i})=\\\{{ll}(1+\beta)Y_{M_{a}}(x_{i}|x_{<i})-\beta Y_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{imp,i}^{\alpha}\\-\infty,&x_{i}\notinV_{imp,i} || s_{int}(x_{i}|x_{<i})= || \{{ll}(1+\beta)Y_{M_{e}}(x_{i}|x_{< i})-\beta Y_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{imp,i}^{\alpha}\\-\infty,&x_{i}\notinV_{imp,i}",,s_{ori}(x_{i}\mid x_{<i}) &=\log\frac{P_{expert}(x_{i}\mid x_{<i})}{P_{amateur}(x_{i}\mid x_{<i})}\\s_{imp}(x_{i}\mid x_{<i}) &=\log P_{expert}(x_{i}\mid x_{<i})-\beta\log P_{amateur}(x_{i}\mid x_{<i}),"The contrastive logit scores for original and improved contrastive decoding, where \(P_{\text{expert}}\) and \(P_{\text{amateur}}\) denote expert and amateur language model probabilities, \(x_i\) is the current token, \(x_{<i}\) is preceding context, and \(\beta\) is a scaling hyperparameter."
2024.acl-short.5,2,"V_{ori,i}^{\alpha}=\{w|P_{M_{e}}(w|x_{<i})>\alpha\max_{w\inV}P_{M_{e}}(w|x_{<i})\} || V_{imp,i}^{\alpha}=\{w|Y_{M_{e}}(w| x_{<i})>\log\alpha+\max_{w\inV}Y_{M_{e}}(w|x_{<i})\}",,"V_{\cdot,i}^{\alpha}=\left\{ x_i\inV : P_{M_e}(x_i\mid x_{<i})\geq\alpha\cdot\max_{w\inV} P_{M_e}(w\mid x_{<i})\right\}","The adaptive plausibility constraint \(\mathcal{V}_{\cdot,i}^{\alpha}\) is the set of tokens \(x_i\) in vocabulary \(\mathcal{V}\) where the expert model \(\mathcal{M}_e\)'s probability exceeds \(\alpha\) times its maximum token probability at position \(i\)."
2024.acl-short.53,1,"L_{FT}=\frac{1}{|D_{M}|}\sum_{d\inD_{M}}L(d;\Phi _{0},\Delta\Phi)","where \(\mathcal{D}_{M}\) is the KE dataset and \(d\) is a fact edit example, \(L\) is the cross entropy loss function applied to autoregressive models, \(\Phi_{0}\) denotes the set of original weights of the language model that are kept frozen, and \(\Delta\Phi\) denotes the additional parameters used by the PEFT adapters","L=-\sum_{t=1}^{T}\log P(x_t\midx_{<t},\theta)","The autoregressive language modeling loss for a sequence of tokens $\mathbf{x} = (x_1, \dots, x_T)$, where $x_t$ is the token at position $t$, $\mathbf{x}_{<t}$ denotes all preceding tokens, and $\theta$ represents the model parameters."
2024.acl-short.53,2,h=W_{0}x+BAx=(W_{0}+BA)x,,\Delta W=BA,"This equation defines the weight update \(\Delta W\) as the product of the low-rank matrices \(B\) and \(A\), where \(B \in \mathbb{R}^{d \times r}\) and \(A \in \mathbb{R}^{r \times k}\) with \(r \ll \min(d,k)\)."
2024.acl-short.56,1,h^{\prime}=SoftMax(h\cdoth^{\prime T})\cdoth^{\prime},,\hat{h}=softmax\left(\frac{h'h^{\top}}{\sqrt{d}}\right)h,The aligned prior memory obtained by cross-attention using the posterior memory as query and the prior memory as key and value.
2024.acl-short.56,2,"\mu^{\prime}_{1},...,\mu^{\prime}_{n}\\\log(\sigma^{\prime 2}_{1}),...,\log(\sigma^{\prime 2}_{n})=[h_{1};h^{\prime}_{1}]\\\cdots\\[h_{n};h^{\prime}_{n}]W^{\prime}_{u}\","where \(W^{\prime}_{u}\) is trainable parameters of \(q_{\phi}(z|r,c)\)",\mu'\\\log\sigma'^2=W\frac{1}{T}\sum_{t=1}^{T}h_t\\\frac{1}{T}\sum_{t=1}^{T}h'_t+b,The mean vector \(\mu'\) and log variance scalar \(\log \sigma'^2\) are computed by a linear transformation of the concatenation of the mean-pooled prior memory \(\mathbf{h}\) and mean-pooled posterior memory \(\mathbf{h}'\).
2024.acl-short.57,1,"a_{k}^{pred}=\operatorname*{arg\,max}_{a_{k}}\!P(a_{k}|q_{k},H_{k},D)",,"a_k^{pred}=Model(q_k, D, H_k)",The model predicts the answer $a_k^{pred}$ for question $q_k$ using document $D$ and conversation history $H_k$.
2024.acl-short.57,2,"P(a_{k}|q_{k},H_{k},D)=P(a_{k}|q_{k},H_{k}^{\star},D)",,"P(a_k | q_k, H_k, D)=P(a_k | q_k, H_k^\star, D)",This equation states that the probability distribution of the answer \(a_k\) should remain invariant when using either the original history \(H_k\) or the augmented history \(H_k^\star\).
2024.acl-short.57,3,"L_{CE}=CE(QA_{\theta^{\prime}}(q_{k},H_{k},D),a_{k}^{gold}) || L_{Cons}=D_{KL}(QA_{\theta^{\prime}}(q_{k},H_{k},D) || QA_{\theta^{\prime}}(q_{k},H_{k}^{\star},D)) || L_{T}=L_{CE}+\lambda L_{Cons}",,L_{T}=L_{CE}+\lambda\cdot L_{Cons},Total loss is the sum of cross-entropy loss and weighted consistency loss.
2024.acl-short.62,1,R(\tau)=\frac{1}{T}\sum_{t=1}^{T}r_{t},,\[ R=\frac{1}{T}\sum_{t=1}^{T} r_t\],The total reward for a response is computed as the average of token-level rewards across the trajectory of length T.
2024.acl-short.62,2,p(\tau^{i}\succ\tau^{j})&=\frac{\exp(R(\tau^{i}))}{\exp(R(\tau^{i}))+\exp(R(\tau^{j}))}\\&=\sigma(R(\tau^{i})-R(\tau^{j})),where \(\tau^{i}\) and \(\tau^{j}\) represent two different responses generated from the same prompt,P(y_i\succ y_j | x)=\frac{\exp(R(\tau_i))}{\exp(R(\tau_i))+\exp(R(\tau_j))},"The Bradley-Terry model defines the probability that response \(y_i\) is preferred over \(y_j\) given prompt \(x\), where \(R(\tau_i)\) and \(R(\tau_j)\) are the trajectory rewards for responses \(y_i\) and \(y_j\) respectively."
2024.acl-short.62,3,"&L=-E_{(\tau^{i},\tau^{j})\simD}[\log\sigma(R(\tau^{i})-R(\tau^{j}))]\\&=-E_{(\tau^{i},\tau^{j})\simD}[\log\sigma((\frac{1}{T^{i}}-\frac{1}{T^{j}})\sum_{t\in U_{0}}r_{t}\\&+\frac{1}{T^{i}}\sum_{t\in U_{1}}r_{t}^{i}-\frac{1}{T^{j}}\sum_ {t\in U_{1}}r_{t}^{j})]",,L=-\log\sigma\left(\frac{1}{T}\sum_{t\in U_{1}}\left( r_{t}^{i}-r_{t}^{j}\right)\right),"The loss function \(\mathcal{L}\) is the negative log-likelihood of the preference probability, computed as the sigmoid of the scaled sum of token-level reward differences over the changed tokens."
2024.acl-short.62,4,"L\approx-E_{(\tau^{i},\tau^{j} )\simD}[\log\sigma(\frac{1}{T^{i}}\sum_{t\in U_{1}}r_{t}^{i}-\frac{ 1}{T^{j}}\sum_{t\in U_{1}}r_{t}^{j})]",,"L=-E_{(\tau^{i},\tau^{j})\simD}\left[\log\sigma\left(\frac{1}{T}\sum_{t\in U_{1}} r_{t}^{i}-\frac{1}{T}\sum_{t\in U_{1}} r_{t}^{j}\right)\right]","The loss function when response lengths are equal ($T^i = T^j = T$), focusing solely on changed tokens."
2024.acl-short.66,1,"H(t,a)=\mathds{1}[\{(i,t)\in a\}=\varnothing]",,"\hat{y}_{t} is a hallucination\iff\nexists j : (j, t)\in a","Target word \(\hat{y}_{t}\) is a hallucination if and only if there is no source word index \(j\) such that the alignment pair \((j, t)\) is in the alignment set \(a\)."
2024.acl-short.66,2,"HR(x,\hat{y},a)=\frac{1}{|\hat{y}|}\sum_{t=1}^{|\hat{y}|}H(t,a)",,"HR=\frac{1}{|\hat{y}|}\sum_{t=1}^{|\hat{y}|} H(t, a)","The Hallucination Rate (HR) is the proportion of hallucinated words in the target translation \(\hat{\mathbf{y}}\), computed as the average of the hallucination indicator \(H(t, a)\) over all target positions."
2024.acl-short.66,3,"H_{wait-k}(t,a)=\mathds{1}[\{(s,t)\in a\mid s\geq t+k\}=\varnothing]",,"H_{GHall}(t, a, k)=\mathds{1}\left[\{(i,t)\in a\mid i\leq k+t-1\}=\varnothing\right]","An indicator function that equals 1 if the target word at position t has no alignment to any source word within the first k+t-1 words, and 0 otherwise."
2024.acl-short.66,4,"R(y_{i},x_{j})=P(y_{i}\midy_{<i},x_{\leq i+k-1}) || \quad-P(y_{i}\midy_{<i},x_{\leq i+k-1, (j,\textbf{0})}) || R(y_{i},y_{j})=P(y_{i}\midy_{<i},x_{\leq i+k-1}) || \quad-P(y_{i}\midy_{<i,(j,\textbf{0} )},x_{\leq i+k-1})",,"R(y_i, w)=\left|\log P(y_i\midc)-\log P(y_i\midc_{\setminus w})\right|","Relevance of a context word w to the next generated word y_i, computed as the absolute difference in log probability when removing w from the context."
2024.acl-short.66,5,"R(y_{i})_{source-side}=\max\{|R(y_{i},x_ {j})|\} || R(y_{i})_{target-side}=\max\{|R(y_{i},y _{j})|\}",,"R_s(i)=\max_{1\leq j\leq\min(|x|, i+k-1)}\left| R(y_i, x_j)\right|","\(R_s(i)\) is the maximum absolute relevance over source words in the current source context at step \(i\), and \(R_t(i)\) is the maximum absolute relevance over target words in the current target context at step \(i\)."
2024.acl-short.66,6,TSSR(y_{i})=\frac{R(y_{i})_{target-side}}{R(y_{i} )_{source-side}},,TSSR(y_i)=\frac{R(y_{i})_{target-side}}{R(y_{i})_{source-side}},\(\text{TSSR}(y_i)\) is the ratio of target-side relevance to source-side relevance for generating the word \(y_i\).
2024.acl-short.68,1,"T_{i}=\operatorname*{Top\_}{d\inM}k\f(s_{i},d)",,"T_{i}=top-k_{d\inM} f(s_i, d)","The set of top-k retrieved passages from corpus \(\mathcal{M}\) for medical code \(c_i\)'s surface name \(s_i\), ranked by similarity function \(f\)."
2024.acl-short.68,2,"e_{i}=LLM([Prompt,t_{i,1},\cdots,t_{i,k}])",where \(t_{i}\in\mathcal{T}_{i}\) stands for the retrieved passages in Eq,"e_i=LLM(s_i,T_i)",The summarized knowledge \( e_i \) for medical code \( c_i \) is generated by an LLM using its surface name \( s_i \) and retrieved passages \( \mathcal{T}_i \).
2024.acl-short.68,3,"h_{i}^{k}=PLM(X_{i}^{k}),\;\;\widehat{y}_{i,1}=MLP ( || _{k\inS}h_{i}^{k})",,"D_i=\mathop{ || }\limits_{c\in D_i} (c, e)",\(D_i\) is the concatenation of each disease code \(c\) and its summarized knowledge \(e\) for all codes in the set \(D_i\) (the set of disease codes in the \(i\)-th visit).
2024.acl-short.68,4,"e_{i}=HyGT(G,V_{i}),\widehat{y}_{i,2}=MLP(e_{i})",where \(\mathbf{e}_{i}\) is the representation of patient \(i\) after hypergraph transformer,"\widehat{y}_{i,2}=MLP\left(HyGT(G)[e_i]\right)",where \(e_i\) is the hyperedge representing patient \(i\) in the hypergraph \(\mathcal{G}\).
2024.acl-short.68,5,"L_{aug}=E_{(V_{i},y_{i})\simP}\;\ell(\widehat{y}_{i,1},y_{i})+\lambdaD_{KL}(\widehat{y}_{i,1},\widetilde{y}) || L_{loc}=E_{(V_{i},y_{i})\simP}\;\ell(\widehat{y}_{i,2},y_{i})+\lambdaD_{KL}(\widehat{y}_{i,2},\widetilde{y})",,"L=\frac{1}{N}\sum_{i=1}^{N}\left[\alpha\cdot\ell(\widehat{y}_{i,1}, y_i)+(1-\alpha)\cdot\ell(\widehat{y}_{i,2}, y_i)\right]","The overall co-training loss \(\mathcal{L}\) averages a weighted combination of per-patient losses from the augmented model \(\widehat{y}_{i,1}\) and local model \(\widehat{y}_{i,2}\) over \(N\) patients, with hyperparameter \(\alpha\) controlling the weight balance and \(\ell\) denoting the per-example loss function."
2024.acl-short.71,1,"hyp^{*}=\operatorname*{arg\,max}_{hyp\inhyps}utility(hyp)",,"hyp^{*}=\arg\max_{hyp_i\inhyp}E_{ref\sim p(\cdot|src)}\left[ u(hyp_i,ref)\right]","The best hypothesis \(\mathit{hyp}^{*}\) is selected by maximizing the expected utility over the set of hypotheses \(\mathit{hyp}\), where the expectation is taken over the reference distribution conditioned on the source."
2024.acl-short.71,2,"utility(hyp)\approx\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}} metric(hyp,\textit{ref})",,"utility(hyp)\approx\frac{1}{m}\sum_{j=1}^{m}metric(hyp,ref_{j})",The utility of a hypothesis is approximated by the average metric score computed against each sampled pseudo-reference.
2024.acl-short.71,3,\overline{\textit{ref}}=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textit{ ref},,\overline{ref}=\frac{1}{m}\sum_{ref\inrefs}ref,The aggregate reference representation is computed as the average of all individual reference representations.
2024.acl-short.71,4,"utility(hyp)\approxmetric(hyp,\overline{\textit{ref}})",,"utility(hyp)\approxmetric(hyp,\overline{\textit{ref}})",This equation approximates the utility of a hypothesis by computing the metric score between the hypothesis and the aggregate representation of the references.
2024.acl-short.71,5,ChrF_{\beta}=\frac{(1+\beta^{2})\cdotChrP\cdotChrR}{\beta^{2}\cdotChrP+ChrR} || ChrP=\frac{|hyp\cap\textit{ref}|}{|hyp|} and ChrR=\frac{|hyp\cap\textit{ref}|}{|\textit{ref}|},"where

\[\text{ChrP}=\frac{|hyp\cap\textit{ref}|}{|hyp|}\text{ and }\text{ChrR}=\frac{|hyp \cap\textit{ref}|}{|\textit{ref}|},\]

and the parameter \(\beta\) controls the relative importance of precision and recall","metric(hyp,\overline{ref})=(1+\beta^2)\frac{precision\cdotrecall}{\beta^2\cdotprecision+recall}",The metric for the aggregated ChrF is the F_{\beta} score where precision and recall are computed by comparing character n-grams between the hypothesis and the aggregate reference representation.
2024.acl-short.71,6,\overline{\textit{ref}}=\frac{1}{m}\underbrace{\biguplus}_{\textit{ref}\in\textit{refs}}\textit{ref},where \(\biguplus\) is an operation that sums up the counts of each n-gram,\overline{\textit{ref}}[g]=\frac{1}{m}\sum_{j=1}^{m}\textit{ref}_j[g],"For each n-gram \( g \), the aggregated reference representation is the average of the counts of \( g \) in the reference set."
2024.acl-short.71,7,"\textbf{{hyp}},\\textbf{{ref}},\\textbf{{src}}=emb(\textbf{{hyp}}),\emb(\textbf{{ref}}),\emb(\textbf{{src}})",,"e_{src}=Encoder_{src}(src),\quade_{ref}=Encoder_{ref}(ref),\quade_{hyp}=Encoder_{hyp}(hyp)","Fixed-size embeddings for the source, reference, and hypothesis computed by separate encoders."
2024.acl-short.71,8,"comet(\textbf{{hyp}})=score(\textbf{{hyp}},\\textbf{{ref}},\\textbf{{src}})",,"score=FFN(\textbf{hyp},\textbf{ref},\textbf{src})","The scalar quality score is computed by a feed-forward network from the embeddings of the hypothesis, reference, and source."
2024.acl-short.71,9,\overline{\textbf{{ref}}}=\frac{1}{m}\sum_{\textbf{{ref}}\in\textbf{{ref}}}emb(\textbf{{ref}}),,\overline{\textbf{ref}}=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}emb(\textit{ref}),The aggregate reference embedding is computed by averaging the embeddings of all references in the set of sampled references.
2024.acl-short.71,10,"comet(\textbf{{hyp}})\approxscore(\textbf{{hyp}},\\overline{\textbf{{ref}}},\\textbf{{src}})",,"comet(\textbf{{hyp}})=score(\textbf{{hyp}},\overline{\textbf{{ref}}},\textbf{{src}})","The COMET score for a hypothesis is computed by applying the score function to the hypothesis embedding, aggregated reference embedding, and source embedding."
2024.acl-short.72,1,h_{i}=XLMRoberta-Layer^{1}(x_{i}),"where \(h_{i}\) is the representation of the ""[CLS]"" token",h_i=XLM-Roberta^{(1)}(x_i),"\( h_i \) denotes the 768-dimensional node representation of the \( i \)-th DOM node, obtained by encoding its text representation \( x_i \) through the first layer of the XLM-Roberta model."
2024.acl-short.72,2,\hat{h}_{i}=Transformer(Linear(h_{i})),where the linear layer projects \(h_{i}\) to 256-dimensional embeddings for efficient modeling,H'=Transformer(H),where \( H' \) is the encoded node representations from the 3-layer transformer with 8 attention heads
2024.acl-short.72,3,P(y^{k}_{i}=1|x_{i})=Sigmoid(MLP(\hat{h}_{i})),,P(y^{k}_{i}=1|x_{i})=\sigma\left(W_{k}\hat{h}_{i}+b_{k}\right),"where \(\mathbf{W}_{k}\) and \(\mathbf{b}_{k}\) are the weight matrix and bias vector for the \(k\)-th label, and \(\sigma\) denotes the sigmoid function."
2024.acl-short.72,4,"L=\sum_{k=1}^{6}\sum_{i=1}^{n}CrossEntropy(P(y^{k}_{i}|x_{i}), Y^{k}_{i})",where \(\mathcal{Y}^{k}_{i}\) is the ground truth label,L=\frac{1}{n}\sum_{i=1}^{n}\sum_{k=1}^{6}\left[-y^{k}_{i}\log P(y^{k}_{i}=1|x_{i})-(1-y^{k}_{i})\log (1-P(y^{k}_{i}=1|x_{i}))\right],The loss \(L\) is the average binary cross-entropy over all \(n\) nodes and all six categories.
ICLR_2024_oral_1,1,I(\theta):=E_{\Upsilon\sim p_{\theta}} [\nabla_{\theta}\log p_{\theta}(\Upsilon)\cdot\nabla_{\bm {\theta}}\log p_{\theta}(\Upsilon)^{\top}],,I(\theta)=E_{\tau\sim p_{\theta}}}\left[\nabla_{\theta}\log p_{\theta}(\tau)\nabla_{\theta}\log p_{\theta}(\tau)^{\top}\right],The Fisher information matrix for the parameter vector \(\mathbf{\theta}\) with respect to the trajectory distribution \(p_{\mathbf{\theta}}\).
ICLR_2024_oral_1,2,E_{D\sim p_{\theta^{\star}}}([\widehat{\theta} (D)-\theta^{\star})(\widehat{\theta}(D)-\theta^{\star})^{\top}]\succeq T^{-1}\cdotI(\theta^{\star})^ {-1},,Cov(\widehat{\theta}(D))\succeq\frac{1}{T}I^{-1}(\theta^\star),"The covariance matrix of the unbiased estimator \(\widehat{\mathbf{\theta}}(\mathfrak{D})\) is bounded below by \(\frac{1}{T} \mathcal{I}^{-1}(\mathbf{\theta}^\star)\), where \(\mathcal{I}(\mathbf{\theta}^\star)\) is the Fisher information matrix for one trajectory."
ICLR_2024_oral_1,3,E_{D\sim p_{\theta^{\star}}}[\|\widehat{\theta} (D)-\theta^{\star}\|_{2}^{2}]=tr(E_{ D\sim p_{\theta^{\star}}}[(\widehat{\theta}(D)-\theta^{\star})(\widehat{\theta}(D)-\theta^{\star})^{\top}])\geq T^{-1}\cdottr(I(\theta^{\star})^{-1}),,E_{D\sim p_{\theta^{\star}}}\left[\|\widehat{\theta}(D)-\theta^{\star}\|_{2}^{2}\right]\geq T^{-1}\cdottrace\left(I(\theta^{\star})^{-1}\right),The mean-squared error of the unbiased estimator \(\widehat{\mathbf{\theta}}\) is bounded below by \(T^{-1}\) times the trace of the inverse Fisher information matrix at \(\mathbf{\theta}^{\star}\).
ICLR_2024_oral_1,4,"I(\theta^{\star},\pi_{exp}):=E_{\tau\sim p_{\theta^{\star}}(\cdot\mid\pi_{exp})}[\nabla_{\theta}\log p_{\theta^{\star}}(\tau\mid\pi_{exp})\cdot\nabla_{\theta}\log p_{\theta^{\star}}(\tau\mid\pi_{ exp})^{\top}]",,I(\theta;\pi_{exp}) :=E_{\tau\sim p_{\theta}(\cdot\mid\pi_{exp})}\left[\nabla_{\theta}\log p_{\theta}(\tau\mid\pi_{exp})\cdot\nabla_{\theta}\log p_{\theta}(\tau\mid\pi_{exp})^{\top}\right],Equation 4 defines the Fisher information matrix for parameter \(\theta\) under exploration policy \(\pi_{\mathrm{exp}}\) as the expected outer product of the score function with respect to the trajectory distribution induced by \(\pi_{\mathrm{exp}}\).
ICLR_2024_oral_1,5,"\arg\min_{\pi}tr(I(\theta^{\star},\pi)^{-1})",,"\pi_{exp}^*\in\arg\min_{\pi_{exp}}tr\left(I(\theta^{\star},\pi_{exp})^{-1}\right)",The optimal exploration policy minimizes the trace of the inverse Fisher information matrix for the true parameter.
ICLR_2024_oral_1,6,"s_{h+1}=f_{\theta}(s_{h},a_{h})+w_{h}","where \(s_{h}\) and \(a_{h}\) are the current state and action, \(w_{h}\sim\mathcal{N}(0,\sigma_{w}^{2}\cdot I)\) is Gaussian process noise, and \(f_{\mathbf{\theta}}\) are the nominal dynamics","s_{h+1}=f_{\theta}(s_h, a_h)+\epsilon_h,\quad\epsilon_h\simN(0,\Sigma)","The next state \(s_{h+1}\) is a Gaussian random vector with mean \(f_{\theta}(s_h, a_h)\) and fixed covariance \(\Sigma\)."
ICLR_2024_oral_1,7,"I(\theta,\pi)=\sigma_{w}^{-2}\cdotE_{p_{\theta}(\cdot\mid\pi)}[\sum_{h=1}^{H}\nabla_{\theta}f_{\theta}(s_{h},a_ {h})\cdot\nabla_{\theta}f_{\theta}(s_{h},a_{h})^{\top}]",,"I(\theta,\pi)=\frac{1}{\sigma_{w}^{2}}E_{\tau\sim p_{\theta}(\cdot\mid\pi)}\left[\sum_{h=1}^{H-1}\nabla_{\theta} f_{\theta}(s_{h},a_{h})^{\top}\nabla_{\theta} f_{\theta}(s_{h},a_{h})\right]","The Fisher information matrix for parameter vector \(\mathbf{\theta}\) under policy \(\pi\) is the expected sum over time steps of the outer product of the gradient of the dynamics function \(f_{\mathbf{\theta}}\) with respect to \(\mathbf{\theta}\), scaled by the inverse noise variance \(\sigma_w^{-2}\)."
ICLR_2024_oral_1,8,"\pi_{exp}=\arg\min_{\pi}E_{\theta\sim q_{0}}[tr (I(\theta,\pi)^{-1})]",,"\pi_{exp}^*\in\arg\min_{\pi}E_{\theta\sim p(\theta)}\left[tr\left(I(\theta,\pi)^{-1}\right)\right]",The optimal exploration policy minimizes the expected trace of the inverse Fisher information matrix over a prior distribution of the parameters.
ICLR_2024_oral_1,9,E_{\theta\sim q_{\theta}}[E_{\tau_{ sim}\sim p_{\theta}(\cdot\midA(\uptau_{real}) )}[\|\uptau_{real}-\uptau_{sim}\|_{2}^{2}]],"where \(p_{\mathbf{\theta}}(\cdot\mid\mathcal{A}(\mathbf{\uptau}_{\mathrm{real}}))\) denotes the distribution over trajectories generated by the simulator with parameter \(\mathbf{\theta}\), and playing the same sequence of actions as were played in \(\mathbf{\uptau}_{\mathrm{real}}\)",E_{\theta\sim q_{\phi}}\left[-\log p_{\theta}(\uptau_{real}\mid\pi_{exp})\right],The expected negative log-likelihood of the real trajectory under parameters sampled from the distribution \(q_{\mathbf{\phi}}\).
ICLR_2024_oral_10,1,"R=\{r_{1},\dots,r_{m}\}",where each ray \(\mathbf{r}_{i}\in\mathbb{R}^{6}\) is associated with a known pixel coordinate \(\mathbf{u}_{i}\),"R=\left\{\left(o_i,d_i\right)\right\}_{i=1}^{m}\quadwith\quado_i\inR^3,d_i\inS^2","The camera is represented by a set \(\mathcal{R}\) of \(m\) rays, where each ray \(i\) is defined by an origin point \(\mathbf{o}_i\) and a unit direction vector \(\mathbf{d}_i\) on the 2-sphere."
ICLR_2024_oral_10,2,"r=\langled,m\rangle\inR^{6}","where \(\mathbf{m}=\mathbf{p}\times\mathbf{d}\in\mathbb{R}^{3}\) is the moment vector, and importantly, is agnostic to the specific point on the ray used to compute it",r=d\\p\timesd,"Each ray \(\mathbf{r}\) is represented by its direction vector \(\mathbf{d}\) and the moment vector \(\mathbf{p} \times \mathbf{d}\), where \(\mathbf{p}\) is a point on the ray."
ICLR_2024_oral_10,3,"d=R^{\top}K^{-1}u,\qquadm=(-R^{\top}t)\timesd",,m=p\timesd,where \(\mathbf{p}\) is the camera center and \(\mathbf{d}\) is the ray direction.
ICLR_2024_oral_10,4,"c=\operatorname*{arg\,min}_{p\inR^{3}}\\sum_{\langled,m\rangle\inR}\lVertp\timesd-m\rVert^{2}",,c=\argmin_{x}\sum_{i=1}^{m}\left\|d_i\timesx-m_i\right\|^2,The camera center \(\mathbf{c}\) is estimated by minimizing the sum of squared distances from \(\mathbf{c}\) to each ray in the bundle.
ICLR_2024_oral_10,5,"P=\operatorname*{arg\,min}_{\|H\|=1}\sum_{i=1}^{m}\|Hd_{i}\timesu_{i}\|",,"P=\operatorname*{arg\,min}_{P}\sum_{i}\lVertu_{i}\times (Pd_{i})\rVert^{2}","where \(\mathbf{P}\) is the homography matrix, \(\mathbf{u}_{i}\) are the 2D pixel coordinates, and \(\mathbf{d}_{i}\) are the predicted ray directions."
ICLR_2024_oral_10,6,f_{feat}(I)=f\inR^{p\times p\times d},,"F_j=\left\{f_{j,1},f_{j,2},\dots,f_{j,m}\right\}","where \(\mathcal{F}_j\) is the set of feature tokens for image \(j\), and \(\mathbf{f}_{j,i}\) is the feature vector for the \(i\)-th patch."
ICLR_2024_oral_10,7,"\{\hat{R}\}_{i=1}^{N}=f_{Regress}(\{f_{i},u_{i}\}_{i=1}^{N\cdot p^{2}})",,\hat{R}=Transformer\left(F\oplusU\right),The transformer processes concatenated spatial features \(\mathbf{F}\) and normalized device coordinates \(\mathbf{U}\) to predict the ray bundle \(\hat{\mathcal{R}}\) for each patch.
ICLR_2024_oral_10,8,L_{recon}=\sum_{i=1}^{N}\|\hat{R}_{i}- R_{i}\|_{2}^{2},,"L_{recon}=\frac{1}{N\cdot m}\sum_{i=1}^{N}\sum_{j=1}^{m}\|\hat{r}_{i,j}-r_{i,j}\|_2^2","where \(\hat{\mathbf{r}}_{i,j}\) and \(\mathbf{r}_{i,j}\) are the predicted and ground truth Plücker coordinates of the j-th ray in the i-th image, respectively, and \(m\) is the number of rays per image."
ICLR_2024_oral_10,9,x_{t}=\sqrt{\alpha_{t}}x_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,"where \(\epsilon\sim\mathcal{N}(0,\mathbf{I})\) and \(\alpha_{t}\) is a hyper-parameter schedule of noise weights such that \(x_{T}\) can be approximated as a standard Gaussian distribution","x_t=\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t}\epsilon,\quad\epsilon\simN(0,I)","The forward diffusion process at timestep \(t\) corrupts the original ray bundle \(x_0\) by scaling it and adding scaled Gaussian noise \(\epsilon\), where \(\bar{\alpha}_t\) is determined by the noise schedule."
ICLR_2024_oral_10,10,"L(\theta)=E_{t,x_{0},\epsilon}\|x_{0}-f_{\theta }(x_{t},t)\|^{2}",,"\hat{x}_0=f_{\theta}(x_t, t)",The denoising network \(f_{\theta}\) predicts the denoised ray bundle \(\hat{\mathbf{x}}_0\) from the noisy ray bundle \(\mathbf{x}_t\) at diffusion time step \(t\).
ICLR_2024_oral_10,11,"\{\hat{R}\}_{i=1}^{N}=f_{Diffusion}(\{f_{i},u_{i},r_{i,t}\}_{i=1}^{N\cdot p^{2}},t) || r_{i,t}=\sqrt{\bar{\alpha}_{t}}r_{i}+\sqrt{1-\bar{\alpha}_{t}}\epsilon","where the noisy rays \(\mathbf{r}_{i,t}\) can be computed as:

\[\mathbf{r}_{i,t}=\sqrt{\bar{\alpha}_{t}}\mathbf{r}_{i}+\sqrt{1-\bar{\alpha}_{t}}\epsilon","\{\hat{r}_{0,i}\}_{i=1}^{N\cdot p^{2}}=f_{\theta}\left(\{f_{i},u_{i},r^{(t)}_{i},\phi(t)\}_{i=1}^{N\cdot p^{2}}\right)","The denoising network \(f_{\theta}\) predicts the denoised ray \(\hat{\mathbf{r}}_{0,i}\) for each patch from the corresponding patch feature \(\mathbf{f}_{i}\), pixel coordinate \(\mathbf{u}_{i}\), noisy ray \(\mathbf{r}^{(t)}_{i}\), and time embedding \(\phi(t)\)."
ICLR_2024_oral_11,1,"O_{ij}=\sum_{v=1}^{k}I[y_{ij}\neq y_{ij}^{(v)}],\forall j\in Y_{i}",where \(\mathbb{I}[\cdot]\) is the indicator function and \(y_{ij}\) is the \(j\)-th candidate label of \(\mathbf{x}_{i}\),O_{ij}=\sum_{p\in N_k(i)}I\{ j\notin Y_p\},The metric \(O_{ij}\) counts how many of the \(k\) nearest neighbors of instance \(\mathbf{x}_i\) do not include the candidate label \(j\) in their candidate label sets.
ICLR_2024_oral_11,2,\gamma_{i}=\lceil\tau(|Y_{i}|-1)\rceil,where \(\lceil\cdot\rceil\) is the ceiling function that returns the least integer greater than or equal to the given number,\sum_{j\in Y_i}I[O_{ij}\geq\tau],The number of eliminated candidate labels for instance \(\mathbf{x}_i\).
ICLR_2024_oral_11,3,\widetilde{Y}_{i}=Top-\gamma_{i}-argmax_{j\in Y_{i}}(O_{ij}),where \(\mathrm{Top}\text{-}\gamma_{i}\text{-}\mathrm{argmax}_{i}\) returns a subset of indices (i,\hat{Y}_i=\left\{ j\in Y_i\mid O_{ij}\leq O_{i}^{(|Y_i|-\gamma_i)}\right\},"where $\hat{Y}_i$ is the pruned candidate label set for instance $\mathbf{x}_i$, $O_{i}^{(k)}$ denotes the $k$-th smallest value in $\{ O_{ij} \mid j \in Y_i \}$, and $\gamma_i$ is the number of candidate labels to eliminate as defined in Eq. (2)."
ICLR_2024_oral_11,4,"P(O_{iy^{\prime}}^{(\xi_{i})}<O_{iy})\leq\sum_{j=1}^{k}\sum_{m=\xi_{i}} ^{|Y_{i}^{\prime}|}\binom{|Y_{i}^{\prime}|}{m}\eta^{m}(1-\eta)^{(|Y_{i}^{\prime }|-m)}b_{\delta_{k}}(k,j)",,\Pr\left[ O_{iy} > O_{iy'}^{(|Y_i'|-\gamma_i+1)}\right]\leq\binom{|Y_i'|}{\gamma_i}\left(\sum_{m=0}^{k}\binom{k}{m} (1-t)^{m} t^{k-m}\cdot\left(\sum_{l=0}^{m-1}\binom{k}{l} (1-q)^{l} q^{k-l}\right)\right)^{\gamma_i},"Upper bound on the probability of incorrect pruning for instance \(\mathbf{x}_{i}\), where the binomial terms represent the down-voting statistics distributions and the inner sums compute the probabilities for the true label and false candidate labels."
ICLR_2024_oral_11,5,"P(O_{iy}^{(\xi_{i}^{2})}<O_{iy})-P(O_{iy}^{(\xi_{i}^{1})}<O _{iy})\leqslant\sum_{j=1}^{k}\sum_{m=\xi_{i}^{2}}^{\xi_{i}^{1}-1}\binom{|Y^{\prime}_{i}|}{m}\eta^{m}(1-\eta)^{|Y^{\prime}_{i}|-m}b_{\delta_{k}}(k,j)",,"P\left( O_{iy^{\prime}}^{(\xi_{i}^2)} < O_{iy}\leq O_{iy^{\prime}}^{(\xi_{i}^1)}\right)\leq\sum_{j=1}^{k}\sum_{m=\xi_{i}^2}^{\xi_{i}^1-1}\binom{|Y_{i}^{\prime}|}{m}\eta^{m} (1-\eta)^{(|Y_{i}^{\prime}|-m)} b_{\delta_{k}}(k,j)",upper bound on the extra pruning error when increasing the number of eliminated candidate labels from \(\gamma_i^1\) to \(\gamma_i^2\)
ICLR_2024_oral_13,1,"q(x_{t}|x_{t-1})=N(x_{t};\sqrt{1-\beta_{t}}x_{t},\beta_{t}I ),\quadfor t\in\{1,...,T\}","where \(\beta_{t}\in(0,1)\) is the scheduled variance at step \(t\)","q(x_t | x_{t-1})=N(x_t;\sqrt{1-\beta_t} x_{t-1},\beta_tI)","The forward diffusion process at step \( t \) is a Gaussian distribution conditioned on the previous state \( x_{t-1} \), with mean \( \sqrt{1 - \beta_t} x_{t-1} \) and variance \( \beta_t \mathbf{I} \), where \( \beta_t \) is the fixed noise schedule parameter."
ICLR_2024_oral_13,2,x_{t}=\sqrt{\bar{\alpha}_{t}}x_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,"where, \(\bar{\alpha}_{t}=\prod_{i=1}^{t}(1-\beta_{t})\)","q(x_t | x_0)=N\left(x_t;\sqrt{\bar{\alpha}_t} x_0, (1-\bar{\alpha}_t)I\right)",where \(\bar{\alpha}_t = \prod_{i=1}^{t} (1 - \beta_i)\) is the cumulative noise schedule product at step \(t\).
ICLR_2024_oral_13,3,\hat{x}_{0}^{t}=\frac{x_{t}-\sqrt{1-\bar{\alpha}_{t}}\epsilon_{\theta}(x_{t}) }{\sqrt{\bar{\alpha}_{t}}},,\hat{x}_{0}=\frac{ x_{t}-\sqrt{1-\bar{\alpha}_{t}}\epsilon_{\theta}(x_{t}) }{\sqrt{\bar{\alpha}_{t}} },where \(\hat{x}_{0}\) is the estimated original image at step \(t\).
ICLR_2024_oral_13,4,"x_{t-1}=\sqrt{\bar{\alpha}_{t-1}}\hat{x}_{0}^{t}+\sqrt{1-\Text-conditional diffusion models, such as Stable Diffusion (Rombach et al., 2022), employ classifier-free diffusion guidance (Rombach et al., 2022) to steer the sampling process. Given a text prompt\(p\), its embedding\(e_{p}=f(p)\) is computed using a pre-trained CLIP text encoder\(f(\cdot)\)(Radford et al., 2021; Cherti et al., 2023). In the reverse process, the conditional sampling adheres to Eq. (3) and Eq. (4), but the predicted noise\(\epsilon_{\theta}(x_{t})\) is changed to:\[\epsilon_{\theta}(x_{t},e_{\theta})+s(\underbrace{\epsilon_{\theta}(x_{t},e_ {p})-\epsilon_{\theta}(x_{t},e_{\theta})}_{text-conditional noise prediction})","where, \(e_{\theta}\) represents the prompt embedding of an empty string, and \(s\) determines the guidance strength, controlling the alignment of the generation to the prompt",x_{t-1}=\frac{\sqrt{\bar{\alpha}_{t-1}}\beta_t }{1-\bar{\alpha}_{t}}\hat{x}_{0}^{t}+\frac{\sqrt{\alpha_t} (1-\bar{\alpha}_{t-1}) }{1-\bar{\alpha}_{t}} x_t,the mean of the reverse diffusion step for \(x_{t-1}\) given the current \(x_t\) and the estimated \(\hat{x}_{0}^{t}\)
ICLR_2024_oral_13,5,"d=\frac{1}{T}\sum_{t=1}^{T}\|\epsilon_{\theta}(x_{t},e_{p})-\epsilon_{\theta} (x_{t},e_{\theta})\|_{2}",,"M(p)=\frac{1}{T}\sum_{t=1}^{T}\left\|\epsilon_{\theta}(x_{t},e_{p})-\epsilon_{\theta}(x_{t},e_{\theta})\right\|_2","where \( M(p) \) is the detection metric for prompt \( p \), \( T \) is the total number of diffusion steps, and \( \| \cdot \|_2 \) denotes the L2 norm."
ICLR_2024_oral_13,6,"L(x_{t},e)=\|\epsilon_{\theta}(x_{t},e)-\epsilon_{\theta}(x_{t},e_{\emptyset})\|_{2}",,"\min_{\delta}\frac{1}{T}\sum_{t=1}^{T}\left\|\epsilon_{\theta}(x_{t}, e_{p}+\delta)-\epsilon_{\theta}(x_{t}, e_{\theta})\right\|_{2}+\lambda\sum_{i=1}^{N}\|\delta^{(i)}\|_{2}","The minimization objective to identify trigger tokens, where \(\delta^{(i)}\) is the perturbation for the \(i\)-th token in the prompt embedding, and \(\lambda\) is a regularization coefficient."
ICLR_2024_oral_13,7,"SS_{e^{i}}=\frac{1}{T}\sum_{t=1}^{T}\|\nabla_{e^{i}}L(x_{t}, e)\|_{2}",,"s_{i}=\left\|\frac{\partialL(x_{t}, e)}{\partial e_{i}}\right\|_{2}",The significance score for the token at position \(i\) is the L2 norm of the gradient of the loss \(\mathcal{L}\) with respect to the token embedding \(e_i\).
ICLR_2024_oral_14,1,"F^{*}&=\operatorname*{argmax}_{F}p(F|D _{src},D_{tgt})=\operatorname*{argmax}_{F}p(D_{src},D_{tgt}|F)\cdot p(F)\\&=\operatorname*{argmax}_{F}\{\underbrace{\log p(D_{src},D _{tgt}|F)}_{data term}+\underbrace{\log p(F)}_{prior term}\}",,"F^{*}=\arg\max_{F} p(D_{src}, D_{tgt} | F) p(F)",The optimal correspondence field \( F^{*} \) is estimated by maximizing the product of the likelihood and the prior.
ICLR_2024_oral_14,2,"X_{t}=\sqrt{\alpha_{t}}X_{0}+\sqrt{1-\alpha_{t}}Z,\quad Z\simN(0,I)",where \(\alpha_{t}=\prod_{i=1}^{t}(1-\beta_{i})\),"q(X_t | X_0)=N(X_t;\sqrt{\bar{\alpha}_t} X_0, (1-\bar{\alpha}_t) I)","The forward diffusion distribution at time step \(t\) given the original data \(X_0\), where \(\bar{\alpha}_t = \prod_{s=1}^{t} (1 - \beta_s)\)."
ICLR_2024_oral_14,3,"X_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(X_{t},t;K)+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t}}}\Big{(}X_{t}-\sqrt{\alpha_{ t}}F_{\theta}(X_{t},t;K)\Big{)}+\sigma_{t}Z",where \(\sigma_{t}\) is the covariance value of Gaussian distribution at time step \(t\),"X_{t-1}=\mu_{\theta}(X_{t}, t)+\sigma_{\theta}(X_{t}, t)\epsilon,\quad\epsilon\simN(0, I)","One step in the reverse diffusion process sampling \(X_{t-1}\) given \(X_t\) with mean \(\mu_{\theta}(X_t, t)\) and standard deviation \(\sigma_{\theta}(X_t, t)\)."
ICLR_2024_oral_14,4,"F^{*}=F_{\theta}(D_{src},D_{tgt})\approx\underset{F }{argmax}\\underbrace{\log p(D_{src},D_{tgt}|F)}_{data term}","where \(\mathcal{F}_{\theta}(\cdot)\) and \(\theta\) represent a feed-forward network and its parameters, respectively","F^{*}=\operatorname*{argmax}_{F}\log p(D_{src}, D_{tgt} | F)","The equation estimates dense correspondence by maximizing the log-likelihood of feature descriptors given the correspondence field, representing the data term without prior regularization."
ICLR_2024_oral_14,5,"F^{*}=F_{\theta}(D_{src},D_{tgt})\approx\underset{F}{argmax}\p(F|D_{src},D_{tgt}) || =\underset{F}{argmax}\{\underbrace{\log p(D_{ src},D_{tgt}|F)}_{data term}+\underbrace{\log p(F)}_{prior term}\}",,"\min_{\theta}E_{t, F_0, Z}\left[\left\| F_0-F_{\theta}(F_t, t; D_{src}, D_{tgt})\right\|^2\right]",the training objective for the conditional diffusion model that minimizes the mean squared error between the ground truth correspondence field and the predicted clean correspondence field at each time step.
ICLR_2024_oral_14,6,"F_{t}=\sqrt{\alpha_{t}}F_{0}+\sqrt{1-\alpha_{t}}Z,\quad Z\simN(0,I)",where \(F_{0}\) is the ground-truth correspondence,"F_t=\sqrt{\alpha_t} F_0+\sqrt{1-\alpha_t} Z,\quad Z\simN(0, I)",where \(\alpha_{t}=\prod_{i=1}^{t}(1-\beta_{i})\)
ICLR_2024_oral_14,7,"F_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(X_{t},t;D_{src},D_{tgt})+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t }}}\Big{(}X_{t}-\sqrt{\alpha_{t}}F_{\theta}(F_{t},t;D_{src },D_{tgt})\Big{)}+\sigma_{t}Z","where \(\mathcal{F}_{\theta}(F_{t},t;D_{\mathrm{src}},D_{\mathrm{tgt}})\) directly predicts the denoised correspondence \(\hat{F}_{0,t}\) with source and target features, \(D_{\mathrm{src}}\) and \(D_{\mathrm{tgt}}\), as conditions","F_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(F_{t},t;F_{init},C^{l})+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t}}}}\Big{(}F_{t}-\sqrt{\alpha_{t}}F_{\theta}(F_{t},t;F_{init},C^{l})\Big{)}+\sigma_{t}Z","where \(F_{\text{init}}\) is the initial correspondence, \(C^{l}\) is the local matching cost, and \(Z\) is a standard Gaussian noise."
ICLR_2024_oral_14,8,"C(i,j)=\frac{D_{src}(i)\cdot D_{tgt}(j)}{\|D_{src}(i)\|\|D_{tgt}(j)\|}","where \(i\in[0,h_{\text{src}})\times[0,w_{\text{src}})\), \(j\in[0,h_{\text{tgt}})\times[0,w_{\text{tgt}})\), and \(\|\cdot\|\) denotes \(l\)-2 normalization","C(i,j)=D_{src}(i)^\top D_{tgt}(j)","The matching cost \( C(i,j) \) between source pixel \(i\) and target pixel \(j\) is computed as the dot product of their feature vectors."
ICLR_2024_oral_14,9,"L=E_{F_{0},t,Z\simN(0,I),D_{src},D_{tgt}}[\|F_{0}-F_{\theta}(F_{t},t;F_{init },C^{l})\|^{2}]",,"L_{diff}=E_{t\simU(0,T), F_0, Z}\left[\left\|F_{\theta}(F_t, t; F_{init}, C^l)-F_0\right\|^2\right]","The diffusion model training loss \(\mathcal{L}_{\text{diff}}\) computes the expected squared L2 distance between the predicted denoised correspondence \(\mathcal{F}_{\theta}(F_t, t; F_{\text{init}}, C^l)\) and the ground truth flow \(F_0\), where \(t\) is uniformly sampled from \([0,T]\), \(F_0\) is the ground-truth correspondence, and \(Z\) is Gaussian noise."
ICLR_2024_oral_15,1,"\nabla_{\Theta}L_{SDS}=E_{t,p,\epsilon}[w(t)(\epsilon_{\phi}(I_{RGB}^{p};t,\tilde{I}_{RGB}^{r},\Delta p)-\epsilon)\frac{\partial I_{RGB}^{p}}{\partial\Theta}]","where \(w(t)\) is a weighting function, \(\epsilon_{\phi}(\cdot)\) is the predicted noise by the 2D diffusion prior \(\phi\), and \(\Delta p\) is the relative camera pose change from the reference camera \(r\)","L_{SDS}=E_{t\simU(0,1),\epsilon\simN(0,I)}\left[ w(t)\left\|\epsilon_{\phi}\left(z_{t}; t,y\right)-\epsilon\right\|_2^2\right]","\(\mathcal{L}_{\text{SDS}}\) is the SDS loss, \(t\) is the timestep sampled uniformly, \(\epsilon\) is Gaussian noise, \(w(t)\) is the timestep weighting, \(\epsilon_{\phi}\) is the diffusion prior's noise prediction, \(\mathbf{z}_{t}\) is the noisy rendered image, and \(\mathbf{y}\) is the conditioning input."
ICLR_2024_oral_15,2,L_{Ref}=\lambda_{RGB} || I_{RGB}^{r}-\tilde{I}_ {RGB}^{r} || _{2}^{2}+\lambda_{A} || I_{A}^{r}-\tilde{I}_{A}^{r} || _{2}^{2},where \(\lambda_{\text{RGB}}\) and \(\lambda_{\text{A}}\) are the weights which are linearly increased during training,L_{align}=\lambda_{rgb}\left\| I_{RGB}^{r}-\tilde{I}_{RGB}^{r}\right\|_1+\lambda_{mask}\left\| I_{A}^{r}-\tilde{I}_{A}^{r}\right\|_1,"The alignment loss \(\mathcal{L}_{\text{align}}\) minimizes the L1 distance between the rendered reference view RGB and the input RGB image, and the L1 distance between the rendered reference view alpha and the input foreground mask, weighted by \(\lambda_{\text{rgb}}\) and \(\lambda_{\text{mask}}\) respectively."
ICLR_2024_oral_15,3,"\nabla_{\Theta}L_{SDS}=E_{t,p,\epsilon}[w(t)(\epsilon_{\phi}(I_{RGB}^{p};t,e)-\epsilon)\frac{\partial I_{RGB }^{p}}{\partial\Theta}]",where \(e\) is the CLIP embeddings of the input text description,"\nabla_{\Theta}L_{SDS}^{text}=E_{t,p,\epsilon}\left[w(t)(\epsilon_{\phi}(I_{RGB}^{p}; t, y)-\epsilon)\frac{\partial I_{RGB}^{p}}{\partial\Theta}\right]","where \( y \) is the input text prompt conditioning the diffusion model, and other terms follow definitions from Equation 1."
ICLR_2024_oral_15,4,d(x)=\sum_{i}\alpha_{i}\exp(-\frac{1}{2}(x-x_{i})^ {T}\Sigma_{i}^{-1}(x-x_{i})),where \(\Sigma_{i}\) is the covariance matrix built from scaling \(\mathbf{s}_{i}\) and rotation \(\mathbf{q}_{i}\),density(x)=\sum_{i}\alpha_{i}\cdot\exp\left(-\frac{1}{2} (x-x_{i})^{\top}\Sigma_{i}^{-1} (x-x_{i})\right),Density at grid point $\mathbf{x}$ computed as the sum of each Gaussian's opacity $\alpha_i$ weighted by its Gaussian function value at $\mathbf{x}$.
ICLR_2024_oral_15,5,"I^{p}_{fine}=f_{\phi}(I^{p}_{coarse}+\epsilon(t_{start}) ;t_{start},c)","where \(\epsilon(t_{\text{start}})\) is a random noise at timestep \(t_{\text{start}}\), \(c\) is \(\Delta p\) for image-to-3D and \(e\) for text-to-3D respectively","I^{p}_{refined}=f_{\phi}(I^{p}_{coarse},\tau, c)","where \( I^{p}_{\text{refined}} \) is the refined image, \( f_{\phi} \) is the multi-step denoising function, \( I^{p}_{\text{coarse}} \) is the coarse rendered image, \( \tau \) is the timestep for perturbation, and \( c \) is the conditioning signal."
ICLR_2024_oral_15,6,L_{MSE}= || I^{p}_{fine}-I^{p}_{coarse} || ^{2}_{2},,L_{MSE}=E_{p}\left[\| I^{p}-I^{p}_{fine}\|_{2}^{2}\right],"where \( I^{p} \) is the image rendered from the current texture at view \( p \), and \( I^{p}_{\text{fine}} \) is the refined image from the diffusion prior for view \( p \)"
ICLR_2024_oral_16,1,"H(x_{t})=\{{cc}\max\{H(\hat{x}_{t}),R_{t}(s_{t},a_{t })\},&if\ || \hat{x}_{t}-x_{t} || _{2}<\delta\\R_{t}(s_{t},a_{t}),&otherwise\","where \(R_{t}(s_{t},\mathbf{a_{t}})\) is the return of a given \((s_{t},\mathbf{a_{t}})\); \(\delta\) is a threshold value of state-embedding difference; and \(\hat{x}_{t}=f_{\phi}(\hat{s}_{t})\) is \(x_{t}=f_{\phi}(s_{t})\)'s nearest neighbor in \(\mathcal{D}_{E}\)","H(x_t)\leftarrow\max\left( H(x_t), G_t\right)",Equation 1 updates the highest return \(H(x_t)\) for the state embedding \(x_t\) by taking the maximum between its current value and the newly observed return \(G_t\).
ICLR_2024_oral_16,2,"Q_{EC}(f_{\phi}(s_{t}),a_{t})=r_{t}(s_{t},a_{t})+\gamma H(f_{\phi}(s_ {t+1}))",,"Q_{EC}(f_{\phi}(s_t),a_t)=r_t+\gamma H(f_{\phi}(s_{t+1}))","where \(r_t\) is the immediate reward, \(\gamma\) is the discount factor, and \(H(f_{\phi}(s_{t+1}))\) is the highest return stored in the episodic buffer for the next state embedding \(f_{\phi}(s_{t+1})\)."
ICLR_2024_oral_16,3,"L_{\theta}^{EC}=(y(s,a)-Q_{tot}(s,a;\theta))^{2}+\lambda(Q_{EC}(f_{\phi}(s),a)-Q_{tot}(s,a;\theta))^{2}","where \(y(s,\mathbf{a})\) is one-step TD target; \(Q_{tot}\) is the joint Q-value function parameterized by \(\theta\); and \(\lambda\) is a scale factor","L_{\theta}^{EC}=\alpha\left( Q_{\theta}(f_{\phi}(s_t),a_t)-\left( r_t+\gamma\max_{a} Q_{\theta}(f_{\phi}(s_{t+1}),a)\right)\right)^2+\beta\left( Q_{\theta}(f_{\phi}(s_t),a_t)-Q_{EC}(f_{\phi}(s_t),a_t)\right)^2","where \( \alpha \) and \( \beta \) are weighting coefficients, \( Q_{\theta} \) is the Q-network with parameters \( \theta \), \( Q_{EC} \) is the episodic control target defined in Equation 2, and \( \mathbf{a} \) denotes the joint action."
ICLR_2024_oral_16,4,"L(\phi,\psi)=(H_{t}-f_{\psi}(f_{\phi}(s_{t})))^ {2}",,"L_{\phi,\psi}=\left( f_{\psi}(f_{\phi}(s_t))-H_t\right)^2","The loss function for training EmbNet, where \( f_{\psi}(f_{\phi}(s_t)) \) is the predicted highest return and \( H_t \) is the stored highest return for state \( s_t \)."
ICLR_2024_oral_16,5,"L(\phi,\psi)=(H_{t}-f_{\psi}^{H}(f_{\phi}(s_{t}|t)|t ))^{2}+\lambda_{rcon} || s_{t}-f_{\psi}^{s}(f_{\phi}(s_{t}|t)|t) || _{2}^{2}",where \(f_{\psi}^{H}\) predicts the highest return; \(f_{\psi}^{s}\) reconstructs \(s_{t}\); \(\lambda_{rcon}\) is a scale factor,"L_{recon}=\left\| s_t-g_{\eta}(f_{\phi}(s_t), t)\right\|_2^2","where \( g_{\eta} \) is the decoder network parameterized by \( \eta \), and \( t \) is the timestep index."
ICLR_2024_oral_16,6,"\eta^{*}(s^{\prime}):=V^{*}(s^{\prime})-\max_{a^{\prime}}\!Q_{\theta^{-}} (s^{\prime},a^{\prime})",,"\eta^{*}(s^{\prime})=V^{*}(s^{\prime})-\max_{a^{\prime}} Q_{\theta^{-}}(s^{\prime},a^{\prime})","where \(V^{*}(s^{\prime})\) is the true state value of state \(s^{\prime}\), and \(\max_{\mathbf{a}^{\prime}} Q_{\theta^{-}}(s^{\prime}, \mathbf{a}^{\prime})\) is the maximum Q-value over actions for state \(s^{\prime}\) predicted by the target network."
ICLR_2024_oral_16,7,"r^{p}=\gamma\hat{\eta}(s^{\prime})=\gammaE_{\pi_{\theta}}[\eta(s^{\prime})]\simeq\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}\eta_{\max}(s^{\prime})=\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}(H(f_ {\phi}(s^{\prime}))-\max_{a^{\prime}}\!Q_{\theta^{-}}(s^{\prime},a^{\prime}))",where \(N_{call}(s^{\prime})\) is the number of visits on \(\hat{x}^{\prime}=\mathrm{NN}(f_{\phi}(s^{\prime}))\in\mathcal{D}_{E}\); and \(N_{\xi}\) is the number of desirable transition from \(\hat{x}^{\prime}\),"r^{p}=\gamma\left( H(f_{\phi}(s'))-\max_{a'} Q_{\theta^{-}}(s',a')\right)","where \(H(f_{\phi}(s'))\) is the highest return for state \(s'\) stored in episodic memory, and \(\max_{\mathbf{a}'} Q_{\theta^{-}}(s',\mathbf{a}')\) is the maximum joint Q-value for state \(s'\) from the target network."
ICLR_2024_oral_16,8,"L_{\theta}^{p}=(r(s,a)+r^{p}+\gamma\!\max_{a^{\prime}}\!Q_{\theta^{-} }(s^{\prime},a^{\prime})-Q_{\theta}(s,a))^{2}",,"L_{\theta}=\left( y(s,a)+r^{p}-Q_{tot}(s,a;\theta)\right)^{2}",The loss function incorporating the episodic incentive \(r^p\) as an additional reward to the one-step TD target for the joint Q-value.
ICLR_2024_oral_16,9,"\nabla_{\theta}L_{\theta}^{p}=-2\nabla_{\theta}Q_{\theta}(s,a)(\Delta\varepsilon _{TD}+r^{p})=-2\nabla_{\theta}Q_{\theta}(s,a)(\Delta\varepsilon_{TD}+\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}\eta_{\max}(s^{\prime}))",,"\nabla_{\theta} L_{\theta}^{p}=-\left( r(s,a)+r^{p}+\gamma\max_{a'} Q_{\theta^{-}}(s',a')-Q_{\theta}(s,a)\right)\nabla_{\theta} Q_{\theta}(s,a)","where \(r(s,\mathbf{a})\) is the immediate reward, \(r^{p}\) is the episodic incentive, \(\gamma\) is the discount factor, \(\max_{\mathbf{a}'}Q_{\theta^{-}}(s',\mathbf{a}')\) is the maximum Q-value of the next state from the target network, \(Q_{\theta}(s,\mathbf{a})\) is the Q-value of the current state-action pair, and \(\nabla_{\theta} Q_{\theta}(s,\mathbf{a})\) is the gradient of the Q-value with respect to parameters \(\theta\)."
ICLR_2024_oral_16,10,"L_{\theta}^{p}=(r(s,a)+r^{p}+\beta_{c}r^{c}+\gamma max_{a^{\prime}}Q_{tot}(s^{\prime},a^{\prime};\theta^{-})-Q_{tot}(s,a;\theta))^{2}",where \(\beta_{c}\) is a scale factor,"L_{\theta}=\left( r(s,a)+r^{p}+r^{c}+\gamma\max_{a^{\prime}} Q_{\theta^{-}}(s^{\prime},a^{\prime})-Q_{\theta}(s,a)\right)^{2}","where \(L_{\theta}\) is the overall loss function for training the joint Q-function; \(r(s,\mathbf{a})\) is the environment reward; \(r^{p}\) is the episodic incentive; \(r^{c}\) is the intrinsic reward; \(\gamma\) is the discount factor; \(Q_{\theta^{-}}\) is the target network; and \(Q_{\theta}\) is the current joint Q-function."
ICLR_2024_oral_21,1,"g(G)=\operatorname*{arg\,max}_{c\in\{1,2,\cdots,C\}}N_{c}",where a label with a smaller index is taken by our ensemble classifier when there are ties,"g(G)=\arg\max_{c\in\{1,2,\cdots,C\}} N_{c}","The ensemble graph classifier \( g(G) \) outputs the class \( c \) that maximizes \( N_c \), the count of sub-graphs predicted as class \( c \) by the base classifier."
ICLR_2024_oral_21,2,"N_{c}-M\leq N_{c}^{p}\leq N_{c}+M,\,\forall c\in\{1,2,\cdots,C\}",,N_c-M\leq N_c^p\leq N_c+M,"For any class \(c\), the perturbed count \(N_c^p\) is bounded between \(N_c - M\) and \(N_c + M\), where \(N_c\) is the original count for class \(c\) and \(M\) is the total number of corrupted sub-graphs."
ICLR_2024_oral_21,3,"M\leq M^{p}=\lfloor\frac{N_{l}-\max_{c\in\{1,2,\cdots,C\}\setminus\{l\}}(N_{c }-I(l<c))}{2}\rfloor",,N_l >\max_{c\neq l}\left( N_c+2M-I(c > l)\right),"The sufficient condition for the ensemble graph classifier \(g\) to predict the same label \(l\) for both the original graph \(G\) and the perturbed graph \(G^p\), where \(N_l\) and \(N_c\) are the original counts of sub-graphs predicted as labels \(l\) and \(c\) respectively, \(M\) is the number of corrupted sub-graphs due to perturbation, and \(\mathbb{I}\) is the indicator function."
ICLR_2024_oral_23,1,"p_{\sigma}(y)=\int p(y|x)\,p(x)\,dx=\int g_{\sigma}(y-x)\,p(x)\,dx",where \(g_{\sigma}(z)\) is the density of \(z\),p_{\sigma}(y)=\int p(x) p(y\mid x)dx,The noisy image density \(p_{\sigma}(y)\) is the integral of the clean image density \(p(x)\) times the conditional density \(p(y \mid x)\) with respect to \(x\).
ICLR_2024_oral_23,2,"D_{KL}(p(x)\,\|\,p_{\theta}(x))\leq\int_{0}^{\infty}E_{y}\big{[}\|\nabla\log p_{\sigma}(y)-s_{\theta}(y)\|^{2}\big{]}\,\sigma\, d\sigma",,"KL(p\| p_{\theta})=\frac{1}{2}\int_{0}^{\infty}E_{y\sim p_{\sigma}(y)}\left[\left\| s_{\theta}(y,\sigma)-\nabla_{y}\log p_{\sigma}(y)\right\|_{2}^{2}\right]d(\sigma^{2})","The Kullback-Leibler divergence between the true data distribution \(p(x)\) and the model distribution \(p_{\theta}(x)\) equals half the integral over \(\sigma^{2}\) of the expected squared L2 error between the learned score \(s_{\theta}(y, \sigma)\) and the true score \(\nabla_{y} \log p_{\sigma}(y)\)."
ICLR_2024_oral_23,3,"\nabla\log p_{\sigma}(y)=(\mathop{E}_{x}[x\,|\,y]-y)/\sigma^{2}",,\nabla_{y}\log p_{\sigma}(y)=\frac{1}{\sigma^{2}}\left(E[x\mid y]-y\right),The score \(\nabla_{y} \log p_{\sigma}(y)\) equals \(\frac{1}{\sigma^{2}}\) times the difference between the posterior mean \(\mathbb{E}[x \mid y]\) and the noisy observation \(y\).
ICLR_2024_oral_23,4,"MSE(f_{\theta},\sigma^{2})=\mathop{E}_{x,y}\Bigl{[}\|x-f_{\theta}(y)\|^{2}\Bigr{]}",,"\min_{\theta}E_{x,y}\left[\|f_{\theta}(y)-x\|^{2}\right]",Training the denoiser \(f_{\theta}(y)\) by minimizing the mean squared error to the clean image \(x\).
ICLR_2024_oral_23,5,"D_{KL}(p(x)\ || \,p_{\theta}(x))\leq\int_{0}^{\infty}\Bigl{(} MSE(f_{\theta},\sigma^{2})-MSE(f^{\star},\sigma^{2})\Bigr{)}\,\sigma^{-3}\,d\sigma","where \(f^{\star}(y)=\mathop{\mathbb{E}}_{x}[x\,|\,y]\) is the optimal denoiser","D_{KL}(p(x)\,\|\,p_{\theta}(x))\leq\int_{0}^{\infty}\frac{E_{y}\left[\|E[x\mid y]-f_{\theta}(y)\|^{2}\right] }{\sigma^{3} }\,d\sigma",The KL divergence between the true and model data distributions is bounded by the integral over noise levels of the expected squared difference between the conditional mean and the denoiser output divided by the cube of the noise level.
ICLR_2024_oral_23,6,"f(y)=\nabla f(y)\,y=\sum_{k}\lambda_{k}(y)\langle y,e_{k}(y)\rangle e_{ k}(y)",,"f(y)=\sum_{k=1}^{d}\lambda_k(y)\, (e_k(y)^\top y)\,e_k(y)","The denoiser output at a noisy input \(y\) is expressed as a sum over the eigenvectors of the Jacobian at \(y\), each scaled by the corresponding eigenvalue and the projection of \(y\) onto that eigenvector."
ICLR_2024_oral_23,7,"MSE(f,\sigma^{2})=\mathop{E}_{y}\![2\sigma^{2}\, tr\,\nabla f(y)+\|y-f(y)\|^{2}-\sigma^{2}d]",,"SURE(f_{\theta}, y,\sigma^{2})=\|y-f_{\theta}(y)\|^{2}+2\sigma^{2}\nabla_y\cdot f_{\theta}(y)-d\sigma^{2}","Stein's unbiased risk estimate (SURE) for the denoiser \(f_{\theta}\) at noise level \(\sigma\), providing an unbiased estimate of the mean squared error without requiring the clean image \(x\)."
ICLR_2024_oral_23,8,"f^{\star}(y)=y+\sigma^{2}\nabla\log p_{\sigma}(y)=\operatorname*{E}_{ x}[x|y] || \nabla f^{\star}(y)=Id+\sigma^{2}\nabla^{2}\log p_{\sigma}(y)=\sigma^ {-2}Cov[x\,|\,y]",,"f^{\star}(y)=\mathop{E}_{x}[x\,|\,y]\quadand\quad\nabla f^{\star}(y)=\frac{1}{\sigma^{2}}\mathop{Cov}_{x}(x|y)",The optimal denoiser is the conditional mean and its Jacobian is the conditional covariance scaled by the inverse noise variance.
ICLR_2024_oral_23,9,"MSE(f^{\star},\sigma^{2})=\operatorname*{E}_{y}[tr \,Cov[x\,|\,y]]=\sigma^{2}\operatorname*{E}_{y}\bigl{[}tr\,\nabla f^{\star}(y)\bigr{]}=\sigma^{2}\operatorname*{E} _{y}\biggl{[}\sum_{k}\lambda_{k}^{\star}(y)\biggr{]}",,"MSE(f^{\star},\sigma^{2})=E_{y}\left[tr\,Cov[x|y]\right]=\sigma^{2}\,E_{y}\left[tr\,\nabla f^{\star}(y)\right]","The minimum mean squared error for denoising is the expected trace of the posterior covariance, which equals \(\sigma^{2}\) times the expected trace of the Jacobian of the optimal denoiser."
ICLR_2024_oral_23,10,"\operatorname*{E}_{x}\biggl{[}\sum_{k}\Bigl{(}(1-\lambda_{k}(x))^{2}\langle x,e_{k}\rangle^{2}+\lambda_{k}(x)^{2}\sigma^{2}\Bigr{)}\biggr{]}",,"MSE(f^{oracle},\sigma^{2})=\mathop{E}_{x}\biggl{[}\sum_{k}\frac{\sigma^{2}x_{k}^{2}}{\sigma^{2}+x_{k}^{2}}\biggr{]}","where \(x_k = \langle x, e_k \rangle\) is the coefficient of the clean image \(x\) in the fixed orthonormal basis \(e_k\)."
ICLR_2024_oral_23,11,"\sigma^{2}{\sum_{k}\lambda_{k}(x)}=\sum_{k}\frac{\sigma^{2}\langle x,e_{k}\rangle^{2}}{\langle x,e_{k}\rangle^{2}+\sigma^{2}}\sim\sum_{k}\min(\langle x,e_{k}\rangle^{2},\sigma^{2})=M\sigma^{2}+\|x-x_{M}\|^{2}","where \(x_{M}=\sum_{\langle x,e_{k}\rangle^{2}>\sigma^{2}}\langle x,e_{k}\rangle\,e_{k}\) is the \(M\)-term approximation of \(x\) with the \(M\) basis coefficients \(\langle x,e_{k}\rangle\) above the noise level, and \(\sim\) means that the two terms are of the same order up to multiplicative constants (here smaller than 2)","E_{x}\left[\sum_{k}\frac{\sigma^{2}\langle x,e_{k}\rangle^{2}}{\langle x,e_{k}\rangle^{2}+\sigma^{2}}\right]",The minimized oracle denoising error in a fixed basis.
ICLR_2024_oral_23,12,M\sigma^{2}+\|x-x_{M}\|^{2}\sim\sigma^{2\alpha/(\alpha+1)},,"MSE(f^{oracle},\sigma^{2})\sim\sigma^{\frac{2\alpha}{\alpha+1}}",The oracle denoising mean squared error in a fixed basis is asymptotically proportional to $\sigma^{2\alpha/(\alpha+1)}$ when the squared basis coefficients of the clean image decay as $k^{-(\alpha+1)}$.
ICLR_2024_oral_24,1,dx_{t}=f_{t}(x_{t})dt+g(t)d w_{t}\quadx_{0}\sim p_{data}(x),,"dx_t=f(x_t, t)dt+g(t)dw_t","This equation defines the forward stochastic differential equation for the diffusion model, where \(\mathbf{x}_t\) is the state at time \(t\), \(\mathbf{f}(\mathbf{x}_t, t)\) is the drift coefficient, \(g(t)\) is the diffusion coefficient, and \(\mathbf{w}_t\) is a standard Wiener process."
ICLR_2024_oral_24,2,"dx_{t}=[f_{t}(x_{t})-g_{t}^{2}\nabla_{ x}\log p(x_{t},t)]dt+g(t)dw_{t},\quadx_{1}\simN(0,I_{d})","where \(p(\cdot,t)\) is the marginal density of (1) at time \(t\) and \(\nabla_{\mathbf{x}}\log p_{t}\) is known as the score function",dx_{t}=\left[ f_{t}(x_{t})-g(t)^{2}\nabla_{x_{t}}\log p_{t}(x_{t})\right]dt+g(t)dw_{t},The time-reversed stochastic differential equation for the diffusion model.
ICLR_2024_oral_24,3,"dx_{t}=[f_{t}(x_{t})-\frac{1}{2}g_{t}^{2}\nabla_{x}\log p(x_{t},t)]dt,\quad x_{1}\simN(0,I_{d})",,"dx_{t}=\left[ f_{t}(x_{t})-\frac{1}{2} g_{t}^{2}\nabla_{x}\log p(x_{t}, t)\right]dt","The probability flow ordinary differential equation corresponding to the reverse-time stochastic differential equation (Equation 2), which shares the same marginal distributions over time."
ICLR_2024_oral_24,4,"dx_{t}=v_{t}(x,t)dt+g_{t}dw_{t}\quad s.t.\quad(x_{0},x_{1})\sim\Pi_{0,1}(x_ {0},x_{1}):=p_{0}\times p_{1}",,dx_{t}=\left[ f_{t}(x_{t})+g_{t}^{2}\nabla_{x}\log p(x_{1} |x_{t})\right]dt+g_{t}dw_{t},"The SDE for the bridge process in bridge matching, featuring a base drift term and an additional term that conditions on the endpoint \(\mathbf{x}_1\) through the conditional score."
ICLR_2024_oral_24,5,"\min_{a_{t}}\int_{\tau}^{1}\lVerta_{t}\rVert_{2}^{2}dt+(m_{1}-m_{1})^{T} R(m_{1}-m_{1})& s.t\underbrace{dx_{t}\\dv_{t}}_{dm_{t}}&=v_{t}\\a_{t}(x_{t},v_{t},t)dt+\underbrace{0&0\\0&g_{t}}_{g_{t}}dw_{t},\\m_{\tau}:=x_{\tau}\\v_{\tau}&=x_{\tau}\\v_{\tau},&R=r&0\\0&r\otimesI_{d},&x_{1}\sim p_{data}",,dX_{t}=\left(AX_{t}+Bu_{t}\right)dt+G_{t}dW_{t},"The stochastic differential equation for the state $\mathbf{X}_t$ in phase space, where $\mathbf{A}$ and $\mathbf{B}$ are system matrices, $\mathbf{u}_t$ is the control input, $\mathbf{G}_t$ is the time-varying diffusion coefficient, and $\mathrm{d}\mathbf{W}_t$ is the increment of a standard Wiener process."
ICLR_2024_oral_24,6,"a^{*}(m_{t},t)=g_{t}^{2}P_{11}(\frac{x_{1}-x_{t}}{1-t}-v_{t})\quadwhere:\quad P_{11}=\frac{-4}{g_{t}^{2}(t-1)}",,"dx_{t} &=v_{t}dt,\\dv_{t} &=\left(\frac{x_{1}-x_{t}}{(1-t)^{2}}-\frac{v_{t}}{1-t}\right)dt+g_{t}dw_{t}","The solution to the stochastic optimal control problem (5) in the limit of infinite terminal cost, where \(\mathbf{x}_t\) and \(\mathbf{v}_t\) are position and velocity vectors at time \(t\), \(\mathbf{x}_1\) is the target position, and \(g_t\) is the diffusion coefficient."
ICLR_2024_oral_24,7,"dx_{t}\\dv_{t}=v_{t}\\F_{t}dt+0&0\\0&h_{t}dw_{t}\quads.t\quadm_{0}:=x_{0}\\v_{0}\simN(\mu_{0},\Sigma_{0}) || Bridge Matching SDE:F_{t}:=F_{t}^{b}(m_{t},t)\equiva_{t}^{*}(m_{t},t), h(t):=g(t) || Probabilistic ODE:F_{t}:=F_{t}^{p}(m_{t},t)\equiva_{t}^{*}(m_{t},t)-\frac{1}{2}g_{t}^{2 }\nabla_{v}\log p(m,t), h(t):=0",,dm_t &=v_t\\\frac{4}{1-t}\left(\frac{x_1-x_t}{1-t}-v_t\right)dt+0\\g_tdw_t\quad(SDE)\\dm_t &=v_t\\\frac{4}{1-t}\left(\frac{x_1-x_t}{1-t}-v_t\right)-\frac{1}{2} g_t^2\nabla_{v_t}\log p_t(m_t)dt\quad(ODE),"The stochastic differential equation (SDE) and probability flow ordinary differential equation (ODE) for the acceleration generative model dynamics, where \(\mathbf{m}_t = (\mathbf{x}_t, \mathbf{v}_t)\) is the phase space state, \(\mathbf{x}_1\) is the target data point, \(g_t\) is the diffusion coefficient, and \(\nabla_{\mathbf{v}_t} \log p_t(\mathbf{m}_t)\) is the velocity score function."
ICLR_2024_oral_24,8,"m_{t}=\mu_{t}+L_{t}\epsilon=\mu_{t}+L_{t}^{xx}\epsilon_{0}\\L_{t}^{xv}\epsilon_{0}+L_{t}^{vv}\epsilon_{1},\nabla_{v}\log p_{t}:=-\ell_{t}\epsilon_{1}","where \(\boldsymbol{\Sigma}_{t}=\mathbf{L}_{t}\mathbf{L}_{t}^{\mathsf{T}}\), \(\epsilon=\begin{bmatrix}\boldsymbol{\epsilon}_{0}\\ \boldsymbol{\epsilon}_{1}\end{bmatrix}\sim\mathcal{N}(\mathbf{0},\mathbf{I}_{2d})\) and \(\ell_{t}=\sqrt{\frac{\Sigma_{t}^{xx}}{\Sigma_{t}^{xx}\Sigma_{t}^{xx}-(\Sigma _{t}^{xx})^{2}}}\)","m_{t}=\mu_{t}+L_{t}\epsilon_{t},\quad\epsilon_{t}\simN(0,I_{2d})",Reparameterization of the intermediate state \(\mathbf{m}_{t}\) using the Cholesky decomposition \(\mathbf{L}_{t}\) of the covariance matrix \(\boldsymbol{\Sigma}_{t}\) for sampling from the Gaussian distribution conditional on \(\mathbf{x}_{1}\).
ICLR_2024_oral_24,9,"a^{*}(m_{t},t)=4x_{1}(1-t)^{2}-g_{t}^{2}P_{11}[ (\frac{L_{t}^{xx}}{1-t}+L_{t}^{xv})\epsilon_{0}+L_{t}^{vv}\epsilon_{1}]",,F_{t}=g_{t}^{2} P_{11}\left(\frac{x_{1}-x_{t}}{1-t}-v_{t}\right)+\frac{1}{2} g_{t}^{2}\ell_{t}\epsilon_{1},"The force term $\mathbf{F}_{t}$ for the probabilistic ODE (AGM-ODE) combines the target data point $\mathbf{x}_{1}$ and Gaussian noise $\boldsymbol{\epsilon}_{1}$, with $P_{11}$ and $\ell_{t}$ as coefficients derived from prior equations."
ICLR_2024_oral_24,10,"\min_{\theta}E_{t\in[0,1]}E_{x_{1}\sim p_{ data}}E_{m_{t}\sim p_{t}(m_{t}|x_{1})}\lambda(t)[\|F_{t}^{\theta}(m_{t},t;\theta)-F _{t}(m_{t},t)\|_{2}^{2}]",Where \(\lambda(t)\) is known as the reweight of the objective function across the time horizon,"L_{AGM}=E_{t\simU(0,1),x_1\sim p_{data},\epsilon\simN(0,I)}\left\|F_t^{\theta}(m_t, t)-a^*(m_t, t)\right\|_2^2","The objective function for regressing the force term in AGM, which minimizes the expected squared L2 distance between the predicted force and the optimal control force over time, data points, and Gaussian noise."
ICLR_2024_oral_24,11,"x_{t_{i+1}}\\v_{t_{i+1}}=\Phi(t_{i+1},t_{i})x _{t}\\v_{t}+\sum_{j=0}^{w}\int_{t_{i}}^{t_{i+1} }(t_{i+1}-\tau)z_{\tau}\cdotM_{i,j}(\tau) d\tau\s_{t}^{\theta}(m_{t_{i-j}},t_{i-j}))\\\int_{t_{i}}^{t_{i+1}}z_{\tau}\cdotM_{i,j}(\tau) d\tau\cdots_{t}^{\theta}(m_{t_{i-j}},t_{i-j})",,"m_{t+\delta}=x_{t}+\deltav_{t}+\frac{\delta^{2}}{2}F_{t}^{p}(m_{t},t)\\v_{t}+\deltaF_{t}^{p}(m_{t},t)",The Exponential Integrator update for AGM-ODE simultaneously injects the learned force term into position and velocity channels during sampling.
ICLR_2024_oral_24,12,"\tilde{x}_{1}^{SDE}=\frac{(1-t)(F_{t}^{\theta}+v_{t })}{g_{t}^{2}P_{11}}+x_{t}, or \quad\tilde{x}_{1}^{ODE}=\frac{F_{t}^{\theta}+g_{t}^{2}P_{ 11}(\alpha_{t}x_{t}+\beta_{t}v_{t})}{4(t-1)^{2}+g_{t}^{2}P_{ 11}(\alpha_{t}\mu_{t}^{x}+\beta_{t}\mu_{t}^{v})}",,"\tilde{x}_{1}=x_{t}+(1-t)v_{t}+\frac{(1-t)^{2}}{4}F_{t}^{\theta}(m_{t}, t)","The estimated data point \(\tilde{\mathbf{x}}_{1}\) at time \(t\) given state \(\mathbf{m}_{t} = (\mathbf{x}_{t}, \mathbf{v}_{t})\) and trained force term \(\mathbf{F}_{t}^{\theta}\)."
ICLR_2024_oral_25,1,"\underbrace{\nu(x)>0,\\\forall x\inInterior(M_{o})}_{Case 1: inside the open surface},\quad\underbrace{\nu(x)=0,\\\forall x\in\partialM_{o}}_{Case 2: on the surface boundary},\quad\underbrace{\nu(x)<0,\\Otherwise}_{ Case 3: outside the open surface}",where \(\nu\) can be instantiated as the signed geodesic distance to the open surface boundary living on the watertight template,M_o=\{ x\inM\mid\nu(x) > 0\},The open surface \(\mathcal{M}_o\) is defined as the set of points \(x\) on the template sphere \(\mathcal{M}\) where the scalar field \(\nu(x)\) is positive.
ICLR_2024_oral_25,2,L_{mSDF-reg}(\theta_{mSDF})=\underbrace{\sum_{u:v_{\theta_{ ndSF}}(u)\geq 0}L_{nuber}(v_{\theta_{noster}}(u))}_{ Encourage hole opening}+\underbrace{\tau\cdot\sum_{{c}u^{\prime}:v_{\theta_{ ndSF}}(u^{\prime})=0\\u^{\prime} visible from some q\in Q}L_{nuber}(v_{\theta_{n ober}}(u^{\prime})-\epsilon)}_{Regularize holes from being too large},,L_{hole}=E_{x\sim p_{unobs}}\left[ReLU\left(\nu(x)\right)\right],The hole-opening loss minimizes positive mSDF values in unobserved regions to encourage boundary formation where camera evidence is absent.
ICLR_2024_oral_25,3,"u^{\prime}=\frac{|\nu_{1}|}{|\nu_{1}-\nu_{2}|}\cdot u_{2}-\frac{|\nu_{2}|}{|\nu_{1}-\nu_{2}|}\cdot u_{1},\quad\nu_{1}<0<\nu_{2}",,p=\frac{\nu_ip_j-\nu_jp_i }{\nu_i-\nu_j },The position $\mathbf{p}$ of a boundary vertex is linearly interpolated between adjacent grid vertices $\mathbf{p}_i$ and $\mathbf{p}_j$ using their mSDF values $\nu_i$ and $\nu_j$ such that $\nu(\mathbf{p})=0$.
ICLR_2024_oral_26,1,E=({cccc}W^{(l)\top}&W^{(2)\top}&W^{(l)\top}&W^{(l)\top}\\\hline\ddots&W^{(2)\top}&W^{(2)\top}&W ^{(l)\top}\\),where \(\mathbf{\mathrm{W}}^{(l)\top}\) denotes the transposed weight matrix,"V=0_{d_0}\\b^{(1)}\\b^{(2)}\\\vdots\\b^{(L)} ,\quadE=0 &0 &\cdots &0\\W^{(1)} &0 &\cdots &0\\0 &W^{(2)} &\cdots &0\\\vdots &\vdots &\ddots &\vdots\\0 &0 &\cdots &0","$\mathbf{V}$ assigns the bias $\mathbf{b}^{(l)}$ to nodes in layer $l$ (for $l \geq 1$) and zero to input nodes, and $\mathbf{E}$ assigns the weight $\mathbf{W}^{(l)}$ to edges from layer $l-1$ to layer $l$ and zero otherwise."
ICLR_2024_oral_26,2,"V_{probe}=\Big{(}x,\alpha\Big{(}W^{(1)}x+b^{(1)}\Big{)},f(x)\Big{)}^{\top}",,E=0 &\widetilde{W}^{(1)\top} &0 &\cdots &0\\0 &0 &\widetilde{W}^{(2)\top} &\cdots &0\\\vdots &\vdots &\ddots &\ddots &\vdots\\0 &0 &\cdots &0 &\widetilde{W}^{(L)\top}\\0 &0 &\cdots &0 &0,The edge features for a CNN form a block matrix where each non-zero block \(\widetilde{\mathbf{W}}^{(l)\top}\) represents the transposed padded and flattened kernels of layer \(l\).
ICLR_2024_oral_26,3,"e_{ij}^{(k+1)}=\phi_{e}^{(k+1)}\Big{(}\Big{[}v_{i}^{(k)},e_{ij}^{(k)},v_{j}^{(k)}\Big{]}\Big{)}",where \(k\) is the layer index in our network,"e_{ij}^{(k+1)}=\phi_{e}\left(e_{ij}^{(k)},h_i^{(k)},h_j^{(k)}\right)","The updated edge feature \(\mathbf{e}_{ij}^{(k+1)}\) is computed by a lightweight neural network \(\phi_{e}\) applied to the current edge feature \(\mathbf{e}_{ij}^{(k)}\) and the node features \(\mathbf{h}_i^{(k)}\) and \(\mathbf{h}_j^{(k)}\) of the sender and receiver nodes, respectively."
ICLR_2024_oral_26,4,"m_{ij}=\phi_{scale}(e_{ij})\odot\phi_{m}([v_ {i},v_{j}])+\phi_{shift}(e_{ij})",,"m_{ij}^{(k)}=\gamma_{ij}\odote_{ij}^{(k)}+\beta_{ij},\quadwhere\quad\gamma_{ij}=\phi_{\gamma}^{(k)}(v_j^{(k)}),\quad\beta_{ij}=\phi_{\beta}^{(k)}(v_j^{(k)})",The message from node \(j\) to node \(i\) at layer \(k\) is computed by modulating the edge feature \(\mathbf{e}_{ij}^{(k)}\) with scaling \(\boldsymbol{\gamma}_{ij}\) and shifting \(\boldsymbol{\beta}_{ij}\) parameters generated from the sending node feature \(\mathbf{v}_j^{(k)}\).
ICLR_2024_oral_26,5,v_{ij}=(W_{scale}^{value}e_{ij} )\odot(W_{n}^{value}v_{j})+ W_{shift}^{value}e_{ij},,V_{ij}=\phi_{scale}(e_{ij})\odot\phi_{v}(v_{j})+\phi_{shift}(e_{ij}),"The modulated value vector for node \(j\) in the context of edge \((i,j)\) is computed by scaling and shifting a transformation of its features using edge-dependent functions."
ICLR_2024_oral_27,1,\sum_{i=1}^{N_{k}}W(A_{i}^{k})=W(\bigcup_{i=1}^{N_{k}}A_{i}^{k})=W(A^{0}),,W(A^0)=\sum_{i=1}^{N_k} W(A_i^k),The integral of the white Gaussian noise over the entire domain \(A^0\) equals the sum of the integrals over the disjoint sub-pixels \(A_i^k\) at resolution level \(k\).
ICLR_2024_oral_27,2,"(W(A^{k})|W(A^{0})=x)\simN(\bar{\mu},\bar{\Sigma}),\quadwith \bar{\mu}=\frac{x}{N_{k}}u,\bar{\Sigma}=\frac{1}{N_{k}} (I_{N_{k}}-\frac{1}{N_{k}}uu^{\top})","where \(\mathbf{u}=(1,\ldots,1)^{\top}\)","\left( W(A^{k}) | W(A^{0})=x\right)\simN\left(\frac{x}{N_k}1_{N_k},\frac{1}{N_k}I_{N_k}-\frac{1}{N_k^2}1_{N_k}1_{N_k}^\top\right)",The conditional distribution of sub-pixel integrals given the entire pixel integral \(x\) is a multivariate Gaussian with mean \(\frac{x}{N_k} \mathbf{1}_{N_k}\) and covariance \(\frac{1}{N_k} \mathbf{I}_{N_k} - \frac{1}{N_k^2} \mathbf{1}_{N_k} \mathbf{1}_{N_k}^\top\).
ICLR_2024_oral_27,3,"(W(A^{k})|W(A^{0})=x)=\bar{\mu}+UZ=\frac{x}{N_{k}} u+\frac{1}{\sqrt{N_{k}}}(Z-\langle Z\rangleu),\quadwith Z\sim(0,I)",where \(\langle Z\rangle\) is the mean of \(Z\),"W(A^{k})=\bar{\mu}+U\epsilon,\quad\epsilon\simN(0,I_{N_k})",where \(\epsilon\) is a standard normal random vector of dimension \(N_k\).
ICLR_2024_oral_27,4,T(W)(A)=\int_{x\in A}\frac{1}{|\nablaT(T^{-1}(x))|^{\frac{1}{2}}}W(T^{-1}(x))\dx,where \(\left|\nabla\mathcal{T}\right|\) is the determinant of the Jacobian of \(\mathcal{T}\),T(W)(A)=\int_{T^{-1}(A)}\sqrt{ |\det\nabla T(x) | } dW(x),The transported noise over a set \(A\) is defined as an Ito integral over the preimage \(T^{-1}(A)\) with the square root of the absolute Jacobian determinant of \(T\).
ICLR_2024_oral_27,5,G(p)=\frac{1}{\sqrt{|\Omega_{p}|}}\sum_{A_{s}^{k}\in\Omega_ {p}}W_{k}(A_{s}^{k})\,,T(W)(p)=\sqrt{\frac{N_k}{|I|}}\sum_{i\inI} W(A_i^k),where \(\mathcal{I}\) is the set of indices of covered sub-pixels and \(|\mathcal{I}|\) is the number of covered sub-pixels
ICLR_2024_oral_27,6,"z_{i}=\alpha x_{i-1}+(1-\alpha)x_{i},\quad z_{i}\simN(0,\,\sigma_{z }^{2}),\quadwith \sigma_{z}^{2}=\alpha^{2}+(1-\alpha)^{2}",,z=(1-\alpha) x_0+\alpha x_1,The transported value $z$ at a position $\alpha$ between two pixels with values $x_0$ and $x_1$ using linear interpolation.
ICLR_2024_oral_27,7,"z_{i}|x_{i},x_{i-1}\simN(\mu_{\infty},\sigma_{\infty}^{2}),\quadwith \{{l}\mu_{\infty}=\alpha x_{i-1}+(1-\alpha)x_{i}\\\sigma_{\infty}^{2}=1-(\alpha^{2}+(1-\alpha)^{2})=1-\sigma_{z}^{2}",,"(z | x_{i-1}, x_i)\simN\left(\alpha x_{i-1}+(1-\alpha) x_i, 2\alpha(1-\alpha)\right)",The conditional distribution of the transported noise value \( z \) given the neighboring noise values \( x_{i-1} \) and \( x_i \).
ICLR_2024_oral_28,1,\lVertA\hat{x}^{\star}-b\rVert_{2}^{2}\leq(1+\epsilon)\lVertAx^{\star}-b\rVert_{2}^{2},,\lVertA\hat{x}^{\star}-b\rVert_{2}^{2}\leq (1+\epsilon)\lVertAx^{\star}-b\rVert_{2}^{2},The squared loss of the estimated model \(\hat{\mathbf{x}}^{\star}\) is at most \((1+\epsilon)\) times the loss of the optimal model \(\mathbf{x}^{\star}\).
ICLR_2024_oral_28,2,\tau_{i}=\|u_{i}\|_{2}^{2}=a_{i}^{T}(A^{T} A)^{-1}a_{i}=\max_{x\inR^{d}}(a_{i}^{T}x)^{2}/\|Ax\|_{2}^{2},,\tau_i=a_i^\top (A^\topA)^{\dagger}a_i,"The leverage score \(\tau_i\) for the \(i\)-th row of \(\mathbf{A}\) is defined as the quadratic form \(\mathbf{a}_i^\top (\mathbf{A}^\top \mathbf{A})^{\dagger} \mathbf{a}_i\), where \(\dagger\) denotes the Moore-Penrose pseudoinverse."
ICLR_2024_oral_28,3,\|A\tilde{x}^{*}-b\|_{2}^{2}\leq(1+\epsilon)\|Ax^{*}-b\|_{2}^{2},,\lVertA\tilde{x}^{*}-b\rVert_{2}^{2}\leq(1+\epsilon)\lVertAx^{\star}-b\rVert_{2}^{2},The squared \(\ell_2\) loss of the solution \(\tilde{\mathbf{x}}^{*}\) obtained via pivotal sampling is at most \((1+\epsilon)\) times the optimal loss.
ICLR_2024_oral_28,4,\|\tilde{p}-b\|_{2}^{2}\leq(1+\epsilon)\underset{degree d polynomial p}{\min}\|p-b\|_{2}^{2},,\int_{\ell}^{u} (\tilde{p}(x)-b(x))^{2} dx\leq (1+\epsilon)\cdot\min_{p\inP_{d}}\int_{\ell}^{u} (p(x)-b(x))^{2} dx,"The squared $L_2$ error of the constructed polynomial $\tilde{p}$ over the interval $[\ell, u]$ is at most $(1+\epsilon)$ times the minimal squared $L_2$ error achievable by any degree-$d$ polynomial."
ICLR_2024_oral_28,5,"I_{\mu}^{S}(i,j)=\Pr_{\mu}[\xi_{j}=1|\xi_{i}=1\wedge\xi_{\ell}=1\forall\ell\inS]-\Pr_{\mu}[\xi_{j}=1|\xi_{\ell}=1\forall\ell\inS]",,"(I_{\mu}^{S})_{i,j}=\max\left(\frac{\Pr[\xi_i=1\mid\xi_{S}=1]\cdot\Pr[\xi_j=1\mid\xi_{S}=1] }{\Pr[\xi_i=1,\xi_j=1\mid\xi_{S}=1] }-1, 0\right)","The (i,j)-th entry of the one-sided influence matrix for distribution μ, measuring the deviation from conditional independence between ξ_i and ξ_j given that all variables in set S are set to 1, computed as the maximum of zero and the ratio of the product of marginal conditional probabilities to the joint conditional probability minus one."
ICLR_2024_oral_29,1,"\frac{dx}{d\sigma}=-\sigma\nabla_{x}\log p _{\sigma}(x)\quad\sigma\in[\sigma_{min},\sigma_{max}]",where the term \(\nabla_{\mathbf{x}}\log p_{\sigma}(\mathbf{x})\) is known as the _score function_ of \(p_{\sigma}(\mathbf{x})\)(Song et al,\frac{dx}{dt}=-\dot{\sigma}(t)\sigma(t)\nabla_{x}\log p_{\sigma(t)}(x),"The probability flow ordinary differential equation (ODE) governing the continuous-time dynamics of data samples \(\mathbf{x}\) with respect to time \(t\), where \(\sigma(t)\) is the noise level function and \(\nabla_{\mathbf{x}} \log p_{\sigma(t)}(\mathbf{x})\) is the score function."
ICLR_2024_oral_29,2,"f_{\theta}(x,\sigma)=c_{skip}(\sigma)x+c_{out}(\sigma)F_{\theta}(x,\sigma)","where \(\mathbf{F}_{\mathbf{\theta}}(\mathbf{x},\sigma)\) is a free-form neural network, while \(c_{\text{skip}}(\sigma)\) and \(c_{\text{out}}(\sigma)\) are differentiable functions such that \(c_{\text{skip}}(\sigma_{\text{min}})=1\) and \(c_{\text{out}}(\sigma_{\text{min}})=0\)","f_{\theta}(x,\sigma)=c_{skip}(\sigma)x+c_{out}(\sigma) F_{\theta}(x,\sigma)","The consistency model \(\mathbf{f}_{\theta}\) is parameterized with coefficients \(c_{\text{skip}}\) and \(c_{\text{out}}\) and a neural network \(F_{\theta}\) to satisfy the boundary condition \(\mathbf{f}_{\theta}(\mathbf{x}, \sigma_{\text{min}})=\mathbf{x}\)."
ICLR_2024_oral_29,3,"L^{N}(\theta,\theta^{-})=E[\lambda(\sigma_{i} )d(f_{\theta}(x_{\sigma_{i+1}},\sigma_{i+1}),f_{\theta}_{-}(\tilde{x}_{\sigma_{i}},\sigma_{i}))]",where \(\tilde{\mathbf{x}}_{\sigma_{i}}=\mathbf{x}_{\sigma_{i+1}}-(\sigma_{i}-\sigma_{ i+1})\sigma_{i+1}\nabla_{\mathbf{x}}\log p_{\sigma_{i+1}}(\mathbf{x})|_{\mathbf{x}= \mathbf{x}_{\sigma_{i+1}}}\),"L_{CM}(\theta)=E_{i\in [\![1, N-1]\!],x\sim p_{data},z\simN(0,I)}\left[\lambda(\sigma_i)\left\|f_{\theta}(x+\sigma_{i+1}z,\sigma_{i+1})-f_{\theta}(\hat{x}_{\sigma_i},\sigma_i)\right\|_2^2\right]","The consistency matching loss where \(\hat{\mathbf{x}}_{\sigma_i}\) is obtained by applying one step of the Euler method to the probability flow ODE from \((\mathbf{x} + \sigma_{i+1} \mathbf{z}, \sigma_{i+1})\) to \(\sigma_i\)."
ICLR_2024_oral_29,4,\theta^{-}arrowstopgrad(\mu\theta^{-}+(1-\mu)\theta),,\theta^{-}\leftarrow\mu\theta^{-}+(1-\mu)\theta,where \(\mu\) is the EMA decay rate.
ICLR_2024_oral_29,5,"L_{CT}^{N}(\theta,\theta^{-})=E[\lambda(\sigma_{i})d(f_{\theta}(x+\sigma_{i+1}z,\sigma_ {i+1}),f_{\theta^{-}}(x+\sigma_{i}z,\sigma_{i}))]",,"L_{CT}^{N}(\theta,\theta^{-})=E\left[\lambda(\sigma_{i})d\left(f_{\theta}(x+\sigma_{i+1}z,\sigma_{i+1}),f_{\theta^{-}}(x+\sigma_{i}z,\sigma_{i})\right)\right]","The consistency training (CT) objective, which uses the approximation \(\tilde{\mathbf{x}}_{\sigma_i} = \mathbf{x} + \sigma_i \mathbf{z}\)."
ICLR_2024_oral_29,6,"\lim_{N\to\infty}L^{N}(\theta,\theta^{-})=\lim_{N\to\infty}L^{N}_{CT}(\theta,\theta^{-})=E\Big{[}\big{(} 1-\frac{\sigma_{min}}{\sigma_{i}}\big{)}^{2}(\theta-\theta^{-})^{2}\Big{]}\quadif\theta^{-}\neq\theta || \lim_{N\to\infty}\frac{1}{\Delta\sigma}\frac{d L^{N}(\theta,\theta^{-})}{d\theta}=\{{ll}\frac{dL}{d\theta}E\Big{[}\frac{\sigma_ {min}}{\sigma_{i}^{2}}\Big{(}1-\frac{\sigma_{min}}{\sigma_{i}}\Big{)}(\theta-\xi)^{2}\Big{]},&\theta^{-}=\theta\\+\infty,&\theta^{-}\prec\theta\\-\infty,&\theta^{-}>\theta",,"L^{N}(\theta,\theta^{-})=E_{i\simU[1,N-1]}\left[\left( (\theta-\theta^{-})+\sigma_{min}\left(\frac{\xi-\theta}{\sigma_{i+1}}-\frac{\xi-\theta^{-}}{\sigma_{i}}\right)\right)^{2}\right]","The consistency matching loss for the toy example with scalar data and a delta distribution at ξ, using uniform weighting and the squared ℓ2 metric."
ICLR_2024_oral_29,7,"d(x,y)=\sqrt{\lVertx-y\rVert_{2}^{2}+c^{2}}-c",,"d(x,y)=\sqrt{\|x-y\|_{2}^{2}+c^{2}}-c","The Pseudo-Huber metric function between vectors \(\mathbf{x}\) and \(\mathbf{y}\), where \(c\) is a constant and \(\|\cdot\|_2\) denotes the Euclidean norm."
ICLR_2024_oral_29,8,"N(k)=\min(s_{0}2^{\lfloor\frac{1}{N}\rfloor},s_{1})+1,\quad K^{\prime}=\Big{|}\frac{K}{\log_{2}[s_{1}/s_{0}]+1}\Big{|}",,"N(k)=\min\left(s_0\cdot 2^{\left\lfloor\frac{k}{K}\right\rfloor}, s_1\right)+1","The total discretization steps \(N(k)\) at training step \(k\), where \(s_0\) and \(s_1\) are hyperparameters, and \(K\) is the total training iterations."
ICLR_2024_oral_3,1,"\theta^{*}\in\operatorname*{arg\,min}_{\theta\inR^{d}}f(\theta),\\\where f(\theta)\triangleqE_{X\sim\mu}[F(\theta,X) ]=\sum_{i\inN}\mu_{i}F(\theta,i)",,"\min_{x\inX}E[f(x,\xi)]","Equation 1 defines the stochastic optimization problem as minimizing the expected value of the objective function $f(x, \xi)$ over the decision variable $x$ in the feasible set $\mathcal{X}$, where $\xi$ is a random variable."
ICLR_2024_oral_3,2,"\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{n+1}),\\\\forall\n\geq 0","where, roughly speaking, \(H(\mathbf{\theta},i)\) contains gradient information \(\nabla_{\mathbf{\theta}}F(\theta,i)\), such that \(\mathbf{\theta}^{*}\) solves \(\mathbf{h}(\mathbf{\theta})\triangleq\mathbb{E}_{X\sim\mathbf{\mu}}[H(\mathbf{\theta},X)]= \sum_{i\in\mathcal{N}}\mu_{i}H(\mathbf{\theta},i)=\mathbf{0}\)","\theta_{n+1}=\theta_n+\beta_n H(\theta_n, X_n)","The stochastic approximation update rule, where $\theta_{n+1}$ is the next parameter, $\theta_n$ is the current parameter, $\beta_n$ is the step size, and $H(\theta_n, X_n)$ is the update function that depends on the current parameter and the noise $X_n$."
ICLR_2024_oral_3,3,"K_{ij}[x]\triangleq\frac{P_{ij}(x_{j}/\mu_{j})^{-\alpha}}{\sum_{k\inN}P_{ik}(x_{k}/\mu_{k})^{-\alpha}},\quad\quad\forall\,i,j\in N",,"K[x]_{ij}=\frac{ w_{ij}\,x_{j}^{-\alpha} }{\sum_{k\inN} w_{ik}\,x_{k}^{-\alpha} }","The non-linear transition kernel \(\mathbf{K}[\mathbf{x}]\) of the self-repellent random walk, where the transition probability from node \(i\) to node \(j\) is proportional to the edge weight \(w_{ij}\) and the \(-\alpha\)-th power of the current empirical measure \(\mathbf{x}_j\)."
ICLR_2024_oral_3,4,"Draw:\qquad X_{n+1}\simK_{X_{n},\cdot}[x_{n}]",,x_{n}=x_{n-1}+\gamma_{n}\left(\delta_{X_{n}}-x_{n-1}\right),"The empirical distribution update with step size \(\gamma_n\), where \(\mathbf{\delta}_{X_n}\) is the Dirac delta at state \(X_n\)."
ICLR_2024_oral_3,5,"\quadx_{n+1}=x_{n}+\gamma_{n+1}(\delta_{X_{n+1}}-x_{n}) || \quad\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{ n+1})",,x_{n+1}=x_{n}+\frac{1}{n+2}\left(\delta_{X_{n+1}}-x_{n}\right),This equation updates the empirical distribution of the token's visits by incorporating the new state \(X_{n+1}\) and adjusting for the new sample size.
ICLR_2024_oral_3,6,"\theta_{n}\xrightarrow[n\to\infty]{a.s.}\theta^{*}\quadand\quad(\theta_{n}-\theta^{*})/\sqrt{\beta_{n}}\xrightarrow[n\to\infty]{dist.}N(0,V_{\theta}^{(k)}(\alpha))",,"\sqrt{n}(\theta_n-\theta^*)\xrightarrow{d}N(0,\Sigma_k(\alpha)),\quad k=1,2,3","The asymptotic distribution of the scaled optimization error under the three timescale regimes, with covariance $\boldsymbol{\Sigma}_k(\alpha)$ depending on case $k$ and repellence strength $\alpha$."
ICLR_2024_oral_3,7,"x_{n}=\frac{\sum_{i=1}^{n}\omega_{i}\theta_{X_{i}}+\omega_{0}x_{0}}{\sum_{i=0}^{n}\omega_{i}},\\where\\\omega_{0}=1,\\and\\\omega_{n}=\frac{\gamma_{n}}{\prod_{i=1}^{n}(1-\gamma_{i})}",,x_{n}=\frac{\sum_{k=0}^{n}\gamma_{k}\prod_{i=k+1}^{n} (1-\gamma_{i})\delta_{X_{k}}}{\sum_{k=0}^{n}\gamma_{k}\prod_{i=k+1}^{n} (1-\gamma_{i})},"The empirical distribution \(\mathbf{x}_{n}\) is expressed as a normalized weighted sum of Dirac measures at the visited states, with weights \(\gamma_{k} \prod_{i=k+1}^{n} (1 - \gamma_{i})\) for each \(X_{k}\)."
ICLR_2024_oral_3,8,"x_{n}\xrightarrow[n\to\infty]{a.s.}\mu,\quadand\quad\gamma_{n}^{-1/2}(x_{n}-\mu)\xrightarrow[n\to\infty]{dist.}N(0,V_{x}(\alpha)) || where\quadV_{x}(\alpha)=\sum_{i=1}^{N-1 }\frac{1}{2\alpha(1+\lambda_{i})+2-\mathds{1}_{\{a=1\}}}\cdot\frac{1+\lambda_ {i}}{1-\lambda_{i}}u_{i}u_{i}^{T}",,"x_{n}=\frac{\sum_{i=1}^{n}\omega_{i}\delta_{X_{i}}+\omega_{0}x_{0}}{\sum_{i=0}^{n}\omega_{i}},\quadwhere\quad\omega_{0}=1,\quadand\quad\omega_{n}=\frac{\gamma_{n}}{\prod_{i=1}^{n} (1-\gamma_{i})}","The weighted empirical measure \(\mathbf{x}_n\) for the SRRW process, expressed in terms of step sizes \(\gamma_n\) and weights \(\omega_i\)."
ICLR_2024_oral_3,9,\tfrac{d}{dt}z(t)=g(z(t))\triangleqH(\theta(t))^{T}\pi[x(t)]\\\pi[x(t)]-x(t)\inR^{D+N},"where matrix \(\mathbf{H}(\boldsymbol{\theta})\triangleq[H(\boldsymbol{\theta},1),\cdot,H( \boldsymbol{\theta},N)]^{T}\in\mathbb{R}^{N\times D}\) for any \(\boldsymbol{\theta}\in\mathbb{R}^{D}\)",\frac{d}{dt}\theta(t)\\x(t)=h(\theta(t))\\\mu-x(t),The coupled mean-field ordinary differential equation for the state vector.
ICLR_2024_oral_3,10,J(\alpha)\!\triangleq\!\nabla g(z^{*})\!=\!\nablah(\theta^{*})&-\alphaH(\theta^{*})^{T}(P^{T}\!+\mathds{I})\\0_{N\!\times\!D}&2\alpha\mu\mathds{1}^{T}\!-\!\alpha\mathds{P}^{T}\!\!-\!(\alpha\!+\!1)\mathds{I}\!\triangleq\!J_{11}&J_{12}(\alpha)\\J_{21}&J_{22}(\alpha),,\frac{d}{dt}z(t)=g(z(t))\triangleqH(\theta(t))^{T}\pi[x(t)]\\\pi[x(t)]-x(t),The coupled mean-field ordinary differential equation governing the evolution of the parameter vector and the empirical distribution vector.
ICLR_2024_oral_3,11,"\beta_{n}^{-1/2}(\theta_{n}-\theta^{*} )\\\gamma_{n}^{-1/2}(x_{n}-\mu)\xrightarrow[n\to\infty]{ait.}N(0,V^{(k)}(\alpha))",,J(\alpha)\!\triangleq\!\nabla g(z^{*})\!=\!\nablah(\theta^{*})&-\alphaH(\theta^{*})^{T}(P^{T}\!+\mathds{I})\\0_{N\!\times\!D}&2\alpha\mu\mathds{1}^{T}\!-\!\alpha\mathds{P}^{T}\!\!-\!(\alpha\!+\!1)\mathds{I}\!\triangleq\!J_{11}&J_{12}(\alpha)\\J_{21}&J_{22}(\alpha),"The Jacobian matrix of the mean-field ODE at the equilibrium, decomposed into blocks for the optimization parameters and the empirical distribution."
ICLR_2024_oral_3,12,U\triangleq\sum_{i=1}^{N-1}\frac{1+\lambda_{i}}{1-\lambda_{i}}\cdotH^{T}u_{i}u_{i}^{T}H&H^{T}u_{i}u_{i}^{T}\\u_{i}u_{i}^{T}H&u_{i}u_{i}^{T}\triangleqU_{11}&U_{12}\\U_{21}&U_{22},,"\beta_{n}^{-1/2}(\theta_{n}-\theta^{*})\\\gamma_{n}^{-1/2}(x_{n}-\mu)\xrightarrow[n\to\infty]{dist.}N(0,V^{(k)}(\alpha))",The normalized optimization error and the normalized sampling error jointly converge in distribution to a zero-mean Gaussian vector with covariance matrix \(\mathbf{V}^{(k)}(\alpha)\).
ICLR_2024_oral_3,13,V^{(k)}(\alpha)=V^{(k)}_{\theta }(\alpha)&0_{D\times\!N}\\0_{N\!\times\!D}&V_{x}(\alpha),,"V^{(k)}(\alpha)=V_{\theta}^{(k)}(\alpha) &0\\0 &V_{x}(\alpha) ,\quad k\in\{1,3\}","Asymptotic covariance matrix for the joint error vector in cases (i) and (iii), with $\mathbf{V}_{\boldsymbol{\theta}}^{(k)}(\alpha)$ and $\mathbf{V}_{\mathbf{x}}(\alpha)$ being the covariances of the normalized optimization and sampling errors, respectively."
ICLR_2024_oral_31,1,P(z;H)=\mathds{1}(H(z)<\bar{H}),where \(\bar{\mathcal{H}}\) is a threshold and \(\mathds{1}(\cdot)\) is indicator function,P(z;H)=1\{H(z) > 0\},"This equation defines the static pruning probability for a sample $z$ as 1 (keep) if its forgetting count $\mathcal{H}(z)$ is greater than zero, and 0 (discard) otherwise, following Toneva et al."
ICLR_2024_oral_31,2,P_{t}(z)=P(z;H_{t}),,P_t(z;H_t)=\mathds{1}(H_t(z)<\bar{H}),where \(\bar{\mathcal{H}}\) is a threshold and \(\mathds{1}(\cdot)\) is the indicator function
ICLR_2024_oral_31,3,"P_{t}(z)=r,&H_{t}(z)<\bar{H}_{t}\\0,&H_{t}(z)\geq\bar{H}_{t}","where \(\bar{\mathcal{H}}_{t}\) is the mean value of all the scores \(\mathcal{H}_{t}\) and \(r\in(0,1)\) is a predefined hyper-parameter as the pruning probability",P_t(z)=\rho_t\cdot\mathds{1}(H_t(z) <\bar{H}_{t}),where \(\rho_t\) is the pruning probability for samples with scores below the threshold \(\bar{\mathcal{H}}_{t}\) at training step \(t\).
ICLR_2024_oral_31,4,"H_{t+1}(z)=H_{t}(z),&z\inD\backslashS_{t}\\L(z),&z\inS_{t}",,H_{t+1}(z)=H_{t}(z) &if  z is pruned at  t\\L(z) &otherwise,"where for each sample \(z\), if it is pruned at epoch \(t\), the score remains unchanged; otherwise, it is updated to the loss \(\mathcal{L}(z)\) computed in epoch \(t\)"
ICLR_2024_oral_31,5,"\operatorname*{arg\,min}_{\theta\in\Theta}\mathop{E}_{z\inD }[L(z,\theta)]=\int_{z}L(z,\theta)\rho(z)dz",,L=E_{z\sim\rho}\left[L(z)\right],"where \(\mathcal{L}\) is the empirical risk, \(\rho(z)\) is the data distribution, and \(\mathcal{L}(z)\) is the loss for sample \(z\)"
ICLR_2024_oral_31,6,"\operatorname*{arg\,min}_{\theta\in\Theta}\mathop{E}_{z\inS _{t}}[\gamma_{t}(z)L(z,\theta)]=\operatorname*{arg\,min}_{\theta\in\Theta}\frac{1}{c_{t}}\int_{z}L(z,\theta)\rho(z)dz","where \(c_{t}=\mathbb{E}_{z\sim\rho}[1-\mathcal{P}_{t}(z)]=\int_{z}\rho(z)(1-\mathcal{ P}_{t}(z))dz\), \(c_{t}\in(0,1)\) is a constant for temporal status \(t\)","\operatorname*{arg\,min}_{\theta\in\Theta}\mathop{E}_{z\inD}\left[\gamma_t(z)L(z,\theta) (1-P_t(z))\right]","where \(\gamma_t(z) = 1/(1-\mathcal{P}_t(z))\) is the rescaling factor, and \(\mathcal{P}_t(z)\) is the pruning probability at step \(t\)."
ICLR_2024_oral_31,7,\frac{1}{c_{t}}=\frac{|D|}{|\sum_{z\inD}(1-P_{t}( z))|}\simeq\frac{|D|}{|S_{t}|}\RightarrowE[\nabla_{\theta}L(S_{t})]\simeq\frac{|D|}{|S_{t}|}\mathop{E}[\nabla_{\theta}L(D)],,|S_{t}|=M_{t},where \(M_{t}\) is the forced sample number for epoch \(t\)
ICLR_2024_oral_31,8,"P_{t}(z)=r,&H_{t}(z)<\tilde{H}_{t}\wedge t<\delta\cdot C\\0,&H_{t}(z)\geq\tilde{H}_{t}\lor t\geq\delta\cdot C",,"P_t(z)=r, &H_{t}(z) <\bar{H}_{t} and  t\leq\delta C\\0, &otherwise","where \(\delta\) is the hyper-parameter controlling the portion of training epochs for pruning, and \(C\) is the total number of epochs."
ICLR_2024_oral_32,1,"sim(I,t)=\langle M_{image}(I),M_{text}(t)\rangle/( || M_{image}(I) || _{2} || M_{text}(t) || _{2})",,"s(I, t)=\frac{ M_{image}(I)\cdot M_{text}(t) }{\left\| M_{image}(I)\right\|\left\| M_{text}(t)\right\| }",The cosine similarity between the image embedding \( M_{\text{image}}(I) \) and text embedding \( M_{\text{text}}(t) \).
ICLR_2024_oral_32,2,M_{image}(I)=PViT(I),,M_{image}(I)=P\cdotViT(I),This equation defines the CLIP image representation as a linear projection of the vision transformer output using projection matrix \(P\).
ICLR_2024_oral_32,3,"\hat{Z}^{l}=MSA^{l}(Z^{l-1})+Z^{l-1},\quad Z^{l}=MLP^{l}(\hat{ Z}^{l})+\hat{Z}^{l}",,Z' &=Z^{l-1}+MSA(Z^{l-1})\\Z^{l} &=Z'+MLP(Z'),"The token representations at layer $l$ are computed by first adding the multi-head self-attention (MSA) output to the previous layer's tokens to form an intermediate representation $Z'$, then adding the MLP output applied to $Z'$."
ICLR_2024_oral_32,4,M_{image}(I)=PViT(I)=P[Z^{0}]_{cls}+\underbrace{\sum_{ l=1}^{L}P[MSA^{l}(Z^{l-1})]_{cls}}_{MSA\terms}+\underbrace{\sum_{l=1}^{L}P[MLP^{l}(\hat{Z}^{l}) ]_{cls}}_{MLP\perms},,M_{image}(I)=P\left( [Z^{0}]_{cls}+\sum_{l=1}^{L}\left( [MSA^{l}(Z^{l-1})]_{cls}+[MLP^{l}(\hat{Z}^{l})]_{cls}\right)\right),The image representation decomposes into the linear projection of the initial class token plus cumulative contributions from each layer's multi-head self-attention and MLP blocks.
ICLR_2024_oral_32,5,"[MSA^{l}(Z^{l-1})]_{cls}=\sum_{h=1}^{H}\sum_{i=0}^{N}x_{i} ^{l,h},\\\x_{i}^{l,h}=\alpha_{i}^{l,h}W_{VO}^{l,h}z_{i}^{l-1}","where \(W_{VO}^{l,h}\in\mathbb{R}^{d\times d}\) are transition matrices and \(\alpha_{i}^{l,h}\in\mathbb{R}\) are the attention weights from the class token to the \(i\)-th token (\(\sum_{i=0}^{N}\alpha_{i}^{l,h}=1\))","[MSA^{l}(Z^{l-1})]_{cls}=\sum_{h=1}^{H}\sum_{j=0}^{N}\alpha_{0j}^{l,h} W_{OV}^{l,h} z_j^{l-1}","The output of the multi-head self-attention block at the class token is decomposed into a sum over attention heads \(h\) and input tokens \(j\), where \(\alpha_{0j}^{l,h}\) is the attention weight from the class token to token \(j\) in layer \(l\) head \(h\), and \(W_{\mathrm{OV}}^{l,h} = W_O^{l,h} W_V^{l,h}\) is the combined value-output projection matrix."
ICLR_2024_oral_32,6,"\sum_{l=1}^{L}P[MSA^{l}(Z^{l-1})]_{cls}=\sum_{l=1}^{L}\sum_{h=1 }^{H}\sum_{i=0}^{N}c_{i,l,h},\\c_{i,l,h}=Px_{i}^{l,h}",,z_{out}=z_{in}+\sum_{h=1}^{H}head_h(z_{in}})W_h^O,The residual stream output after the multi-head self-attention module equals the input residual stream plus the sum over all attention heads of each head's output multiplied by its output projection matrix.
ICLR_2024_oral_32,7,"V_{explained}(T)=\frac{1}{K}\sum_{k=1}^{K}\| Proj_{T}(c_{k}-c_{avg})\|_{2}^{2}, where c_{avg}=\frac{1}{K}\sum_{k=1}^{K}c_{k}",,variance explained by T=\frac{1}{K}\sum_{k=1}^{K}\left\|Proj_{T}\left( c_k-\frac{1}{K}\sum_{j=1}^{K} c_j\right)\right\|^2,The variance explained by the set of text descriptions \(\mathcal{T}\) is the variance of the head output vectors under the projection onto the span of the text directions.
ICLR_2024_oral_35,1,P_{d}\approx 12lh^{2}+Vh\hskip 28.452756pt(1)\hskip 36.135ptP_{e}\approx(1-\rho)P_{d}+\rho(4h^{2}+8h^{2}N_{e})l,,P_{d}=V\cdot h+12 l h^{2},"This equation calculates the parameter count \(P_d\) of a dense LLM, where \(V\) is the vocabulary size, \(h\) is the hidden size, and \(l\) is the number of layers."
ICLR_2024_oral_35,2,"L(P,D)=\frac{A}{P^{\alpha}}+\frac{B}{D^{\beta}}+E\hskip 14.226378pt(3)\hskip 28.452756ptTC\approx 6PD\hskip 14.226378pt(4)\hskip 28.452756ptIC\approx 2PD\hskip 14.226378pt(5)",,L=E+\frac{A}{P^{\alpha}}+\frac{B}{D^{\beta}}\hskip 28.452756pt (2),The test loss \(L\) equals the summation of an irreducible term \(E\) and reducible terms that diminish with scaling of parameter count \(P\) and training dataset size \(D\).
ICLR_2024_oral_35,3,eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n }&re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2}&re>n || eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n }&re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2}&re>n,,n=t\cdot p\cdot d\hskip 28.452756pt(6),The number of devices required to achieve optimal hardware efficiency for both dense and MoE LLM processing.
ICLR_2024_oral_35,4,energy_{hard}=\sum_{i\in hardware\_set}(P_{i}\cdoteff_{i}\cdot n_{i}\cdot t_{i}) || energy_{oper}=energy_{hard}\cdotPUE,,eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n} &if  re < n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2} &if  re > n\hspace{1cm} (6),"The hardware efficiency when using \(re\) devices, where \(n\) is the optimal number of devices, \(\mathit{eff}_{n}\) is the optimal hardware efficiency, and \(\gamma_{0}\), \(\gamma_{1}\), \(\gamma_{2}\) are fitting constants."
ICLR_2024_oral_35,5,CO2eq_{oper}=energy_{oper}\cdot carb\_int,,energy_{oper}=energy_{hard}\cdotPUE\hskip 28.452756pt(5),The operational energy consumption is the product of the hardware energy consumption and the Power Usage Effectiveness (PUE).
ICLR_2024_oral_35,6,CO2eq_{emb}=\sum_{i\in hardware\_set}\frac{t_{i}\cdotCO2eq_{chip_{i}}}{lifetime_{i}},,PUE=\frac{energy_{oper}}{energy_{hard}},Power Usage Effectiveness (PUE) is defined as the ratio of the total operational energy to the energy consumed by the computing hardware.
ICLR_2024_oral_36,1,"\gamma,\beta=MLP^{mod}(\tilde{c}) || ModLN_{c}(f_{j})=LN(f_{j})\cdot(1+\gamma)+\beta",,ModLN_{c}(f_j)=W_{\gamma}c\odotLayerNorm(f_j)+W_{\beta}c,The modulation function applies adaptive layer normalization to the transformer token $\mathbf{f}_j$ using scale and shift parameters linearly projected from the camera feature $\mathbf{c}$.
ICLR_2024_oral_36,2,f_{j}^{cross}=CrossAttn(ModLN_{c}(f_{j}^{in});\{h_{i}\}_{i=1}^{n})+f_{j}^{in} || f_{j}^{self}=SelfAttn(ModLN_{c}(f_{j}^{cross} );\{ModLN_{c}(f_{j}^{cross})\}_{j})+f_{j}^{cross},,"f_j^{ca}=CrossAttention\left(ModLN_{c}(f_j^{in}),\{h_i\}_{i=1}^n\right)","Each transformer layer updates the $j$-th triplane entry through cross-attention, self-attention, and MLP sub-layers, with camera modulation applied to each sub-layer input and residual connections around each sub-layer."
ICLR_2024_oral_36,3,f_{j}^{out}=MLP^{tfm}(ModLN_{c}(f_{j}^{self}))+f_{j}^{self},,f_{j}^{out}=MLP^{tfm}(ModLN_{c}(f_{j}^{self}))+f_{j}^{self},This equation computes the output feature $\mathbf{f}_{j}^{\mathit{out}}$ for the $j$-th triplane entry by applying the MLP sub-layer to the modulated self-attention features and adding a residual connection.
ICLR_2024_oral_36,4,"L_{recon}(x)=\frac{1}{V}\sum_{v=1}^{V}( L_{MSE}(\hat{x}_{v},x_{v}^{GT})+\lambdaL_{LPIPS}(\hat{x}_{v},x_{v}^{GT}))","where \(\mathcal{L}_{\mathrm{MSE}}\) is the normalized pixel-wise L2 loss, \(\mathcal{L}_{\mathrm{LPIPS}}\) is the perceptual image patch similarity (Zhang et al",L=\sum_{v=1}^{V}\left\|\hat{x}_v-x^{GT}_v\right\|_1,The reconstruction loss for a single input image is the sum of the L1 norms between each of the V rendered images and the corresponding ground truth images.
ICLR_2024_oral_37,1,"z_{t}=z_{0}+\int_{0}^{t}f(z_{s},s)ds","where the hidden state \(z_{t}\in\mathbb{R}^{d}\) evolves with certain dynamics characterized by a neural network \(f:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\), \(z_{0}\) is the initial state, and \(s\) represents time in integrals","\frac{dh(t)}{dt}=f(h(t), t,\theta)",This equation defines the continuous-time dynamics of the hidden state $\mathbf{h}(t)$ as a neural network parameterized by $\theta$.
ICLR_2024_oral_37,2,"z_{t}=z_{0}+\int_{0}^{t}f(z_{s},s)ds+\int_{0}^{t}g(z_{s},s)dB_{s}","where \(z_{t}\) is a latent state that evolves over time, \(f:\mathbb{R}^{d}\times\mathbb{R}\rightarrow\mathbb{R}^{d}\) is the drift function to capture the evolving dynamics, \(g:\mathbb{R}^{d}\times\mathbb{R}\rightarrow\mathbb{R}^{d\times\omega}\) is the diffusion function to reflect the uncertainties, and \(B_{s}\) is an \(d\)-dimensional Brownian motion (Wiener Process)","z_{t}=z_{0}+\int_{0}^{t} f(z_{s}, s)ds+\int_{0}^{t} g(z_{s}, s)dW_{s}","where the hidden state \(z_{t}\) evolves with drift function \(f\), diffusion function \(g\), and \(W_s\) is a Wiener process representing injected noise."
ICLR_2024_oral_37,3,"\min_{\theta}R_{\nu}(h_{\theta})=\min_{\theta}E_{(z,y)\simD (z_{M+1:M+L},y_{M+1:M+L})}[h_{\theta}(z)\neq y]","where \(\nu\) is the distribution of the stochastic path (Boue & Dupuis, 1998) of \(\mathcal{D}\) along timestamps \(T\) to \(T+T^{*}\), \(z_{M+1:M+L}\) and \(y_{M+1:M+L}\) are short for \(z\) and \(y\) at the timestamps \(\{t_{M+1},\dots,t_{M+L}\}\), \(R_{\nu}\) is the risk of a learning model \(h_{\theta}\) parameterized by parameters \(\theta\)","\min_{h}\frac{1}{L}\sum_{l=1}^{L}E_{(z,y)\simD(z,y|t_{M+l})}\left[\ell(h(z), y)\right]","The objective of evolving domain generalization is to minimize the average expected loss over target domains at future timestamps \(t_{M+l}\), where \(h\) is the predictive model, \(\ell\) is the loss function, and \(\mathcal{D}(z,y|t_{M+l})\) is the joint distribution of latent features and labels at time \(t_{M+l}\)."
ICLR_2024_oral_37,4,"\hat{z}_{i|m+1}^{k}=\underset{z_{i|m+1}^{k}=\underset{z_{i|m+1}^{k}\in S_{m+1}^{k}}{argmin}}Dist(z_{i|m}^{k},z_{j|m+1}^{k})","where \(\text{Dist}:\mathcal{Z}\times\mathcal{Z}\rightarrow[0,+\infty)\) is a distance metric defined over the embedding space, \(\mathbb{S}_{m+1}^{k}\) be the set of \(N_{B}\) data points sampled from \(\mathcal{D}_{m+1}\) (short for \(\mathcal{D}(z,y|t_{m+1})\)) with class \(y=k\in\{1,","z_{m+1}^{k,i}=\arg\min_{z'\inZ_{m+1}^{k}}\| z'-z_{m}^{k,i}\|_2","For each class \(k\) and each sample \(i\) at time \(t_m\), the corresponding sample at \(t_{m+1}\) is the one in class \(k\) at \(t_{m+1}\) that is closest in the representation space."
ICLR_2024_oral_37,5,"\hat{z}_{i|m+\lambda}=Interp(z_{i|m}^{k},\hat{z}_{i|m+1}^{k},\lambda)=(1-\lambda)z_{i|m}^{k}+\lambda\hat{z}_{i|m+1}^{k},\forall z_{i|m}^{k}\inS_{m}^{k}","where the interpolation rate \(\lambda\in(0,1)\) is sampled from a Beta distribution \(\mathcal{B}(\beta_{1},\beta_{2})\), \(\beta_{1}\) and \(\beta_{2}\) are the parameters of the Beta distribution, and \(\mathbb{S}_{m}^{k}\) consists of instances sampled from \(k\)-th class of \(m\)-th domain","z_i^k(t)=z_{i|m}^k+\frac{t-t_m}{t_{m+1}-t_m}\left(\hat{z}_{i|m+1}^k-z_{i|m}^k\right),\quad t\in [t_m, t_{m+1}]",The interpolated representation \( z_i^k(t) \) at time \( t \) for the \( i \)-th sample of class \( k \) is generated by linearly interpolating between \( z_{i|m}^k \) and \( \hat{z}_{i|m+1}^k \).
ICLR_2024_oral_37,6,"\hat{z}_{m^{\prime}}^{k}=z_{m}^{k}+\int_{t_{m}}^{t_{m^{\prime}}}f_{k}(\hat{z}_ {s}^{k},s)ds+\int_{t_{m}}^{t_{m^{\prime}}}g_{k}(\hat{z}_{s}^{k},s)dB_{s}","where the latent variable \(\hat{z}_{m^{\prime}}^{k}\) is transformed from \(m\)-th domains latent variable \(z_{m}^{k}\), and \(f_{k}\) is the drift function of the \(k\)-th class to capture the evolving patterns, and \(g_{k}\) is the diffusion function of the \(k\)-th class to characterize the stochastics of the latent representations","z_{t_{m'}}=z_{t_{m}}+\int_{t_{m}}^{t_{m'}} f_k(z_s, s)ds+\int_{t_{m}}^{t_{m'}} g_k(z_s, s)dB_s","where \(z_{t_m}\) is the initial latent state at time \(t_m\) for a sample of class \(k\), \(z_{t_{m'}}\) is the latent state at future time \(t_{m'} > t_m\), \(f_k\) and \(g_k\) are class-specific drift and diffusion functions, and \(B_s\) is a Brownian motion."
ICLR_2024_oral_37,7,J_{mle}=\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_{B}}-\frac{1}{MKN_ {B}}\Big{(}\logD(z=\hat{z}_{i|m+1}^{k}|z=z_{i|m}^{k})+\logD \big{(}z=\hat{z}_{i|m+\lambda}^{k}|z=z_{i|m}^{k}\big{)}\Big{)},,"L_{path}=E_{(z_{m}^{k},\hat{z}_{m+\lambda}^{k},\hat{z}_{m+1}^{k})\inT}\left[-\log p\left(\hat{z}_{m+\lambda}^{k}\mid z_{m}^{k}\right)-\log p\left(\hat{z}_{m+1}^{k}\mid\hat{z}_{m+\lambda}^{k}\right)\right]","The path alignment loss defined as the expected negative log-likelihood of the intermediate and next state given the current state under the SDE-EDG model, over the IFGET triplets."
ICLR_2024_oral_37,8,"D(y=k|z,t=t_{m})=\frac{D(z|y=k,t=t_{m})\timesD(y=k|t=t_{m})}{\sum_{k^{\prime}=1}^{K}D(z|y=k^{\prime},t=t_{m})\timesD(y=k^{\prime}|t=t_{m})}","where we model \(\mathcal{D}(z|y=k,t=t_{m})\) with non-parametric model, and \(\mathcal{D}(y|t=t_{m})\) as a neural net with input as timestamp \(t\), function denoted as \(r(t)\)","P(y|z, t)=\frac{P(z|y, t) P(y|t)}{P(z|t)}","The predictive distribution of class label \(y\) given latent representation \(z\) at time \(t\), where \(P(z|y,t)\) is the likelihood of \(z\) under class \(y\) and time \(t\), \(P(y|t)\) is the class prior at time \(t\), and \(P(z|t)\) is the marginal distribution of \(z\) at time \(t\)."
ICLR_2024_oral_37,9,"D(z|y=k,t=t_{m})=\frac{\sum_{\hat{z}_{i}\in\hat{S}_{m}^{k}}- exp(-Dist(z,\hat{z}_{i}))}{|\hat{S}_{m}^{k}|}",where \(\hat{S}_{m}^{k}\) includes instances sample from learned SDE-EDG belong to \(k\)-th class of \(m\)-th domain,"D(z|y=k,t=t_{m})=\frac{1}{|\hat{S}_{m}^{k}|}\sum_{z_{j}\in\hat{S}_{m}^{k}}K(z,z_{j})","The conditional distribution \(\mathcal{D}(z|y=k,t=t_{m})\) is approximated by a Parzen window density estimator with kernel \(K\) over the set \(\hat{S}_{m}^{k}\) of samples from class \(k\) at time \(t_{m}\)."
ICLR_2024_oral_37,10,"J_{cls}=\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_{B}}-\frac{1}{MKN _{B}}\logD(y=k|z=z_{i},t=t_{m})",,"L_{cls}=\frac{1}{M\cdot K\cdot N_B}\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_B}-\logD(y=k | z_{i|m}^{k}, t_m)","The classification loss for the source domains, where \(\mathcal{D}(y=k|z,t_m)\) is the predictive distribution, \(z_{i|m}^{k}\) is the latent representation of the \(i\)-th sample in the \(m\)-th domain and \(k\)-th class, and \(N_B\) is the batch size per class per domain."
ICLR_2024_oral_38,1,P_{F}^{\top}(x)\propto\exp(-E(x)),where \(P_{F}^{\top}(x)\) is the distribution of sampling an object \(x\) induced from marginalizing over the trajectories conditioned on \(x=s_{T}\),\pi(x)=\frac{\exp(-E(x))}{\sum_{x'\inX}\exp(-E(x'))},The target Boltzmann distribution \(\pi(x)\) for objects \(x \in \mathcal{X}\) defined by the energy function \(\mathcal{E}\).
ICLR_2024_oral_38,2,"L_{DB}(s,s^{\prime})=(\log F(s)+\log P_{F}(s^{\prime}|s)-\log F(s^{\prime})-\log P_{B}(s|s^{\prime}))^{2}","where the flow \(F(s)\) for the terminal state \(s_{T}=x\) is defined to be identical to the exponent of the negative energy \(\exp\left(-\mathcal{E}(x)\right)\), i","L_{DB}(s, s';\theta)=\left(\log\frac{F(s) P_F(s'|s)}{F(s') P_B(s|s')}\right)^2","The detailed balance loss function for state transition \((s \to s')\), where \(F(s)\) and \(F(s')\) are state flow estimates, \(P_F(s'|s)\) is the forward policy, and \(P_B(s|s')\) is the backward policy."
ICLR_2024_oral_38,3,L_{TB}=(\log Z+\sum_{t=0}^{T-1}\log P_{F}(s_{t+1}|s_{t} )-E(x)-\sum_{t=0}^{T-1}\log P_{B}(s_{t}|s_{t+1}))^{2},,L_{TB}(\tau)=\left(\log\frac{Z\prod_{t=0}^{T-1} P_F(s_{t+1}|s_t)}{\exp(-E(x))\prod_{t=0}^{T-1} P_B(s_t|s_{t+1})}\right)^2,"where \(Z\) is a learnable scalar estimating the partition function, \(\tau = (s_0, s_1, \dots, s_T)\) is a complete trajectory, \(x = s_T\) is the terminal state, and the products are over the \(T\) transitions of the trajectory."
ICLR_2024_oral_38,4,L_{subTB}=(\log F(s_{U})+\sum_{t=U}^{U+L-1}\log P_{F}(s_ {t+1}|s_{t})-\log F(s_{U+L})-\sum_{t=U}^{U+L-1}\log P_{B}(s_{t}|s_{t+1})) ^{2},,"L_{subTB}(s_U,\dots, s_{U+L})=\left(\log F(s_U)+\sum_{u=U}^{U+L-1}\log P_F(s_{u+1}|s_u)-\log F(s_{U+L})-\sum_{u=U}^{U+L-1}\log P_B(s_u|s_{u+1})\right)^2",The sub-trajectory balance loss for a sub-trajectory from state \(s_U\) to \(s_{U+L}\) minimizes the squared difference between the log forward flow plus forward transitions and the log backward flow plus backward transitions.
ICLR_2024_oral_38,5,"L_{FL}(s,s^{\prime})=(\log\tilde{F}(s)+\log P_{F}(s^{\prime}| s)-E(s)+E(s^{\prime})-\log\tilde{F}(s^{\prime})-\log P _{B}(s|s^{\prime}))^{2}",where \(\tilde{F}(s)=F(s)\exp\left(\mathcal{E}(s)\right)\) is the re-parameterized flow function and \(\mathcal{E}(s^{\prime})-\mathcal{E}(s)\) is the energy gain associated with the transition from \(s\) to \(s^{\prime}\),"L_{FL-DB}(s,s^{\prime})=\left(-E(s)+\log P_{F}(s^{\prime}|s)+E(s^{\prime})-\log P_{B}(s|s^{\prime})\right)^{2}",The modified detailed balance loss for FL-GFN that uses the energy of the current state \(s\) and the next state \(s'\) to provide local credit for the transition.
ICLR_2024_oral_38,6,E(x)\approx\Phi_{\theta}(\tau)=\sum_{t=0}^{T-1}\phi_{\theta}(s_{t}\to s_{t+1}),"where \(\tau=(s_{0},s_{1},\ldots,s_{T})\), \(x=s_{T}\), and the potential functions are defined on state transition \(s_{t}\to s_{t+1}\)","E(x)=\sum_{t=0}^{T-1}\phi_{\theta}(s_t, s_{t+1})","where \(\phi_{\theta}(s_t, s_{t+1})\) is the learned potential for the transition from state \(s_t\) to \(s_{t+1}\) and \(x = s_T\) is the terminal state."
ICLR_2024_oral_38,7,"L_{LED}(s,s^{\prime})=(\log\tilde{F}(s)+\log P_{F}(s^{\prime} |s)+\phi_{\theta}(s\to s^{\prime})-\log\tilde{F}(s^{\prime})-\log P_{B}(s|s^{\prime}))^{2}",,"L_{LED}(s,s^{\prime})=\left(\log F(s)+\log P_{F}(s^{\prime}|s)+\phi_{\theta}(s\to s^{\prime})-\log F(s^{\prime})-\log P_{B}(s|s^{\prime})\right)^{2}",where \(\phi_{\theta}(s\to s^{\prime})\) is the potential for the transition from \(s\) to \(s^{\prime}\) and \(F\) is the state flow function.
ICLR_2024_oral_38,8,\ell_{LS}(\tau)=E_{z\simBern(\gamma)} [(\frac{1}{T}E(s_{T})-\frac{1}{C}\sum_{t=0}^{T-1}z_{t}\phi_{\theta}(s_{t}\to s_{t+1}))^{2}],,L_{pot}(\tau)=\left(E(x)-\sum_{t=0}^{T-1}\phi_{\theta}(s_t\to s_{t+1})\right)^2+\lambda\sum_{t=0}^{T-1}\left(\phi_{\theta}(s_t\to s_{t+1})-\frac{1}{T}\sum_{t'=0}^{T-1}\phi_{\theta}(s_{t'}\to s_{t'+1})\right)^2,The loss function for training potential functions consists of a squared error term to match the terminal energy and a variance regularization term to minimize the variance of potentials along the trajectory.
ICLR_2024_oral_39,1,"\epsilon_{\theta}(o_{t}^{(k)},k|h_{t-1},a_{t-1})=(1+\eta)\epsilon_{\theta}(o_{ t}^{(k)},k|h_{t-1},a_{t-1})-\eta\epsilon_{\theta}(o_{t},k|h_{t-1})",where \(\eta\) controls action conditioning strength,\{\beta_k\}_{k=1}^K\quadwith\quad 0 <\beta_1 <\beta_2 <\cdots <\beta_K < 1,"The variance schedule for the diffusion process, where \(\beta_k\) is the noise variance at diffusion step \(k\) and \(K\) is the total number of diffusion steps."
ICLR_2024_oral_39,2,"L_{MSE}=\|\epsilon-\epsilon_{\theta}\Big{(}\sqrt{1-\beta^{(k)}}o_{t}+\sqrt{\beta^{(k)}}\epsilon,\,k\Big{|}h_{t-1},a_{t-1}\Big{)}\|^{2}","where \(\epsilon\sim\mathcal{N}(0,I)\), and \(\beta^{(k)}\in\mathbb{R}\) are a set of \(K\) different noise levels for each \(k\in[1,K]\)","E_{k,\epsilon, h_{t-1}, a_{t-1}, o_t}\left[\left\|\epsilon-\epsilon_{\theta}\left( o_t^{(k)}, k|h_{t-1},a_{t-1}\right)\right\|_2^2\right]","the mean squared error loss for training the denoising model over timesteps, noise, and data tuples"
ICLR_2024_oral_39,3,"o_{t}^{(k-1)}=\alpha^{(k)}(o_{t}^{(k)}-\gamma^{(k)}\epsilon_{\theta}(o_{t}^{( k)},k|h_{t-1},a_{t-1}))+\xi,\quad\xi\simN\big{(}0,\sigma_{k}^{2}I\big{)}","where \(\gamma^{(k)}\) is the denoising step size, \(\alpha^{(k)}\) is a linear decay on the current denoised sample, and \(\sigma_{k}\) is a time varying noise level that depends on \(\alpha^{(k)}\) and \(\beta^{(k)}\)","o_t^{(k-1)}=\frac{1}{\sqrt{\alpha^{(k)}}}\left( o_t^{(k)}-\frac{\beta^{(k)}}{\sqrt{1-\bar{\alpha}^{(k)}}}\epsilon_\theta(o_t^{(k)}, k | h_{t-1}, a_{t-1})\right)+\sigma^{(k)} z^{(k)}","The iterative denoising step from noise level \(k\) to \(k-1\), where \(\alpha^{(k)} = 1 - \beta^{(k)}\), \(\bar{\alpha}^{(k)} = \prod_{i=1}^{k} \alpha^{(i)}\), \(\sigma^{(k)} = \sqrt{\beta^{(k)}}\) for \(k>1\) and \(0\) for \(k=1\), and \(z^{(k)} \sim \mathcal{N}(0,I)\)."
ICLR_2024_oral_39,4,RDG=\frac{\|s_{0}-s_{goal}\|_{2}-\|s_{T}-s_{goal}\|_{2}}{\|s_{0}-s_{goal}\|_{2}},"where \(s_{T}\) represents the underlying block locations after executing the policy, \(s_{0}\) and \(s_{\text{goal}}\) represents the initial and goal block locations",RDG=\frac{\sum_{i=1}^{n} d_i^{initial}-\sum_{i=1}^{n} d_i^{final}}{\sum_{i=1}^{n} d_i^{initial}},"RDG is the normalized reduction in total Euclidean distance to goal states for \(n\) blocks, where \(d_i^{\text{initial}}\) and \(d_i^{\text{final}}\) are the initial and final distances of block \(i\) to its goal state."
ICLR_2024_oral_4,1,p(Y\mid X)=\sum_{Z}p_{LM}(ZY\mid X)=\sum_{Z}p_{LM}(Y\mid XZ)p_{LM}(Z\mid X),where \(p_{\text{LM}}\) denotes the likelihood assigned to a sequence by a language model and apposition of variables (_e,"P(Y, Z\mid X)",The joint probability of the answer \(Y\) and the chain of thought \(Z\) given the question \(X\).
ICLR_2024_oral_4,2,"p_{LM}(Z\mid X,Y)=\frac{p_{LM}(XZY)}{\sum_{Z^{\prime}}p_{ LM}(XZY^{\prime}Y)}\propto p_{LM}(XZY)",,"p_{LM}(Z\mid X, Y)=\frac{p_{LM}(XZY)}{\sum_{Z'} p_{LM}(XZ'Y)}",The posterior distribution over the latent chain of thought \(Z\) given the input \(X\) and the output \(Y\).
ICLR_2024_oral_4,3,L(Z;\theta)=\sum_{0\leq i<j\leq n}(\log\frac{R(z_{1:i}\top)\prod_{k=i+1}^{j}q_{GFN}(z_{k}\mid z_{1:k-1})q_{GFN}(\top\mid z_ {1:j})}{R(z_{1:j}\top)q_{GFN}(\top\mid z_{1:i})})^{2},,L_{SubTB}(Z)=\sum_{t=0}^{n}\left(\log\frac{F(s_t)\cdot q_{GFN}(z_{t+1}\mid s_t)}{F(s_{t+1})}\right)^2,"The subtrajectory balance loss for sequence Z, ensuring flow consistency at each generation step by matching forward policy probabilities and state flows."
ICLR_2024_oral_41,1,"q_{0t}(x_{t}|x_{0})=N(x_{ t}|\alpha_{t}x_{0},\sigma_{t}^{2}I)","where \(\alpha_{t}\) and \(\sigma_{t}\) are referred to as the noise schedule, satisfying \(\alpha_{t}^{2}+\sigma_{t}^{2}=1\)","q_{0t}(x_{t} |x_{0})=N\left(x_{t};\sqrt{\bar{\alpha}_t}x_{0}, (1-\bar{\alpha}_t)I\right)",The conditional distribution of the noisy data $\mathbf{x}_t$ given the clean data $\mathbf{x}_0$ is a Gaussian with mean $\sqrt{\bar{\alpha}_t} \mathbf{x}_{0}$ and covariance $(1 - \bar{\alpha}_t) \mathbf{I}$.
ICLR_2024_oral_41,2,"dx_{t}=f(t)x_{t}dt+g(t )dw_{t},\quadx_{0}\sim q_{0}(x_{0})","where \(\mathbf{w}_{t}\) is the standard Wiener process, \(f(t)=\frac{\mathrm{d}\log\alpha_{t}}{\mathrm{d}t}\) and \(g(t)=2\sigma_{t}^{2}\frac{\mathrm{d}\log(\sigma_{t}/\alpha_{t})}{\mathrm{d}t}\)",dx_t=-\frac{1}{2}\beta(t)x_t dt+\sqrt{\beta(t)} dw_t,where \(\beta(t)\) is the noise schedule function and \(\mathbf{w}_t\) is a standard Wiener process.
ICLR_2024_oral_41,3,"dx_{t}=[f(t)x_{t}-g(t)^{2}\nabla_{x_{t}}\log q_{t}(x_{t})]dt+g (t)d\bar{w}_{t},\quadx_{T}\sim q_{T} (x_{T})",where \(\bar{\mathbf{w}}_{t}\) is a standard Wiener process in the reverse time,dx_{t}=\left[ f(t)x_{t}-g(t)^{2}\nabla_{x_{t}}\log q_t(x_{t})\right]dt+g(t)d\bar{w}_{t},where \(\bar{\mathbf{w}}_{t}\) is a reverse-time standard Wiener process and \(\nabla_{\mathbf{x}_{t}} \log q_t(\mathbf{x}_{t})\) denotes the score function of the marginal distribution \(q_t(\mathbf{x}_{t})\).
ICLR_2024_oral_41,4,"L(\theta):=E_{t\simU(0,T),x_{0}\sim q_{0}(x_{0}),\epsilon\simN (0,I)}[\|\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon,t)-\epsilon\|_{2}^{2}]",,"L(\theta)=E_{t\simU(0,T),x_0\sim q_0(x_0),\epsilon\simN(0,I)}\left[\|\epsilon-\epsilon_{\theta}(x_t, t)\|^2\right]","The training objective \(\mathcal{L}(\theta)\) minimizes the expected squared error between the true noise \(\mathbf{\epsilon}\) and the predicted noise \(\mathbf{\epsilon}_{\theta}(\mathbf{x}_t, t)\) over time, data, and noise."
ICLR_2024_oral_41,5,"\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}=\frac{\alpha_{t}}{\sqrt{1-\alpha_{t}^{2}}}\frac{d\alpha_{t}}{dt}\nabla_{x}\log q_{t}(x)-\frac{\partial\nabla_{x }\log q_{t}(x)}{\partial t}\sigma_{t}",,"\frac{\partial\epsilon_{\theta}(x, t)}{\partial t}=-\frac{d\sigma_t}{dt}\nabla_{x}\log q_t(x)-\sigma_t\frac{\partial}{\partial t}\nabla_{x}\log q_t(x)","The partial derivative of the noise prediction model with respect to time \(t\), decomposing into two terms: one involving the noise schedule derivative and score function, and another involving the noise level and time derivative of the score function."
ICLR_2024_oral_41,6,"\lim\sup_{t\to 0+}\|\frac{\partial\epsilon_{\theta}(x,t )}{\partial t}\|\to\infty;\quad\lim\sup_{t\to 0+}\|\frac{\partial\nabla_{x}\log q_{t}(x)}{\partial t}\sigma_{t}\|\to\infty",,"\limsup_{t\to 0^+}\left\|\frac{\partial\epsilon_{\theta}(x, t)}{\partial t}\right\|=\infty",The limsup of the norm of the partial derivative of the noise prediction model with respect to time is infinite as time approaches zero from the right.
ICLR_2024_oral_41,7,\nabla_{x}\log q_{t}(x)=\nabla_{x}\log (\frac{1}{\sqrt{2\pi}}\exp(-\frac{\|x\|_{2}^{2}}{2}) )=-x,,\nabla_{x}\log q_t(x)=-x,The score function \(\nabla_{\mathbf{x}} \log q_t(\mathbf{x})\) equals \(-\mathbf{x}\) when the data distribution is standard normal.
ICLR_2024_oral_41,8,"K(t,t^{\prime})=\frac{E_{x_{t}}[\|\epsilon_{\theta} (x_{t},t)-\epsilon_{\theta}(x_{t},t^{\prime})\|_{2}]}{\Delta t}",where \(\Delta t=|t-t^{\prime}|\),"\left\|\frac{\partial\epsilon_{\theta}(x, t)}{\partial t}\right\|",the norm of the partial derivative of the noise prediction model with respect to time.
ICLR_2024_oral_41,9,"L(\epsilon_{\theta}):=E_{t\simU(0,T),x_{0}\sim q(x_{0}),\epsilon\simN(0,I)} [\|\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon,f_{T}(t))-\epsilon\|_{2}^{2}]","where \(f_{\mathbb{T}}(t)=\max_{1\leq i\leq n}\{t_{i-1}\in\mathbb{T}:t_{i-1}\leq t\}\) for \(t<\tilde{t}\), while \(f_{\mathbb{T}}(t)=t\) for \(t\geq\tilde{t}\)","L_{E-TSDM}(\theta) :=E_{t\simU(0,T),x_{0}\sim q_{0}(x_{0}),\epsilon\simN(0,I)}\left[\left\|\epsilon_{\theta}\left(\alpha_{t}x_{0}+\sigma_{t}\epsilon, c(t)\right)-\epsilon\right\|_{2}^{2}\right]","The training loss for the early timestep-shared diffusion model (E-TSDM), where $c(t)$ is the shared timestep condition defined as the left endpoint of the sub-interval containing $t$ for $t \in [0, \tilde{t})$ and $c(t) = t$ for $t \geq \tilde{t}$."
ICLR_2024_oral_41,10,"p_{\theta}(x_{t-1}|x_{t})=N(x_{t-1};\frac{\alpha_{t-1}}{\alpha_{t}}(x_{t}-\frac{\beta_{t}}{\sigma_{t}}\epsilon_{\theta}(x_{t},f_{T} (t))),\eta_{t}^{2}I)","where \(\beta_{t}=1-\frac{\alpha_{t}}{\alpha_{t-1}}\), and \(\eta_{t}^{2}=\beta_{t}\)","dx_{t}=\left[f(t)x_{t}+\frac{g(t)^{2}}{\sigma_{t}}\epsilon_{\theta}(x_{t},f_{T}(t))\right]dt+g(t)d\bar{w}_{t},\quadx_{T}\sim q_{T}(x_{T})",The reverse-time SDE for E-TSDM using shared timestep conditions \(f_{\mathbb{T}}(t)\).
ICLR_2024_oral_41,11,"\|\epsilon^{*}(x,f_{T}(t)-\epsilon(x,t)\|\leq\sigma_{\tilde{t}}K (x)\Delta t+B(x)\Delta\sigma_{\max}",,"\|\epsilon^{*}(x,f_{T}(t))-\epsilon(x,t)\|\leq C\sqrt{\frac{\tilde{t}}{n}}","where \(C\) is a constant, \(\tilde{t}\) is the length of the interval for sharing conditions, and \(n\) is the number of sub-intervals."
ICLR_2024_oral_41,12,"K(x)=\sup_{t\neq\tau}\frac{\|\nabla_{x}\log q_{t }(x)-\nabla_{x}\log q_{\tau}(x )\|}{|t-\tau|},\quad B(x)=\sup_{t}\|\nabla_{x}\log q_{t}(x)\|",,"\Delta t=\max_{i} (t_i-t_{i-1}),\quad\Delta\sigma_{\max}=\max_{i}\sup_{t\in [t_{i-1}, t_i)} |\sigma_t-\sigma_{t_{i-1}}|","\(\Delta t\) is the maximum sub-interval length, \(\Delta\sigma_{\max}\) is the maximum change of \(\sigma_t\) within any sub-interval, and \(K(\mathbf{x})\) and \(B(\mathbf{x})\) are bounded functions."
ICLR_2024_oral_44,1,"I(S;Z)=D_{KL}(p(s,z)\|p(s)p(z))",,I(s; z),The mutual information between states \(s\) and skills \(z\).
ICLR_2024_oral_44,2,"I_{W}(S;Z)=W(p(s,z),p(s)p(z))",where \(I_{\mathcal{W}}(S;Z)\) is the Wasserstein dependency measure (WDM) (Ozair et al,"I_{W}(S;Z)\triangleq W_d(p(s,z)\| p(s)p(z))",The Wasserstein dependency measure between states and skills.
ICLR_2024_oral_44,3,"I_{W}(S;Z)=\sup_{\|f\|_{L}\leq 1}E_{p(s,z)}[f(s,z)]-E_{p(s)p(z)}[f(s,z)]","where \(\|f\|_{L}\) denotes the Lipschitz constant for the function \(f:\mathcal{S}\times\mathcal{Z}\rightarrow\mathbb{R}\) under the given distance metric \(d\), _i","I_{W}(S;Z)=\sup_{\|f\|_{L}\leq 1}\left(E_{p(s,z)}[f(s,z)]-E_{p(s)p(z)}[f(s,z)]\right)","The dual representation of the Wasserstein dependency measure via Kantorovich-Rubinstein duality, where the supremum is over 1-Lipschitz functions."
ICLR_2024_oral_44,4,"I_{W}(S;Z)\approx\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}E_{p( s,z)}[\phi(s)^{\top}\psi(z)]-E_{p(s)}[\phi(s)]^{\top}E_{p(z)}[\psi(z)]",,"I_{W}(S;Z)=\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}\left(E_{p(s,z)}[\phi(s)^{\top}\psi(z)]-E_{p(s)p(z)}[\phi(s)^{\top}\psi(z)]\right)",where \(\phi: \mathcal{S} \to \mathbb{R}^D\) and \(\psi: \mathcal{Z} \to \mathbb{R}^D\) are 1-Lipschitz functions.
ICLR_2024_oral_44,5,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}E_{p(\tau,z)}[\phi(s_{T})^{\top}\psi(z)]-E_{p(\tau)}[\phi(s_{T})]^{\top}E_{p(z)}[\psi(z)] || =\sup_{\phi,\psi}\sum_{t=0}^{T-1}(E_{p(\tau,z)}[(\phi(s_{t+1})-\phi(s_{t}))^{\top}\psi(z)]-E_{p(\tau)}[\phi(s_{t+1})-\phi(s_{t})]^{\top}E_{p(z)}[\psi(z)])",,I_{W}(S_T; Z)=\sum_{t=0}^{T-1} I_{W}(S_{t+1}; Z | S_t),Decomposition of the Wasserstein dependency measure for the final state into a sum of conditional Wasserstein dependency measures over each time step.
ICLR_2024_oral_44,6,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1}E_{p(\tau,z)}[\sum_{t=0}^{T-1}(\phi(s_{t+1})-\phi(s_{t}))^{\top}(z-\bar{z}) ]",where \(\bar{z}=\mathbb{E}_{p(z)}[z]\),"\sum_{t=0}^{T-1}E_{p(\tau,z)}\left[\left(\phi(s_{t+1})-\phi(s_t)\right)^{\top} z\right]",The objective maximizes the expected directional derivative of $\phi(s)$ in the direction of $z$.
ICLR_2024_oral_44,7,"\sup_{\pi,\phi}\E_{p(\tau,z)}[\sum_{t=0}^{T-1}(\phi(s_{t+1})-\phi(s_{t}))^{\top}z]\\s.t.\\\|\phi(s)-\phi(s^{\prime})\|_{2}\leq 1,\\\forall(s,s^{\prime})\inS_{adj}",where \(\mathcal{S}_{\mathrm{adj}}\) denotes the set of adjacent state pairs in the MDP,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L,temp}\leq 1}E_{p(\tau,z)}\left[\sum_{t=0}^{T-1} (\phi(s_{t+1})-\phi(s_t))^{\top} z\right]",The Wasserstein dependency measure objective with the Lipschitz constraint defined using the temporal distance metric.
ICLR_2024_oral_45,1,"x^{\prime}(t)=Ax(t)+Bu(t),\quad y(t)=Cx(t)+Du(t)",,\dot{x}(t)=A x(t)+B u(t)\\y(t)=C x(t)+D u(t),The continuous-time state space equations defining the linear dynamical system with state evolution and observation output.
ICLR_2024_oral_45,2,"x_{n}=\bar{A}x_{n-1}+\bar{B}u_{n},\quad y_{n}=\bar{ C}x_{n}+\bar{D}u_{n}","where \(\bar{\mathbf{A}},\bar{\mathbf{B}},\bar{\mathbf{C}}\), and \(\bar{\mathbf{D}}\) are discrete-time parameters obtained from the continuous-time parameters and \(\Delta\) using methods like zero-order hold and bilinear technique (Smith et al",x_k=\overline{A} x_{k-1}+\overline{B} u_k,The discrete-time state update equation with discretized parameters \(\overline{\mathbf{A}}\) and \(\overline{\mathbf{B}}\) using step size \(\Delta\).
ICLR_2024_oral_45,3,"L(\theta)=\operatorname*{E}_{z_{1:T}\sim q_{\theta}}\sum_{ t=1}^{T}L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})+L^{rep}(\theta,h_{t},o_{t})+L^{dyn}(\theta,h _{t},o_{t})",,"L(\theta)=\sum_{t=1}^{T}\left[E_{z_{t}\sim q_{\theta}(z_{t}\mid o_{t})}\left[-\ln p_{\theta}(o_{t}\mid z_{t}, h_{t})-\ln p_{\theta}(r_{t}\mid z_{t}, h_{t})-\ln p_{\theta}(c_{t}\mid z_{t}, h_{t})\right]+\beta\cdot D_{KL}\left( q_{\theta}(z_{t}\mid o_{t})\parallel p_{\theta}(\hat{z}_{t}\mid h_{t})\right)\right]","The objective function for training the world model, consisting of the reconstruction losses for observation, reward, and continuation, and a KL divergence term between the posterior and prior distributions of the stochastic state."
ICLR_2024_oral_45,4,"L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})=-\beta_{pred}(\ln p_{\theta}(o_{t}\mid z_{t},h_{t})+\ln p_{\theta}(r_{t}\mid z_{t},h_{t})+\ln p_{\theta}(c_{t}\mid z_{t},h_{t})) || L^{dyn}(\theta,h_{t},o_{t})=\beta_{dyn}\max(1,KL[\lessdot\circ g(q_{\theta}(z_ {t}\mid o_{t}))\parallel p(z_{t}\mid h_{t})\mid)]",,"L^{pred}(\theta, h_t, o_t, r_t, c_t, z_t)=-\ln p_{\theta}(o_{t}\mid z_{t}, h_{t})-\ln p_{\theta}(r_{t}\mid z_{t}, h_{t})-\ln p_{\theta}(c_{t}\mid z_{t}, h_{t})","The prediction loss is the sum of the negative log-likelihoods of the observation, reward, and continuation flag under the world model's prediction heads."
ICLR_2024_oral_45,5,"L^{rep}(\theta,h_{t},o_{t})=\beta_{rep}\max(1,KL[\quad q_{\theta}(z_{t}\mid o_ {t})\parallel\lessdot\circ g(p(z_{t}\mid h_{t}))\,])",,"L^{rep}(\theta,h_{t},o_{t})=\beta_{rep}\max(1,KL[q_{\theta}(z_{t}\mid o_{t})\parallelsg(p_{\theta}(z_{t}\mid h_{t}))])","Representation loss, which is the KL divergence from the posterior to the stop-gradient prior, clipped at 1 and scaled by β_rep."
ICLR_2024_oral_45,6,"h_{1:T},x_{1:T}=f_{\theta}((a_{1:T},z_{1:T}),x_{0})",,g(x)=sg(x),Function \( g \) applies the stop-gradient operator to its input.
ICLR_2024_oral_49,1,"e_{i}^{num}=x_{i}^{num}\cdotw_{i}^{num}+b_{i}^{num},\\e_{i}^{cat}=x_{i}^{oh}\cdotW_{i}^{cat }+b_{i}^{cat}","where \(\mathbf{w}_{i}^{\mathrm{num}},\mathbf{b}_{i}^{\mathrm{num}},\mathbf{b}_{i}^{\mathrm{cat}} \in\mathbb{R}^{1\times d}\), \(\mathbf{W}_{i}^{\mathrm{cat}}\in\mathbb{R}^{C_{i}\times d}\) are learnable parameters of the tokenizer, \(\mathbf{e}_{i}^{\mathrm{num}},\mathbf{e}_{i}^{\mathrm{cat}}\in\mathbb{R}^{1\times d}\)","z_j=W_j^{num} x_j+b_j^{num}, &if column  j is numerical\\x_jE_j, &if column  j is categorical","This equation computes the token $\mathbf{z}_j$ for column $j$, applying a linear transformation with weight $\mathbf{W}_j^{\mathrm{num}}$ and bias $\mathbf{b}_j^{\mathrm{num}}$ to numerical features, or an embedding lookup via matrix $\mathbf{E}_j$ for categorical features."
ICLR_2024_oral_49,2,"E=[e_{1}^{num},\cdots,e_{M_{num}}^{ num},e_{1}^{cat},\cdots,e_{M_{cat}}^{cat}]\inR^{M\times d}",,E=e_{1}^{num}\\e_{2}^{num}\\\vdots\\e_{M_{num}}^{num}\\e_{1}^{cat}\\e_{2}^{cat}\\\vdots\\e_{M_{cat}}^{cat}\inR^{M\times d},"The entire record embedding matrix \(\mathbf{E} \in \mathbb{R}^{M \times d}\) is formed by vertically stacking the embeddings of the \(M_{\mathrm{num}}\) numerical columns followed by the \(M_{\mathrm{cat}}\) categorical columns, where \(M = M_{\mathrm{num}} + M_{\mathrm{cat}}}\)."
ICLR_2024_oral_49,3,"&\hat{x}_{i}^{num}=\hat{e}_{i}^{num}\cdot\hat{w}_{i}^{num}+\hat{b}_{i}^{num},\\\hat{e}_{i}^{oh}=Softmax(\hat{e}_{i}^{cat}\cdot\hat{W}_{i}^{cat}+\hat{b}_{i}^{cat}),\\&\hat{x}=[\hat{x}_{1}^{num},\cdots,\hat{x}_{M_{num}}^{num},\hat{x}_{1}^{oh},\cdots,\hat{x }_{M_{cat}}^{oh}]","where \(\hat{\mathbf{w}}_{i}^{\mathrm{num}}\in\mathbb{R}^{d\times 1},\hat{b}_{i}^{ \mathrm{num}}\in\mathbb{R}^{1\times 1}\), \(\mathbf{W}_{i}^{\mathrm{cat}}\in\mathbb{R}^{d\times C_{i}},\hat{\mathbf{b}}_{i}^{ \mathrm{cat}}\in\mathbb{R}^{1\times C_{i}}\) are detokenizer's parameters","\hat{x}_{i}^{num}=\hat{e}_{i}^{num}v_{i}^{num}+c_{i}^{num},\quad\hat{z}_{i}^{cat}=\hat{e}_{i}^{cat}V_{i}^{cat}+c_{i}^{cat}","where \(\mathbf{v}_{i}^{\mathrm{num}} \in \mathbb{R}^{d}\), \(c_{i}^{\mathrm{num}} \in \mathbb{R}\), \(\mathbf{V}_{i}^{\mathrm{cat}} \in \mathbb{R}^{d \times C_{i}}\), and \(\mathbf{c}_{i}^{\mathrm{cat}} \in \mathbb{R}^{1 \times C_{i}}\) are learnable parameters of the detokenizer."
ICLR_2024_oral_49,4,"L=\ell_{recon}(x,\hat{x})+\beta\ell_{kl}",,L=-E_{q_{\phi}(z|x)}\left[\log p_{\theta}(x|z)\right]+\beta\cdot D_{KL}\left( q_{\phi}(z|x)\| p(z)\right),The β-VAE loss function \(\mathcal{L}\) balances the reconstruction loss (negative log-likelihood) and the KL divergence with weight \(\beta\).
ICLR_2024_oral_49,5,"z_{t}=z_{0}+\sigma(t)\varepsilon,\\varepsilon\simN(0,I), (Forward Process) || dz_{t}=-2\hat{\sigma}(t)\sigma(t)\nabla_{z_{t}}\log p(z_{t})dt+\sqrt{2\hat{\sigma}(t)\sigma(t)}d\omega_{t}, (Reverse Process)",,\beta=\lambda\beta,"The adaptive update rule for the weight coefficient \(\beta\) in the VAE loss, where \(\lambda < 1\) is a decay factor applied when reconstruction loss stagnates."
ICLR_2024_oral_49,6,"L=E_{z_{0}\sim p(z_{0})}E_{t\sim p (t)}E_{\varepsilon\simN(0,I)}\|\varepsilon_{\theta}(z_{t},t)-\varepsilon)\|_{2}^{2},\\where\z_{t}=z_{0}+\sigma(t)\varepsilon",where \(\mathbf{\epsilon}_{\theta}\) is a neural network (named denoising function) to approximate the Gaussian noise using the perturbed data \(\mathbf{x}_{t}\) and the time \(t\),"\ell_{DSM}=E_{z_0, t,\varepsilon}\left[\|\varepsilon_{\theta}(z_t, t)-\varepsilon\|^2\right]","The denoising score matching loss \(\ell_{\mathrm{DSM}}\) is defined as the expectation of the squared error between the noise prediction model \(\mathbf{\varepsilon}_{\theta}(\mathbf{z}_t, t)\) and the true noise \(\mathbf{\varepsilon}\)."
ICLR_2024_oral_52,1,"p(x(t)\midx(0))=N(x(t);x(0),\sigma^{2}(t)I)\",,"p_\sigma(\tilde{x}\midx)=N(\tilde{x};x,\sigma^2I)",The Gaussian perturbation kernel defining the conditional distribution of perturbed data $\mathbf{\tilde{x}}$ given original data $\mathbf{x}$ with noise level $\sigma$.
ICLR_2024_oral_52,2,"dx(t)=-\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt\",,\frac{dx}{dt}=-\dot{\sigma}(t)\sigma(t)\nabla_{x}\log p(x;\sigma(t)),"This equation describes the probability flow ODE for the forward evolution of a data point \(\mathbf{x}(t)\) in time, where \(\dot{\sigma}(t)\) is the derivative of the noise schedule \(\sigma(t)\) and \(\nabla_{\mathbf{x}} \log p(\mathbf{x}; \sigma(t))\) is the score function."
ICLR_2024_oral_52,3,"dx(t)=\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt\",,"dx(t)=\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt\","This equation represents the backward ordinary differential equation for the denoising process, obtained by inverting the forward probability flow ODE in time."
ICLR_2024_oral_52,4,"E_{t\simU([0,T])}E_{x(0)\sim p(x (0))}E_{x(t)\sim p(x(t)|x(0))}\|S^{\theta}(x(t),\sigma(t))-\nabla_{x(t)}\log p (x(t)\midx(0))\|_{2}^{2}",,"L(\theta)=E_{t,x(0),x(t)\midx(0)}\left[\lambda(t)\left\| S^{\theta}(x(t),\sigma(t))-\frac{x(0)-x(t)}{\sigma^{2}(t)}\right\|^{2}_{2}\right]",The loss function \(\mathcal{L}(\theta)\) minimizes the expected squared error between the network's predicted score and the true score of the noisy data given the clean data.
ICLR_2024_oral_52,5,"E_{t\simU([0,T])}E_{x(0)\sim p(x (0))}E_{x\simN(0,\sigma^{2}(t)I )}\|D^{\theta}(x(0)+\epsilon,\sigma(t))-x(0)\|_ {2}^{2}\","where we define \(S^{\theta}(\mathbf{x}(t),\sigma(t))=:(D^{\theta}(\mathbf{x}(t),\sigma(t))- \mathbf{x}(t))/\sigma^{2}(t)\)","E_{t\simU([0,T])}E_{x(0)\sim p(x(0))}E_{x(t)\sim p(x(t)|x(0))}\left\|S^{\theta}(x(t),\sigma(t))-\frac{x(0)-x(t)}{\sigma(t)^2}\right\|_{2}^{2}",The simplified score-matching loss after substituting the conditional score with the expression derived from the Gaussian perturbation kernel.
ICLR_2024_oral_52,6,"\nabla_{x(t)}\log p(x(t))=\nabla_{(x_{1}(t),\ldots,x_{N}(t))}\log p(x_{1}(t),\ldots,x_{N}(t))\",,"S^{\theta}(x(t),\sigma(t))=\frac{ D^{\theta}(x(t),\sigma(t))-x(t) }{\sigma^2(t) }",The score function approximation \( S^{\theta} \) for the joint state of all sources is defined using the denoising network \( D^{\theta} \).
ICLR_2024_oral_52,7,"S^{\theta}(x(t),\sigma(t)):R^{N\times D}\timesR arrowR^{N\times D}\","where \(\mathbf{x}(t)=(\mathbf{x}_{1}(t),\ldots,\mathbf{x}_{N}(t))\) denotes the sources perturbed with the Gaussian kernel in Eq","S^{\theta}(x(t),\sigma(t))",The neural network approximating the joint score function for all sources at noise level \(\sigma(t)\).
ICLR_2024_oral_52,8,\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t)),,"\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t))=S^{\theta}(x(t),\sigma(t))_{\overline{I}}",The conditional score for the generated sources is the subset of the approximated joint score function corresponding to the indices \(\overline{\mathcal{I}}\).
ICLR_2024_oral_52,9,"\nabla_{x_{\overline{I}}(t)}\log p([x_{\overline{I}}(t),\hat{x}_{I}(t)])\","where \(\hat{\mathbf{x}}_{\mathcal{I}}\) is a sample from the forward process: \(\hat{\mathbf{x}}_{\mathcal{I}}(t)\sim\mathcal{N}(\mathbf{x}_{\mathcal{I}}(t) ;\mathbf{x}_{\mathcal{I}}(0),\sigma(t)^{2}\mathbf{I})\)","\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t))=\left[ S^{\theta}(x(t),\sigma(t))\right]_{\overline{I}}",The conditional score for the unknown sources given the fixed sources is approximated by the unconditional score function restricted to the unknown sources.
ICLR_2024_oral_52,10,"\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t))\approx S_{\overline{I}}^{\theta}([x_{\overline{I}}(t),\hat{x }_{I}(t)],\sigma(t))\",where \(S_{\overline{\mathcal{I}}}^{\theta}\) denotes the entries of the score network corresponding to the sources indexed by \(\overline{\mathcal{I}}\),"S^{\theta}([x_{\overline{I}}(t),\hat{x}_{I}(t)],\sigma(t))_{\overline{I}}",The approximation of the conditional score function for the generated sources is given by the subset of the network output corresponding to indices \(\overline{\mathcal{I}}\) when evaluated on the concatenated sources and noise level.
ICLR_2024_oral_52,11,\nabla_{x(t)}\log p(x(t)\midy(0))\,,\nabla_{x(t)}\log p(x(t)\midy(0)),The score function of the posterior distribution of the noisy sources \(\mathbf{x}(t)\) given the clean mixture \(\mathbf{y}(0)\).
ICLR_2024_oral_52,12,"p(y(t)\midx(t))=N(y(t)\mid\sum_{n=1}^{N}x_{n}(t),\gamma^{2}(t)I)",,"p(y(0)\midx(t))=N(y(0);y(t), N\sigma(t)^2I)","Gaussian likelihood function for the clean mixture \(\mathbf{y}(0)\) given the noisy sources \(\mathbf{x}(t)\), with mean \(\mathbf{y}(t)\) and covariance \(N \sigma(t)^2 \mathbf{I}\)."
ICLR_2024_oral_52,13,p(y(t)\midx(t))=1_{y(t)=\sum_{n=1}^{N}x_{ n}(t)}\,,"\nabla_{x_n(t)}\log p(x(t)\midy(t))\approx\nabla_{x_n(t)}\log p(x(t))+\frac{1}{\gamma(t)^2}\left(y(t)-\sum_{k=1}^{N}x_{k}(t)\right),\quad n=1,\ldots,N",Approximated posterior score for the $n$-th source at time $t$ as the gradient of the log-prior with respect to $\mathbf{x}_n(t)$ plus a data consistency term scaled by the inverse squared hyperparameter $\gamma(t)$.
ICLR_2024_oral_52,14,"\nabla_{x_{m}(t)}\log p(x(t)\midy(0))\approx S_{m}^{\theta}((x_{1}(t),\dots,x_{N-1}(t),y(0)-\sum_{n=1}^{N-1}x_{n}(t)),\sigma(t)) || -S_{N}^{\theta}((x_{1}(t),\dots,x_{N-1}(t),y(0)-\sum_{n=1}^{N-1}x_{n}(t)),\sigma(t))\",,"s_n(t)=\nabla_{x_n(t)}\log p_t(x_n(t))-\nabla_{x_N(t)}\log p_t(x_N(t))\Bigg|_{x_N(t)=y(0)-\sum_{j=1}^{N-1}x_j(t)}\quadfor\quad n=1,\dots,N-1","The MSDM Dirac score function for the \(n\)-th source at time \(t\), combining its prior score and the negative prior score of the residual source \(N\) evaluated under the mixture constraint."
ICLR_2024_oral_53,1,L=L_{clip}+\lambdaL_{video},where video-paragraph contrastive loss \(\mathcal{L}_{\text{video}}\) explores the temporal correlations between the long video \(\mathbf{V}_{i}\) and its corresponding paragraph \(\mathbf{T}_{i}\) through a novel noise robust temporal optimal transport distance,"L_{VTC}=-\frac{1}{|P|}\sum_{(a,b)\inP}\log\frac{\exp(s(v_a,t_b)/\tau)}{\sum_{k\inN_a}\exp(s(v_a,t_k)/\tau)}","The video-text contrastive loss where \( \mathcal{P} \) is the set of aligned clip-caption pairs, \( s \) denotes cosine similarity, \( \tau \) is a temperature hyperparameter, and \( \mathcal{N}_a \) represents negative captions for clip \( \mathbf{v}_a \)."
ICLR_2024_oral_53,2,"\max_{Q\inQ}&\langleQ,\S\rangle+\varepsilon H(Q)\\s.t.&Q=\{Q\inR _{+}^{n\times m}\midQ1_{m}=\mu,Q^{\top}1_{n}=\nu\}","where \(\mathbf{1}_{m}\) represents the vector of ones in dimension \(m\), \(\boldsymbol{\mu}\in\mathbb{R}^{n}\) and \(\boldsymbol{\nu}\in\mathbb{R}^{m}\) indicate the relative importance of each clip or caption","\max_{Q\geq0}\langleQ,S\rangle+\epsilon H(Q)\quads.t.\quadQ1_m=\frac{1}{n}1_n,Q^{\top}1_n=\frac{1}{m}1_m","The robust optimal transport objective maximizes the global clip-caption alignment similarity with an entropic regularization term, subject to uniform marginal constraints."
ICLR_2024_oral_53,3,"Q^{*}&=Diag(\kappa_{1})\exp(S/\varepsilon)Diag(\kappa_{2}),\\with iteratively updated \kappa_{1}& arrow\mu./(\exp(S/\varepsilon)\kappa_{2}),\\kappa_{2}arrow\nu_{.}/(\exp(S^{\top}/\varepsilon)\kappa_{1})","where \(\boldsymbol{\kappa}_{1}\in\mathbb{R}^{n}\), \(\boldsymbol{\kappa}_{2}\in\mathbb{R}^{m}\) are the non-negative left and right scaling vectors",Q^*=diag(u)\exp\left(\frac{S}{\varepsilon}\right)diag(v),"The optimal transport assignment matrix \(\mathbf{Q}^*\) solved via Sinkhorn iterations, where \(\mathbf{u}\) and \(\mathbf{v}\) are scaling vectors satisfying the marginal constraints \(\mathbf{Q}^* \mathbf{1}_m = \boldsymbol{\mu}\) and \((\mathbf{Q}^*)^\top \mathbf{1}_n = \boldsymbol{\nu}\)."
ICLR_2024_oral_53,4,"L_{video}=-\sum_{i=1}^{N}(\log\frac{\exp((Q_{ii},\S_{ii})/\tau)}{\sum_{j=1}^{N}\exp((Q_{ ij},\S_{ij})/\tau)}+\log\frac{\exp((Q_{ii},\S_{ii})/\tau)}{\sum_{j=1}^{N}\exp((Q_{ ji},\S_{ji})/\tau)})","where \(\mathbf{S}_{ij}\in\mathbb{R}^{n\times m}\) is the clip-caption similarity matrix between video \(\mathbf{V}_{i}\) and paragraph \(\mathbf{T}_{j}\), \(\mathbf{Q}_{ij}\) is the corresponding transport assignment of \(\mathbf{S}_{ij}\), and \(\tau\) is a learnable temperature initialized as 0","L_{video}=-\frac{1}{B}\sum_{i=1}^{B}\log\frac{\exp\left(OT_{\varepsilon}(V_i,T_i)/\tau\right)}{\sum_{j=1}^{B}\exp\left(OT_{\varepsilon}(V_i,T_j)/\tau\right)}",\(\mathcal{L}_{\text{video}}\) is the contrastive loss that measures alignment between videos and paragraphs using entropy-regularized optimal transport similarity within a batch.
ICLR_2024_oral_53,5,"[S]_{a,b}=\frac{1}{2}(\frac{1}{f}\sum_{i=1}^{f}\alpha\log(\sum_{j=1}^{w}\exp(\frac{v_{a}^{i}\cdott_{b}^{j}}{\alpha}) )+\frac{1}{w}\sum_{i=1}^{w}\alpha\log(\sum_{j=1}^{f}\exp(\frac{t_{b}^{i}\cdotv_{a}^{j}}{\alpha})))",,"S_{a,b}=\log\left(\sum_{j=1}^{f}\sum_{k=1}^{w}\exp\left(\frac{v_a^j\cdott_b^k }{\tau_f }\right)\right)",The fine-grained similarity between clip \(\mathbf{v}_{a}\) and caption \(\mathbf{t}_{b}\) is computed by applying the log-sum-exp operator to the frame-word similarity matrix.
ICLR_2024_oral_53,6,"[\bar{S}]_{a,m+1}=[\bar{S}]_{n+1,b}=[\bar{S}]_{n+1, m+1}=p,\,[\bar{S}]_{a,b}=[S]_{a,b},\\forall a\in[1,n],\b\in[1,m]",,\tilde{S}=S & p1_{n}\\p1_{m}^{\top} & p,"the extended clip-caption similarity matrix with an alignable prompt bucket, where \( p \) is a learnable bucket parameter"
ICLR_2024_oral_53,7,"\max_{\hat{Q}\in\hat{Q}}\\\\langle\hat{Q},\\hat{S}\rangle+\varepsilon H(\hat{Q})\\\\s.t.\\\\hat{Q}=\{\hat{Q}\inR^{B\times B}_{+}\mid\hat{Q}1_{B}=\frac{1}{B}1_{B},\hat{Q}^{\top}1_{B}=\frac{1}{B}1_{B}\}",where the transport assignment \(\hat{\mathbf{Q}}\) attempts to realign the clips with similar captions (_i,"\max_{Q\inQ}&\langleQ,\\hat{S}\rangle+\varepsilon H(Q)\\s.t.&Q=\{Q\inR_{+}^{B\times B}\midQ1_{B}=\mu,Q^{\top}1_{B}=\nu\}","where \(\hat{\mathbf{S}}\in\mathbb{R}^{B\times B}\) is the within-batch clip-caption similarity matrix, \(\mathbf{Q}\) is the transport assignment, \(\boldsymbol{\mu}\in\mathbb{R}^{B}\) and \(\boldsymbol{\nu}\in\mathbb{R}^{B}\) are the marginals, and \(\varepsilon\) controls the entropy regularization."
ICLR_2024_oral_53,8,"L_{clip}=-\sum\limits_{i=1}^{B}\sum\limits_{j=1}^{B}[ T]_{i,j}(\log\frac{\exp([\hat{S}]_{i,j}/\tau)}{\sum_{k=1}^{B}\exp([\hat{S}]_{i,k}/\tau)}+\log\frac{\exp([\hat{S}]_{i,j}/\tau)}{\sum_{k=1}^{B}\exp([\hat{S}]_{i,j}/\tau)}),T=(1-\beta )\,I_{B}+\beta\hat{Q}^{*}",where \(\beta\) is a weighted parameter that balances the identity target \(\mathbf{I}_{B}\) and realigned targets \(\hat{\mathbf{Q}}^{*}\),L_{clip}=-\frac{1}{2}\left(\sum_{i=1}^{B}\sum_{j=1}^{B}\hat{Q}_{ij}^{*}\log\frac{\exp(\hat{S}_{ij}/\tau)}{\sum_{k=1}^{B}\exp(\hat{S}_{ik}/\tau)}+\sum_{j=1}^{B}\sum_{i=1}^{B}\hat{Q}_{ij}^{*}\log\frac{\exp(\hat{S}_{ij}/\tau)}{\sum_{k=1}^{B}\exp(\hat{S}_{kj}/\tau)}\right),The clip-caption contrastive loss \(\mathcal{L}_{\text{clip}}\) uses the optimal transport assignment \(\hat{\mathbf{Q}}^{*}\) as soft targets to incorporate faulty negatives in both clip-to-caption and caption-to-clip contrastive learning.
ICLR_2024_oral_54,1,"\min_{S\inR^{N\times d}}D(\nabla_{\theta}\ell(S;\theta),\nabla_{\theta}\ell(B;\theta))=D( S,B;\theta)","where the function \(D(\cdot)\) is defined as a distance metric such as MSE, \(\theta\) represents the model parameters, and \(\nabla_{\theta}\ell(\cdot)\) denotes the gradient, utilizing either the big dataset \(\mathcal{B}\) or its synthetic version \(\mathcal{S}\)","\min_{S}\sum_{t=0}^{T-1}\left\|\nabla_{\theta}L(\theta_t,B)-\nabla_{\theta}L(\theta_t,S)\right\|^2",Objective function minimizing the gradient distance between the big dataset \(\mathcal{B}\) and synthetic dataset \(\mathcal{S}\) over T training steps.
ICLR_2024_oral_54,2,"SarrowS-\lambda\nabla_{S}D( S,B;\theta),\quad\thetaarrow\theta-\eta\nabla_{\theta}\ell(\theta;S)","where \(\lambda\) and \(\eta\) are learning rates designated for \(\mathcal{S}\) and \(\theta\), respectively","S^{(t+1)}=S^{(t)}-\eta\nabla_{S^{(t)}} D(S^{(t)},B;\theta^{(t)})",update of the synthetic dataset \(\mathcal{S}\) at optimization step \(t\) using gradient descent with learning rate \(\eta\)
ICLR_2024_oral_54,3,"\min_{S\inR^{N\times d}}D(\nabla_{\theta }\ell(S_{[1]},S_{[2]},\ldotsS_{[N]};\theta ),\nabla_{\theta}\ell(B;\theta))","where \(\mathcal{S}_{[n]}=\mathcal{S}_{\{1,2,\ldots,n\}}\subset\mathcal{S}=\mathcal{S}_ {[N]}\) represents \(n_{th}\) subset of the synthetic dataset \(\mathcal{S}\in\mathbb{R}^{N\times d}\)","\min_{S}\sum_{k\inK}D(S_{1:k},B;\theta)","The new objective minimizes the sum of the gradient distance between the original dataset $\mathcal{B}$ and the subset $\mathcal{S}_{1:k}$ for every desired size $k$ in $\mathcal{K}$, where $\mathcal{S}_{1:k}$ denotes the first $k$ images of $\mathcal{S}$."
ICLR_2024_oral_54,4,"SarrowS-\lambda(\nabla_{S}D(S,B;\theta)+\nabla_{S_{[n]}}D(S_{[n]},B;\theta)),\hskip 14.226378ptn\in[1,N-1]","where \(\mathcal{S}=\mathcal{S}_{[N]}\) represents the condensed dataset of \(N\) images and is associated with the ""base loss""","S\leftarrowS-\lambda\nabla_{S}\left[\sum_{n=1}^{N} D\left(\nabla_{\theta}\ell(S_{[n]};\theta),\nabla_{\theta}\ell(B;\theta)\right)\right],\quad\theta\leftarrow\theta-\eta\nabla_{\theta}\ell(\theta;S)","where \(\lambda\) and \(\eta\) are learning rates for \(\mathcal{S}\) and \(\theta\) respectively, and the update for \(\mathcal{S}\) incorporates the gradient of the total loss summing gradient distances for all subsets \(\mathcal{S}_{[n]}\) from size 1 to \(N\)."
ICLR_2024_oral_54,5,"F_{t}(S_{[n]},B)=D(f_{t}(S _{[n]}),f_{t}(B))","where \(f_{t}(\cdot)\) is the feature extraction function for \(t_{th}\) condensation iteration, and \(D(\cdot)\) is a distance metric like MSE","D\left(\frac{1}{n}\sum_{i=1}^{n}\phi(s_i;\theta_t),\frac{1}{M}\sum_{j=1}^{M}\phi(b_j;\theta_t)\right)","The feature distance at condensation iteration \(t\) for subset \(\mathcal{S}_{[n]}\) is defined as the distance \(D\) between the average feature vector of \(\mathcal{S}_{[n]}\) and the average feature vector of \(\mathcal{B}\), both computed using model parameters \(\theta_t\) at iteration \(t\)."
ICLR_2024_oral_54,6,"F_{t}(S_{[p]},B)>F_{t}(S_{[q]},B),\;\;if\;\;\;1<p<q<N",,"F_t(S_{[p]},B)\quadand\quad F_t(S_{[q]},B)\quadfor\quad 1 < p < q < N",The feature distances at condensation iteration \(t\) for two subsets \(\mathcal{S}_{[p]}\) and \(\mathcal{S}_{[q]}\) where \(1 < p < q < N\) so that the size of \(\mathcal{S}_{[p]}\) is less than the size of \(\mathcal{S}_{[q]}\).
ICLR_2024_oral_54,7,"\underbrace{F_{t-\Delta t}(S_{[p]},B)>F_{t} (S_{[p]},B)}_{p},\;\;\underbrace{F_{t-\Delta t }(S_{[q]},B)>F_{t}(S_{[q]},B)}_{q}",where \(t-\Delta t\) and \(t\) are two different time points for the condensation process,"n_t^*=\arg\max_{n\in [1, N-1]} F_t(S_{[n]},B)",\(n_t^*\) is the index of the Most Learnable Subset (MLS) at iteration \(t\) that maximizes the feature distance to the big dataset \(\mathcal{B}\).
ICLR_2024_oral_54,8,"R(S_{[n]},t)=\frac{\Delta F_{S_{[n]}}}{\Delta t}=\frac{ |F_{t}(S_{[n]},B)-F_{t-\Delta t}(S_{[n]},B)|}{\Delta t}","where \(R(\mathcal{S}_{[n]},t)\) represents the rate of change of feature distance for subset \(\mathcal{S}_{[n]}\) at the time point \(t\), and \(\Delta F_{\mathcal{S}_{[n]}}\) denotes the change in feature distance of subset \(\mathcal{S}_{[n]}\) from time \(t-\Delta t\) to \(t\)","r_t(S_{[n]})=\frac{ F_{t-\Delta t}(S_{[n]},B)-F_t(S_{[n]},B) }{\Delta t }",where \(r_t(\mathcal{S}_{[n]})\) is the feature distance reduction rate for subset \(\mathcal{S}_{[n]}\) over time interval \(\Delta t\).
ICLR_2024_oral_54,9,"S_{MLS}(t)=S_{[n_{t}^{*}]}=\operatorname*{arg\, max}_{S_{[n]}}(R(S_{[n]},t))\;\; where\;\;n\in[1,N-1]",,"MLS_t=S_{[n^{*}]}\quadwhere\quad n^{*}=\arg\max_{n\in [1, N-1]} R(S_{[n]}, t)","The Most Learnable Subset (MLS) at condensation iteration \(t\) is the subset \(\mathcal{S}_{[n^{*}]}\) where \(n^{*}\) is the index that maximizes the feature distance reduction rate \(R(\mathcal{S}_{[n]}, t)\)."
ICLR_2024_oral_54,10,{l}Using Eq.~{\ref{eq:mLS} to~{}}Update&S\\Update&S\setminusS_{MLS}(t-\Delta t)if\;S_{MLS}(t)\supsetS_{MLS}(t-\Delta t),where \(\setminus\) is the symbol for set minus,"S\leftarrowS-\lambda\left(\nabla_{S} D(S,B;\theta)+I_{\{n_t^*\neq n_{t-\Delta t}^*\}}\nabla_{S_{[n_t^*]}} D(S_{[n_t^*]},B;\theta)\right)",The update rule for \(\mathcal{S}\) conditionally incorporates the gradient of the subset loss for the current most learnable subset (MLS) based on a change in its size from the previous MLS.
ICLR_2024_oral_55,1,"\operatorname*{arg\,max}_{\theta}\prod_{\bar{D}}p(Y_{Q}|f_ {\theta}(S,X_{Q}))",,"\min_{\theta}\sum_{(x,y)\inS}L(f_{\theta}(x), y)",Objective function minimizing the total loss over the support set.
ICLR_2024_oral_55,2,"\operatorname*{arg\,max}_{\alpha,\phi}\prod_{\bar{D}_{test}} p(Y_{Q}|f_{\alpha,\phi}(S,X_{Q}))",,"\operatorname*{arg\,max}_{\phi,\alpha} p(Y_{Q}|f_{\theta,\alpha}(S,X_{Q}))","Equation 2 maximizes the probability of the query labels by optimizing the fine-tuned parameters $\phi \subset \theta$ and adapter parameters $\alpha$ for the target task using the base parameters $\theta$, support set, and query inputs."
ICLR_2024_oral_55,3,"g_{\phi,\phi^{\prime},\alpha}(x)=g_{\phi,\phi^{\prime}}(x)+h_{\alpha}(x)","where \(x\in\mathbb{R}^{W,H,C}\)",z=g_{\phi}(x)+h_{\alpha}(x),The output of the adapted layer is the sum of the main branch transformation \(g_{\phi}(x)\) and the residual adapter module \(h_{\alpha}(x)\).
ICLR_2024_oral_55,4,"g_{\phi,\phi^{\prime},\alpha}(x)=z(A_{qkv}[q\;;\;g_{\phi,\phi^{\prime}}(x)]+h _{\alpha 1})+h_{\alpha 2}",where \(x\in\mathbb{R}^{D}\) and \([\cdot\;;\;\cdot]\) denotes the concatenation operation,"adapted  A_{qkv}(x)=Attention\left(Q=x, K=concat(P_k, x), V=concat(P_v, x)\right)+h_{\alpha_1}(x)",The adapted self-attention module prepends a learnable prefix to the key and value vectors and adds a residual adapter to the output.
ICLR_2024_oral_55,5,"L(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\log\frac{e^{-d_{cos}(C_{Q_{i}},f(Q_{i}))}}{\sum_{j=1}^{|C|}e^{-d_{cos}(C_{j},f(Q_{cj}))}}","where \(C_{\mathcal{Q}_{i}}\) denotes the embedding of the class centroid that corresponds to the true class of \(\mathcal{Q}_{i}\), and \(d_{cos}\) denotes the cosine distance","L(f,S,Q)=\frac{1}{|Q|}\sum_{(x,y)\inQ}-\log\frac{\exp\left(-\|f(x)-v_y\|^2\right)}{\sum_{c\inC}\exp\left(-\|f(x)-v_c\|^2\right)}","The prototypical loss function, which measures the average negative log-probability of the true class for the query set by comparing embeddings to class prototypes derived from the support set."
ICLR_2024_oral_55,6,"\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}\E_{p\sim P}E_{S,Q}\L(f^{p}_{\theta,\alpha,\phi^{\prime}},S,Q)",,"\operatorname*{arg\,min}_{\alpha,\phi'}E_{\bar{D}}E_{p\sim P}\left[L(f^{p}_{\theta,\alpha,\phi'},S,Q)\right]",The objective for supernet training minimizes the expected prototypical loss over tasks and sampled paths.
ICLR_2024_oral_55,7,"p_{k}=\operatorname*{arg\,max}_{p\in P}E_{S,Q}A(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}},S,Q),\quads.t || \alpha^{*},\phi^{\prime*}=\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}L(f^{p} _{\theta,\alpha,\phi^{\prime}},S,S)",,"\{p_1, p_2,\dots, p_N\}=\operatorname*{argmin}_{P\subseteq P, |P|=N}\sum_{p\inP}E_{(S,Q)}L(f^p_{\theta,\alpha,\phi'},S,Q)",The set of \(N\) paths minimizing the sum of expected losses over meta-training tasks.
ICLR_2024_oral_55,8,"\quad\forall_{j=1,\dots,k-1}\\d_{cos}(p_{k},p_{j})\geq T",,"A(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}1\left(\arg\min_{c\inY} d_{cos}(f(x_i), C_c)=y_i\right)",The accuracy function \(A\) measures the proportion of correctly classified query examples using the nearest class centroid based on cosine distance.
ICLR_2024_oral_55,9,"A(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}[\operatorname*{arg\,min}_{j}d_{cos}(C_{Q_{j}},f(Q_{i}))=Y_ {Q_{i}}]",,"A(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}1\left( y_i=\arg\min_{c} d_{cos}\left(f(x_i), C_c\right)\right)",\(A\) is the classification accuracy of a nearest centroid classifier on the query set \(\mathcal{Q}\) using class centroids computed from the support set \(\mathcal{S}\).
ICLR_2024_oral_55,10,"p^{*}=\operatorname*{arg\,min}_{p\in\{p_{1},...,p_{N}\}}L(f^{p}_{O_{\alpha^{*}},\phi^{\prime\prime*}},S,S),\quads.t || \alpha^{*},\phi^{\prime*}=\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}L(f^{p}_{O,\alpha,\phi^{\prime}},S,S)",,"p^{*}=argmax_{p\in\{p_1,\dots, p_N\}} A(f^{p}_{\theta,\alpha^{*},\phi^{\prime*}},S,S)",The final path \( p^{*} \) is selected by maximizing the accuracy on the support set \( \mathcal{S} \) after fine-tuning parameters \( \alpha^{*} \) and \( \phi^{\prime *} \) on \( \mathcal{S} \) for each candidate path.
ICLR_2024_oral_56,1,"\vec{x}_{n}&=A\vec{x} _{n-1}+Bu_{n}&A\inC^{N\times N},B\inC^{N\times 1}\\y_{n}&=C\vec{x}_{n}&C\inC^{1\times N}",,\vec{x}_{n} &=A\vec{x}_{n-1}+B u_n\\y_n &=C\vec{x}_{n},"The state-space model equations define the state update \(\vec{\mathbf{x}}_n = \mathbf{A} \vec{\mathbf{x}}_{n-1} + \mathbf{B} u_n\) and output computation \(y_n = \mathbf{C} \vec{\mathbf{x}}_{n}\) for scalar input \(u_n\), state vector \(\vec{\mathbf{x}}_n\), and scalar output \(y_n\) at step \(n\)."
ICLR_2024_oral_56,2,A=A-PQ^{\star} || \bar{A}=(I-\Delta/2\cdotA)^{-1}(I+\Delta/2\cdotA),,\overline{A} &=\exp(\DeltaA)\\\overline{B} &=A^{-1} (\exp(\DeltaA)-I)B,The discretized state matrix \(\overline{\mathbf{A}}\) and input matrix \(\overline{\mathbf{B}}\) obtained from continuous-time parameters \(\mathbf{A}\) and \(\mathbf{B}\) using zero-order hold with step size \(\Delta\).
ICLR_2024_oral_56,3,\bar{B}=(I-\Delta/2\cdotA)^{-1}\DeltaB\quad\bar{C}=C,,\bar{B}=\Delta (I-\Delta/2\cdotA)^{-1}B,The discretized input matrix obtained through bilinear transformation.
ICLR_2024_oral_56,4,K_{k}=\bar{C}^{T}\bar{A}^{k}\bar{B},"where \(\mathbf{A},\mathbf{P},\mathbf{Q},\mathbf{B},\mathbf{C},\Delta\) are learnable parameters and \(\mathbf{A}\in\text{{Diag}}(\mathbb{C}^{N\times N}),\mathbf{P},\mathbf{Q}\in\mathbb{C}^{N \times 1}\)",\vec{x}_{n} &=\bar{A}\vec{x}_{n-1}+\bar{B} u_{n}\\y_{n} &=\bar{C}\vec{x}_{n},The discretized state space model recurrence with transformed parameters.
ICLR_2024_oral_56,5,"\vec{x}_{n}&=A\vec{x} _{n-1}+I\,u_{n}&A\in{diag}(C^{N\times N })\\y_{n}&=C\vec{x}_{n}&C\inC^{1\times N}",where \(\mathbf{I}\) is the all-ones vector,"\vec{x}_{n} &=A\vec{x}_{n-1}+B u_{n}\quadA\inDiag(C^{N\times N}),B\inC^{N\times 1}\\y_{n} &=C\vec{x}_{n}\quadC\inC^{1\times N}","The diagonal linear RNN (DLR) computes the next state \(\vec{\mathbf{x}}_{n}\) from the previous state \(\vec{\mathbf{x}}_{n-1}\) and input \(u_n\) using a diagonal transition matrix \(\mathbf{A}\) and input vector \(\mathbf{B}\), and the output \(y_n\) from the state via output vector \(\mathbf{C}\)."
ICLR_2024_oral_58,1,"\mu_{m,k}\triangleqE_{(x,y)\simG}[\upsilon_{m,k}(x) ],\\sigma_{m,k}^{2}\triangleqE_{(x,y)\simG}[(\upsilon_{m,k}(x)-\mu_{m,k})^{2}]",,"\mu_{m,k}=\frac{1}{N}\sum_{i=1}^{N}\phi_{m,k}^{(i)},\quad\sigma_{m,k}^2=\frac{1}{N}\sum_{i=1}^{N}\left(\phi_{m,k}^{(i)}-\mu_{m,k}\right)^2","The mean \(\mu_{m,k}\) and variance \(\sigma_{m,k}^2\) of the \(k^{\text{th}}\) feature for model \(m\), computed over \(N\) data points where \(\phi_{m,k}^{(i)}\) is the feature activation for the \(i^{\text{th}}\) data point."
ICLR_2024_oral_58,2,"\rho_{(i,j),(a,b)}\triangleqE_{(x,y)\simG}[(\upsilon_{i,a}(x)-\mu_{i,a})(\upsilon_{j,b}(x)-\mu_{j,b}) ](\sigma_{i,a}\\sigma_{j,b})^{-1}",,"\rho_{i,j}^{a,b}=\frac{E_{(x,y)\simG}\left[(\upsilon_{i,a}(x)-\mu_{i,a})(\upsilon_{j,b}(x)-\mu_{j,b})\right]}{\sigma_{i,a}\sigma_{j,b}}",The correlation between the \(a^{\text{th}}\) feature of model \(f_i\) and the \(b^{\text{th}}\) feature of model \(f_j\).
ICLR_2024_oral_58,3,Acc=p_{d}(1-\frac{1}{2}\binom{t_{d}-c_{d}}{a_{d}}\\\binom{t_{d}}{a_{d}}^{+}p_{r}(1-\frac{1}{2}\binom{t_{r}-c_{r}}{c_{r}}\\\binom{t_{r}}{c_{r}}),,Acc=1-\frac{1}{2}\left( p_d\frac{\binom{t_d-n_d}{c_d}}{\binom{t_d}{c_d}}+p_r\frac{\binom{t_r-n_r}{c_r}}{\binom{t_r}{c_r}}\right),"\(\mathrm{Acc}\) is the expected accuracy, \(p_d\) and \(p_r\) are the proportions of dominant and rare data, \(t_d\) and \(t_r\) are the total numbers of dominant and rare features for one class, \(n_d\) and \(n_r\) are the numbers of features in a dominant and rare data point, and \(c_d\) and \(c_r\) are the numbers of dominant and rare features a model learns for one class."
ICLR_2024_oral_59,1,\Pr[A(D)\in R]\leq e^{\epsilon}\Pr[A(D^{\prime})\in R]+\delta,,\Pr[A(D)\in R]\leq e^{\epsilon}\Pr[A(D')\in R]+\delta,"The probability that algorithm $A$ outputs a result in region $R$ on dataset $D$ is bounded by $e^{\epsilon}$ times the probability on adjacent dataset $D'$ plus $\delta$, ensuring user-level differential privacy."
ICLR_2024_oral_59,2,"\hat{\epsilon}=\max\{\log\frac{1-\delta-FPR}{FNR},\log\frac{1-\delta-FNR}{FPR}\}",,FPR+e^{\epsilon}\cdotFNR\geq 1-\delta,"The condition that must hold for any acceptance region in the hypothesis testing interpretation of $(\epsilon,\delta)$-differential privacy, relating false positive rate (FPR) and false negative rate (FNR)."
ICLR_2024_oral_59,3,f_{d}(t)=\frac{\Gamma(\frac{d}{2})}{\Gamma(\frac{d-1}{2})\sqrt{\pi}}(1-t^{2})^{\frac{d-3}{2}},,"f(\tau_d)=\frac{\Gamma\left(\frac{d}{2}\right)}{\sqrt{\pi}\Gamma\left(\frac{d-1}{2}\right)} (1-\tau_d^2)^{\frac{d-3}{2}},\quad\tau_d\in [-1,1]",The probability density function of the cosine similarity \(\tau_d\) between a random vector \(c\) sampled uniformly from the unit sphere \(\mathbb{S}^{d-1}\) and an arbitrary independent nonzero vector \(v\).
ICLR_2024_oral_6,1,"\epsilon_{k}(x)\mathop{=}^{def}u_{k}(\texttt{BR}_{k},x_{-k})-u_{k}(x) where \texttt{BR}_{k}\in\operatorname*{arg\,max}_{z}u_{k}(z,x_{-k})",,"\eta(\sigma)=\sum_{i\in N}\left(\max_{\sigma'_i} u_i(\sigma'_i,\sigma_{-i})-u_i(\sigma_i,\sigma_{-i})\right)",The total exploitability $\eta(\sigma)$ measures the sum over all players of the difference between their maximum achievable utility under unilateral deviation and their current utility under joint strategy $\sigma$.
ICLR_2024_oral_6,2,L(x)=\sum_{k}\eta_{k} || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || ^{2},"where each \(\eta_{k}>0\) represents a scalar weight, or equivalently, a step size to be explained next",L(x)\mathop{=}^{def}\sum_{k}\left\|\Pi_{T\Delta}\left(\nabla_{x_k} u_k(x)\right)\right\|^2,The loss function defined as the sum over players of the squared norm of the projected gradient of each player's utility with respect to their own strategy.
ICLR_2024_oral_6,3,\epsilon_{k}(x)\leq\sqrt{2} || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || ,,\epsilon_k(x)\leq M_k\left\|\Pi_{T\Delta}\left(\nabla_{x_k} u_k(x)\right)\right\|,"For each player \(k\), the exploitability \(\epsilon_k(\mathbf{x})\) is bounded by a constant \(M_k\) times the norm of the projected gradient of the utility."
ICLR_2024_oral_6,4,\epsilon\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L(x)}\stackrel{{\tiny def}}{{=}}f(L),,\epsilon(x)\leq\sqrt{\frac{2L(x)}{\min_k\eta_k}},The exploitability of the joint strategy \(\mathbf{x}\) is bounded by \(\sqrt{\frac{2 \mathcal{L}(\mathbf{x})}{\min_k \eta_k}}\).
ICLR_2024_oral_6,5,L(x)=E[\sum_{k}\eta_{k}\underbrace{(\hat{\nabla}_{x_{ k}}^{k(1)}-\frac{1}{m_{k}}(1^{\top}\hat{\nabla}_{x_{k}}^{k(1)}))}_{ projected-gradient 1})^{\top}(\underbrace{\hat{\nabla}_{x_{k}}^{k(2)}-\frac{1}{m_{k}}(1^{\top}\hat{\nabla}_{x_{k}}^{k(2)})1)}_{projected-gradient 2}),where \(\hat{\nabla}^{k(p)}_{x_{k}}\) is an unbiased estimator of player \(k\)'s gradient,"\hat{L}(x)=\sum_{k}\eta_{k}\left\langle\Pi_{T\Delta}\left(\nabla_{x_k}^{k(1)}\right),\Pi_{T\Delta}\left(\nabla_{x_k}^{k(2)}\right)\right\rangle",\(\hat{\mathcal{L}}\) is the unbiased estimator of the loss \(\mathcal{L}\) using two independent projected gradient samples per player.
ICLR_2024_oral_6,6,L^{\tau}(x)=\sum_{k}\eta_{k} || \Pi_{T\Delta}(\nabla^{k\tau}_{x_ {k}}) || ^{2},,L^{\tau}(x)=\sum_{k}\eta_{k}\left\|\Pi_{T\Delta}\left(\nabla_{x_{k}}^{k}+\tau\frac{dS}{dx_k}\right)\right\|^{2},"The entropy-regularized loss function for the quantal response equilibrium, where \(\tau\) controls the entropy bonus and \(\frac{dS}{dx_k}\) is the gradient of the Shannon entropy."
ICLR_2024_oral_6,7,\epsilon_{QRE}\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L^{\tau}(x)}\overset{\tiny{def}}{=}f(L^{\tau}),,\epsilon_{QRE}\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L^{\tau}(x)},The entropy-regularized exploitability of a joint strategy \(\mathbf{x}\) is bounded by a function of the entropy-regularized loss.
ICLR_2024_oral_6,8,\epsilon\leq\tau\log\Big{(}\prod_{k}m_{k}\Big{)}+\sqrt{\frac{2n}{\min_{k}\eta_ {k}}}\sqrt{L^{\tau}(x)}\overset{\tiny{def}}{=} f_{\tau}(L^{\tau}),,\epsilon(x)\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L^{\tau}(x)}+\tau\sum_{k} S(x_{k}),The exploitability of a joint strategy \(\mathbf{x}\) in the original game is upper bounded by the sum of a function of the entropy-regularized loss and a term proportional to the temperature times the total entropy of the players' strategies.
ICLR_2024_oral_6,9,\nabla_{x_{l}}L^{\tau}(x)=2\sum_{k}\eta_{k}B_{kl}^{\top}\Pi_{T\Delta}(\nabla_{x_{k}}^{kT}),,\nabla_{x_{l}}L^{\tau}=-2\eta_{l}\tau\frac{\Pi_{T\Delta}(\nabla^{l\tau}_{x_{l}})}{x_{l}}+2\sum_{k\neq l}\eta_{k}\left(\nabla_{x_{l}}\nabla_{x_{k}} u_{k}\right)\Pi_{T\Delta}(\nabla^{k\tau}_{x_{k}}),The gradient of the entropy-regularized loss function \(\mathcal{L}^{\tau}\) with respect to player \(l\)'s strategy \(x_l\).
ICLR_2024_oral_6,10,\textsl{Hess}(L^{\tau})=2\big{[}\tilde{B}^{\top}\tilde{B}+T\Pi_{T\Delta}(\tilde{\nabla}^{\tau})\big{]},,\nabla_{x_{m}}\nabla_{x_{l}}}L^{\tau}(x)=2\sum_{k}\eta_{k}\left(\frac{\partial B_{kl}^{\top}}{\partial x_{m}}\Pi_{T\Delta}(\nabla_{x_{k}}^{k\tau})+B_{kl}^{\top}\frac{\partial}{\partial x_{m}}\Pi_{T\Delta}(\nabla_{x_{k}}^{k\tau})\right),The Hessian of the entropy-regularized loss function.
ICLR_2024_oral_6,11,"M(x)=-\sqrt{\eta_{1}}\Pi_{T\Delta}(\frac{1}{x_{1}})&\sqrt{\eta_{1}}\Pi_{T\Delta}(H^{1}_{12})&\ldots&\sqrt{\eta_{1}}\Pi_{T\Delta}(H^{1}_{ 1n})\\\vdots&\vdots&\vdots&\vdots\\\sqrt{\eta_{n}}\Pi_{T\Delta}(H^{n}_{n1})&\ldots&\sqrt{\eta_{n}}\Pi_{T\Delta}( H^{n}_{n,n-1})&-\tau\sqrt{\eta_{n}}\Pi_{T\Delta}(\frac{1}{x_{n}})\\1_{1}^{\top}&0&\ldots&0\\\vdots&\vdots&\vdots&\vdots\\0&\ldots&0&1_{n}^{\top}",where \(\Pi_{T\Delta}(z\in\mathbb{R}^{n\times b})=[I_{a}-\frac{1}{a}\mathbf{_{1}}\mathbf{_{ 1}}^{\top}]z\) subtracts the mean from each column of \(z\) and \(\frac{1}{x_{k}}\) is shorthand for \(\texttt{diag}\big{(}\frac{1}{x_{k}}\big{)}\),\textsl{Hess}(L^{\tau})=2\big{[}\tilde{B}^{\top}\tilde{B}+T\Pi_{T\Delta}(\tilde{\nabla}^{\tau})\big{]},The Hessian of the entropy-regularized loss function \(\mathcal{L}^{\tau}\) is expressed in terms of \(\tilde{B}\) and the tensor \(T\) acting on the projected gradients.
ICLR_2024_oral_60,1,y_{i}^{\prime}=I_{\tau}(h)(x_{i}),,y_{i}^{\prime}=I_{\tau}(h)(x_i),The predicted output \( y_{i}^{\prime} \) for the \(i\)-th unseen example is generated by applying the interpreter-compiled rule \( I_{\tau}(h) \) to input \( x_i \).
ICLR_2024_oral_60,2,"a_{\tau}=\frac{1}{|D_{\tau}^{u}|}\sum_{(x,y)\inD_{\tau}}\mathbbm{1}\big{[}I_{\tau}(h)(x)=y\big{]}",,"acc_{\tau}(h)=\frac{1}{|D_{\tau}^u|}\sum_{(x, y)\inD_{\tau}^u}1\left( I_{\tau}(h)(x)=y\right)",The accuracy of rule $h$ on task $\tau$ is the average of indicator functions over the unseen examples $\mathcal{D}_{\tau}^u$ that check if the interpreter $I_{\tau}(h)$ applied to input $x$ equals the true output $y$.
ICLR_2024_oral_60,3,c=\frac{1}{|T|}\sum_{\tau\inT}a_{\tau}\hskip 28.452756ptc_{t}=\frac{1}{|T|}\sum_{\tau\inT}\mathbbm{1}\big{[}a_{\tau}=1\big{]},,"c=\frac{\sum_{\tau\inT}\sum_{(x,y)\inD_{\tau}^{u}}\mathbbm{1}\big[I_{\tau}(h)(x)=y\big]}{\sum_{\tau\inT} |D_{\tau}^{u}|},\quad c_t=\frac{1}{|T|}\sum_{\tau\inT} a_{\tau}","Raw accuracy \(c\) is the overall example-level accuracy across all tasks, and task accuracy \(c_t\) is the average of task-specific accuracies \(a_{\tau}\) over the set of tasks \(\mathcal{T}\)."
ICLR_2024_oral_60,4,"h^{t}\sim P_{LM}\big{(}\cdot\,|d^{t-1},x_{1},y_{1},...,x_{k},y_{k})",where \(d^{t-1}\) is the feedback from previous iterations and which is set to be an empty string at the initial iteration,"H^{t}=\{ h_1^t, h_2^t,\dots, h_N^t\}",The set of \( N \) hypotheses generated at iteration \( t \).
ICLR_2024_oral_60,5,"s(h,D_{\tau}^{s})=\frac{1}{|D_{\tau}^{s}|}\sum_{(x,y)\inD_{\tau}^{s}}\mathbbm{1}\big{[}I_{\tau}(h)(x)=y\big{]}",,"s(h,D_{\tau}^{s})=\frac{1}{|D_{\tau}^{s}|}\sum_{(x,y)\inD_{\tau}^{s}}\mathbbm{1}\big[I_{\tau}(h)(x)=y\big]",The scoring function \( s \) is the accuracy of rule \( h \) on the seen examples \( \mathcal{D}_{\tau}^{s} \).
ICLR_2024_oral_60,6,"h^{t^{*}}=\operatorname*{arg\,max}_{h^{\prime}\in H^{t}}s(h^{\prime}, D_{\tau}^{s})",,"h^{t*}=\arg\max_{h\in H^t} s(h,D_{\tau}^{s})",The best hypothesis at iteration \(t\) is selected by maximizing the scoring function over the generated set of hypotheses.
ICLR_2024_oral_61,1,"P(a_{t:t+k}|s_{t},s^{g})=\int_{s_{t+1},\ldots,s_{t+k}}ds_{t+1}\ldots ds_{t+k}\prod_{i=t}^{t+k}P_{\phi}(a_{i}|s_{i},s^{g})P(s_{i+1}|s_{i},a_{i})",where \(s^{g}\in S\) is the goal state,"P_{\phi}(a_t\mid s_t, g)",The goal-conditioned policy $P_{\phi}$ models the probability of action $a_t$ given the current state $s_t$ and goal state $g$.
ICLR_2024_oral_61,2,"L(\phi)=E_{D}[-\log P_{\phi}(a_{i}|s_{i},s^{g})]",,"L=E_{\tau\simD}\left[\sum_{i=t}^{t+k}-\log P_{\phi}(a_i | s_i, s^{g})\right]","the behavior cloning loss for training the goal-conditioned policy \(P_{\phi}\), where \(\tau\) is a subsequence sampled from the dataset \(\mathcal{D}\), and \(s^{g} = s_{t+k}\) is the goal state"
ICLR_2024_oral_61,3,L(\psi)=E_{D}[-\log\pi^{p}_{\psi}(a^{h}|s_{t})],,"L(\psi)=E_{(s_t, s^g)\sim D}\left[-\log\pi^{p}_{\psi}(a^{h} | s_t)\right]","where \(D\) is the dataset, \(s_t\) is the current state, \(s^g\) is the goal state, and \(a^{h}\) is the discrete goal index corresponding to the goal state \(s^g\)"
ICLR_2024_oral_61,4,"J(\theta)=E\pi_{\theta}[\sum_{t=0}^{\infty}\gamma^{t}(\sum _{i=kt}^{(k+1)t}R(s_{i},a_{i})-\alpha D_{KL}(\pi^{p}_{\psi}(a^{h }|s_{kt})\|\pi_{\theta}(a^{h}|s_{kt})))]",where \(t\) represents the number of steps for the high-level policy and \(\alpha\) is a hyperparameter balancing the environmental rewards and the intrinsic rewards,\max_{\theta}E_{\tau}\left[\sum_{t=0}^{T}\gamma^t r_t-\alpha\sum_{j=0}^{M}KL\left(\pi_{\theta}(\cdot|s_{j k})\parallel\pi^{p}_{\psi}(\cdot|s_{j k})\right)\right],"where \( r_t \) is the environment reward at time step \( t \), \( \gamma \) is the discount factor, \( \alpha \) is the regularization coefficient, \( \text{KL} \) is the Kullback-Leibler divergence, \( \pi_{\theta} \) is the high-level policy, \( \pi^{p}_{\psi} \) is the goal prior model, \( j \) indexes the high-level decision steps, \( k \) is the fixed number of low-level steps per high-level action, and \( M \) is the number of high-level steps in the trajectory."
ICLR_2024_oral_63,1,p_{\theta}(x)\propto e^{-f_{\theta}(x)},,p_{\theta}(x)=\frac{e^{-f_{\theta}(x)}}{Z(\theta)},"The Boltzmann distribution defining the probability density \(p_{\theta}(x)\) for data point \(x\), where \(f_{\theta}(x)\) is the energy function and \(Z(\theta)\) is the partition function."
ICLR_2024_oral_63,2,"x_{k+1}=x_{k}-\delta\,\nabla f_{\theta}(x_{k})+\sqrt{2\delta}\,\varepsilon_{k },\,\varepsilon_{k}\simN(0,I_{d})","where \(\nabla\) denotes the gradient of the energy function with respect to inputs, \(k\) is the sampling step, \(\delta\) is the (discretization) step size, and the noise \(\varepsilon_{k}\) is drawn from the normal distribution at each step","x_{t+1}=x_t-\eta\nabla_x f_{\theta}(x_t)+\sqrt{2\eta}\epsilon_t,\quad\epsilon_t\simN(0, I)","This equation defines the discretized Langevin diffusion update step, where \(x_t\) is the current sample, \(\eta\) is the step size, \(f_{\theta}\) is the energy function, and \(\epsilon_t\) is standard Gaussian noise."
ICLR_2024_oral_63,3,\hat{x}(y)=y+\sigma^{2}\nabla\log p(y),where \(p(y)=\int p(y|x)p(x)dx\) is the probability distribution function of the smoothed density,E[X\mid Y=y]=y+\sigma^{2}\nabla_{y}\log p(y),"where \( p(y) \) is the density of the noisy observation \( Y \) at \( y \), and \( \nabla_{y} \) denotes the gradient with respect to \( y \)."
ICLR_2024_oral_63,4,\hat{x}_{\phi}(y)=y+\sigma^{2}g_{\phi}(y),,\hat{x}_{\phi}(y)=y+\sigma^{2} g_{\phi}(y),The parametric form of the least-squares estimator using the neural network \( g_{\phi} \) for the score function.
ICLR_2024_oral_63,5,"L(\phi)=E_{x\sim p(x),y\sim p(y|x)}\|x-\hat{x}_{\phi}(y)\|^ {2}",,"L(\theta,\phi)=E_{x\sim p_{data},y\simN(x,\sigma^{2}I)}\left[\left\|\hat{x}_{\phi}(y)-\hat{x}_{\theta}(y)\right\|^{2}\right]",The learning objective minimizes the expected squared difference between the parametric least-squares estimator \(\hat{x}_{\phi}(y)\) and the model-based estimator \(\hat{x}_{\theta}(y)\).
ICLR_2024_oral_63,6,"\operatorname*{arg\,max}_{\theta}E_{y\sim p_{Y}}[\log p_{\theta}( y)]=\operatorname*{arg\,max}_{\theta}(E_{y^{-}\sim p_{Y}(y)}[f_{\theta}(y^{-})]-E_{y^{+}\sim p_{Y}}[f_{\theta}(y^{+})])",where \(y^{+}\) are noisy training data and \(y^{-}\) are noisy data sampled from the model,"L(\theta)=E_{x\sim p(x), y\sim p(y|x)}\left[\log p_\theta(y)\right]",The objective function for training the energy-based model on noisy data by maximizing the log-likelihood.
ICLR_2024_oral_63,7,\nabla_{\theta}\log p_{\theta}(y)=-\nabla_{\theta}f_{\theta}(y)-\nabla_{\theta}\log Z(\theta) || =-\nabla_{\theta}f_{\theta}(y)+\frac{\int\nabla_{\theta}f_{\theta}(y)e^{-f_{\theta}(y)}dy}{Z(\theta)} || =-\nabla_{\theta}f_{\theta}(y)+\int\nabla_{\theta}f_{\theta}(y)\cdot p_{\theta}(y)dy || =-\nabla_{\theta}f_{\theta}(y)+E_{y\sim p_{\theta}(y)}[\nabla_{\theta}f_{\theta}(y)],,\nabla_{\theta}E_{y\sim p_Y}\left[\log p_{\theta}(y)\right]=E_{y^{-}\sim p_{\theta}}\left[\nabla_{\theta} f_{\theta}(y^{-})\right]-E_{y^{+}\sim p_Y}\left[\nabla_{\theta} f_{\theta}(y^{+})\right],"where \(y^{+}\) are noisy training data, \(y^{-}\) are noisy data sampled from the model, and \(\nabla_{\theta}\) is the gradient with respect to the model parameters \(\theta\)."
ICLR_2024_oral_63,8,"P^{\top}argmax\,\hat{x}(y,t)=P^{\top}s",,Px=Px_{0},where \( P \) is a binary projection matrix that selects the constrained positions and \( x_{0} \) is the starting sequence.
ICLR_2024_oral_63,9,\chi_{ii^{\prime}}=\frac{ || X_{i}-X_{i^{\prime}} || }{2\sqrt{d}},where \(d\) is the dimension of the data and the \(\frac{1}{2\sqrt{d}}\) scaling comes from the concentration of isotropic Gaussians in high dimensions,\chi_{ij}=\frac{\| e_i-e_j\|_2^2}{4\sigma^2},"The matrix \(\chi\) with entries \(\chi_{ij}\) defined as the squared Euclidean distance between one-hot vectors \(e_i\) and \(e_j\) for tokens \(i\) and \(j\), scaled by \(1/(4\sigma^2)\)."
ICLR_2024_oral_63,10,\sigma_{c}=\max_{ii^{\prime}}\chi_{ii^{\prime}},,\sigma_c=median\left(\left\{\chi_{ii'}\mid i\neq i'\right\}\right),The critical noise level \(\sigma_c\) is the median of the off-diagonal entries of the matrix \(\chi\).
ICLR_2024_oral_64,1,Z_{k}\subseteqR^{M}\quadand\quadZ=Z_{1}\times\dots\timesZ_{K}\subseteqR^{KM},,Z=Z_1\timesZ_2\times\cdots\timesZ_K,"The latent space $\mathcal{Z}$ factorizes into $K$ independent slots $\mathcal{Z}_k$, each of dimension $M$."
ICLR_2024_oral_64,2,"x=f(z),\quadz\sim p_{z},\quadsupp(p_{z })=Z^{S}",,"z\sim p_{Z^S},\quadx=f(z)","Generative process for training data: $\mathbf{z}$ is sampled from distribution $p_{\mathcal{Z}^S}$ over the slot-supported subset $\mathcal{Z}^S$, and $\mathbf{x} = \mathbf{f}(\mathbf{z})$."
ICLR_2024_oral_64,3,"L_{rec}(X^{S})=L_{rec}\big{(}\hat {g},\hat{f},X^{S}\big{)}:=E_{x\sim p_{x }}\big{[}\big{\|}\hat{f}\big{(}\hat{g}(x)\big{)}-x\big{\|} _{2}^{2}\big{]},\quadsupp(p_{x})=X^{S}",,"\min_{\hat{g},\hat{f}}E_{z\sim p_{z}}}\left[\|f(z)-\hat{f}(\hat{g}(f(z)))\|^2\right]",The reconstruction objective minimizes the expected squared error between the true image and the autoencoder's output over the training distribution defined by the latent variable model.
ICLR_2024_oral_64,4,"\frac{\partialf_{n}}{\partialz_{k}}(z)\neq 0\implies\frac{\partialf_{n}}{\partialz_{j}}(z)=0,\quadfor any $k,j\in[K]$, $k\neq j$ and any $n\in[N]$.",,"\forall i\in [N],\\exists k\in [K] such that \forall l\neq k,\\frac{\partial f_i}{\partialz_l}(z)=0",Compositionality requires that each output dimension $i$ is locally influenced by at most one latent slot $\mathbf{z}_k$ at $\mathbf{z}$.
ICLR_2024_oral_64,5,"z^{\prime}=\big{(}h_{1}(z_{\pi(1)}),\ldots,h_{K}(z_{\pi(K)})\big{)},\quadZ^{\prime}=h_{1}(Z_{\pi(1)})\times\cdots\timesh_{K}(Z_{\pi(K)})",,"\hat{z}=\left(h_1(z_{\pi(1)}),h_2(z_{\pi(2)}),\dots,h_K(z_{\pi(K)})\right)",The inferred latent vector \(\hat{\mathbf{z}}\) for any ground-truth latent \(\mathbf{z} \in \mathcal{Z}\) is defined by applying slot-wise diffeomorphisms \(\mathbf{h}_k\) to permuted ground-truth slots \(\mathbf{z}_{\pi(k)}\).
ICLR_2024_oral_64,6,\hat{g}\big{(}f(z)\big{)}=z^{\prime}\quadand\quad\hat{f}(z^{\prime})=f(z),,\hat{g}\left(f(z)\right)=z'\quad\forallz\inZ,The encoder applied to the ground-truth data equals the slot-identified representation for any latent vector in the full latent space.
ICLR_2024_oral_64,7,"\hat{f}(z)=\sum_{k=1}^{K}\varphi_{k}(\hat{z}_{k}),\quadwhere \varphi_{k}:R^{M}\toR^{N} for any k\in[K] and \hat{z}\inR^{KM}",,\hat{f}(\hat{z})=\sum_{k=1}^{K}\hat{f}_{k}(\hat{z}_{k}),"An additive decoder decomposes the reconstruction as the sum of slot-wise rendering functions \(\hat{\mathbf{f}}_{k}\), each depending only on one slot \(\hat{\mathbf{z}}_{k}\)."
ICLR_2024_oral_64,8,"L_{cons}\big{(}\hat{g},\hat{f},Z^{\prime}\big{)}=E_{z^{\prime}\sim q_{z^{\prime}}}\Big{[}\big{\|}\hat{g}\big{(}\hat{f}(z^{\prime})\big{)}-z^{\prime}\big{\|} _{2}^{2}\Big{]}",,"L_{cons}(\hat{g},\hat{f},q_{z^{\prime}}):=E_{z^{\prime}\sim q_{z^{\prime}}}\big[\big\|\hat{g}\big(\hat{f}(z^{\prime})\big)-z^{\prime}\big\|_{2}^{2}\big]",The compositional consistency loss enforces invertibility of the autoencoder on the entire latent space \(\mathcal{Z}^{\prime}\) by penalizing the expected squared error between \(\mathbf{z}^{\prime}\) and its reconstruction after encoding and decoding.
ICLR_2024_oral_64,9,"L_{rec}\big{(}\hat{g},\hat{f},X^{S}\big{)}+\lambdaL_{cons}\big{(}\hat{g},\hat{f},Z ^{\prime}\big{)}=0,\qquadfor some \lambda>0",,"\min_{\hat{g},\hat{f}}L_{rec}\big(\hat{g},\hat{f},X^{S}\big)+\lambdaL_{cons}\big(\hat{g},\hat{f},Z^{\prime}\big)","The minimization objective for the autoencoder to achieve compositional generalization, combining the reconstruction loss on the training space and the compositional consistency loss on the OOD latent space with a hyperparameter \(\lambda\)."
ICLR_2024_oral_64,10,"\hat{f}(z)=\sum_{k=1}^{K}\tilde{m}_{k}\odotx_{k},\qquad\tilde{m}_{k}=\sigma(m)_{k},\qquad(m_{k},x_{k})=\varphi _{k}(z_{k})",where \(\odot\) is an element-wise multiplication and \(\sigma(\cdot)\) denotes the softmax function,"L_{rec}\big{(}\hat{g},\hat{f},X^{S}\big{)}+\lambdaL_{cons}\big{(}\hat{g},\hat{f},Z^{\prime}\big{)}=0",The autoencoder minimizes the sum of the reconstruction loss and the weighted compositional consistency loss to zero.
ICLR_2024_oral_64,11,h_{k}(z_{\pi(k)})=\hat{g}_{k}\big{(}f(z)\big{)}\quadand\quadZ^{\prime}=\hat{g}_{1}(X^{S})\times\cdots\times\hat{g}_{K}(X^{S}),,"\hat{f}(z)=\sum_{k=1}^{K}\tilde{m}_{k}\odotx_{k},\qquad\tilde{m}_{k}=\sigma(m)_{k},\qquad (m_{k},x_{k})=\varphi_{k}(z_{k})","The standard non-additive decoder in object-centric learning, which uses a softmax over slots to normalize masks, introducing dependencies between slots."
ICLR_2024_oral_64,12,"z^{\prime}=\big{(}\hat{z}^{(\rho_{1})}_{1},\ldots,\hat{z}^{(\rho _{K})}_{K}\big{)},\quadwhere for i\in\{1,2\}\quad\hat{z}^{(i)}=\hat{g}\big{(}x^{(i)}\big{)},\,x^{(i)}\sim p_{z}",,"z'=\left(\hat{z}_1^{(\rho_1)},\hat{z}_2^{(\rho_2)},\dots,\hat{z}_K^{(\rho_K)}\right)","The out-of-distribution latent vector \(\mathbf{z}'\) is constructed by independently for each slot \(k\) selecting the slot value from one of two training examples \(\hat{\mathbf{z}}^{(1)}\) or \(\hat{\mathbf{z}}^{(2)}\) via a random index \(\rho_k \sim \mathcal{U}\{1,2\}\)."
ICLR_2024_oral_66,1,"\theta^{*}\:=\\operatorname*{arg\,min}_{\theta}\E_{(x,t,\ell(x,t),\cdot)\simH}\\Big{[}-\log p(\ell(x,t)\mid x,t,\hat{\ell}(x,t;\theta))\Big{]}",,"\theta^*,\sigma^*=\arg\min_{\theta,\sigma}\sum_{i=1}^{n}\left[\frac{1}{2}\log(2\pi\sigma^2)+\frac{\left(\ell(x_i, t_i)-\hat{\ell}(x_i, t_i;\theta)\right)^2}{2\sigma^2}\right]","The training objective for the probabilistic performance estimator minimizes the negative log-likelihood of observed performance values under a Gaussian distribution parameterized by mean \(\hat{\ell}(x_i, t_i; \theta)\) and variance \(\sigma^2\)."
ICLR_2024_oral_66,2,"\gamma^{*}\:=\\operatorname*{arg\,min}_{\gamma}\E_{(x,t,\cdot,c(x,t))\simH}\\Big{[}c(x,t)-\hat{c}(x,t;\gamma)\Big{]}^{2}",,"\gamma^{*} :=\operatorname*{arg\,min}_{\gamma}E_{(x,t,\cdot,c(x,t))\simH}\left[-\log p(c(x,t)\mid x, t,\hat{c}(x,t;\gamma))\right]",The cost estimator parameters \(\gamma\) are optimized by minimizing the expected negative log-likelihood of the true cost given the predicted cost over the history \(\mathcal{H}\).
ICLR_2024_oral_66,3,"x^{*}:=\operatorname*{arg\,max}_{x\inX}\frac{EI(x,H,\hat{\ell}(x,\tau(x)))}{\hat{c}\Big{(}x,\tau(x)\Big{)}{-}c\Big{(}x,\tau(x)-\Delta t\Big{)}}=\operatorname*{arg\,max}_{x\inX}\frac{E_{\hat{\ell}(x,\tau(x))}[\max(\ell_{\tau(x)}^{\min}-\hat{\ell}(x,\tau(x)),0)]}{\hat{c}\Big{(}x,\tau(x){-}c\Big{(}x,\tau(x){-}\Delta t\Big{)}}",,"\alpha(x,t) :=\frac{E_{\hat{\ell}(x,t)}\left[\max\left(0,\ell^*-\hat{\ell}(x,t)\right)\right] }{\hat{c}(x,t;\gamma) }","The cost-sensitive acquisition function \(\alpha(x,t)\) is defined as the ratio of the Expected Improvement over the best observed loss \(\ell^*\) to the predicted cost \(\hat{c}(x,t;\gamma)\), where \(\ell^* = \min_{(x_i,t_i,\ell_i,\cdot) \in \mathcal{H}} \ell_i\)."
ICLR_2024_oral_66,4,"\theta^{(M)} :=\\operatorname*{arg\,min}_{\theta}\E_{(x,t,\ell(x,t,d),c(x,t,d))\simH^{(M)}}\\[-\log p(\ell(x,t,d)\mid x,t,d,\hat{\ell}(x,t,d;\theta))] || \gamma^{(M)} :=\\operatorname*{arg\,min}_{\gamma}\E_{(x,t,\ell(x,t,d),c(x,t,d))\simH^{(M)}}\\(c(x,t,d)-\hat{c}(x,t,d;\gamma))^{2}",,"\theta^{*} &:=\operatorname*{arg\,min}_{\theta}E_{(x,t,\ell(x,t,d),\cdot)\simH^{(M)}}\left[-\log p\left(\ell(x,t,d)\mid x, t, d,\hat{\ell}(x,t,d;\theta)\right)\right]\\\gamma^{*} &:=\operatorname*{arg\,min}_{\gamma}E_{(x,t,\cdot,c(x,t,d))\simH^{(M)}}\left[\left( c(x,t,d)-\hat{c}(x,t,d;\gamma)\right)^2\right]",The meta-learning objectives for performance estimator parameters \(\theta^{*}\) and cost estimator parameters \(\gamma^{*}\) minimize the expected negative log-likelihood of validation loss and expected squared cost error over the meta-dataset.
ICLR_2024_oral_66,5,"M=\{m^{*}\,|\,m^{*}\in\operatorname*{arg\,max}_{m\inM _{Timm}}[f_{ImageNet}(m),\-S(m)]\}",,M_{hub}=\left\{ m\inM_{Timm}}\mid\nexists m'\inM_{Timm}}:\left( f_{ImageNet}(m')\geq f_{ImageNet}(m)\land S(m')\leq S(m)\right)\land\left( f_{ImageNet}(m') > f_{ImageNet}(m)\lor S(m') < S(m)\right)\right\},The set \(\mathcal{M}_{\text{hub}}\) consists of Pareto-optimal models in \(\mathcal{M}_{\mathrm{Timm}}}\) with respect to maximizing ImageNet accuracy \(f_{\mathrm{ImageNet}}\) and minimizing model size \(S\).
ICLR_2024_oral_68,1,P(v\middo(x))=\prod_{i:v_{i}\notinx}P(v_{i }\midpa_{v_{i}})&if $v$ consistent with $x$\\0&otherwise.,,P(v\middo(X=x))=\left[\prod_{i: V_i\notinX} P(v_i\midPa_{V_i})\right]\cdotI(v_{X}=x),The truncated factorization formula for the interventional distribution gives the probability of assignment \(\mathbf{v}\) under intervention \(\text{do}(\mathbf{X}=\mathbf{x})\) as the product of conditionals for non-intervened variables and an indicator that intervened variables equal \(\mathbf{x}\).
ICLR_2024_oral_68,2,"P(v_{i}\,|pa_{i};\sigma)=\sum_{v_{i}^{\prime}:f(v_{i}^{\prime})=v_{i}}P(v_ {i}^{\prime}\,|pa_{i})",,P'(v_i\midpa_i)=1 &if  v_i=f(v) for  v\indom(V_i)\\0 &otherwise,"The conditional probability distribution for $V_i$ after a local intervention $\sigma = \mathrm{do}(V_i = f(v_i))$ is deterministic and assigns probability 1 to the value $f(v)$ for $v \in \operatorname{dom}(V_i)$ and 0 otherwise, independent of the parent variables $\mathbf{pa}_i$."
ICLR_2024_oral_7,1,"y_{i}=M(x_{i}|\Delta W,W_{0},\theta)",,y_{i}=(W_{0}+BA)x_{i},"The output \(\mathbf{y}_{i}\) is computed as the product of the input \(\mathbf{x}_{i}\) and the adapted weight matrix \(W_{0} + BA\), where \(W_{0}\) is the pre-trained weight matrix and \(BA\) is the low-rank LoRA adapter."
ICLR_2024_oral_7,2,y_{i}=\phi(W_{i}^{T}x_{i}) || =\phi\big{(}(W_{0}^{T}\circ\Delta W_{i}^{T})x_{i}\big{)},,h_{i}=\left( (B_{i} A_{i})\circ W_{0}\right)x_{i},"The next layer's activation vector \(\mathbf{h}_i\) for example \(i\) is computed by the element-wise product of the adapter matrix \(B_i A_i\) and the pre-trained weight matrix \(W_0\), multiplied by the current activation vector \(\mathbf{x}_i\)."
ICLR_2024_oral_7,3,=\phi\big{(}(W_{0}^{T}\circ(B_{i}A_{i})^{T})x_{i}\big{)},,"Y=\phi\left(\left[ (W_0^T\circ\Delta W_1^T)x_1, (W_0^T\circ\Delta W_2^T)x_2,\dots, (W_0^T\circ\Delta W_m^T)x_m\right]\right)","The batched activations for the next layer, where each column corresponds to the transformed activations of an example in the minibatch after applying example-specific adapters."
ICLR_2024_oral_7,4,=\phi\Big{(}A_{i}\circ\big{(}W_{0}^{T}(B_{i}\circ x_{i})\big{)}\Big{)},,"[y_{i}]_j=\phi\left(\sum_{l=1}^{d}\sum_{p=1}^{r} [W_0]_{j,l}\cdot [A_i]_{p,j}\cdot [B_i]_{l,p}\cdot [x_i]_l\right)","Each output element for example i is computed by summing over input dimensions and rank dimensions the product of pretrained weights, adapter matrices, and input elements."
ICLR_2024_oral_7,5,Y=\phi\Big{(}A\circ\big{(}(B\circX)W_{0}\big{)}\Big{)},,Y=\phi\left(reduce\left(A\circ\left( W_0^{\top}\left(B\circX\right)\right)\right)\right),"The vectorized forward pass for a minibatch in Flora, where $\mathbf{X}$ is the input batch matrix, $\mathbf{B}$ and $\mathbf{A}$ are the batched adapter matrices, $\circ$ denotes element-wise multiplication with broadcasting, and $\mathrm{reduce}$ denotes a dimension reduction operation (e.g., mean) over the rank dimension."
ICLR_2024_oral_7,6,\frac{2c_{1}}{dc_{2}}+\frac{1}{r}\geq 1,,2c_{1} b l d r+c_{2} b l d^{2} > c_{2} r b l d^{2},The inequality that must hold for fLoRA's computational cost to be lower than the baseline LoRA approach.
ICLR_2024_oral_73,1,\tilde{x}_{i}=\frac{\mu_{k}+\varepsilon\eta}{\sqrt{1+\varepsilon^{2}}},where \(\eta\) is drawn from the same distribution as the \(\mu_{k}\)'s and \(\varepsilon\) sets the within-class variability,"\tilde{x}_i=\mu_{c_i}+\epsilon_i,\quad\epsilon_i\simN\left(0,\frac{1}{D}I\right)",The content vector \(\tilde{x}_i\) for item \(x_i\) is the sum of the class mean \(\mu_{c_i}\) and isotropic Gaussian noise \(\epsilon_i\) with variance \(1/D\) per component.
ICLR_2024_oral_73,2,"v_{i}=u_{i}+V_{1}\sum_{j\leq i}p_{ij}^{(1)}u_{j},\quad w_{i}=v_{i}+V_{2}\sum_{ j\leq i}p_{ij}^{(2)}v_{j} || p_{ij}^{(\mu)}=\frac{e^{(K_{\mu}u_{j})^{T}(Q_{\mu}u_{i})}}{\sum_{k\leq i}e^{(K _{\mu}u_{k})^{T}(Q_{\mu}u_{i})}}","where

\[p_{ij}^{(\mu)}=\frac{e^{(K_{\mu}u_{j})^{T}(Q_{\mu}u_{i})}}{\sum_{k\leq i}e^{(K _{\mu}u_{k})^{T}(Q_{\mu}u_{i})}} \tag{3}\]

is the attention paid by query \(i\) on key \(j\) in the \(\mu\)th layer",v_i=\sum_{j=1}^{i}\frac{\exp\left(\frac{ (u_i W_1^Q)\cdot (u_j W_1^K) }{\sqrt{d_k} }\right) }{\sum_{m=1}^{i}\exp\left(\frac{ (u_i W_1^Q)\cdot (u_m W_1^K) }{\sqrt{d_k} }\right) } u_j W_1^V,"the output of the first attention layer at position \(i\), where \(W_1^Q\), \(W_1^K\), and \(W_1^V\) are learnable weight matrices for queries, keys, and values, and \(d_k\) is the key dimension."
ICLR_2024_oral_73,3,"v_{i}^{(b)}=\sum_{j\leq i}q_{ij}^{(1)}u_{j}^{(c)},\quad v_{i}^{(c )}=u_{i}^{(c)} || w_{i}^{(b)}=\sum_{j\leq i}q_{ij}^{(2)}v_{j}^{(c)},\quad w_{i}^{( c)}=v_{i}^{(c)}",,"v_i &=\ell_i\\\beta_1x_{i-1} &if  i is even\\x_i\\0 &otherwise\tag{3a}\\w_q &=v_q+\beta_2\sum_{j=1}^{N} p_{q,2j}^{(2)}0\\\ell_{2j}\tag{3b}\\p_{q,2j}^{(2)} &=\frac{\exp\left(\gamma\beta_1x_q^\topx_{2j-1}\right) }{\sum_{k=1}^{N}\exp\left(\gamma\beta_1x_q^\topx_{2k-1}\right) }\tag{3c}","A minimal three-parameter model for the induction head, where the first layer writes item content to the buffer of the subsequent label, and the second layer writes a weighted sum of label contents to the target's buffer based on attention that matches the target item to items stored in label buffers."
ICLR_2024_oral_73,4,"q_{ij}^{(1)}=\frac{e^{\beta_{1}\delta_{i-1,j}}}{\sum_{k\leq i}e^{\beta_{1}\delta_ {i-1,k}}},\quad q_{ij}^{(2)}=\frac{e^{\alpha v_{j}^{(k)},v_{i}^{(c)}+\beta_{2}\Delta_{i,j}}}{\sum_{k\leq i}e^{\alpha v_{k}^{(k)},v_{i}^{(c)}+\beta_{2}\Delta_ {i,k}}}",,"q_{ij}^{(1)}=\frac{\exp\left(\beta_{self}\delta_{j,i}+\beta_{prev}\delta_{j,i-1}\right)}{\sum_{k\leq i}\exp\left(\beta_{self}\delta_{k,i}+\beta_{prev}\delta_{k,i-1}\right)},\quad q_{ij}^{(2)}=\frac{\exp\left(\beta_2\left(u_i^{(c)}\cdot v_j^{(b)}\right)\right)}{\sum_{k\leq i}\exp\left(\beta_2\left(u_i^{(c)}\cdot v_k^{(b)}\right)\right)}","The first layer attention weight $q_{ij}^{(1)}$ uses parameters $\beta_{\mathrm{self}}$ for self and $\beta_{\mathrm{prev}}$ for the previous token, while the second layer weight $q_{ij}^{(2)}$ scales the dot product between current content and key buffer content with $\beta_2$."
ICLR_2024_oral_74,1,\partial_{k}|s_{k}\rangle=\sum_{l=0}^{k-1}(-1)^{l}|s_{k-1}(l)\rangle,where \(\left|s_{k-1}(l)\right\rangle\) is the _lower_ simplex obtained by leaving out vertex \(l\) (i,\partial_k\left| s_k\right\rangle=\sum_{i=0}^{k} (-1)^i\left| s_k\setminus\{j_i\}\right\rangle,"The boundary operator $\partial_k$ acts on a $k$-simplex state $\left| s_k \right\rangle$ by summing over all its $(k-1)$-dimensional faces with alternating signs, where each face is obtained by removing one vertex $j_i$."
ICLR_2024_oral_74,2,\beta_{k}:=\dim\ker(\Delta_{k}),,\beta_k=\dim\ker\Delta_k,The \(k\)th Betti number \(\beta_k\) equals the dimension of the kernel of the combinatorial Laplacian \(\Delta_k\).
ICLR_2024_oral_74,3,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|\leq\epsilon,"where \(|S_{k}|\) is the the number of \(k\)-simplices \(S_{k}\in\Gamma\) or \(\dim\tilde{\mathcal{H}}_{k}\), the dimension of the Hilbert space spanned by the set of \(k\)-simplices in the complex",\left|\chi_k-\frac{\beta_k}{|S_k|}\right|\leq\epsilon,The estimate \(\chi_k\) must satisfy that the absolute difference between \(\chi_k\) and the normalized Betti number \(\beta_k / |S_k|\) is at most \(\epsilon\) with probability \(1-\eta\).
ICLR_2024_oral_74,4,"\rank(\Delta_{k})\stackrel{{\tiny{def}}}{{=}}\trace(h(\tilde{\Delta}_{k})), where h(x)=\{{ll}1& if \x>\delta\\0& otherwise",,rank(\Delta_k)=Tr\left[h_\delta(\tilde{\Delta}_k)\right],"The rank of the \(k\)-Laplacian \(\Delta_k\) is expressed as the trace of the step function \(h_\delta\) applied to the normalized Laplacian \(\tilde{\Delta}_k = \Delta_k / n\), which equals the number of eigenvalues of \(\tilde{\Delta}_k\) that are at least \(\delta\)."
ICLR_2024_oral_74,5,n_{v}=O(\frac{\log(1/\eta)}{\epsilon^{2}})\qquad\qquadand\qquad\qquad m>\frac{\log(1/\epsilon)}{\sqrt{\delta}},,n_{v}=O\left(\epsilon^{-2}\log\eta^{-1}\right)\quadand\quad m=O\left(\delta^{-1}\log\epsilon^{-1}\right),"The parameters \(n_{\mathrm{v}}\) and \(m\) are set to \(O(\epsilon^{-2} \log \eta^{-1})\) and \(O(\delta^{-1} \log \epsilon^{-1})\), respectively, to ensure the accuracy and confidence of the Betti number estimation."
ICLR_2024_oral_74,6,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|\leq\epsilon,,\left|\chi_k-\frac{\beta_k}{|S_k|}\right|\leq\epsilon,The inequality showing that the estimated normalized Betti number \(\chi_k\) is within \(\epsilon\) of the true normalized Betti number \(\beta_k / |S_k|\) with probability at least \(1-\eta\).
ICLR_2024_oral_74,7,"O(\frac{1}{\epsilon^{2}}\max\{\frac{n\log(1/\epsilon)}{\sqrt{\delta} },\frac{n}{\zeta_{k}}\})",,O\left(\frac{n^{3}\log^{2}(1/\epsilon)\log(1/\eta)}{\epsilon^{2}\delta}\right),The total time complexity of the NISQ-TDA algorithm.
ICLR_2024_oral_82,1,LayerNorm(x)=\frac{x-E[x]}{\sqrt {Var[x]+\epsilon}}\odot\gamma+\beta,,LayerNorm(x)=\gamma\odot\frac{x-\mu}{\sigma}+\beta,"Let \(\mu\) and \(\sigma\) be the mean and standard deviation of \(\mathbf{x}\) over its feature dimension, computed as \(\mu = \frac{1}{D} \sum_{i=1}^{D} x_i\) and \(\sigma = \sqrt{\frac{1}{D} \sum_{i=1}^{D} (x_i - \mu)^2 + \epsilon}\), with \(\epsilon\) a small constant for numerical stability, and let \(\gamma, \beta \in \mathbb{R}^{D}\) be learnable affine parameters."
ICLR_2024_oral_82,2,{BiasNorm}(x)=\frac{x}{RMS[x-b]}\cdot\exp(\gamma),"where \(\mathbf{b}\) is the learnable channel-wise bias, \(\mathrm{RMS}[\mathbf{x}-\mathbf{b}]\) is the root-mean-square value taken over channels, and \(\gamma\) is a scalar",BiasNorm(x)=(x-E[x])+\beta,BiasNorm subtracts the mean \(\mathrm{E}[\mathbf{x}]\) from the input \(\mathbf{x}\) and adds a learnable per-channel bias \(\mathbf{\beta}\) without scaling or variance normalization.
ICLR_2024_oral_82,3,Swish(x)=x\cdot(1+\exp(-x))^{-1},,Swish(x)=x\cdot\sigma(x),\(x\) is the input and \(\sigma\) denotes the sigmoid function.
ICLR_2024_oral_82,4,"\textit{SwooshR}(x)&=\log(1+\exp(x-1))-0.08x-0.313261687,\\\textit{SwooshL}(x)&=\log(1+\exp(x-4))-0.08x-0.035",,"SwooshR(x)=x\cdot\sigma(\beta x),\quadSwooshL(x)=x\cdot\sigma(-\beta x)","The SwooshR and SwooshL activation functions replace Swish, with learnable slope parameter \(\beta\)."
ICLR_2024_oral_82,5,\Delta_{t}=-\alpha_{t}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon},"where \(\alpha_{t}\) is the learning rate typically specified by an external schedule, \(\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{2}}\) is the bias-correction term, and \(\epsilon=10^{-8}\)",\Delta_{t}=\alpha\cdots_{t-1}\odot\frac{m_{t} }{\sqrt{v_{t}}+\epsilon },"where \(\alpha\) is the learning rate, \(\mathbf{s}_{t-1}\) is the learned scale vector at step \(t-1\), \(\mathbf{m}_{t}\) and \(\mathbf{v}_{t}\) are the first and second moments of the gradients, and \(\epsilon\) is a small constant for numerical stability."
ICLR_2024_oral_82,6,\Delta^{\prime}_{t}=-\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^ {2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon},,\Delta_{t}=-\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon,where \(r_{t-1}\) is the parameter scale at step \(t-1\).
ICLR_2024_oral_82,7,"\Delta^{\prime}_{t,r}&=-\eta\cdot\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{2}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\odot\theta^{\prime}_{t-1}\\&=-\eta\cdot\alpha_{t}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta _{1}^{t}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\odot\theta_{t-1}","where \(\eta\) is a scaling factor on learning rate \(\alpha_{t}\), and we found that setting \(\eta=0","\Delta^{\prime}_{t,r}=-\alpha_{t}\cdot\frac{\sqrt{1-\beta_{2}^{t}}}{1-\beta_{1}^{t}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\cdot\theta_{t-1}","where \(\mathbf{\Delta}^{\prime}_{t,r}\) is the change in the parameters \(\mathbf{\theta}\) resulting from the update of the scale \(r\), \(\alpha_t\) is the learning rate, \(\beta_1\) and \(\beta_2\) are the exponential decay rates, \(n_t\) and \(w_t\) are the first and second moments of the scale gradient, and \(\epsilon\) is a small constant."
ICLR_2024_oral_82,8,"\alpha_{t}=\alpha_{base}\cdot(\frac{t^{2}+\alpha_{step }^{2}}{\alpha_{step}^{2}})^{-0.25}\cdot(\frac{e^{2}+\alpha_{epoch}^{2}}{\alpha_{epoch}^{2}})^{-0.25}\cdotlinear(\alpha_{start},t_{warmup},t)",,\alpha_t=\alpha_{base}\cdot\sqrt{\frac{RMS[\theta_0]}{t}},"where \(\alpha_{\mathrm{base}}\) is the base learning rate, \(\mathrm{RMS}[\boldsymbol{\theta}_0]\) is the root-mean-square value of the initial parameters, and \(t\) is the step number."
ICML_2024_oral_1,1,"J(\pi)=\sum_{t=0}^{\infty}E_{(s_{t},a_{t})\sim\rho (\pi)}[\gamma^{t}(r(s_{t},a_{t})+\alphaH(\pi(\cdot|s_{t})))]",,"J(\pi)=E_{\pi}\left[\sum_{t=0}^{\infty}\gamma^{t}\left( r(s_t, a_t)+\alphaH\left(\pi(\cdot|s_t)\right)\right)\right]",The SAC objective function maximizes the expected discounted return augmented with policy entropy regularization.
ICML_2024_oral_1,2,"r_{t}=r_{M}(B_{s\to r|a}\odots_{t},B_{a\to r|s}\odota_{t},\epsilon_{t})","where \(\mathbf{B}_{\mathbf{s}\to r|\mathbf{a}}\in\mathbb{R}^{\mathrm{dim} \mathcal{S}\times 1}\) and \(\mathbf{B}_{\mathbf{a}\to r|\mathbf{s}}\in\mathbb{R}^{\mathrm{dim}\mathcal{A} \times 1}\) are vectors that represent the graph structure 1 from \(\mathbf{s}_{t}\) to \(r_{t}\) given \(\mathbf{a}_{t}\) and from \(\mathbf{a}_{t}\) to \(r_{t}\) given \(\mathbf{s}_{t}\), respectively","r_t=f(Pa(r_t),\epsilon_t)",Reward generated by a structural equation model with parents of \( r_t \) and independent noise.
ICML_2024_oral_1,3,"H_{c}(\pi(\cdot|s))&=-E_{a\inA}[\sum_{i=1}^{\dimA}B_{a_{i}\to r|s}\pi(a_{i}|s)\log\pi(a_{i}|s)],\\&a=(a_{1},\ldots,a_{\dimA})",,H_{c}(\pi(\cdot|s))=\sum_{i=1}^{dimA} [B_{a\to r|s}]_i\cdotE_{a_i\sim\pi_i(\cdot|s)}\left[-\log\pi_i(a_i|s)\right],"The causality-aware entropy \(\mathcal{H}_{c}\) is defined as the weighted sum of the marginal entropies of each action dimension, with weights given by the causal structure vector \(\mathbf{B}_{\mathbf{a}\to r|\mathbf{s}}\)."
ICML_2024_oral_1,4,"T_{c}^{\pi}Q(s_{t},a_{t })\triangleq& r(s_{t},a_{t})+\gammaE_{s_{t+1}\sim P}[E_{a_{t}\sim\pi}[Q(s_{t+1},a_{t+1})\\&+\alphaH_{c}(\pi(a_{t+1}|s_{t+1}))]]",,"(T_c^\pi Q)(s_t, a_t) &=r(s_t, a_t)+\gamma\,E_{s_{t+1}\sim p}\left[ V_c(s_{t+1})\right],\\V_c(s_{t+1}) &\triangleqE_{a_{t+1}\sim\pi(\cdot|s_{t+1})}\left[ Q(s_{t+1}, a_{t+1})\right]+\alphaH_c(\pi(\cdot|s_{t+1}))","The modified Bellman operator $\mathcal{T}_c^\pi$ for iterative Q-value computation with causality-aware entropy, where $V_c$ is the causality-aware value function."
ICML_2024_oral_1,5,\frac{n_{i}^{l}(x)}{\frac{1}{N^{l}}\sum_{k\in l}n_{k}^{l}}\leq\tau,where \(\tau\) is a constant serving as a threshold to determine the gradient dormancy of neurons in each layer,n_i^l <\epsilon,Neuron \(i\) in layer \(l\) is gradient-dormant if the L2 norm of its weight gradients \(n_i^l\) is less than a small positive threshold \(\epsilon\).
ICML_2024_oral_1,6,\alpha_{\tau}=\frac{\sum_{l\in\phi}N_{\tau}^{l}}{\sum_{l\in\phi}N^{l}},,\alpha_{\tau}=\frac{N_{\tau}^{l}}{\sum_{l} N^{l}},where \(N_{\tau}^{l}\) is the total number of gradient-dormant neurons in the neural network and \(N^{l}\) is the number of neurons in layer \(l\).
ICML_2024_oral_1,7,"\theta_{t}=(1-\eta)\theta_{t-1}+\eta\phi_{i},\\phi_{i}\siminitializer",,\theta\leftarrow (1-\eta)\theta+\eta\theta_{init},"The reset operation for neural network parameters, where $\theta$ represents current parameters, $\theta_{\text{init}}$ denotes initial parameters, and $\eta$ is the reset factor controlling the magnitude of perturbation."
ICML_2024_oral_10,1,"attention(Q,K,V)=softmax(QK)^{T}/\sqrt{d})V",,"Attention(Q, K, V)=softmax\left(\frac{QK^T}{\sqrt{d_k}}\right) V",The attention mechanism computes a weighted sum of the value vectors (V) using weights derived from the softmax of scaled dot products between the query (Q) and key (K) vectors.
ICML_2024_oral_10,2,"d\hat{x}_{t}=f(\hat{x}_{t},t)dt+g(t)dw",,"dx=f(x, t)dt+g(t)dw","Here, \( x \) is the state variable, \( t \) is time, \( f \) and \( g \) are the drift and diffusion coefficients respectively, and \( w \) is a standard Wiener process."
ICML_2024_oral_10,3,"d\hat{x}_{t}=[f(\hat{x}_{t},t)-g(t)^{2}s(\hat{x}_{t},t) ]dt+g(t)d\tilde{w}",where \(\mathbf{\tilde{w}}\) is a backward-in-time Wiener process,"d\hat{x}_{t}=\left[ f(\hat{x}_{t}, t)-g(t)^2\nabla_{\hat{x}}\log p_t(\hat{x}_t)\right] dt+g(t) d\bar{w}","The reverse-time stochastic differential equation (SDE) for generating samples, where \(\bar{\mathbf{w}}\) is a standard Wiener process running backward in time and \(\nabla_{\mathbf{\hat{x}}} \log p_t(\mathbf{\hat{x}}_t)\) is the score function."
ICML_2024_oral_10,4,"L(\phi)=E_{t,\hat{x}_{0},\hat{x}_{t}}[\lambda (t)\|s_{\phi}(\hat{x}_{t},t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t}|\hat{x}_{0})\|_{2}^{2}]",where \(\lambda\) denotes a positive weighting function,"L(\phi)=E_{t,\hat{x}_0,\hat{x}_t}\left[\lambda(t)\left\| s_{\phi}(\hat{x}_t, t)-\nabla_{\hat{x}_t}\log p_t(\hat{x}_t |\hat{x}_0)\right\|_2^2\right]","The loss function for training the score model \(s_{\phi}\) using denoising score matching, where \(\lambda(t)\) is a weighting function, and the expectation is taken over time \(t\), data \(\mathbf{\hat{x}}_0\), and noisy data \(\mathbf{\hat{x}}_t\)."
ICML_2024_oral_10,5,"\ell(\phi,M_{C},t,\hat{x}_{0},\hat{x}_{t})=\\(1-M_{C})\cdot(s_{\phi}^{M_{E}}(\hat{x}_{t}^{Mc}, t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t}|\hat{x}_{0}))",where \(s_{\phi}^{M_{E}}\) denotes the score model equipped with a specific attention mask \(M_{E}\),"L(\phi)=E_{t,\hat{x}_0,\hat{x}_t, M_C}\left[\lambda(t)\left\| (1-M_C)\odot\left( s_{\phi}\left(\hat{x}_{t}^{M_C}, t\right)-\nabla_{\hat{x}_t}\log p_t(\hat{x}_t |\hat{x}_0)\right)\right\|_2^2\right]","The Simformer training loss function, which applies denoising score matching with a mask \(M_C\) to condition on specific variables, where the expectation is over the time \(t\), the original sample \(\hat{\mathbf{x}}_0\), the noisy sample \(\hat{\mathbf{x}}_t\), and the condition mask \(M_C\), and \(\lambda(t)\) is a weighting function."
ICML_2024_oral_10,6,"L(\phi)=E_{M_{C},t,\hat{x}_{0},\hat{x}_{ t}}[\|\ell(\phi,M_{C},t,\hat{x}_{0},\hat{x}_{t})\|_{2}^{2}]",,"L(\phi)=E_{t,\hat{x}_0, M_C,\hat{x}_t}\left[\lambda(t)\left\| (1-M_C)\odot\left( s_{\phi}^{M_E}(\hat{x}_t^{M_c}, t)-\nabla_{\hat{x}_t}\log p_t(\hat{x}_t |\hat{x}_0)\right)\right\|_2^2\right]","The overall training objective for the Simformer, which is the expectation of the masked denoising score-matching loss over noise levels \(t\), data \(\hat{\mathbf{x}}_0\), condition masks \(M_C\), and noisy samples \(\hat{\mathbf{x}}_t\)."
ICML_2024_oral_10,7,"s(\hat{x}_{t},t|y)\approx s_{\phi}(\hat{x}_{t},t)+\nabla_{\hat{x}_{t}}\log p_{t}(y|\hat{x}_{t})",,"s_{guided}(\hat{x}_t, t)=s_{\phi}^{M_E}(\hat{x}_t, t)+\nabla_{\hat{x}_t}\log p(y |\hat{x}_t)",The guided score is the sum of the model score and the gradient of the log-likelihood of the context \(\mathbf{y}\) given the state \(\hat{\mathbf{x}}_t\).
ICML_2024_oral_10,8,"s_{\phi}(\hat{x}_{t},t|c)\approx s_{\phi}(\hat{x}_{t},t)+\nabla_{\hat{x}_{t}}\log\sigma(-s(t)c(\hat{x}_{t}))",,"s(\hat{x}_{t},t|y)=s_{\phi}(\hat{x}_{t},t)-\nabla_{\hat{x}_{t}} E(\hat{x}_{t},y)","where \( E(\hat{\mathbf{x}}_{t}, \mathbf{y}) \) is an energy function designed for the specific conditioning task."
ICML_2024_oral_101,1,"G(z)=\sum_{j_{1}=0}^{d-1}\cdots\sum_{j_{n}=0}^{d-1}p(j_{1},\ldots,j_{n})z_{1}^ {j_{1}}\cdots z_{n}^{j_{n}}",,"G(z_1,\dots, z_n)=\sum_{a_1=0}^{d-1}\cdots\sum_{a_n=0}^{d-1} p(a_1,\dots, a_n) z_1^{a_1}\cdots z_n^{a_n}","The probability generating function \( G \) for the joint distribution of \( X_1, \dots, X_n \) is defined as a polynomial in variables \( z_1, \dots, z_n \) with coefficients given by the joint probabilities \( p(a_1, \dots, a_n) \)."
ICML_2024_oral_101,2,"f(V_{1},...,V_{n},E_{1,N(1,1)},...,E_{n,N(n,3)})=\prod_{i=1}^{n}\sum_{j\in N(i )}E_{i,j}V_{j}",,f=\prod_{i=1}^{n}\left(\sum_{j\in N(i)} V_j\right),The polynomial f is defined as the product over all vertices u_i of the sum of the formal variables V_j for each neighbor j of u_i.
ICML_2024_oral_101,3,"\Pr[V_{1}=1,\ldots,V_{n}=1]=h(1,\ldots,1)=\frac{\#PM(G)}{3^{n}}",,"\Pr[V_1=1, V_2=1,\ldots, V_n=1]=\frac{\#PM(G)}{3^n}",The marginal probability that all \(V_j\) variables are 1 equals the number of perfect matchings in graph \(G\) divided by \(3^n\).
ICML_2024_oral_101,4,"f(z_{1},...,z_{n})=\sum_{s=(s_{1},\ldots,s_{n})\in\{0,1,\ldots,k-1\}^{n}}c_{s}\cdot\prod_{i=1}^{n}z_{i}^{s_{i}}",,"f(z_1,\dots, z_n)=\sum_{a_1=0}^{k-1}\cdots\sum_{a_n=0}^{k-1} p(a_1,\dots, a_n) z_1^{a_1}\cdots z_n^{a_n}",The probability generating function for the joint distribution of k-nary random variables.
ICML_2024_oral_101,5,"g(x_{1},\overline{x_{1}},...,x_{n},\overline{x_{n}})=f(\frac{x_{1}}{\overline{ x_{1}}},\frac{x_{2}}{\overline{x_{2}}},...,\frac{x_{n}}{\overline{x_{n}}})\cdot\prod_{i=1}^{n}\overline{x_{i}}",,"\sum_{s_1\in V_1,\ldots, s_n\in V_n} c_s",The selective marginal probability of the event that each \(X_i\) is in \(V_i\).
ICML_2024_oral_101,6,m^{\prime}=c_{S}\cdot(\prod_{i\in S}\frac{x_{i}}{\overline{x_{i}}})\cdot(\prod _{j=1}^{n}\overline{x_{j}})=c_{S}(\prod_{i\in S}x_{i})\cdot(\prod_{i\notin S}\overline{x_{i}}),,m'=c_{S}\cdot\prod_{i\in S} x_{i}\cdot\prod_{i\notin S}\overline{x_{i}},The monomial in g corresponding to a monomial m in f is the coefficient c_S multiplied by the product of x_i for indices i in S and \overline{x_i} for indices i not in S.
ICML_2024_oral_101,7,"& f(x_{1}(1+\overline{x_{1}}),x_{2}(1+\overline{x _{2}}))\cdot(1-\overline{x_{1}})(1-\overline{x_{2}})\\&=(0.6x_{1}x_{2}(1+\overline{x_{1}})(1+\overline{x_{2}})\\&\quad+0.4x_{1}(1+\overline{x_{1}}))(1-\overline{x_{1}})(1-\overline{x_{2}})\\&=0.6x_{1}x_{2}+0.4x_{1}(1-\overline{x_{2}})\+\higher degree terms",,m^{\prime}=c_{S}\cdot\left(\prod_{i\in S}x_{i}\right)\cdot\left(\prod_{i\notin S}\overline{x_{i}}\right),The transformed monomial in the nonmonotone PC corresponding to the monomial \(m\) in the original PGC.
ICML_2024_oral_101,8,"P=\sum_{j_{1}=0}^{d-1}\cdots\sum_{j_{n}=0}^{d-1}\Pr[X_{1}=j_{1},\ldots,X_{n}=j _{n}]z_{1,j_{1}}\cdots z_{n,j_{n}}",,"& f(x_{1}(1+\overline{x_{1}}),x_{2}(1+\overline{x_{2}}))\cdot(1-\overline{x_{1}})(1-\overline{x_{2}})\\&=(0.6x_{1}x_{2}(1+\overline{x_{1}})(1+\overline{x_{2}})\\&\quad+0.4x_{1}(1+\overline{x_{1}}))(1-\overline{x_{1}})(1-\overline{x_{2}})\\&=0.6x_{1}x_{2}+0.4x_{1}(1-\overline{x_{2}})\+\higher degree terms","The expansion of the example polynomial after substitution and first-order approximation, showing the desired terms and higher-degree terms."
ICML_2024_oral_101,9,"e_{i,j}=1&if $j=a_{i$},\\0&otherwise",,"e(z_{i,j})=1 &if  j\in A_i\\0 &otherwise","Definition of the evaluation vector e for the set-multilinear polynomial P, where e assigns 1 to z_{i,j} if j is in the set A_i and 0 otherwise."
ICML_2024_oral_101,10,"v_{i,j}=1&if $j\in A_{i$},\\0&otherwise",,"e_{i,j}=1&if j=a_{i}\\0&otherwise","The vector \(e\) sets \(e_{i,j} = 1\) when \(j\) equals the observed value \(a_i\) for variable \(X_i\), and \(0\) otherwise."
ICML_2024_oral_101,11,"P(v)=\sum_{j_{1}\in A_{1}}\cdots\sum_{j_{n}\in A_{n}}\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}]\cdot 1 || =\Pr[X_{1}\in A_{1},\ldots,X_{n}\in A_{n}]",,"v_{i,j}=1 &if  j\in A_i\\0 &otherwise",The evaluation vector for the polynomial to compute the marginal probability for each variable being in a specified set.
ICML_2024_oral_101,12,"f(a)=\sum_{a\in\Delta^{|A|}}\alpha_{a}\prod_{i\in A}z_{i,a_{i}},\quad g(b)=\sum_{b\in\Delta^{|B|}}\beta_{b}\prod_{j\in B}z_{j,b_{j}}",where \(\alpha_{a}=\Pr[X_{A}=a]\) and \(\beta_{b}=\Pr[X_{b}=b]\),"P(v)=\sum_{j_{1}\in A_{1}}\cdots\sum_{j_{n}\in A_{n}}\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}]=\Pr[X_{1}\in A_{1},\ldots, X_{n}\in A_{n}]",The evaluation of the set-multilinear polynomial at the point v yields the marginal probability that each variable \(X_i\) takes a value in its respective set \(A_i\).
ICML_2024_oral_101,13,"f(a,b^{\prime})= || (\sum_{a\in\Delta^{|A|}}\alpha_{a}\prod_{i\in A}z_{i,a_{i}} )\prod_{j\in B\setminus A}\frac{1}{d}(z_{j,0}+\cdots+z_{j,d-1})",,"f_{ext}=f\cdot\prod_{i\in B\setminus A}\left(\frac{1}{d}\sum_{k=0}^{d-1} z_{i,k}\right)","The extended probability generating function for the set \(A \cup B\), defined as the product of \(f\) and uniform distribution polynomials for variables in \(B \setminus A\)."
ICML_2024_oral_104,1,call-count(u)=\sum_{v\in Q(u)}(1+call-count(v)),,R(u)=|Q(u)|+\sum_{v\in Q(u)} R(v),"The recurrence relation for the recursive call count of node $u$, defined as the number of edges in the recursive tree $\mathcal{T}_{u}$."
ICML_2024_oral_104,2,\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots || \leq\sigma(u_{L-1})\leq\pi(u_{L-1})\leq\sigma(u_{L})\leq\pi(u_{L}),,"\sigma(u_i)\geq\pi(u_{i-1})\quadfor all  i=1,\dots, L","A path is a query path if and only if for every consecutive pair of nodes, the settled time of the later node is at least the rank of the earlier node."
ICML_2024_oral_104,3,"\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots || \leq\sigma(u_{L-2})\leq\pi(u_{L-2})\leq\min(\sigma(u_{L-1}),\sigma (u_{L}))",,\sigma(u_0)\leq\pi(u_0)\leq\sigma(u_1)\leq\pi(u_1)\leq\cdots\leq\sigma(u_{L-2})\leq\pi(u_{L-2})\leq\sigma(u_{L-1})\leq\pi(u_{L-1})\quadand\quad\pi(u_{L-2})\leq\sigma(u_L)\leq\pi(u_L),"The necessary and sufficient conditions for a path \((u_0, u_1, \dots, u_L)\) of length \(L \geq 2\) to be an extended query path."
ICML_2024_oral_104,4,\sigma(u_{0})<\sigma(u_{1}) and\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq || \cdots\leq\pi(u_{L-2})\leq\sigma(u_{L-1})=\sigma(u_{L}),,"\sigma(u_0) <\sigma(u_1)\quadand\quad\sigma(u_{L-1})=\sigma(u_L)\quadand\\\sigma(u_0)\leq\pi(u_0)\leq\sigma(u_1)\leq\pi(u_1)\leq\cdots\leq\sigma(u_{L-2})\leq\pi(u_{L-2})\leq\min(\sigma(u_{L-1}),\sigma(u_L))",The inequalities defining an expensive extended query path for nodes \(u_0\) to \(u_L\).
ICML_2024_oral_104,5,"E_{\pi}|X|\leq 2E\Big{[}\sum_{(u,v)\in E}1 (\sigma(u)\neq\sigma(v))\Big{]}",,"E_{\pi}[|X|]\leq 2\cdotE_{\pi}\bigl[\bigl|\bigl\{ (u,v)\in E :\sigma(u)\neq\sigma(v)\bigr\}\bigr|\bigr]",The expected number of expensive extended query paths is at most twice the expected number of edges cut by the Pivot algorithm.
ICML_2024_oral_104,6,"\Phi_{t}(a,b)=2|D_{t}(a,b)|+|Q_{t}(a,b)| || \Psi_{t}(a,b)=2|D_{t}(a,b)|+|X_{t}(a,b)|",,"\Phi_t=|D_t(a,b)|+|Q_t(a,b)|","The potential function combining the number of dangerous paths and query paths starting with edge (a,b) at time t."
ICML_2024_oral_106,1,"p(u)=\prod_{i=1}^{n}p(u_{i}|u_{1},...,u_{i-1},\Theta)",,\log P(U)=\sum_{i=1}^{n}\log P(u_i\mid u_{<i}),The log-likelihood of the corpus \(\mathcal{U}\) is the sum of the log-probabilities of each token \(u_i\) given the preceding tokens \(u_{<i}\).
ICML_2024_oral_106,2,L=-log\;p(u),,"L=-\sum_{i=1}^{n}\log p(u_i\mid u_{1},\ldots, u_{i-1},\Theta)",The negative log-likelihood loss minimized during training for the sequence.
ICML_2024_oral_106,3,"p(x)=\prod_{i=1}^{n}p(x_{i}|x_{1},...,x_{i-1},\Theta)",,"p(X)=\prod_{i=1}^{n} p(x_i | x_1,\dots, x_{i-1},\Theta)",The autoregressive probability of the image \( X \) modeled as the product of conditional probabilities for each pixel given all preceding pixels in the sequence.
ICML_2024_oral_106,4,L=-log\;p(x),,L=-\log p(x),aiming to minimize the negative log-likelihood of the target pixels
ICML_2024_oral_106,5,"p(s)=\prod_{i=1}^{n}p(s_{i}|s_{1},...,s_{i-1},\Theta)",,"p(s)=\prod_{i=1}^{n} p(s_i | s_1,\ldots, s_{i-1},\Theta)","The autoregressive probability of the cluster sequence \( s \) is the product of the conditional probabilities of each cluster \( s_i \) given all preceding clusters \( s_1, \ldots, s_{i-1} \) and model parameters \( \Theta \)."
ICML_2024_oral_106,6,"L_{G}=-\sum_{i=1}^{n}cosine(G(f(x_{s_{1}:s_{i-1}});\theta_{G}),f_{\phi }(x)_{s_{i}})","where \(f(\cdot)\) is the encoder, \(f_{\phi}(x)_{s_{i}}\) is the semantically enriched tokens corresponding to the cluster \(s_{i}\), \(G(\cdot;\ \theta_{G})\) is the generative decoder for autoregressive prediction, and \(cosine\) is the cosine similarity loss","p(t)=\prod_{i=1}^{n}p(t_{i}|t_{1},...,t_{i-1},\Theta)","This equation represents the autoregressive probability of the sequence of semantic tokens \( t \), where each token \( t_i \) is predicted based on the preceding tokens \( t_1 \) to \( t_{i-1} \)."
ICML_2024_oral_106,7,"L_{D}=-\sum_{i=1}^{n}cosine(D(f(x_{s_{1}:s_{i-1}});\theta_{D}),f_{\phi}(x)_{s_{1}:s_{i-1}})","where \(D(\cdot;\ \theta_{D})\) is the discriminative decoder, tasked with predicting the semantic tokens of visible pixels","L_{sup}=-\sum_{i\inV}CE\left(g_{\psi}(f(x)_{s_i}), y_{s_i}\right)","where \( \mathcal{L}_{sup} \) is the additional supervision loss on visible clusters, \( \mathcal{V} \) denotes the set of visible cluster indices, \( g_{\psi} \) is a classification head, \( f(x)_{s_i} \) is the semantic token for cluster \( s_i \), \( y_{s_i} \) is a supervised target for the cluster, and CE is the cross-entropy loss."
ICML_2024_oral_107,1,"L_{eval}=-\log p_{M}(<\)cc\(>\)\(|X_{l},X_{r})",,L_{eval}=-\left[ y\log(p)+(1-y)\log(1-p)\right],"The self-assessment loss \(\mathcal{L}_{\text{eval}}\) is a binary cross-entropy loss where \(y\) is the true label indicating whether retrieved context improves generation (1 if \(\text{label}\) is true, 0 otherwise), and \(p\) is the model's predicted probability for outputting the \(\langle \text{cc} \rangle\) token immediately after \(\langle \text{eof} \rangle\)."
ICML_2024_oral_107,2,"L_{gen}=-\log p_{M}(Y|X_{l},X_{r},CC),& if label\\-\log p_{M}(Y|X_{l},X_{r}),&otherwise",,"L_{gen}=-\sum_{t=1}^{|Y|}\log p_{M}(y_t\mid S, y_{<t})","The generation loss \(\mathcal{L}_{gen}\) is the cross-entropy loss over target tokens \(y_t\) given input context \(S\) and preceding tokens \(y_{<t}\), where \(S\) includes in-file context and retrieved context \(CC\) when \(label\) is true."
ICML_2024_oral_107,3,"ES(\hat{Y},Y)=\frac{1-Lev(\hat{Y},Y)}{\max(|\hat{Y}|,|Y|)}",where \(Lev\) is the Levenshtein distance (Levenshtein et al,"ES(Y,\hat{Y})=1-\frac{edit\_distance(Y,\hat{Y})}{\max(|Y|, |\hat{Y}|, 1)}","Edit Similarity (ES) between the target code \(Y\) and the model's prediction \(\hat{Y}\) is defined as one minus the normalized Levenshtein distance, with normalization by the maximum sequence length (minimum length 1)."
ICML_2024_oral_109,1,"\operatorname*{arg\,max}_{k=1,\dots,K}\,\cos(\phi(x),\psi(t_{k}))",,"\hat{y}=\arg\max_{k\in\{1,\dots,K\}}\frac{\phi(x)^\top\psi(t_k) }{\|\phi(x)\|_2\cdot\|\psi(t_k)\|_2 }",The predicted class \(\hat{y}\) for image \(x\) is the class \(k\) that maximizes the cosine similarity between the image embedding \(\phi(x)\) and the text embedding \(\psi(t_k)\) of the prompt for class \(k\).
ICML_2024_oral_109,2,"f_{k}(\phi,x)=\cos(\phi(x),\psi(t_{k}))=\langle\frac{\phi(x)}{\|\phi (x)\|_{2}},\frac{\psi(t_{k})}{\|\psi(t_{k})\|_{2}}\rangle",,f_k(x)=\phi(x)^\top\psi(t_k),The logit for class \(k\) is defined as the dot product between the image embedding \(\phi(x)\) and the fixed text embedding \(\psi(t_k)\).
ICML_2024_oral_109,3,"\operatorname*{arg\,max}_{k=1,\dots,K}\,f_{k}(\phi,z)\neq y,\quad\|z-x\|_{p}\leq\varepsilon,\quad z\in I",where \(\varepsilon\) is the perturbation size,"\|z-x\|_p\leq\epsilon\quadand\quad f_y(\phi, z)\leq\max_{k\neq y} f_k(\phi, z)","An adversarial image \(z\) must satisfy an \(\ell_p\)-norm bound \(\|z - x\|_p \leq \epsilon\) and induce misclassification where the true class logit \(f_y(\phi, z)\) is at most the maximum logit over incorrect classes."
ICML_2024_oral_109,4,"L_{TeCoA}(y,f(\phi,x))=-\log(\frac{e^{f_{y}(\phi,x)}}{\sum_{k=1}^ {K}e^{f_{k}(\phi,x)}})",,"\min_{\phi}E_{(x,y)\simD}\left[\max_{\|z-x\|_{\infty}\leq\varepsilon}-\log\frac{\exp(f_y(\phi, z))}{\sum_{k=1}^{K}\exp(f_k(\phi, z))}\right]",The training objective minimizes the expected worst-case cross-entropy loss for adversarial examples within an \(\ell_\infty\)-ball of radius \(\varepsilon\).
ICML_2024_oral_109,5,"\phi_{FT}=\operatorname*{arg\,min}_{\phi}\sum_{i=1}^{n}\max_{\|z-x_{i}\|_{\infty}\leq\varepsilon}L_{TeCoA}(y_{i},f(\phi,z))",where the inner problem is approximately solved with projected gradient descent (PGD) during training and \(\phi_{\mathrm{FT}}\) indicates the weights of the robust CLIP vision encoder,"\min_{\phi}\frac{1}{n}\sum_{i=1}^{n}\max_{\|z_i-x_i\|_{\infty}\leq\varepsilon} L_{TeCoA}(y_i, f(\phi, z_i))",The adversarial training objective minimizes the average over the training set of the maximum TeCoA loss within an \(\ell_\infty\)-ball of radius \(\varepsilon\) around each training image.
ICML_2024_oral_109,6,"L_{FARE}(\phi,x)=\max_{\|z-x\|_{\infty}\leq\varepsilon}\|\phi(z)-\phi_{Org}(x)\|_{2}^{2}",,"L_{embed}(\phi, x)=\left\|\phi(x)-\phi_{Org}(x)\right\|_{2}^{2}+\max_{\|z-x\|_{\infty}\leq\varepsilon}\left\|\phi(z)-\phi_{Org}(x)\right\|_{2}^{2}",The embedding loss for image \(x\) is the sum of the squared L2 distance between the fine-tuned encoder output and the original encoder output on the clean image and the worst-case squared L2 distance of the adversarial embedding from the original clean embedding over adversarial perturbations within an \(\ell_\infty\)-ball of radius \(\varepsilon\).
ICML_2024_oral_109,7,"\phi_{FT}=\operatorname*{arg\,min}_{\phi}\sum_{i=1}^{n}L_{ FARE}(\phi,x_{i})",,\min_{\phi}\sum_{i=1}^{n}\max_{\|z-x_i\|_{\infty}\leq\varepsilon}\|\phi(z)-\phi_{Org}(x_i)\|_{2}^{2},The overall training objective minimizes the sum over all images of the maximum embedding deviation under adversarial perturbation.
ICML_2024_oral_109,8,"|\cos(\phi_{FT}(x),\psi(t))-\cos(\phi_{Org},\psi(t))| || \leq\min(\frac{2}{\|\phi_{Org}(x)\|_{2}},\frac{2}{\|\phi_{FT}(x)\|_{2}})\|\phi_{FT}(x)-\phi_{Org}(x)\|_{2}",,"\left|\cos\left(\phi_{FT}(x),\psi(t)\right)-\cos\left(\phi_{Org}(x),\psi(t)\right)\right|\leq\frac{2}{\min\left(\|\phi_{Org}(x)\|_2,\|\phi_{FT}(x)\|_2\right)}\|\phi_{FT}(x)-\phi_{Org}(x)\|_2",Upper bound on the absolute difference between the cosine similarities of the original and fine-tuned image embeddings with a fixed text embedding.
ICML_2024_oral_110,1,F_{iso}=\{f:\Omega\subsetR^{d}\to&R^{D}:\Df^{\top}(s)Df(s)=Id\\&for all s\in\Omega\},,J_f(s)^\top J_f(s)=I_d\quad\forall s\in\Omega,The local isometry condition requires the Jacobian matrix of $f$ at each $s$ to have orthonormal columns.
ICML_2024_oral_110,2,"\Theta_{p}^{p}(f,\Omega)=\int_{\Omega}&dist(Df(s),SO(d))^{p}\\&+dist\big{(}(Df)^{-1}(s),SO(d)\big{)}^{p}\,ds",,\Theta(f)=\sup_{s\in\Omega}\| Df(s)^\top Df(s)-Id\|_{F},"The deviation measure \(\Theta(f)\) quantifies the distance of the function \(f\) from being a local isometry, defined as the supremum over the domain \(\Omega\) of the Frobenius norm of the difference between the Jacobian product and the identity matrix."
ICML_2024_oral_110,3,"\Theta_{p}^{p}(f,\Omega)=&\int_{\Omega }dist^{p}(Df(z),SO(d,T_{f(z)}M))\\&+dist^{p}\big{(}(Df)^{-1}(z),SO(T_{f(z)}M,d)\big{)}\,dz","where \(T_{f(z)}M\) denotes the tangent space of \(M\) at \(f(z)\) and \(\mathrm{SO}(d,T_{f(z)}M)\) denotes the set of orthogonal matrices \(Q\in\mathbb{R}^{D\times d}\) (i","\Theta_{p}^{p}(f,\Omega)=\int_{\Omega}&dist\big{(}Df(s),St(D,d)\big{)}^{p}\\&+dist\big{(}(Df(s))^{+},St^{\top}(d,D)\big{)}^{p}\,ds","The measure \(\Theta_p^p\) for a function \(f: \Omega \subset \mathbb{R}^d \to \mathbb{R}^D\) with \(D \geq d\), defined by integrating the \(p\)-th power of the distance of the derivative to the Stiefel manifold of orthonormal \(D \times d\) matrices and the distance of the pseudo-inverse to the set of \(d \times D\) matrices with orthonormal rows."
ICML_2024_oral_110,4,"MCC(\tilde{S},\tilde{S})=\max_{\pi\in S_{d}}d^{-1}\sum_{i=1}^{ d}|\rho(S_{i},\tilde{S}_{\pi(i)})|","where \(\rho(X,Y)=\operatorname{Cov}(X,Y)/(\operatorname{Var}(X)\operatorname{Var}( Y))^{1/2}\) denotes the correlation coefficient","\[MCC(\tilde{S}, S)=\frac{1}{d}\max_{\pi\in\Pi_d}\sum_{i=1}^{d} |corr(\tilde{S}_{\pi(i)}, S_i)|\]",The mean correlation coefficient (MCC) for a pair of d-dimensional random variables \(\tilde{S}\) and \(S\) is defined as the maximum average absolute correlation between their components over all permutations \(\pi\).
ICML_2024_oral_110,5,"MCC(\hat{S},S)\geq 1-C\Theta_{p}^{2}(f)",,"1-MCC(S,\hat{S})\leq C\cdot\Theta_p(f,\Omega)",Bound on the deviation of the mean correlation coefficient from one in terms of the isometry deviation measure.
ICML_2024_oral_110,6,"\min_{L}&\|u-L\|_{L^{q}(\Omega)}\\&\leq C(\Omega,p)(\int_{\Omega}dist(Du(s),SO (d))^{p}\,ds)^{\frac{1}{p}}",,"\inf_{\substack{R\inR^{D\times d}\\R^\top R=Id\\b\inR^D}}\| f-(R\cdot+b)\|_{W^{1,p}(\Omega)}\leq C\Theta_p(f,\Omega)",Bound on the Sobolev distance between the mixing function \(f\) and the closest affine map with orthonormal columns.
ICML_2024_oral_110,7,"M(f_{*}P)=\{&(g,Q,\Omega^{\prime}):g\inF(\Omega^{\prime}), where \\g_{*}Q=f_{*}P,\,supp(Q)=\Omega^{\prime}\}",,"\min_{L}&\|u-L\|_{L^{q}(\Omega)}\\&\leq C(\Omega,p)\left(\int_{\Omega}dist(Du(s),SO (d))^{p}\,ds\right)^{\frac{1}{p}}","This bound states that the minimum \(L^q\) distance (with \(q = pd/(d-p)\)) from a function \(u\) to an affine map \(L(s) = A s + b\) where \(A \in \mathrm{SO}(d)\) is controlled by a constant \(C(\Omega,p)\) times the \(L^p\) norm of the distance of the gradient \(Du(s)\) to \(\mathrm{SO}(d)\)."
ICML_2024_oral_110,8,"&(g,Q,\Omega^{\prime})\in\\&\operatorname*{argmin}_{(\bar{g},\bar{Q},\Omega)\inM(f,P)}\int_{\Omega}dist((D\bar{g})^{-1}(g(s)),SO(d))^ {p}\,\bar{Q}(ds)",,"M(f_{*}P)=\{ &(g,Q,\Omega') : g\inF(\Omega'), where \\& g_{*}Q=f_{*}P,\,supp(Q)=\Omega'\}","The set of all models \((g, \mathbb{Q}, \Omega')\) that generate the observed distribution \(f_*\mathbb{P}\) via \(g_*\mathbb{Q} = f_*\mathbb{P}\) and the support of \(\mathbb{Q}\) is \(\Omega'\)."
ICML_2024_oral_110,9,"\|h\|_{P,q}\leq C_{1}\Theta_{p}(f,\Omega)",,"&(g,Q,\Omega^{\prime})\in\\&\operatorname*{argmin}_{(\bar{g},\bar{Q},\bar{\Omega})\inM(f_{*}P)}\int_{\bar{\Omega}}dist\big{(}(D\bar{g})^{-1}(s),SO(d)\big{)}^{p}\bar{Q}(ds)","The triple (g, Q, Omega') minimizes the integral of the p-th power of the distance between the inverse derivative of g and the rotation group SO(d) over the latent domain with respect to the latent measure, among all models generating the observational distribution."
ICML_2024_oral_110,10,x=f(s)=As+\eta h(s),where \(h:\mathbb{R}^{d}\to\mathbb{R}^{d}\) is a non-linear function and \(\eta\in\mathbb{R}\) is a small constant,X=A S+g(S),where \(A\) is a linear mixing matrix and \(g\) is a nonlinear perturbation function.
ICML_2024_oral_110,11,H(w)=EG(w^{\top}\Sigma_{X}^{-\frac{1}{2}}X),where \(\Sigma_{X}\) denotes the covariance matrix of \(X\) so that \(\Sigma_{X}^{-\frac{1}{2}}X\) is whitened and \(G\) is the so-called contrast function,x=f(s)=As+\eta h(s),where \(h:\mathbb{R}^{d}\to\mathbb{R}^{d}\) is a non-linear function and \(\eta\in\mathbb{R}\) is a small constant.
ICML_2024_oral_110,12,\bar{w}_{i}=(AA^{\top})^{\frac{1}{2}}A^{-\top}e_{i},,H(w)=E G(w^{\top}\Sigma_{X}^{-\frac{1}{2}} X),The function \(H(w)\) is the expected value of the contrast function \(G\) applied to the projection of the whitened data \(\Sigma_X^{-\frac{1}{2}} X\) onto the direction \(w\).
ICML_2024_oral_110,13,"|G^{(k)}(x)|\leq C_{g}(1+|x|)^{\max(d_{g}-k,0)}",where \(G^{(k)}\) denotes the \(k\)-th derivative of \(G\),\bar{w}_{i}=(AA^{\top})^{\frac{1}{2}}A^{-\top}e_{i},The vector \(\bar{w}_i\) that recovers the i-th source component \(S_i\) when applied to the whitened data in the linear ICA setting.
ICML_2024_oral_110,14,E(|S|^{q})=M,,"\max_{i=1,\ldots,d}E(|S_i|^q)\leq M",The maximum q-th moment of the latent sources is bounded by M.
ICML_2024_oral_110,15,E(S_{i}g(S_{i})-g^{\prime}(S_{i}))=\alpha_{i},,E(|S|^{q})=M,The q-th moment of the Euclidean norm of the latent sources S is bounded by the constant M.
ICML_2024_oral_111,1,"L_{sup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE} (M_{i,j}^{l},Y_{i,j}^{l})","where \(M_{i,j}^{l}\) denotes the prediction mask of Burn-In model for the \(j\)-th pixel of \(i\)-th labeled image, \(Y_{i,j}^{l}\) denotes the corresponding ground truth, \(\mathcal{L}_{BCE}\) denotes binary cross entropy loss (Csiszar, 2008)","L_{sup}=-\frac{1}{|D_l|}\sum_{x_i\inD_l}\sum_{c=1}^{C} y_{i,c}\log(f_{\theta}(x_i)_c)","Equation 1 defines the supervised cross-entropy loss for the burn-in stage, where $\mathcal{D}_l$ is the labeled dataset, $C$ is the number of classes, $y_{i,c}$ is the one-hot encoded label for sample $x_i$ at class $c$, and $f_{\theta}(x_i)_c$ is the model's predicted probability for class $c$."
ICML_2024_oral_111,2,"\theta_{t}arrow\theta,\theta_{s}arrow\theta","where \(\theta_{t},\theta_{s},\theta\) denote the parameters of the teacher, student and Burn-In model, respectively","L_{total}=\frac{1}{|B|}\left(\sum_{i\inB_l}\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE}(S_{i,j}^{l}, Y_{i,j}^{l})+\lambda\sum_{i\inB_u}\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE}(S_{i,j}^{u}, T_{i,j}^{u})\right)","where \( \mathcal{B} \) is the batch of images, \( \mathcal{B}_l \) and \( \mathcal{B}_u \) denote the sets of labeled and unlabeled images in the batch, \( S_{i,j}^{l} \) and \( S_{i,j}^{u} \) represent the student model's predictions for the \( j\)-th pixel of the \( i\)-th labeled and unlabeled image respectively, \( Y_{i,j}^{l} \) is the ground truth for the \( j\)-th pixel of the \( i\)-th labeled image, \( T_{i,j}^{u} \) is the teacher model's prediction for the \( j\)-th pixel of the \( i\)-th unlabeled image, \( \mathcal{L}_{BCE} \) denotes the binary cross entropy loss, and \( \lambda \) is a weighting factor."
ICML_2024_oral_111,3,"L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE} (M_{i,j}^{u},\hat{M}_{i,j}^{u})","where \(M_{i,j}^{u}\) and \(\hat{M}_{i,j}^{u}\) denote the predicted mask for \(j\)-th pixel of \(i\)-th unlabeled image by student and teacher, respectively","\hat{Y}_{i,j}^u=M_{i,j}^{u,t}","where \(\hat{Y}_{i,j}^u\) denotes the pseudo-label for the \(j\)-th pixel of the \(i\)-th unlabeled image, and \(M_{i,j}^{u,t}\) denotes the prediction mask of the teacher model for the same pixel."
ICML_2024_oral_111,4,L=\lambda_{sup}L_{sup}+\lambda_{unsup}L_{unsup},where \(\lambda_{sup}\) and \(\lambda_{unsup}\) is the hyperparameter of supervised loss \(\mathcal{L}_{sup}\) and unsupervised loss \(\mathcal{L}_{unsup}\),L_{total}=L_{sup}+L_{unsup},where \(\mathcal{L}_{sup}\) denotes the supervised loss for the student on labeled data and \(\mathcal{L}_{unsup}\) denotes the unsupervised loss for the student on unlabeled data.
ICML_2024_oral_111,5,\theta_{t}arrow\alpha\theta_{t}+(1-\alpha)\theta_{s},"where \(\alpha\) is the decay coefficient of EMA, typically set within the small range of 0",\theta_t\leftarrow\beta\theta_t+(1-\beta)\theta_s,"where \(\theta_t\) and \(\theta_s\) denote the parameters of the teacher and student models, respectively, and \(\beta\) is the decay hyperparameter controlling the update rate."
ICML_2024_oral_111,6,"s^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i, j,k}^{u})}{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cup\widetilde{M}_{i, j,k}^{u})}","where \(\hat{M}_{i,j}^{u}\) and \(\widetilde{M}_{i,j,k}^{u}\) denote the pseudo-labels and \(k\)-th segment mask generated by SAM for \(j\)-th pixel of \(i\)-th unlabeled image \(\mathcal{I}_{i}^{u}\), respectively","IoU(\hat{M}_i^{u}, S_{i,k})=\frac{ |\hat{M}_i^{u}\cap S_{i,k} | }{ |\hat{M}_i^{u}\cup S_{i,k} | }","where \(\hat{M}_i^{u}\) denotes the pseudo-label mask for the \(i\)-th unlabeled image, \(S_{i,k}\) denotes the \(k\)-th candidate segment generated by SAM for the \(i\)-th image, and \(|\cdot|\) denotes the cardinality of the set of foreground pixels."
ICML_2024_oral_111,7,"s_{1}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{ i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u})+\epsilon}",where \(\epsilon\) is the smoothing factor to prevent a denominator of zero,"r^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i, j,k}^{u})}{\sum_{j=1}^{H\times W}\hat{M}_{i,j}^{u}}",where \(r^{k}\) denotes the overlap ratio between the pseudo-label and the \(k\)-th candidate segment mask generated by SAM for the \(i\)-th unlabeled image.
ICML_2024_oral_111,8,"s_{2}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M} _{i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\widetilde{M}_{i,j,k}^{u} )}",,"s_{2}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i,j,k}^{u})}{\sum_{j=1}^{H\times W}\widetilde{M}_{i,j,k}^{u}+\epsilon}","where \(s_{2}^{k}\) denotes the overlap ratio for the \(k\)-th candidate mask, \(\hat{M}_{i,j}^{u}\) and \(\widetilde{M}_{i,j,k}^{u}\) denote the pseudo-labels and \(k\)-th segment mask generated by SAM for the \(j\)-th pixel of \(i\)-th unlabeled image, respectively, and \(\epsilon\) is the smoothing factor."
ICML_2024_oral_111,9,"\Psi(\hat{M}^{u}_{i,j})=\gamma-\frac{1}{\sqrt{2\pi\sigma}}\exp(-\frac{(\hat{M}^{u}_{i,j}-\mu)^{2}}{2\sigma^{2}})","where \(\gamma,\sigma^{2},\mu\) are hyperparameters, which are set to 1",\Psi(p)=2 |p-0.5|,"where \( p \) denotes the confidence score of a pixel (i.e., the predicted probability from the teacher model)."
ICML_2024_oral_111,10,"L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}\Psi(\hat{M}^{u} _{i,j})*L_{BCE}(M^{u}_{i,j},\hat{M}^{u}_{i,j})",,"L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}\Psi(\hat{M}_{i,j}^{u})\cdotL_{BCE}(M_{i,j}^{u},\hat{M}_{i,j}^{u})","where \(\Psi(\hat{M}_{i,j}^{u})\) denotes the confidence-based weight for the \(j\)-th pixel of the \(i\)-th unlabeled image computed by the mapping function in Eq. 9, and \(\mathcal{L}_{BCE}\) is the binary cross entropy loss."
ICML_2024_oral_113,1,"\nabla_{\theta}J(\pi_{\theta})=\operatorname*{E}_{s\sim\rho_{d},a\sim\pi(\cdot|s)}[\nabla_{\theta}\log(\pi_{\theta}(a))\hat{A}^{\pi_{\theta}}(s,a)]","where \(\hat{A}^{\pi_{\theta}}(s,a)\) is an advantage function that estimates the contribution of the transition to the gradient","\nabla_\thetaJ(\pi)=E_{\tau\sim\pi}\left[\sum_{t=0}^{T-1}\nabla_\theta\log\pi_\theta(a_t | s_t)\cdot\left(\sum_{k=t}^{T-1}\gamma^{k-t} r(s_k, a_k)\right)\right]",The policy gradient is the expected sum over trajectories of the gradient of the log-policy at each time step multiplied by the discounted return from that time step.
ICML_2024_oral_113,2,"L_{on}(\pi_{\theta})&=\operatorname*{E}_{\pi_{old}}[\min(r_{t}(\pi_{\theta}),.\\&.clip(r_{t}(\pi_{\theta}),1-\epsilon,1+\epsilon))A_{t}^{\pi_{old}}]",,"L^{CLIP}(\theta)=E_{t}\left[\min\left(\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}\hat{A}_{t},clip\left(\frac{\pi_{\theta}(a_t|s_t)}{\pi_{\theta_{old}}(a_t|s_t)}, 1-\epsilon, 1+\epsilon\right)\hat{A}_{t}\right)\right]","The PPO clipped objective function that restricts policy updates by clipping the probability ratio to the interval \([1-\epsilon, 1+\epsilon]\), where \(\hat{A}_{t}\) is the advantage estimate at time \(t\) under the old policy and \(\epsilon\) is a hyperparameter."
ICML_2024_oral_113,3,"& L_{off}(\pi_{i};X)=\frac{1}{|X|}\sum_{j\inX}\operatorname*{E}_{(s,a)\sim\pi_{j}}[\min (r_{\pi_{i}}(s,a),..\\&..clip(r_{\pi_{i}}(s,a),\mu(1-\epsilon),\mu(1+\epsilon)))A^{\pi_{i,old}}(s,a)]","where \(r_{\pi_{i}}(s,a)=\frac{\pi_{i}(s,a)}{\pi_{j}(s,a)}\) and \(\mu\) is an off-policy correction term \(\mu=\frac{\pi_{i,old}(s,a)}{\pi_{j}(s,a)}\)","L_{agg}(\pi_i)=E_{j\simX, (s,a)\sim\pi_j}\left[\frac{\pi_i(a|s)}{\pi_j(a|s)}\hat{A}^{\pi_i}(s,a)\right]",The objective for updating policy \(\pi_i\) using data from policies \(\pi_j\) (for \(j \in \mathcal{X}\)) by importance sampling with the advantage function of \(\pi_i\).
ICML_2024_oral_113,4,L(\pi_{i})=L_{on}(\pi_{i})+\lambda\cdot L_{off}(\pi_{i};X),,L_{total}(\pi_i)=L_{on}(\pi_i)+\beta\cdot L_{off}(\pi_i;X),"The total loss for policy \(\pi_i\) combines the on-policy PPO loss and the off-policy loss that aggregates data from other policies, scaled by a factor \(\beta\)."
ICML_2024_oral_113,5,"V^{target}_{on,\pi_{j}}(s_{t})=\sum_{k=t}^{t+2}\gamma^{k-t}r_{k}+\gamma^{3}V_{\pi_{j},old}(s_{t+3})",,y_t=r_t+\gamma r_{t+1}+\gamma^2 r_{t+2}+\gamma^3\hat{V}(s_{t+3}),The 3-step return target for the critic update at time step \(t\).
ICML_2024_oral_113,6,"V^{target}_{off,\pi_{j}}(s^{\prime}_{t})=r_{t}+\gamma V_{\pi_{j},old}(s^{\prime}_{t+1})",,"V^{target}_{off,\pi_i}(s_t)=r_t+\gamma V_{\pi_i, old}(s_{t+1})",The off-policy critic target for policy \(\pi_i\) at state \(s_t\) is the immediate reward plus the discounted old value of the next state.
ICML_2024_oral_113,7,"L^{critic}_{on}(\pi_{i})=\operatorname*{E}_{(s,a)\sim\pi_{i}}[( V_{\pi_{i}}(s)-V^{target}_{on,\pi_{i}}(s))^{2}] || L^{critic}_{off}(\pi_{i};X)=\frac{1}{|X|}\sum_{j\inX}\operatorname*{E}_{(s,a)\sim\pi_{j}}[(V_{\pi_{i}}(s)-V^{target}_{off,\pi_{i}}(s))^{2}] || L^{critic}(\pi_{i})=L^{critic}_{on}(\pi_{i})+\lambda\cdot L^{critic}_{off}(\pi_{i})",,"L_{critic}(\pi_i) &=\operatorname*{E}_{(s_t,\ldots)\sim\pi_i}\left[\left( V_{\pi_i}(s_t)-V^{target}_{on,\pi_i}(s_t)\right)^2\right]\\&+\lambda_c\cdot\frac{1}{|X|}\sum_{j\inX}\operatorname*{E}_{(s_t, a_t, r_t, s_{t+1})\sim\pi_j}\left[\left( V_{\pi_i}(s_t)-\left( r_t+\gamma V_{\pi_i,old}(s_{t+1})\right)\right)^2\right]","The critic loss for policy \(\pi_i\) combines the on-policy mean squared error with n-step returns and a scaled off-policy mean squared error using 1-step returns, averaged over the policy set \(\mathcal{X}\)."
ICML_2024_oral_117,1,"Attention(q,K,V)=softmax(\frac{qK^{T}}{\sqrt{d_{model}}})V",,v=softmax\left(\frac{q K^{\top}}{\sqrt{d_{model}}}\right) V,"The output vector $\mathbf{v}$ is computed by the scaled dot-product attention mechanism using the query vector $\mathbf{q}$, keys matrix $K$, and values matrix $V$."
ICML_2024_oral_117,2,"FTr_{i}=\frac{AUC_{i}-AUC_{i}^{b}}{1-AUC_{i}^{ b}},\quadAUC_{i}=\frac{1}{\Delta}\int_{(i-1)\cdot\Delta}^{i\cdot\Delta}p_{i}(t)dt || AUC_{i}^{b}=\frac{1}{\Delta}\int_{0}^{\Delta}p_{i}^{b}(t)dt",,FTr_{i}=\frac{1}{\Delta}\sum_{t=t_i}^{t_i+\Delta-1}\left( p_i(t)-p_i^b(t)\right),The forward transfer for task \(i\) is the normalized area between the method's and baseline's performance curves during the training period of task \(i\).
ICML_2024_oral_117,3,"RT=\frac{1}{N}\sum_{i=2}^{N}\max_{j<i}FTr(j,i)","where \(\text{FTr}(j,i)\) is the forward transfer obtained by training a model from scratch in the \(j\)-th task and fine-tuning it in the \(i\)-th task",RT_i=\max_{j < i}\frac{AUC_{j\to i}-AUC_{i}^{b}}{1-AUC_{i}^{b}},Reference forward Transfer for task \(i\) is the maximum over all previous tasks \(j\) of the normalized improvement in the area under the curve when fine-tuning from task \(j\) to task \(i\) compared to training from scratch.
ICML_2024_oral_121,1,"p(x;p^{m})=\sum_{i}^{N}k(x,d_{i})p_{i}^{m}",,f(x)=\frac{1}{2h}\sum_{i=1}^{N} p_i^m\exp\left(-\frac{|x-d_i|}{h}\right),The probability density function \( f(x) \) of the continuous disparity \( x \) is obtained by interpolating the discrete distribution \( \mathbf{p}^m \) with a Laplacian kernel of bandwidth \( h \).
ICML_2024_oral_121,2,"\texttt{argmin}_{y}F(y,p^{m})=\texttt{argmin}_{y}\intL(y,x )p(x;p^{m})dx","where \(F(y,\mathbf{p}^{m})\) is called as the risk at \(y\), and \(\mathcal{L}(y,x)\) is the error function between \(y\) and \(x\)",R(y)=\int_{-\infty}^{\infty} |x-y| p(x;p^{m}) dx,The risk function for a disparity prediction \(y\) is defined as the expected absolute error under the continuous disparity distribution.
ICML_2024_oral_121,3,y=\int xp(x;p^{m})dx,,y=\sum_{i=1}^{N} d_i p_i^m,The expected disparity \( y \) is computed as the weighted average of the discrete disparities \( d_i \) with weights \( p_i^m \).
ICML_2024_oral_121,4,"\texttt{argmin}_{y}F(y,p^{m})=\texttt{argmin}_{y}\int|y-x|p(x;p^{m})dx",,"L(y,x)=|y-x|",The loss function is defined as the absolute difference between the predicted disparity \(y\) and the ground truth disparity \(x\).
ICML_2024_oral_121,5,"G(y,p^{m})\triangleq\frac{\partial F(y,p^{m})} {\partial y} || =\sum_{i}p_{i}^{m}\texttt{Sign}(y-d_{i})(1-\exp-\frac{|y-d_{i}|}{\sigma})=0",,\int_{-\infty}^{y} p(x;p^{m}) dx=\int_{y}^{\infty} p(x;p^{m}) dx,The optimal disparity prediction \(y\) satisfies the condition that the cumulative probability from negative infinity to \(y\) equals the cumulative probability from \(y\) to positive infinity.
ICML_2024_oral_121,6,"dG(y,p^{m})=\frac{\partial G}{\partial y}dy+\frac{\partial G}{\partialp^{m}}dp^{m}=0",,\frac{\partial y}{\partialp^{m}}=-\frac{\frac{\partial G}{\partialp^{m}} }{\frac{\partial G}{\partial y} },"The equation computes the gradient of the optimal disparity \( y \) with respect to the discrete probability vector \( \mathbf{p}^{m} \) using the Implicit Function Theorem applied to \( G(y, \mathbf{p}^{m}) = 0 \)."
ICML_2024_oral_121,7,"\frac{dy}{dp^{m}}=-\frac{\partial G/\partialp^{m}}{\partial G/\partial y} || =[\dots,\frac{\sigma\texttt{Sign}(d_{i}-y)(1-\exp-\frac{|y-d_{i} |}{\sigma})}{\sum_{j}p_{j}^{m}\exp-\frac{|y-d_{i}|}{\sigma}},\dots]^{T}",,dy=-\left(\frac{\partial G}{\partial y}\right)^{-1}\frac{\partial G}{\partialp^{m}} dp^{m},The differential of the predicted disparity \( dy \) expressed in terms of the differential of the probability distribution \( d\mathbf{p}^{m} \).
ICML_2024_oral_121,8,"L(x^{\texttt{gt}},x^{\texttt{pred}})=0.5(x^{\texttt{gt}}-x^{\texttt{pred}})^{2},&if |x^{\texttt{gt}}-x^{\texttt{pred}}|<1.0\\|x^{\texttt{gt}}-x^{\texttt{pred}}|-0.5,&otherwise",,"\frac{dy}{dp^{m}}=\left[\dots,\frac{\sigma\cdot\texttt{Sign}(d_i-y)\cdot\left(1-\exp\left(-\frac{|y-d_i|}{\sigma}\right)\right)}{\max\left(\sum_{j} p_j^m\exp\left(-\frac{|y-d_i|}{\sigma}\right), 0.1\right)} ,\dots\right]^T","The gradient of the optimal disparity \(y\) with respect to the discrete probability vector \(\mathbf{p}^m\), with the denominator clipped to a minimum of 0.1 for numerical stability during backpropagation."
ICML_2024_oral_122,1,"\min_{\theta}\,\sum_{i=1}^{N}(\hat{y}(x;\theta)-y_{i})^{2}",,\[L_{MSE}(\theta)=\frac{1}{N}\sum_{i=1}^{N} (y_i-\hat{y}(x_i;\theta))^2\],The mean-squared error loss for regression parameterized by $\theta$ over $N$ data points.
ICML_2024_oral_122,2,"\min_{\theta}\,\sum_{i=1}^{N}\int_{Y}p(y\,|\,x_{i})\log(\hat{p}(y\,|\,x_ {i};\theta))dy",,\min_{\theta}\sum_{i=1}^{N} D_{KL}\left( p(y | x_i)\parallel\hat{p}(y | x_i;\theta)\right),Minimization of the sum of KL divergences between the true conditional distribution \(p(y|x_i)\) and the parameterized model \(\hat{p}(y|x_i;\theta)\) for each data point.
ICML_2024_oral_122,3,"Z=\{\sum_{i=1}^{m}p_{i}\,\delta_{z_{i}}\,:\,p_{i}\geq 0,\sum_{i=1} ^{m}p_{i}=1\}",where \(p_{i}\) is the probability associated with location \(z_{i}\) and \(\delta_{z_{i}}\) is the Dirac delta function at location \(z_{i}\),"z_j=v_{min}+(j-1)\frac{v_{max}-v_{min}}{m-1},\quad j=1,\dots,m",The $j$-th support point in the evenly spaced grid from $v_{\text{min}}$ to $v_{\text{max}}$ with $m$ points.
ICML_2024_oral_122,4,"\boxed{TD_{MSE}(\theta)=E_{D}[((\tilde{T}Q)(S,A;\tilde{\theta})-\,Q(S,A;\theta))^{2}]} || (\tilde{T}Q)(s,a;\tilde{\theta})=R+\gamma\max_{a^{\prime}}Q(S^{\prime },a^{\prime};\tilde{\theta})\,\big{|}\,S=s,A=a\","where \(\tilde{\theta}\) is a slow moving copy of the parameters \(\theta\) that parameterize the ""target network"" and

\[(\tilde{\mathcal{T}}Q)(s,a;\tilde{\theta})=R+\gamma\max_{a^{\prime}}Q(S^{\prime },a^{\prime};\tilde{\theta})\,\big{|}\,S=s,A=a\,,\]

is the sample version of the Bellman optimality operator which defines our scalar regression target","\min_{\theta}\,E_{(S,A,R,S')\simD}\left[\left(R+\gamma\max_{a^{\prime}}Q(S^{\prime},a^{\prime};\theta^{-})-Q(S,A;\theta)\right)^{2}\right]","The DQN loss minimizes the expected squared temporal difference error between the current Q-value \(Q(S,A;\theta)\) and the target value \(R + \gamma \max_{a'} Q(S',a';\theta^{-})\) over transitions sampled from \(\mathcal{D}\)."
ICML_2024_oral_122,5,"\alpha\,E_{D}[\log\big{(}\sum_{a^{\prime}}\exp(Q(S^{\prime},a^{\prime};\theta))\big{)}-Q(S,A;\theta)]",,"R_{CQL}(\theta)=\alpha\cdot\left(E_{s\simD}\left[\log\sum_{a}\exp(Q(s,a;\theta))\right]-E_{(s,a)\simD}\left[ Q(s,a;\theta)\right]\right)","The behavior regularization loss for conservative Q-learning, where \(\alpha\) is a scaling factor, \(\mathcal{D}\) is the dataset, and \(Q(s,a;\theta)\) is the Q-value function parameterized by \(\theta\)."
ICML_2024_oral_122,6,"Q(s,a;\theta)=E[\,Z(s,a;\theta)\,],\Z(s,a;\theta)=\sum_{i=1}^{m}\hat{p}_{i}(s,a;\theta)\cdot\delta_{z_{i}} || \hat{p}_{i}(s,a;\theta)=\frac{\exp(l_{i}(s,a;\theta))}{\sum_{j=1} ^{m}\exp(l_{j}(s,a;\theta))}\",,"\hat{p}_i(s,a;\theta)=\frac{\exp(l_i(s,a;\theta))}{\sum_{j=1}^{m}\exp(l_j(s,a;\theta))}","The probability \(\hat{p}_i(s,a;\theta)\) for class \(z_i\) is obtained by applying the softmax function to the logits \(l_i(s,a;\theta)\)."
ICML_2024_oral_122,7,"\boxed{TD_{CE}(\theta)=E_{D}[\sum_{i=1 }^{m}p_{i}(S,A;\tilde{\theta})\log\hat{p}_{i}(S,A;\theta)]}",,"\boxed{TD_{CE}(\theta)=E_{D}\left[-\sum_{i=1}^{m}p_{i}(S,A;\tilde{\theta})\log\hat{p}_{i}(S,A;\theta)\right]}","The temporal difference cross-entropy loss, defined as the expectation over the dataset of the cross-entropy between the target categorical distribution probabilities and the predicted probabilities."
ICML_2024_oral_122,8,"p_{i}(S,A;\tilde{\theta})=\frac{y-z_{i}}{z_{i+1}-z_{i}},\p_{i+1}(S,A;\tilde{\theta})=\frac{z_{i+1}-y}{z_{i+1}-z_{i}}\",,"p_i=\frac{z_{i+1}-y}{z_{i+1}-z_i},\quad p_{i+1}=\frac{y-z_i}{z_{i+1}-z_i}",The two-hot categorical probabilities for the target \( y \) at bins \( z_i \) and \( z_{i+1} \).
ICML_2024_oral_122,9,"p_{i}(S,A;\tilde{\theta})=\int_{z_{i}-\nicefrac{{\varsigma}}{{2}}}^{z_{i}+\nicefrac{{\varsigma}}{{2}}}f_{Y|S,A}(y|S,A)dy || =F_{Y|S,A}(z_{i}+\nicefrac{{\varsigma}}{{2}}|S,A)-F_{Y|S,A}(z_{i}-\nicefrac{{\varsigma}}{{2}}|S,A)",,"p_i(S,A;\tilde{\theta})=\int_{z_i-\nicefrac{\varsigma}{2}}^{z_i+\nicefrac{\varsigma}{2}} f_{Y|S,A}(y;\tilde{\theta})\, dy","The probability \(p_i\) for the bin centered at \(z_i\) is computed by integrating the probability density function \(f_{Y|S,A}\) over the interval \([z_i - \nicefrac{\varsigma}{2}, z_i + \nicefrac{\varsigma}{2}]\)."
ICML_2024_oral_122,10,"(\widehat{T}Z)(s,a;\tilde{\theta})\overset{D}{=}\sum_{i=1}^{m}\hat{p}_{i}(S^{\prime},A^{\prime};\tilde{\theta})\cdot\delta_{R+\gamma z_{i}}\bigm{|}S=s,\,A=a\","where \(A^{\prime}=\operatorname*{arg\,max}_{a^{\prime}}Q(S^{\prime},a^{\prime}; \tilde{\theta})\)","(T Z)(s,a;\tilde{\theta})=\Pi_{Z}\left( R+\gamma Z\left(S',\underset{a'}{argmax}\, Q(S',a';\tilde{\theta});\tilde{\theta}\right)\right)\mid S=s, A=a","The distributional Bellman operator \(\mathcal{T}\) applied to \(Z\) yields the target categorical distribution by projecting \(R + \gamma Z(S', a^*; \tilde{\theta})\) onto \(\mathcal{Z}\) given \(S=s, A=a\), where \(a^* = \operatorname{argmax}_{a'} Q(S',a';\tilde{\theta})\)."
ICML_2024_oral_122,11,"p_{i}(S,A;\tilde{\theta})=\sum_{j=1}^{m}\hat{p}_{j}(S^{\prime},A ^{\prime};\tilde{\theta})\cdot\xi_{j}(R+\gamma z_{i}) || \xi_{j}(x)=\frac{x-z_{j}}{z_{j+1}-z_{j}}\mathds{1}\{\lfloor x\rfloor=z_{j}\}+\frac{z_{j+1}-x}{z_{j+1}-z_{j}}\mathds{1}\{\lceil x\rceil=z_ {j}\}\",,"p_{i}(S,A;\tilde{\theta})=\sum_{k=1}^{m}\hat{p}_{k}(S^{\prime},A^{\prime};\tilde{\theta})\left[I\{\lfloor R+\gamma z_{k}\rfloor=z_{i}\}\frac{\lceil R+\gamma z_{k}\rceil-(R+\gamma z_{k})}{\lceil R+\gamma z_{k}\rceil-\lfloor R+\gamma z_{k}\rfloor}+I\{\lceil R+\gamma z_{k}\rceil=z_{i}\}\frac{(R+\gamma z_{k})-\lfloor R+\gamma z_{k}\rfloor}{\lceil R+\gamma z_{k}\rceil-\lfloor R+\gamma z_{k}\rfloor}\right]","The target probability \( p_i(S,A;\tilde{\theta}) \) for bin \( i \) is computed by distributing the probability mass of each atom \( k \) from the Bellman target distribution to the two nearest bins \( \lfloor R+\gamma z_k \rfloor \) and \( \lceil R+\gamma z_k \rceil \) proportionally to their distances."
ICML_2024_oral_125,1,"E_{i}=L_{i}(E_{i-1}),\\i=1,...,N || \dot{y}=\texttt{Head}(e_{N}^{0})",,"E_{i}=L_i(E_{i-1}),\quad i=1,2,\ldots,N","The forward computation of the Vision Transformer (ViT) model, where each layer $L_i$ processes the embedding $\mathbf{E}_{i-1}$ to produce $\mathbf{E}_{i}$, which serves as input to the next layer."
ICML_2024_oral_125,2,"\min_{\tilde{\Theta}}L(x;\Theta),\x\sim Q(x)",where \(\tilde{\Theta}\subseteq\Theta\) denotes the model parameters involved for updating,\min_{\Theta}\ell(x;\Theta),The unsupervised objective function minimized during test-time adaptation for a test sample.
ICML_2024_oral_125,3,"p^{*}=\operatorname*{arg\,min}_{p}L(f_{\Theta}(p;x))","where \(\mathcal{L}(\cdot)\) is a fitness function and \(\mathbf{p}\in\mathbb{R}^{d\times N_{p}}\) consists of \(N_{p}\) prompt embeddings, each of dimension \(d\)","p^{*}=\arg\max_{p}F(p;x,\Theta)",\(\mathbf{p}^{*}\) is the optimal prompt maximizing the fitness function \(\mathcal{F}\) for the test sample \(\mathbf{x}\) and model parameters \(\Theta\).
ICML_2024_oral_125,4,L(f_{\Theta}(p;X_{t}))=\sum_{ x\inX_{t}}\sum_{c\inC}-\hat{y}_{c}\log\hat{y}_{c} || \qquad+\lambda\sum_{i=1}^{N}\lvert\lvert\mu_{i}(X_ {t})-\mu_{i}^{S}\rvert\rvert_{2}+\lVert\sigma_{i}(X_{t})-\sigma_{i}^{S}\rvert\rvert_{2},,L(X_t;p)=\frac{1}{|X_t|}\sum_{x\inX_t} H\left(\dot{y}(x;p)\right)+\lambda\sum_{i=0}^{N}\left(\left\|\mu_i(X_t)-\mu_i^S\right\|_2^2+\left\|\sigma_i(X_t)-\sigma_i^S\right\|_2^2\right),The fitness function \(\mathcal{L}\) for test batch \(\mathcal{X}_t\) combines the average prediction entropy over the batch and a layer-wise regularization term that aligns the mean and standard deviation of CLS token activations with source in-distribution statistics.
ICML_2024_oral_125,5,"p_{k}^{(t)}\simm^{(t)}+\tau^{(t)}N(0,\bm {\Sigma}^{(t)})",,"p_t^{(k)}\simN(m_t,C_t),\quad k=1,\dots,K","\(\mathbf{p}_t^{(k)}\) is the \(k\)-th candidate prompt vector sampled at iteration \(t\), \(\mathbf{m}_t\) is the mean vector, \(\mathbf{C}_t\) is the covariance matrix, and \(K\) is the population size."
ICML_2024_oral_125,6,e_{N}^{0}arrowe_{N}^{0}+\gammad,where \(\mathbf{d}\) is a shifting direction and \(\gamma\) is a step size,e_{N}^{0}\leftarrow (1-\alpha)e_{N}^{0}+\alpha\mu_{N}^{S},The shifted CLS token \(\mathbf{e}_{N}^{0}\) is a linear interpolation between the original token and the source mean \(\mathbf{\mu}_{N}^{S}\) with weight \(\alpha\) controlling the shift towards the source domain.
ICML_2024_oral_125,7,d_{t}=\mu_{N}^{S}-\mu_{N}(t),where \(\boldsymbol{\mu}_{N}^{S}\) is the mean of the \(N\)-th final layer CLS feature \(\mathbf{e}_{N}^{0}\) and calculated over source in-distribution samples \(\mathcal{D}_{S}\) (the same one used in Eqn,d^{(t)}=(1-\beta)d^{(t-1)}+\beta\left(\mu_N^S-\mu_N(X_t)\right),"where \(\mathbf{d}^{(t)}\) is the shifting direction at the \(t\)-th batch, \(\beta\) is a momentum factor, \(\mathbf{\mu}_N^S\) is the precomputed source in-distribution mean of the final-layer CLS features, and \(\mathbf{\mu}_N(\mathcal{X}_t)\) is the mean of the final-layer CLS features for the current test batch \(\mathcal{X}_t\)."
ICML_2024_oral_125,8,\mu_{N}(t)=\alpha\mu_{N}(X_{t})+(1-\alpha )\mu_{N}(t-1),where \(\boldsymbol{\mu}_{N}(\mathcal{X}_{t})\) is the mean of the \(N\)-th layer's CLS feature and calculated over the \(t\)-th test batch \(\mathcal{X}_{t}\),\mu_{N}(t)=(1-\beta)\mu_{N}(t-1)+\beta\cdot\frac{1}{|X_t|}\sum_{x\inX_{t}}e_{N}^{0}(x),"where \(\boldsymbol{\mu}_{N}(t)\) is the exponential moving average of the mean of the \(N\)-th layer CLS features at batch \(t\), \(\beta\) is a smoothing hyperparameter, \(\mathcal{X}_t\) is the current batch of test samples, and \(\mathbf{e}_{N}^{0}(\mathbf{x})\) is the CLS token for sample \(\mathbf{x}\) at the final layer."
ICML_2024_oral_127,1,\sup_{x}\mathds{E}_{D^{j}\sim\chi}[\lfloor\frac{j}{i}\hat{f}(x )-f_{D^{j}}(x)\rceil]\geq\frac{\sqrt{k}}{4},,\sup_{x}\mathds{E}_{D\sim\chi}\left[\left|\frac{j}{i}\hat{f}(x)-f_{D^{j}}(x)\right|\right]\geq C\frac{j-i}{i},The expected maximum generalization error of model $\hat{f}$ on dataset $\mathbf{D}^{j}$ is lower bounded by a constant times the relative insertion count $(j-i)/i$.
ICML_2024_oral_127,2,\mathds{P}_{D\sim\chi}[\|f_{\chi}-\hat{f}\|_{\infty}\geq\epsilon]\leq\varkappa_ {1}e^{-\varkappa_{2}(\frac{\epsilon}{\sqrt{n}}-1)^{2}},,\sup_{x}\mathds{E}_{D\sim\chi}\left[\left|\hat{f}(x)-f_{D}(x)\right|\right]\leqB_{n}^{X},"This equation defines the accuracy condition for distribution learnability, requiring that the worst-case expected absolute error of the model \(\hat{f}\) over queries \(\mathbf{x}\) and datasets \(\mathbf{D}\) of size \(n\) from distribution \(\chi\) is bounded by \(\mathcal{B}_{n}^{\mathfrak{X}}\)."
ICML_2024_oral_13,1,"&P\{X_{1}=x_{1}\}\\&P\{X_{2}=x_{2}|X_{1}=x_{1}\}\\&\quad\vdots\\&P\{X_{n}=x_{n}|X_{1}=x_{1},\cdots,X_{n-1}=x_{n-1 }\}",,"P\left( (X_{1},\cdots,X_{n})=(x_{1},\cdots,x_{n})\right)=P(X_1=x_1)\cdot\prod_{t=2}^{n}P(X_t=x_t\mid X_1=x_1,\ldots, X_{t-1}=x_{t-1})","The joint probability of the token sequence \((x_1, \dots, x_n)\) is the product of the marginal probability of the first token and the conditional probabilities of each subsequent token given all preceding tokens."
ICML_2024_oral_13,2,"&P\{X_{n}=x_{n}\}\\&P\{X_{n-1}=x_{n-1}|X_{n}=x_{n}\}\\&\quad\vdots\\&P\{X_{1}=x_{1}|X_{n}=x_{n},\cdots,X_{2}=x_{2}\}",,"&P\{X_{n}=x_{n}\}\\&P\{X_{n-1}=x_{n-1}|X_{n}=x_{n}\}\\&\quad\vdots\\&P\{X_{1}=x_{1}|X_{2}=x_{2},\cdots,X_{n}=x_{n}\}","The backward factorization of the joint probability for the token sequence, starting from the last token and conditioning on future tokens."
ICML_2024_oral_13,3,"\sum_{i=1}^{n}\ell_{i}^{arrow}=-\lnP_{n}^{arrow}\{X_ {1}=x_{1},\cdots,X_{n}=x_{n}\}",,"\sum_{i=1}^{n}\ell_i^{\leftarrow}=-\lnP_n^{\leftarrow}(x_1,\dots, x_n)",The total cross-entropy loss for the backward model on a sequence equals the negative log of the backward joint probability of the sequence.
ICML_2024_oral_13,4,L_{n}^{arrow}=D_{KL}(P_{n}\big{|}\big{|}P_{n}^{arrow})+H(P_{n}),where \(H\) denotes the entropy and \(\mathrm{D}_{\mathrm{KL}}\) the Kullback-Leibler divergence,"L_{n}^{\leftarrow}=E_{(x_1,\dots,x_n)\simP_n}\left[-\lnP_{n}^{\leftarrow}\{X_1=x_1,\cdots,X_n=x_n\}\right]",The expected total backward cross-entropy loss over sequences of length \(n\) sampled from the true distribution.
ICML_2024_oral_132,1,P(A(D)\in S)\leq e^{\epsilon}P(A(D^{\prime})\in S)+\delta,,\Pr[A(D)\in S]\leq e^{\epsilon}\Pr[A(D^{\prime})\in S]+\delta,"The probability that algorithm \(\mathcal{A}\) outputs a result in set \(S\) when applied to dataset \(\mathcal{D}\) is bounded by \(e^{\epsilon}\) times the probability for dataset \(\mathcal{D}^{\prime}\) plus \(\delta\), for all adjacent datasets \(\mathcal{D}, \mathcal{D}^{\prime}\) differing by one sample and all measurable subsets \(S\)."
ICML_2024_oral_132,2,\epsilon=\epsilon_{\alpha}+\log(\frac{\alpha-1}{\alpha})-\frac{\log\delta+\log\alpha}{\alpha-1},,\epsilon=\epsilon_{\alpha}+\frac{\log(1/\delta)}{\alpha-1},"The conversion from (\alpha, \epsilon_{\alpha})-RDP to (\epsilon, \delta)-DP, providing the value of \epsilon for a given \delta."
ICML_2024_oral_132,3,"\widetilde{g}_{t}=\frac{1}{B}(\sum_{x\inB_{t}}clip_{C}(\nabla_{\theta}\ell(x;\theta_{t})+N(0,\sigma^{2}C^{2}I))","where \(\eta_{t}\) is the learning rate, \(\mathcal{B}_{t}\) is the sampled batch, \(B\) is the average batch size, \(\sigma>0\) is the noise multiplier, and \(\mathsf{clip}_{C}\) is the operation that clips the per-sample gradient norm to at most \(C>0\)","\widetilde{g}_t=\frac{1}{|B_t|}\sum_{i\in B_t}clip_C(\nabla\ell(\theta_t;x_i))+N(0,\sigma^2 C^2 I)",The noisy gradient \(\widetilde{\mathbf{g}}_t\) is the average of per-sample gradients clipped to maximum L2 norm \(C\) over minibatch \(B_t\) plus Gaussian noise with variance \(\sigma^2 C^2\) per coordinate.
ICML_2024_oral_132,4,"L_{MAE}(\theta):=\frac{1}{n}\sum_{i=1}^{n}\underbrace{\xi_{ MSE}(g\circ\psi(mask(x_{i});\theta),x_{i})}_{\ell(x_{i};\theta)}","where \(n\) is the number of training samples, \(\mathbf{x}_{i}\in\mathbb{R}^{C\times H\times W}\) is the input of the \(i\)-th training image (\(C\)-number of channels, \(H\)-height, \(W\)-width), mask\((\cdot)\) is a function that mask out a fraction of the image, \(\psi:\mathbb{R}^{C\times H\times W}\rightarrow\mathbb{R}^{d}\) is the encoder and \(g:\mathbb{R}^{d}\rightarrow\mathbb{R}^{C\times H\times W}\) is the decoder",L_{MAE}(\theta)=\frac{1}{|M|}\sum_{i\inM}\|x_i-\hat{x}_i\|^2,"The MAE training objective for parameters \(\theta\) is the mean squared error between the original and reconstructed pixel values of the masked patches, where \(\mathbf{x}\) is the input image, \(\mathcal{M}\) is the set of indices of masked patches, \(\mathbf{x}_i\) is the \(i\)-th patch of \(\mathbf{x}\), and \(\hat{\mathbf{x}}_i\) is the reconstructed \(i\)-th patch."
ICML_2024_oral_15,1,\min_{p(T|X)}\quad I(X;T),where \(I(X;T)\) denotes the mutual information of \(X\) and \(T\),"\min_{p(t|x)}\left\{E\left[ d(X, T)\right]+\beta I(X; T)\right\}","The rate-distortion optimization problem for acquiring the representation set \(\mathcal{T}\) as an optimal split of \(\mathscr{X}\), minimizing expected distortion plus \(\beta\)-weighted mutual information."
ICML_2024_oral_15,2,\min_{p(T|X)} I(X;T),,\min_{p(T|X)}\quad I(X;T)-\beta I(T;Q),"where \(Q\) is the information retrieval variable, \(\beta\) is a trade-off parameter, and \(I(T;Q)\) denotes the mutual information between \(T\) and \(Q\)."
ICML_2024_oral_15,3,I(T;Q)\geq\varepsilon,where \(\varepsilon>0\) is a threshold,I(T; Q)\geq I_0,"where \(I(T;Q)\) denotes the mutual information between representations \(T\) and query term \(Q\), and \(I_0\) is a constant representing the minimum required information."
ICML_2024_oral_15,4,L(p(T|X))=I(X;T)-\beta I(T;Q),where \(\beta\) is the Lagrange multiplier,\min_{p(T|X)}\max_{\beta\geq 0}L=I(X;T)-\beta (I(T;Q)-\varepsilon),where \(\beta \geq 0\) is the Lagrange multiplier for the constraint \(I(T;Q) \geq \varepsilon\).
ICML_2024_oral_15,5,L(p(T|X))=I(X;T)+\beta I(X;Q|T)+constant,,"\min_{p(T|X)} I(X;T)+\beta\cdotE_{x,t}\left[ D_{KL}\left( p(Q|x)\parallel p(Q|t)\right)\right]",where \(D_{\text{KL}}\left( p(Q|x) \parallel p(Q|t) \right)\) is the Kullback-Leibler divergence between the conditional distributions of \(Q\) given \(x\) and given \(t\)
ICML_2024_oral_15,6,"p^{*}(T|X)=\frac{p^{*}(T)}{Z(X,\beta)}\exp\Bigl{(}-\betaKL[p(Q|X)\\big{\|}\p(Q|T)]\Bigr{)}","where \(Z(X,\beta)\) is a probability normalization term, \(p^{*}(T)=\mathbb{E}_{X}[p^{*}(T|X)]\)","p(t|x)=\frac{p(t)}{Z(x,\beta)}\exp\left(-\beta\, D_{KL}\!\left(p(q|x)\,\|\, p(q|t)\right)\right)","The stationarity condition for the optimal conditional distribution \(p(t|x)\), where \(D_{\mathrm{KL}}\) is the Kullback-Leibler divergence and \(Z(x,\beta)\) is the normalization factor."
ICML_2024_oral_15,7,"p(X,Q|f)\equiv\prod_{x\inX}p^{*}\big{(}X=x\\big{|}\T=f(x)\big{)}",where \(p^{*}\) is given by Formula (5),"p(X,Q | f)=\prod_{x\inX} p^{*}(T=f(x) | X=x)",The likelihood function for the indexing function \(f\) is defined as the product of the optimal conditional probabilities \(p^{*}(T|X)\) evaluated at \(T=f(x)\) for each document \(x\).
ICML_2024_oral_15,8,"I(X;T)=E_{X,T}\log\frac{p(X|T)}{p(X)} || I(X;Q|T)=E_{X,T,Q}\log\frac{p(X,Q|T)}{p(X|T)p(Q|T)}",,\mu_{Q|x}=\frac{1}{|Q_{x}|}\sum_{q\inQ_{x}}BERT(q),"where \(\mu_{Q|x}\) is the estimated mean vector of query embeddings for document \(x\), \(\mathcal{Q}_{x}\) is the set of queries for \(x\), and \(\text{BERT}(q)\) is the embedding of query \(q\)"
ICML_2024_oral_15,9,"=E_{X,T,Q}\log\frac{p(X|Q)}{p(T|Q)}\frac{p(T)}{p(X)}",,I(X;Q|T)=I(X;Q)-I(T;Q),which expresses the conditional mutual information in terms of mutual information under the Markov assumption.
ICML_2024_oral_22,1,"x_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\Big{(}x_{t}-\frac{1-\alpha_{t}} {\sqrt{1-\bar{\alpha}_{t}}}\epsilon_{\theta}(x_{t},t,c)\Big{)}+\sigma_{t}\epsilon","where \(\mathbf{\epsilon}\sim\mathcal{N}(0,I)\), \(\alpha_{0}:=1\), \(\alpha_{t}\) and \(\bar{\alpha}_{t}\) define the noise schedule, \(\sigma_{t}\) is the sampling standard deviation","x_{t-1}=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{\beta_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_{\theta}(x_t, t,c)\right)+\sqrt{\beta_t}z","The reverse diffusion sampling step that iteratively refines noisy data \(\mathbf{x}_t\) to \(\mathbf{x}_{t-1}\) by removing predicted noise \(\mathbf{\epsilon}_{\theta}\) and adding Gaussian noise \(\mathbf{z} \sim \mathcal{N}(0,I)\)."
ICML_2024_oral_22,2,"x_{T}^{*}=\arg\min_{x_{T}}L(f(x_{0}),y) || x_{0}=\texttt{Sampler}_{T}(\epsilon_{\theta},x_{T},c)",,"\min_{x_T}L\left(f(x_0),y\right)\quadwhere\quadx_0=\texttt{Sampler}_T(\epsilon_{\theta},x_T,c)",The optimization objective for the initial noise latents \(\mathbf{x}_T\) to minimize the loss \(\mathcal{L}\) between the feature \(f(\mathbf{x}_0)\) of the generated sample \(\mathbf{x}_0\) and the target control \(\mathbf{y}\).
ICML_2024_oral_24,1,"\omega_{1}(D_{1},D_{2},J)=\frac{1}{N}\sum_{i=1}^{N}\mathds{1}\{J(q_{i},a_{i1}, a_{i2})=a_{i1}\}",,"\omega_1=\frac{1}{N}\sum_{i=1}^{N}1\left[J(q_i, a_{i1}, a_{i2})=a_{i1}\right]",The win rate \(\omega_1\) for Debater \(D_1\) is the fraction of questions where the judge selects the answer \(a_{i1}\) supported by \(D_1\).
ICML_2024_oral_24,2,"\bar{\omega}_{1}(D_{1},D_{2},J)>\frac{1}{2}",,"\bar{\omega}_{1}(D_{1},D_{2},J)=\frac{1}{2}\left(\omega_{1}(D_{1},D_{2},J)+1-\omega_{1}(D_{2},D_{1},J)\right)","The average win rate for Debater 1 is the mean of the win rate under original assignments and the win rate when assignments are flipped, where the flipped win rate is derived from one minus Debater 2's win rate in the flipped match."
ICML_2024_oral_24,3,"\bar{\omega}_{1}(D_{1},D_{2},J)=\frac{1}{1+10^{(E_{2}-E_{1})/400}}",,"\bar{\omega}_{1}(D_1, D_2, J)=\frac{1}{1+\exp(-(E_1-E_2))}",The aggregate Elo ratings \(E_1\) for debater \(D_1\) and \(E_2\) for debater \(D_2\) with judge \(J\) satisfy the equality where the average win rate of \(D_1\) against \(D_2\) equals the logistic function of their rating difference.
ICML_2024_oral_24,4,"\omega_{C}(D_{1},D_{2},J)=\frac{1}{1+10^{(E^{I}_{2}-E^{C}_{1})/400}}",,"\omega_C(D_1, D_2, J)=\frac{1}{1+10^{(E^I_{D_2}-E^C_{D_1})/400}}","The win rate of debater \(D_1\) when assigned the correct answer against debater \(D_2\) assigned the incorrect answer, expressed in terms of the correct rating of \(D_1\) and the incorrect rating of \(D_2\)."
ICML_2024_oral_25,1,"\min_{\theta}KL(p(Y|X)\|q(Y|X,\theta))",,"L^{(k)}(\theta^{(k)})=-\frac{1}{N}\sum_{i=1}^{N}\sum_{c=1}^{C} y_{i,c}\log\left( p_{c}^{(k)}(x_i;\theta^{(k)})\right)","Equation 1 defines the cross entropy loss \(\mathcal{L}^{(k)}(\mathbf{\theta}^{(k)})\) for the \(k\)-th ensemble model, where \(N\) is the number of training samples, \(C\) the number of classes, \(y_{i,c}\) the binary indicator for sample \(i\) belonging to class \(c\), and \(p_{c}^{(k)}(\mathbf{x}_i; \mathbf{\theta}^{(k)})\) the probability predicted by model \(k\) for class \(c\) given input \(\mathbf{x}_i\)."
ICML_2024_oral_25,2,"H(q(Y|X))=\underbrace{I(Y;\theta| X)}_{D}+\underbrace{E_{q(\theta|D)}H(q(Y|X,\theta))}_{D}",where \(\mathcal{I}\) denotes the mutual information under the \(q\) distribution,"H\left[q(Y|X)\right]=E_{q(\theta|D)}\left[H\left[q(Y|X,\theta)\right]\right]+I\left[Y,\theta\midX,D\right]",The predictive entropy decomposes into the expected conditional entropy (aleatoric uncertainty) and the mutual information between parameters and predictions (epistemic uncertainty).
ICML_2024_oral_25,3,H(q(Y|X))=\underbrace{I(Y;C|X)}_ {Q^{\prime}}+\underbrace{E_{q(C|X)}H( q(Y|X\oplusC))}_{Q^{\prime}},,H(q(Y|X))=I(Y;C |X)+E_{q(C|X)}H(q(Y|X\oplusC)),The entropy of the ensemble prediction is decomposed into the mutual information between the output and the clarification given the input and the expected entropy of the model's predictions on the clarified inputs.
ICML_2024_oral_26,1,"&Attention(Q,K,V)=softmax(QK^{\intercal})V,\\&where Q,K,V\inR^{n\times d}",where \(n\) denotes the number of tokens and \(d\) denotes the hidden dimension of the attention,"Attention(Q, K, V)=softmax\left(QK^\top\right)V",The self-attention output is computed as the softmax of the dot products between queries and keys multiplied by the value matrix.
ICML_2024_oral_26,2,"& o_{i}=\sum_{j=1}^{n}\frac{e^{q_{i}k_{j}^{\intercal}} }{\sum_{j^{\prime}=1}^{n}e^{q_{i}k_{j^{\prime}}^{\intercal}}v_{j}},\\&where q_{i},k_{i},v_{i}\inR^{1\times d},i=\{1,2,...,n\}",,o_i=\sum_{j=1}^{n}\frac{\exp(q_i k_j^\top)}{\sum_{m=1}^{n}\exp(q_i k_m^\top)} v_j,"Each output token vector \(o_i\) is computed as the weighted sum of all value vectors \(v_j\), with weights determined by the softmax-normalized dot products between the query vector \(q_i\) and each key vector \(k_j\)."
ICML_2024_oral_26,3,"o_{i}=\sum_{j=1}^{n}\frac{K(q_{i},k_{j})}{\sum_{j^{\prime}=1}^{n}K( q_{i},k_{j^{\prime}})}v_{j}",,"o_i=\frac{\sum_{j=1}^{n} K(q_i, k_j) v_j}{\sum_{j=1}^{n} K(q_i, k_j)}",where \(K: \mathbb{R}^{d} \times \mathbb{R}^{d} \to \mathbb{R}^+\) is a positive-definite kernel function that computes the similarity between query \(q_i\) and key \(k_j\).
ICML_2024_oral_26,4,o_{i}=\sum_{j=1}^{n}\frac{\phi(q_{i})\phi(k_{j})^{\intercal}}{\sum_{j^{\prime }=1}^{n}\phi(q_{i})\phi(k_{j^{\prime}})^{\intercal}}v_{j},where \(\phi(\cdot):\mathbb{R}^{d}\rightarrow\mathbb{R}^{m}\) is a projection to map the inputs into \(m\) dimension features,o_{i}=\frac{\phi(q_i)^\top\left(\sum_{j=1}^{n}\phi(k_j) v_j\right) }{\phi(q_i)^\top\left(\sum_{j=1}^{n}\phi(k_j)\right) },"where \(\phi(\cdot)\) is the feature map associated with kernel \(K\), enabling linear decomposition via precomputation of the sums over \(j\)."
ICML_2024_oral_26,5,\phi_{PRF}(x)=e^{\omega x^{\intercal}-\frac{1+x^{2}}{2}},where \(\omega\in\mathbb{R}^{m\times d}\),\phi_{PRF}(x)=\frac{1}{\sqrt{m}}\exp\left(-\frac{\|x\|^{2}}{2}\right)\exp(Wx),"where \( W \in \mathbb{R}^{m \times d} \) is a random matrix with each row independently drawn from \( \mathcal{N}(0, I_d) \), and \( \exp(\cdot) \) is applied element-wise."
ICML_2024_oral_26,6,"K(x,z)=\int_{R^{d}}e^{i(x-z)^{\intercal}w}p(w)dw=E_{w\sim p(\cdot)}[ e^{iw^{\intercal}x}(e^{iw^{\intercal}z})^{\intercal}]",,"K(x, z)=\int_{R^d} e^{i\omega^{\top} (x-z)} dp(\omega)","where \(x, z \in \mathbb{R}^d\) are input vectors, \(\omega \in \mathbb{R}^d\) is the frequency vector, and \(p\) is a probability measure on \(\mathbb{R}^d\)."
ICML_2024_oral_26,7,"K(x,z)=E_{w\sim p(\cdot)}[e^{iw^{\intercal}x}(e^{iw^{\intercal}z})^{\intercal }]\approx\varphi_{p}(x)^{\intercal}\varphi_{p}^{*}(z)",where \(w_{i}\sim p(\cdot)\) are samples constructed by Monte Carlo methods,\varphi_{p}(x)=\frac{1}{\sqrt{m}} e^{-i w_{1}^{\intercal} x}\\e^{-i w_{2}^{\intercal} x}\\\vdots\\e^{-i w_{m}^{\intercal} x},"where \(\varphi_{p}(x)\) is the feature map for input \(x\), \(w_j \in \mathbb{R}^{d}\) are random feature vectors sampled from probability measure \(p(w)\), and \(m\) is the number of random features."
ICML_2024_oral_26,8,"K_{G}(x,y):=e^{-\frac{\|x-y\|^{2}}{2}}=e^{-\frac{\|x\|^{2}+\|y\|^{2}}{2}}e^{x ^{\intercal}y}",,"\phi_{QMC}(x)=\frac{1}{\sqrt{m}}\left[ e^{-i w_{1}^{\intercal} x}, e^{-i w_{2}^{\intercal} x},\dots, e^{-i w_{m}^{\intercal} x}\right]^{\intercal}","where \( w_{1}, w_{2}, \dots, w_{m} \) are deterministic samples drawn from the distribution \( p(\cdot) \) using the Quasi-Monte Carlo method."
ICML_2024_oral_26,9,"\varphi_{PFF}(x):=\frac{e^{-\|x\|^{2}}}{\sqrt{m}}[e^{\Phi^{-1}(t_{1}) x^{\intercal}v_{1}},...,e^{\Phi^{-1}(t_{m})x^{\intercal}v_{m}}]^{\intercal}",,\phi_{PFF}(x)=\exp\left( W x^{\intercal}-\frac{1+\|x\|^2}{2}\right),"where \(W \in \mathbb{R}^{m \times d}\) is a fixed matrix of frequencies obtained by Quasi-Monte Carlo sampling from \(\mathcal{N}(0, I)\)"
ICML_2024_oral_26,10,"\varphi_{WPFF}(x):=\frac{De^{-\|x\|^{2}}}{\sqrt{m}}[e^{\Phi^{-1}(t_{1 })x^{\intercal}v_{1}},...,e^{\Phi^{-1}(t_{m})x^{\intercal}v_{m}}]^{\intercal}",,"\varphi_{WPFF}(x)=e^{-\|x\|^{2}}\left[\sqrt{w_1} e^{\Phi^{-1}(t_{1}) x^{\intercal} v_{1}},\dots,\sqrt{w_m} e^{\Phi^{-1}(t_{m}) x^{\intercal} v_{m}}\right]^{\intercal}","where \( w_i \) are positive weights, \( t_i \sim U(0,1) \), \( v_i \in \mathbb{S}^{d} \) are asymptotically uniformly distributed, and \( \Phi^{-1} \) is the inverse cumulative distribution function of the standard normal distribution"
ICML_2024_oral_26,11,\smallC_{j_{1}j_{2}}=s_{j_{1}}s_{j_{2}}\sum_{i_{1}=0}^{n-1}\sum_{i_{2}=0 }^{d-1}\cos(\frac{\pi(2i_{1}+1)j_{1}}{2d})\cos(\frac{\pi(2i_{2}+1)j_{2}}{2d}),where \(s_{j}=\sqrt{1/d}\) if \(j=0\) and \(s_{j}=\sqrt{2/d}\) otherwise,"C_{u,v}=\alpha(u)\alpha(v)\sum_{i=0}^{d-1}\sum_{j=0}^{d-1} x_{i,j}\cos\left(\frac{\pi (2i+1) u}{2d}\right)\cos\left(\frac{\pi (2j+1) v}{2d}\right)","The Discrete Cosine Transform coefficient matrix \(\mathcal{C}\) mapping spatial domain features to frequency domain representations, where \(\alpha(u) = \sqrt{\frac{1}{d}}\) for \(u=0\) and \(\sqrt{\frac{2}{d}}\) otherwise, and \(x_{i,j}\) denotes input features."
ICML_2024_oral_26,12,\small\phi_{WDCF}(x)=De^{TCx^{\intercal}},"where \(\mathcal{C}\in\mathbb{R}^{m\times d}\) is the DCT coefficient, \(D\in\mathbb{R}^{m}\) is a learnable weight, and \(T=\text{diag}(t_{1},\dots,t_{m})\) is a random diagonal matrix following the inverse cumulative distribution","\varphi_{WDCF}(x) :=\frac{De^{-\|x\|^{2}}}{\sqrt{m}}\left[\exp\left(DCT_{1}(x)\right),\exp\left(DCT_{2}(x)\right),\ldots,\exp\left(DCT_{m}(x)\right)\right]^{\intercal}","where \(\mathrm{DCT}_{k}(x)\) denotes the \(k\)-th coefficient of the Discrete Cosine Transform applied to input \(x\), and \(D\) is a learnable parameter."
ICML_2024_oral_26,13,"\smallFKA(Q,K,V)=\phi_{WDCF}(Q)\phi_{WDCF}(K)^{\intercal}V,\\where Q,K,V\inR^{n\times d}",,o_{i}=\sum_{j=1}^{n}\frac{\phi_{WDCF}(q_{i})\phi_{WDCF}(k_{j})^{\intercal}}{\sum_{j^{\prime}=1}^{n}\phi_{WDCF}(q_{i})\phi_{WDCF}(k_{ j^{\prime}})^{\intercal}}v_{j},where the kernelized attention in frequency domain (FKA) computes output \(o_i\) for token \(i\) using the Weighted Discrete Cosine Features mapping \(\phi_{\text{WDCF}}\).
ICML_2024_oral_28,1,f\in\operatorname*{argmin}_{f}\sup_{e\inE}R^{e}(\tilde{f}),"where the risk \(R^{e}(f)=\mathbb{E}_{(x,y)\sim P^{e}}[\ell(f(x),y)]\) measures the average loss \(\ell\) incurred by the predictor \(f\) across examples from environment \(e\), all of them drawn iid from \(P^{e}\)",f:X\toY,The predictor function mapping inputs to labels across all environments.
ICML_2024_oral_28,2,(p_{y_{i}^{out}}^{out}-1/n_{classes})\cdot n_{ classes}/(n_{classes}-1),,"\max_j p_{i,j}^{out}",The probability of flipping the label of the \(i\)-th example to the held-out prediction.
ICML_2024_oral_28,3,"\llbracket(y\notin\operatorname*{argmax}_{j}f^{a}(x)_{j})\,\vee\,(y\notin\operatorname*{argmax}_{j}f^{b}(x)_{j})\rrbracket","where ""\(\vee\)"" denotes logical-OR, and ""\(\llbracket\)"" is the Iverson bracket","e(x,y)=1\left( f^a(x)\neq y\land f^b(x)\neq y\right)","The environment annotation for an example (x,y) is 1 if both twin classifiers misclassify it, and 0 otherwise."
ICML_2024_oral_28,4,Y\perp E\mid X_{inv},,X_{inv}\perp\!\!\!\perp E\mid Y,The invariant feature \(X_{\text{inv}}\) is conditionally independent of the environment \(E\) given the label \(Y\).
ICML_2024_oral_3,1,"\operatorname*{argmin}_{\Theta_{T},M_{T}}\frac{1}{|D|}\sum_{x,y\inD}L(x,y|\Theta_{T},M_{T})",,"\min_{\{M_{t}\}_{t=1}^{T},\{R_{t}\}_{t=1}^{T}}L(\theta)\quads.t.\quad\dfrac{\|M_{T}\|_0}{N_0}=1-\gamma_{T}\quadand\quad\forall t\in [1, T] :\dfrac{\|M_{t}\|_0}{N_0}\leq 1-\gamma_{t}\quadand\quadnumber of tuning parameters\leq\Delta_{t}","The optimization minimizes the task loss \(\mathcal{L}\) over pruning masks \(\mathcal{M}_{1:T}\) and tuning ranks \(\mathcal{R}_{1:T}\) subject to the final model sparsity being \(\gamma_{T}\), the sparsity at each step \(t\) being at least \(\gamma_{t}\), and the number of tuning parameters at each step \(t\) being at most \(\Delta_{t}\)."
ICML_2024_oral_3,2,"1-\frac{C(\Theta_{t},M_{t})}{C(\Theta_{0},M_{0})}\geq\gamma_{t} || \delta(\Theta_{t},M_{t},R_{t})\leq\Delta_{t} || \forall t\in\{0,1,\dots,T\}",,"\|M_t\|_0 &\leq |\Theta_0| (1-\gamma_t)\quad\forall t\in\{1,\dots, T\}\\\|M_T\|_0 &=|\Theta_0| (1-\gamma_T)\\Params_{tune}(M_t,R_t) &\leq\Delta_t\quad\forall t\in\{1,\dots, T\}","The constraints enforce that the number of remaining parameters is at most \(|\Theta_0|(1 - \gamma_t)\) for all steps \(t\), exactly \(|\Theta_0|(1 - \gamma_T)\) at step \(T\), and the number of tuning parameters is bounded by \(\Delta_t\) at every step."
ICML_2024_oral_3,3,H_{apt}(X)=m_{o}\circ(W+s\cdot W_{B}W_{A})X\circ m_{i},"where \(s\) is the constant scaling factor following LoRA's implementation, and \(\circ\) denotes the Hadamard product between the masks and their corresponding matrices",H_{apt}(X)=m_{o}\odot\left( W_{B}\cdot\left( W_{A}\cdot\left(m_{i}\odot X\right)\right)\right),"The APT adapter output, where \(\mathbf{m}_{i}\) and \(\mathbf{m}_{o}\) are binary pruning masks for input and output dimensions, and \(W_A\) and \(W_B\) are tuning matrices with dynamic rank \(r_{\text{apt}}\)."
ICML_2024_oral_3,4,"S(W_{i,j})=|W_{i,j}\cdot\frac{\partialL}{\partial W_{i,j}}|",,s_i=\left| w_i\cdot\frac{\partialL}{\partial w_i}\right|,The salience score \(s_i\) for the \(i\)-th parameter is the absolute value of the product of the parameter value \(w_i\) and the gradient of the loss with respect to that parameter.
ICML_2024_oral_3,5,"\widetilde{S}_{t}(W_{:,j})=\sum_{(x,y)\inD_{t}}\sum_{i}|\frac{\partialL (x,y|\Theta_{t},M_{t})}{\partial H_{j,i}}| || \sum_{(x,y)\inD_{t}}\sum_{i}|H_{j,i}| || \hat{S}((W_{:,j})=\widetilde{S}(W_{:,j})+(Kurt(O_{j:}))^{\frac{1}{2}}",,\hat{S}=\left\|\left(\sum_{b=1}^{B}a_b\right)\odot\left(\sum_{b=1}^{B}\frac{\partialL}{\partiala_b}\right)\right\|_1\cdot\kappa(A),"\(\hat{S}\) is the outlier-aware salience score for a parameter block, computed as the product of the L1 norm of the element-wise product of the batch-summed activation and gradient vectors and the kurtosis of the activation matrix."
ICML_2024_oral_3,6,C(\Theta_{t};M_{t})\approx d_{m}\sum_{i=1}^{n_{L}}(4n_{h} ^{i}\cdot d_{h}+2n_{f}^{i}),where \(d_{h}\) is the dimension per MHA head,"C(\Theta_0,M_0)=4 n_L d_m^2+2 d_m\sum_{i=1}^{n_L} n_f^i","$\mathcal{C}(\Theta_0, \mathcal{M}_0)$ is the total number of parameters in the original unpruned LM, where $n_L$ is the number of transformer layers, $d_m$ is the hidden dimension size, and $n_f^i$ is the number of FFN neurons in layer $i$."
ICML_2024_oral_3,7,"L&=\muL_{ distill}+(1-\mu)L_{ft}\\L_{layer}&=\sum_{i=1}^{T}MSE(Tr(H_{s}^{\phi(i)}),H_{t}^{i})","where \(\mu\) is a moving term linearly scales from 0 to 1 during distillation to encourage the pre-pruned model vastly fit to the training data, \(\mathcal{L}_{distill}\) is the distillation objective from CoFi, and \(\mathcal{L}_{ft}\) is the supervised fine-tuning objective","L_{distill}=L(x,y|\Theta_s,M)+\lambda\cdot D_{KL}\left( p_{teacher}(x|\Theta_t,M)\parallel p_{student}(x|\Theta_s,M)\right)",The distillation loss combines the task loss and the Kullback-Leibler divergence between the teacher and student model outputs.
ICML_2024_oral_30,1,W^{\prime}=W_{0}+\Delta W=W_{0}+\underline{BA},"where \(W_{0}\) remains static during the fine-tuning process, and the underlined parameters are being trained",W^{\prime}=W_{0}+BA,The fine-tuned weight matrix \(W^{\prime}\) equals the original pre-trained weight matrix \(W_{0}\) plus the low-rank update \(BA\).
ICML_2024_oral_30,2,W=m\frac{V}{ || V || _{c}}= || W || _{c}\frac{W}{ || W || _{c}},"where \(m\in\mathbb{R}^{1\times k}\) is the magnitude vector, \(V\in\mathbb{R}^{d\times k}\) is the directional matrix, with \(||\cdot||_{c}\) being the vector-wise norm of a matrix across each column",W=diag(\mu)\Theta,where \(\boldsymbol{\mu} \in \mathbb{R}^d\) is the magnitude vector and \(\boldsymbol{\Theta} \in \mathbb{R}^{d \times k}\) is the direction matrix with each row being a unit vector.
ICML_2024_oral_30,3,"\Delta M_{FT}^{t}=\frac{\sum_{n=1}^{k}|m_{FT}^{n,t}-m_{0}^{n}|}{ k} || \Delta D_{FT}^{t}=\frac{\sum_{n=1}^{k}(1-\bf cos(V_{FT}^{ n,t},W_{0}^{n}))}{k}",,"\Delta m &=m_{FT}-m_{0},\\\Delta D &=D_{FT}-D_{0}","The magnitude variation vector \(\Delta m\) is the difference between the magnitude vectors of \(W_{\text{FT}}\) and \(W_0\), and the directional variation matrix \(\Delta D\) is the difference between their normalized direction matrices."
ICML_2024_oral_30,4,W^{\prime}=\underline{m}\frac{V+\Delta V}{ || V+\Delta V || _{c}}=\underline{m}\frac{W_{0}+\underline{BA}}{ || W_{0}+\underline{BA} || _{c}},"where \(\Delta V\) is the incremental directional update learned by multiplying two low-rank matrices \(B\) and \(A\), and the underlined parameters denote the trainable parameters",W'=\underline{m'}\frac{V+\underline{BA}}{\|V+\underline{BA}\|_{c}},"\( V \) is the frozen directional matrix initialized from \( W_0 \), \( \underline{m'} \) is the trainable magnitude vector, and \( \underline{BA} \) is the low-rank update to the directional matrix."
ICML_2024_oral_30,5,\nabla_{V^{\prime}}L=\frac{m}{ || V^{\prime} || _{c}}(I-\frac{V^{\prime}V^{\primeT}}{ || V^{\prime} || _{c}^{2}})\nabla_{W^{\prime}}L || \nabla_{m}L=\frac{\nabla_{W^{\prime}}L\cdot V^{\prime}}{ || V^{\prime} || _{c}},,"\frac{\partialL}{\partial m}=\left(\frac{\partialL}{\partial W'}\odot\frac{V'}{\|V'\|_{c}}\right)1_{d},\quad\frac{\partialL}{\partial V'}=\frac{m}{\|V'\|_{c}}\odot\left(\frac{\partialL}{\partial W'}-\frac{V'}{\|V'\|_{c}}\cdotdiag\left(diag\left(\left(\frac{V'}{\|V'\|_{c}}\right)^{\top}\frac{\partialL}{\partial W'}\right)\right)\right)","where \(\frac{\partial \mathcal{L}}{\partial m}\) is the gradient of the loss with respect to the magnitude vector, \(\frac{\partial \mathcal{L}}{\partial V'}\) is the gradient with respect to the directional matrix, \(\odot\) denotes element-wise multiplication, \(\mathbf{1}_{d}\) is a \(d\)-dimensional all-ones vector, and \(\operatorname{diag}(\cdot)\) extracts the diagonal elements of a matrix."
ICML_2024_oral_30,6,"cos(\nabla_{w^{\prime}}L,v^{\prime})=cos(\nabla_{w^{\prime}}L,v)=\frac{\nabla_{w^{\prime}}L\cdot v}{ || \nabla_{w^{\prime}}L ||  || v || }",,"\bf cos(v, w)=\frac{v\cdot w}{\|v\|\|w\|}","where \(v\) and \(w\) are vectors, and \(\text{\bf cos}(v, w)\) is the cosine similarity between them."
ICML_2024_oral_30,7,"\nabla_{m_{*}}L=\frac{\nabla_{w^{\prime}}L\cdot v^{\prime }}{ || v^{\prime} || }= || \nabla_{w^{\prime}}L || \cdot cos(\nabla_{w^{\prime}}L,v)",,"cos(\nabla_{w^{\prime}}L, v^{\prime})=\frac{\nabla_{m_*}L}{ || \nabla_{w^{\prime}}L || }","where \(m_*\) is the magnitude scalar for the weight vector \(w'\), and \(\nabla_{m_*}\mathcal{L}\) is the gradient of the loss with respect to \(m_*\)."
ICML_2024_oral_30,8," || \nabla_{w^{\prime}}^{S1}L || \cdot|cos(\nabla_{w^{\prime}}^{S1}L,v)|> || \nabla_{w^{\prime}}^{S2}L || \cdot|cos(\nabla_{w^{\prime}}^{S2}L,v)|",,\nabla_{m_{*}}L=\frac{\nabla_{w^{\prime}}L\cdot v}{ || v || },"The gradient of the loss with respect to the magnitude scalar \(m_{*}\) equals the dot product of the gradient with respect to the weight vector and the directional vector \(v\), divided by the norm of \(v\)."
ICML_2024_oral_30,9,\nabla_{V^{\prime}}L=\frac{m}{C}\nabla_{W^{\prime}}L\text { where }C= || V^{\prime} || _{c},,\nabla_{V^{\prime}}L=\frac{m}{\|V^{\prime}\|_{c}}\nabla_{W^{\prime}}L,"where \( \nabla_{V^{\prime}}\mathcal{L} \) is the gradient of the loss with respect to \( V^{\prime} \), \( m \) is the magnitude vector, \( \|V^{\prime}\|_{c} \) is the column-wise norm of \( V^{\prime} \), and \( \nabla_{W^{\prime}}\mathcal{L} \) is the gradient of the loss with respect to \( W^{\prime} \)."
ICML_2024_oral_37,1,"P_{t}=\{W_{t},O_{t}\}",,"P_{t}=(W_{t},O_{t})",The checkpoint at iteration \(t\) is defined as the tuple containing the model weights and optimizer momentum parameters.
ICML_2024_oral_37,2,"P=\{P_{1},P_{2},\cdots,P_{t}\,\cdots,P_{T}\}",,"P=\left(P^{(1)},P^{(2)},\dots,P^{(T)}\right)","The series \(\mathcal{P}\) is an ordered tuple of T checkpoints, where \(\mathcal{P}^{(i)}\) is the i-th checkpoint saved during training."
ICML_2024_oral_37,3,"O_{t}=\{v_{t},m_{t}\}",,"O_{t}=\{m_{t}, v_{t}\}",The optimizer parameters \(\mathcal{O}_{t}\) at iteration \(t\) comprise the first-order moment \(m_{t}\) and second-order moment \(v_{t}\).
ICML_2024_oral_37,4,"\DeltaP_{t}=\{\DeltaW_{t},O_{t}\}=\{W_ {t}-W_{t-1},O_{t}\}",,"\DeltaP_{t}=\{W_{t}-W_{t-1},O_{t}\}",The residual checkpoint \(\Delta\mathcal{P}_{t}\) contains the model weight residual \(\mathcal{W}_{t} - \mathcal{W}_{t-1}\) and the current optimizer state \(\mathcal{O}_{t}\).
ICML_2024_oral_37,5,"r_{w}=\frac{\alpha}{\sqrt{m_{t}}}\timesmedian(W),M _{w}(i)=\mathds{1}_{w_{t}(i)>r_{w}}",,"\tau^{(l)}=quantile\left(\{ v_{t,i}\mid i\in\Omega_l\}, s_l\right)","The threshold \(\tau^{(l)}\) for layer \(l\) is the \(s_l\)-th quantile of the second-order moments \(v_{t,i}\) in layer \(l\)."
ICML_2024_oral_37,6,"r_{o}=\beta\timesmean(v_{t}),M_{o}(i)=\mathds{1}_{v_{t}(i)> r_{o} and M_{w}(i)=1}",,"r_{o}=\beta\cdotmedian(|v_{t}|),\quadM_{o}(i)=M_{w}(i)\cdot\mathds{1}_{|v_{t}(i)| > r_{o}}","The momentum pruning threshold \( r_o \) is defined as hyperparameter \( \beta \) multiplied by the median of the absolute first-order moment, and the momentum mask \( \mathcal{M}_o(i) \) is the element-wise product of the weight mask and an indicator function requiring the absolute first-order moment at index \( i \) to exceed \( r_o \)."
ICML_2024_oral_37,7,"\tilde{R}(T)\leq\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}\sqrt {T\widehat{v}_{T,i}} || +\frac{\alpha(1+\beta_{1})G_{\infty}}{(1-\beta_{ 1})\sqrt{1-\beta_{2}}(1-\gamma)^{2}}\sum_{i=1}^{d}\|g_{1,\tau,i}\|_{2} || +\frac{D_{\infty}^{2}G_{\infty}\sqrt{1-\beta_{2}}}{2\alpha}\sum_ {i=1}^{d}\sum_{t=1}^{t}\frac{\beta_{1,t}}{(1-\beta_{1,t})}\sqrt{t} || +\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}})",,"R(T)\leq\frac{D^2}{2\alpha(1-\beta_1)}\sum_{i=1}^{d}\sqrt{T\hat{v}_{T,i}}+\frac{\alpha (1+\beta_1) G_\infty}{(1-\beta_1)\sqrt{1-\beta_2} (1-\gamma)^2}\sum_{i=1}^{d}\|g_{1:T,i}\|_2+\sum_{i=1}^{d}\frac{D_\infty^2 G_\infty\sqrt{1-\beta_2}}{2\alpha (1-\beta_1) (1-\lambda)^2}",The regret bound for Adam optimizer when the momentum states are pruned at iteration \(\tau\).
ICML_2024_oral_37,8,"\Delta\tilde{R}(T)&=\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}})\\&=\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}(1-M_{o})})",,"\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}\left(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}}\right)",The additional regret term due to pruning the moments.
ICML_2024_oral_37,9,\lim_{Tarrow\infty}\frac{\tilde{R}(T)}{T}\leq\lim_{Tarrow\infty}\frac{R(T)+\Delta\tilde{R}(T)}{T}=0,,\tilde{R}(T)=R(T)+\Delta\tilde{R}(T),Equation 9 expresses the regret bound of the proposed method as the sum of the original Adam regret bound and the additional term due to momentum pruning.
ICML_2024_oral_37,10,\frac{R(T)}{T}=O(\frac{1}{\sqrt{T}}),,"\tilde{R}(T)\leq\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}\sqrt{T\widehat{v}_{T,i}}+\frac{\alpha(1+\beta_{1})G_{\infty}}{(1-\beta_{1})\sqrt{1-\beta_{2}}(1-\gamma)^{2}}\sum_{i=1}^{d}\|g_{1,\tau,i}\|_{2}+\frac{D_{\infty}^{2}G_{\infty}\sqrt{1-\beta_{2}}}{2\alpha}\sum_{i=1}^{d}\sum_{t=1}^{T}\frac{\beta_{1,t}}{(1-\beta_{1,t})}\sqrt{t}+\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}\sqrt{T\widehat{v}_{\tau,i}(1-M_{o}(i))}",The regret bound for the training process with the proposed joint weight-momentum pruning method.
ICML_2024_oral_4,1,S_{opt_{t}}=\arg\min_{S\subseteq V_{t}}\{\textsc{Cost}(S):f(S)=f(V_{t})\}\enspace,where \(V_{t}\) denotes the set of the currently present elements after the first \(t\) updates,\min_{S\subseteq V_t}\sum_{v\in S} w(v)\quadsubject to\quad f(S)=f(V_t),"This equation defines the objective for the dynamic submodular cover problem at time \(t\), which is to select a subset \(S \subseteq V_t\) of minimum total weight that achieves the full submodular value \(f(V_t)\)."
ICML_2024_oral_4,2,"f(S)\geq(1-\epsilon)f(V),\quadand\quad\textsc{Cost}(S)\leq c\textsc{ Cost}(S_{opt})",where \(S_{opt}\) denotes the optimal solution,f(S)\geq (1-\epsilon) f(V)\quadand\quad\textsc{Cost}(S)\leq c\cdot\textsc{OPT}_{\textsc{cost}},"The conditions that a set \(S\) must satisfy to be considered a \((1-\epsilon, c)\)-bicriteria approximate solution for the dynamic submodular cover problem."
ICML_2024_oral_4,3,"E[\,X(r)\,]\geq 1-2\epsilon for all r\in[1,m^{*}] and || E[\,X(m^{*}+1)\,]\leq 1-\frac{\epsilon}{2}",,"\forall j\in\{1, 2,\dots, m^{*}\},\quad\Pr\left[\,X_j=1\,\right]\geq 1-\epsilon","For every position j from 1 to m^*, the probability that the j-th element in the random ordering is added to G is at least 1-ε."
ICML_2024_oral_41,1,"\min_{\theta_{1},\theta_{2},...,\theta_{N}}[\frac{1}{N}\sum_{i=1}^{N}L_{i}(\theta_{i})]+R(\theta_{1},\theta_{2},...,\theta_{N})",,"\min_{\theta_1,\theta_2,\dots,\theta_N}\frac{1}{N}\sum_{i=1}^{N}E_{(x, y)\simD_i}\left[\ell_i\left( f_{A_i}(x;\theta_i), y\right)\right]",The global objective of MFL minimizes the average expected loss across all clients over their local data distributions.
ICML_2024_oral_41,2,A_{i}\capA_{i^{\prime}}=\{B_{enc}^{(m)}|\forall m\inI_{i}\capI_{i^{\prime}}\}\cup\{B_{share}\},,"A_i=\left\{B_{enc}^{(m)}\mid\forall m\inI_i\right\}\cup\left\{B_{share}\right\}\cup\left\{B_{dec,i\right\}","The model architecture for client $i$ comprises modality-specific encoders for each modality $m \in \mathcal{I}_i$, a shared block $\mathcal{B}_{\mathrm{share}}$, and a client-specific decoder $\mathcal{B}_{\mathrm{dec},i}$."
ICML_2024_oral_41,3,A_{i}\capA_{i^{\prime}}=\emptyset,,"\forall i\neq i'\in [N],A_i\capA_{i'}=\emptyset","For any two distinct clients, the intersection of their model architectures is empty, indicating no predefined shared components."
ICML_2024_oral_41,4,"\theta_{i}:=h(A_{i},c_{i};\phi),\\\\forall i\in[N]","where the first generative factor \(\mathcal{A}_{i}\in\mathcal{G}\) is the local neural architecture from a globally-shared _latent topology space_\(\mathcal{G}\) and the second generative factor \(\mathbf{c}_{i}\in\mathcal{T}\) represents the lo

Figure 1: (a) Local mapping functions per client in Multimodal Federated Learning (MFL)","\theta_{i}=h(g_{i},z_{i};\phi)","The bridge function \(h\) generates local weights \(\theta_i\) for client \(i\) conditioned on its topological graph \(\mathbf{g}_i\) and latent vector \(\mathbf{z}_i\), using global parameters \(\phi\)."
ICML_2024_oral_41,5,"A_{i}:=(V_{i},E_{i},Z_{i}^{(0)})",,"A_i=(V_i,E_i)",The multimodal neural architecture \(\mathcal{A}_i\) of client \(i\) is represented as a directed acyclic graph with node set \(\mathcal{V}_i\) and edge set \(\mathcal{E}_i\).
ICML_2024_oral_41,6,"h(A_{i},c_{i};\phi)=\texttt{Comb}(c_{i},\texttt{Role}(A_{i};\phi_{1});\phi_{2})","where the first stage \(\texttt{Role}(\cdot;\phi_{1})\) parameterized by \(\phi_{1}\) learns the implicit roles of layers such that layers across clients share a unified _layer-role embedding_ space, and the second stage \(\texttt{Comb}(\cdot,\cdot;\phi_{2})\) parameterized by \(\phi_{2}\) aims to combine the two heterogeneity patterns and directly generates the weights","\theta_i=h(A_i,c_i;\phi)=g_{\phi_h}\left( f_{\phi_g}(A_i),c_i\right)",The bridge function is implemented by a topology-aware hypernetwork (TAHN) consisting of a graph neural network that encodes the client's architecture into node embeddings and a hypernetwork that generates weights for each parametric node from the node embeddings and the client's task vector.
ICML_2024_oral_41,7,"Z_{i}^{(L)}=\texttt{Role}(A_{i};\phi_{1}) || :=g_{L}\circ g_{L-1}\circ...\circ g_{1}(Z_{i}^{(0)}; V_{i},E_{i})",,"z_{i,v}^{(l)}=\sigma\left(W_{self}^{(l)}z_{i,v}^{(l-1)}+W_{neigh}^{(l)}\sum_{u\inN_{in}(v)}z_{i,u}^{(l-1)}\right)","The update rule for node \(v\) at layer \(l\) of the GNN in the layer-role encoder, where \(\mathbf{z}_{i,v}^{(l)}\) is the node embedding after the \(l\)-th layer, \(\mathcal{N}_{\text{in}}(v)\) is the set of in-neighbors of node \(v\), and \(\sigma\) is an activation function."
ICML_2024_oral_41,8,"z_{i,v}^{(l)}=\sigma(W_{self}^{(l)}z_{i,v}^{(l-1)}+W_{in}^{(l)}\sum_{(v^{\prime},v)\inE_{i}}z_{i,v^{\prime}}^ {(l-1)} || \qquad+W_{out}^{(l)}\sum_{(v,v^{\prime})\in E_{i}}z_{i,v^{\prime}}^{(l-1)}+b^{(l)})",,"z_{i,v}^{(l)}=ReLU\left(W_{self}^{(l)}z_{i,v}^{(l-1)}+W_{neigh}^{(l)}\sum_{u\inN_{in}(v)}z_{i,u}^{(l-1)}\right)","The embedding of node \(v\) at layer \(l\) is computed by a linear transformation of its own embedding from layer \(l-1\) and the aggregated embeddings of its incoming neighbors, followed by a ReLU activation."
ICML_2024_oral_41,9,"\theta_{i,v}:=g_{node}(c_{i}\oplusz_{i,v}^{(L)};\phi_{ 2}),\;\forall v\inV_{i}",where \(\oplus\) denotes an operation (e,"\theta_{i,v}=g_{node}(c_{i},z_{i,v}^{(L)};\phi_{2})",The weight tensor for each parametric computational operator node \(v\) in client \(i\)'s architecture is generated by a node decoder function \(g_{\text{node}}\) using the client-specific task embedding and the node's layer-role embedding.
ICML_2024_oral_41,10,\Deltac_{i}=\nabla_{c_{i}}L_{i}(\theta_{i})=\Delta\theta_{i}\cdot\nabla_{c_{i}}\theta_{i} || \Delta\phi_{2}=\frac{1}{|N_{r}|}\sum_{i\inN_{r}}(\Delta\theta_{i}\cdot\nabla_{\phi_{2}}\theta_{i}) || \Delta\phi_{1}=\frac{1}{|N_{r}|}\sum_{i\inN_{r}}(\Delta\theta_{i}\cdot\nabla_{z_{1}^{(L)}}\theta_{i}\cdot\nabla_{\phi_{i} }Z_{i}^{(L)}),,"\theta_{i,v}:=g_{node}(c_{i}\oplusz_{i,v}^{(L)};\phi_{ 2}),\;\forall v\inV_{i}","The weights $\theta_{i,v}$ for each parametric computational operator $v$ in client $i$'s model are generated by a node decoder function $g_{\text{node}}$ that combines the client-specific task embedding $\mathbf{c}_i$ and the layer-role embedding $\mathbf{z}_{i,v}^{(L)}$ via an operation $\oplus$."
ICML_2024_oral_44,1,"\operatorname*{arg\,max}_{\theta\in\Theta}E_{G^{\prime}\sim D_{\theta}}[u_{\tau}(G^{\prime})]",where \(D_{\theta}\) is a parameterized distribution and \(\Theta\) represents a feasible set of real-valued parameters,\max_{\theta}E_{E\sim p_{\theta}}\left[ u_{\tau}(G_{E})\right],The objective function maximizes the expected utility of the DAG \(G_{\mathcal{E}}\) under the distribution \(p_{\theta}\) over edge sets \(\mathcal{E}\).
ICML_2024_oral_44,2,"\prod_{i=1}^{d}\theta_{i}&if\,(N,E\cup(\{e_{j}\}_{j=1}^{i-1}\capE)\cup\{e_{i}\})\,is a DAG,\\0&otherwise",,P(G^{\prime}=G_{E})=\prod_{i=1}^{d}\theta_i^{1_{\{e_i\inE\}} (1-\theta_i)^{1_{\{e_i\notinE\}}},"The probability of graph \(G'\) with edge set \(\mathcal{E}\) is the product of independent Bernoulli probabilities for each non-required potential edge \(e_i\), where \(\theta_i\) is the probability of edge \(e_i\) being included."
ICML_2024_oral_44,3,\nabla_{\theta}E_{G_{E}\sim D_{\theta}} [u_{\tau}(G_{E})]\approx\frac{1}{M}\sum_{i=1}^{M}\hat{u}_ {\tau}(G_{i})\nabla_{\theta}\log(p_{\theta}(G_{i})),"where \(G_{1},G_{2},\ldots,G_{N}\sim D_{\theta}\) are mutually independent and \(\hat{u}_{\tau}(G_{i})\) is an independent unbiased estimate of \(u_{\tau}(G_{i})\) for all \(i\) and some \(M\in\mathbb{N}\)",\nabla_{\theta}E_{G'\sim D_{\theta}} [u_{\tau}(G')]=E_{G'\sim D_{\theta}}\left[ u_{\tau}(G')\nabla_{\theta}\log D_{\theta}(G')\right],The gradient of the expected utility with respect to the parameters $\theta$ expressed as an expectation for unbiased estimation via the REINFORCE algorithm.
ICML_2024_oral_5,1,x_{i}^{\ell+1}=x_{i}^{\ell}+\texttt{MLP}^{\ell}(x_{i}^{\ell}+\texttt{Att}^{\ell}(x_{i}^{\ell})),,x_i^{(l)}=x_i^{(l-1)}+Attn^{(l)}(x_i^{(l-1)})+MLP^{(l)}\left(x_i^{(l-1)}+Attn^{(l)}(x_i^{(l-1)})\right),"This equation updates the residual stream for token i at layer l by adding the attention output and the MLP output, where the MLP operates on the sum of the previous residual stream and the attention output."
ICML_2024_oral_5,2,\texttt{MLP}^{\ell}(x^{\ell})=\sigma(W_{K}^{\ell}x^{\ell})W_{V}^{\ell},"where \(W_{K}^{\ell},W_{V}^{\ell}\in\mathbb{R}^{d_{mlp}\times d}\)",\texttt{MLP}^{\ell}(x)=W_2^{\ell}\sigma\left( W_1^{\ell}x\right),"The MLP block at layer \(\ell\) applies two linear transformations with a point-wise activation function \(\sigma\) in between, defined by weight matrices \(W_1^{\ell}\) and \(W_2^{\ell}\)."
ICML_2024_oral_5,3,\texttt{MLP}^{\ell}(x^{\ell})=\sum_{i=1}^{d_{mlp}}\sigma(x^{\ell}\cdotk_{i}^{\ell})v_{i}^{\ell}=\sum_{i=1}^{d_{mlp}}m_{i} ^{\ell}v_{i}^{\ell},,\texttt{MLP}^{\ell}(x^{\ell})=\sum_{i=1}^{d_{mlp}} m_i^{\ell}v_i^{\ell},The MLP output is the sum of the value vectors \(\mathbf{v}_i^\ell\) scaled by the coefficients \(m_i^\ell\).
ICML_2024_oral_5,4,"p\big{(}w\midx^{\ell}+m_{i}^{\ell}v_{i}^{\ell},E\big{)}\propto\exp\big{(}e_{w}\cdotx^{\ell}\big{)}\cdot\exp\big{(}e_{w}\cdot m_{i}^{\ell}v_{i}^{\ell}\big{)}",where \(\mathbf{e}_{w}\) is the embedding of \(w\),effect_i^\ell(w)=U[w]v_i^\ell,The effect of the value vector \(\mathbf{v}_i^\ell\) on the logit of token \(w\) is given by the dot product between the unembedding vector of \(w\) and the value vector.
ICML_2024_oral_5,5,\texttt{GLU}^{\ell}(x^{\ell})=(\sigma(W_{1}x^{\ell})\odot W_{ 2}x^{\ell})W_{V}^{\ell},"where \(W_{1}^{\ell},W_{2}^{\ell},W_{V}^{\ell}\in R^{d_{mlp}\times d}\)",\texttt{GLU}^{\ell}(x^{\ell})=W_V^{\ell}\left( (W_K^{\ell}x^{\ell})\odot\sigma(W_G^{\ell}x^{\ell})\right),"The GLU block at layer $\ell$ applies linear transformations $W_K^{\ell}$ and $W_G^{\ell}$ to the residual stream, takes the element-wise product of $W_K^{\ell} \mathbf{x}^{\ell}$ and the activated $\sigma(W_G^{\ell} \mathbf{x}^{\ell})$, and projects by $W_V^{\ell}$."
ICML_2024_oral_5,6,"P(Toxic|\bar{x}^{L-1})=softmax(W_{Toxic}\bar{x}^{L-1}),W_{Toxic}\inR^{d}",,z=W_{Toxic}\bar{x}^{L-1},"where \(z\) is the toxicity logit, \(W_{\text{Toxic}}\) is the probe weight vector, and \(\bar{\mathbf{x}}^{L-1}\) is the averaged residual stream at layer \(L-1\)."
ICML_2024_oral_5,7,x^{L-1}=x^{L-1}-\alpha*W,where \(a\) is a heuristic scale value and \(W\) is one of our toxicity vectors,x^{L}=x^{L}-v_{Toxic},"$\mathbf{x}^{L}$ is the residual stream at the final layer, and $\mathbf{v}_{\text{Toxic}}$ is a toxic vector (e.g., $W_{\text{Toxic}}$, MLP.$\mathbf{v}_{\text{Toxic}}$, or SVD.$\mathbf{U}_{\text{Toxic}}[i]$)."
ICML_2024_oral_5,8,"L_{DPO}=-E[\log\sigma(\beta\log P-\beta\log N)] || P=\frac{\pi_{\theta}(y_{+}\midw)}{\pi_{ref}(y_{+}\midw)},N=\frac{\pi_{\theta}(y_{-}\midw)}{\pi_{ref}(y_{-}\midw)}",,"L_{DPO}=-E_{(x, y_w, y_l)\simD}\left[\log\sigma\left(\beta\left(\log\frac{\pi_\theta(y_w | x)}{\pi_{ref}(y_w | x)}-\log\frac{\pi_\theta(y_l | x)}{\pi_{ref}(y_l | x)}\right)\right)\right]",The DPO loss function that promotes the likelihood of preferred responses and suppresses non-preferred ones.
ICML_2024_oral_5,9,p(y\mid a)\propto p(y)p(a\mid y),,x\leftarrowx+\alpha\frac{\nabla_{x}\log p(a\midx)}{\|\nabla_{x}\log p(a\midx)\|},"where \(\mathbf{x}\) is the residual stream, \(a\) is the desired attribute, and \(\alpha\) is a step size."
ICML_2024_oral_5,10,"\gamma(k_{i}^{\ell}):=\{g|g\inR^{d},\sigma(k_{i}^{\ell}\cdotg)>0\}",where \(\sigma\) is a non-linear activation,R_{i}^{\ell}=\left\{x\inR^d\midx\cdotk_i^\ell\geq\theta\right\},The activation region for the key vector \(\mathbf{k}_i^\ell\) is the set of residual stream vectors \(\mathbf{x}\) with a dot product above threshold \(\theta\).
ICML_2024_oral_5,11,"\forall j<\ell,\forall i<d_{mlp}:cos(\delta_{x}^{\ell\_midmid},\delta_{MLP,v_{i}}^{j})",,"\gamma(k_{i}^{\ell}) :=\left\{g\midg\inR^{d},\sigma(k_{i}^{\ell}\cdotg) > 0\right\}",The activation region for a key vector $\mathbf{k}_{i}^{\ell}$ is the set of residual stream vectors $\mathbf{g}$ that yield a positive activation output.
ICML_2024_oral_53,1,generalization gap\leq\sqrt{\frac{CMI_{D}(A_{n})}{n}},,E[gen(W)]\leq\sqrt{\frac{2\ln 2\cdotCMI_{D}(W)}{n}},This equation bounds the expected generalization error in terms of the conditional mutual information (CMI) and the sample size $n$.
ICML_2024_oral_53,2,F_{D}(A_{n}(S_{n}))-\min_{\theta\in\Theta}F_{D}(\theta)\leq\varepsilon,,O\left(\sqrt{\frac{1}{\varepsilon^{2} n} }\right),Asymptotic upper bound on the generalization gap for the Lipschitz bounded SCO case after substituting the CMI lower bound.
ICML_2024_oral_53,3,CMI_{D}(A_{n})\triangleq I(A_{n}(S_{n}) ;U|\tilde{Z}),,CMI_{D}(A_{n})=I\left(A_{n}(S_{n}); U\mid\tilde{Z}\right),The conditional mutual information (CMI) of algorithm \(\mathcal{A}_n\) with respect to distribution \(\mathcal{D}\).
ICML_2024_oral_53,4,E[F_{D}(A_{n}(S_{n}) )]-\min_{\theta\in\Theta}F_{D}(\theta) || \leqEGE_{D}(A_{n})+E\big{[}\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\big{]},,CMI_{D}(A_{n})\geq\Omega\left(\frac{1}{\varepsilon}\right),Lower bound on the conditional mutual information for any \(\varepsilon\)-learner in the strongly convex setting.
ICML_2024_oral_53,5,E[F_{D}(A_{n}(S_{n}) )]-\min_{\theta\in\Theta}F_{D}(\theta) || \leq LR\sqrt{\frac{8CMI_{D}(A_{n})}{ n}}+E\big{[}\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\big{]},,E\left[F_{D}(A_{n}(S_{n}))\right]-\min_{\theta\in\Theta}F_{D}(\theta)\leq LR\sqrt{\frac{8CMI_{D}(A_{n})}{n}}+E\left[\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\right],Upper bound on the expected excess population error in terms of the CMI-based generalization bound and the expected empirical excess risk.
ICML_2024_oral_53,6,"ISCMI_{D}(A_{n})\triangleq\sum_{i=1}^{n}I(A_{n}(S);U_{i}|Z_{0,i},Z_{1,i})",,E[F_{D}(A_{n}(S_{n}) )]-\min_{\theta\in\Theta}F_{D}(\theta),Decomposition of expected excess error into a CMI-based generalization bound and the expected empirical optimization error.
ICML_2024_oral_53,7,E[\sum_{i=1}^{n}\sum_{k=1}^{d}(\frac{144\varepsilon^{2}-d(\mu^{(k)})^{2}}{1-d(\mu^{(k)})^{2}})(\hat{\theta} ^{(k)})(Z_{i}^{(k)}-\mu^{(k)})] || \quad\geq 2\varepsilon-4\delta,,"ISCMI_{D}(A_{n})\triangleq\sum_{i=1}^{n}I(A_{n}(S);U_{i}|Z_{0,i},Z_{1,i})",The individual sample conditional mutual information (ISCMI) of algorithm \(\mathcal{A}_n\) with respect to distribution \(\mathcal{D}\) is defined as the sum over training samples of the mutual information between the algorithm's output and each selection bit \(U_i\) given the two possible samples for the \(i\)-th index.
ICML_2024_oral_55,1,"D_{LCA}(y^{\prime},y):=f(y)-f(N_{LCA}(y,y^{\prime}))","where \(f(y)\geq f(N_{LCA}(y,y^{\prime}))\) and \(N_{LCA}(y^{\prime},y)\) denotes the lowest common ancestor class node for classes \(y\) and \(y^{\prime}\) within the hierarchy, and \(f(\cdot)\) represents a function of a node, such as the tree depth or entropy","d_{LCA}(y, y')=\frac{ h_{\max}-h(LCA(y, y')) }{ h_{\max} }",The LCA distance between the ground truth class \( y \) and predicted class \( y' \) is defined as the normalized difference between the maximum height in the taxonomy and the height of their lowest common ancestor.
ICML_2024_oral_55,2,"D_{LCA}(model,M):=\frac{1}{n}\sum_{i=1}^{n}D_{LCA}(\widehat{y}_{i},y _{i})\iff y_{i}\neq\widehat{y}_{i}","where \(\widehat{y}_{i}\) is the predicted class for sample \(X_{i}\) using the model, \(y_{i}\) is the ground truth class for sample \(X_{i}\), and \(y_{i}\neq\widehat{y}_{i}\)",IC(c)=-\log P(c),"where \(P(c)\) is the probability of node \(c\) in dataset \(\mathcal{M}\), computed as the relative frequency of samples whose ground truth class belongs to the subtree rooted at \(c\)"
ICML_2024_oral_58,1,"Sequence model:\hat{z}_{t},\,h_{t}=seq(z_{t-1},\,h_{t-1},\,a_{t-1}) || Multimodal encoder: z_{t}\simenc(x_{t},\,l_{t},\,h_{t}) || Multimodal decoder:\hat{x}_{t},\,\hat{l}_{t},\,\hat{r}_{t},\,\hat{c}_{t}=dec(z_{t},\,h_{t})",,"\hat{z}_{t+1}=SeqModel(h_t, z_t, a_t)","The sequence model predicts the next latent representation \(\hat{z}_{t+1}\) using the recurrent state \(h_t\), current latent representation \(z_t\), and action \(a_t\)."
ICML_2024_oral_58,2,"Image loss:\qquad\quadL_{x}=\|\hat{x}_{t}-x_{t}\|_{2}^{2} || Language loss:\qquad\quadL_{t}=catext(\hat {t}_{t},l_{t}) || Reward loss:\qquad\quadL_{r}=catext(\hat {r}_{t},twoot(r_{t})) || Continue loss:\qquad\quadL_{c}=binkent(\hat{c}_{t},c_{t}) || Regularizer:\qquad\quadL_{reg}=\beta_{reg}\max(1,KL\big{[}z_{t}\bigm{\|}\\sg(\hat{z}_{t})\big{]})",,"L_{repr}=catxent(x_{t},\hat{x}_{t})+catxent(l_{t},\hat{l}_{t})+catxent(r_{t},\hat{r}_{t})+binxent(c_{t},\hat{c}_{t})+\beta_{reg}\cdotKL\left( q(z_{t}\mid x_{t}, l_{t}, h_{t})\parallelsg\left(p(z_{t}\mid h_{t})\right)\right)","The representation learning loss consists of reconstruction losses for the image, language token, and reward using categorical cross entropy, a continuation loss using binary cross entropy, and a KL regularization term scaled by \(\beta_{\mathrm{reg}}\) that aligns the posterior with the stop-gradient prior."
ICML_2024_oral_58,3,"Prediction loss:\quadL_{pred}=\beta_{pred}\\max(1,KL\big{[}\,sg(z_{t})\bigm{\|}\hat{z}_{t}\big{]})",where the gradient around the target distribution for \(z_{t}\) is stopped since it is also a learned representation and \(\beta_{\mathrm{pred}}=0,"L_{pred}=catext(\hat{z}_{t}, z_{t})",Future prediction loss: categorical cross entropy between the predicted representation and the actual representation.
ICML_2024_oral_58,4,"Actor net:\quad\pi(a_{t}|h_{t},z_{t})\qquadCritic net:\quadV(h_{t},z_{t})",,Actor:\quad a_t\sim\pi_\phi(s_t)\\Critic:\quad V_t=V_\psi(s_t),"The actor $\pi_\phi$ and critic $V_\psi$ are MLPs that map the state $s_t = [h_t, z_t]$ to an action distribution and a state value estimate, respectively."
ICML_2024_oral_60,1,"\min_{M}\alphaL_{in}(f(M\odot X),y) || -\betaL_{out}(f((1-M)\odot X),y)+R(M)",,L=-\log p(y\mid x_{masked-in})+\lambda\log p(y\mid x_{masked-out}),"The masking loss function combines the negative log-likelihood of the true label given the masked-in input and the log-likelihood of the true label given the masked-out input, scaled by a hyperparameter $\lambda$."
ICML_2024_oral_60,2,"\min_{\theta}\lambda_{in}L_{in}(\log f(M_{\theta}(h)\odot X),y) || -\lambda_{out}L_{out}(\log f((1-M_{\theta}(h))\odot X),y)+R(M_{\theta}(h))",,"\min_{\theta}\alphaL_{in}(f(M_{\theta}(h)\odot X), y)","Optimization objective for the decoder parameters \(\theta\) generating mask \(M_{\theta}(h)\), combining the in-mask loss, the negative out-mask loss, and a regularization term."
ICML_2024_oral_60,3,R(M_{\theta}(h))=\lambda_{g}\|M_{\theta}(h)\odot X-X\|+\lambda_{s}\|M_{\theta} (h)\|_{1},"where \(\lambda_{g}\) and \(\lambda_{s}\) are regularization coefficients, and \(X\) represents the spectrogram of the original signal",R(M)=\lambda_{reg}\|M\|_1+\gammaR_{ft}(M),"Here, \(\mathcal{R}_{\text{ft}}(M)\) denotes the additional regularization term introduced during fine-tuning to enhance interpretation quality."
ICML_2024_oral_60,4,x_{interpretation}=ISTFT((M_{\theta}(h)\odot X)e^{jX_{ phase}}),,\hat{x}=ISTFT\left( (M_{\theta}(h)\odot X)\cdot e^{j\phi}\right),where \(\phi\) is the phase of the original audio waveform \(x\).
ICML_2024_oral_60,5,FF_{n}:=f(X_{n})_{c}-f(X_{n}\odot(1-M_{\theta}(h)))_{c},,FF=f_y(X)-f_y((1-M)\odot X),The Faithfulness on Spectra (FF) metric computes the decrease in the predicted class logit \( f_y(X) \) when the masked-out portion \( (1 - M) \odot X \) is fed to the classifier.
ICML_2024_oral_60,6,AI:=\frac{1}{N}\sum_{n=1}^{N}1_{[f(X_{n}\odot M_{\theta}(h))>f (X_{n})_{c}]}\cdot 100,where \(\mathbf{1}_{[,AI_{n}:=f(X_{n}\odot M_{\theta}(h))_{c}-f(X_{n}\odot(1-M_{\theta}(h)))_{c},This metric measures the increase in confidence for the masked-in portion of the interpretation.
ICML_2024_oral_60,7,"AD:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n})_{c}-f(X_{n}\odot M_ {\theta}(h))_{c})}{f(X_{n})_{c}}\cdot 100",,"AD :=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0, f(X_n)_c-f(X_n\odot M_{\theta}(h))_c ) }{ f(X_n)_c }\times 100",Average Drop (AD) measures the average relative decrease in classifier confidence for the original predicted class when using the masked-in portion of the input audio.
ICML_2024_oral_60,8,"AG:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n}\odot M_{\theta}(h))_ {c}-f(X_{n})_{c})}{1-f(X_{n})_{c}}\cdot 100",,"AG :=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0, f(X_{n}\odot M_{\theta}(h))_{c}-f(X_{n})_{c})}{f(X_{n})_{c}}\cdot 100","Average Gain (AG) measures the average relative increase in the classifier's confidence for the target class when only the masked-in portion of the input is used, expressed as a percentage."
ICML_2024_oral_60,9,Fid-In=\frac{1}{N}\sum_{n=1}^{N}1_{[\arg\max_{c}f(X_{n})_{c}=\arg\max_{c}f_{c}(X_{n}\odot M_{\theta}(h))]},,Fid-In :=\frac{1}{N}\sum_{n=1}^{N}1_{[\arg\max_k f(X_n\odot M_{\theta}(h))_k=\arg\max_k f(X_n)_k]},Input Fidelity (Fid-In) is the fraction of examples where the classifier's top prediction on the masked input matches that on the original input.
ICML_2024_oral_66,1,"cost(P,S)=\sum_{p\in P}\min_{s\in S}dist(p,s)^{ z}",,cost(S)=\sum_{p\in P}\min_{s\in S}\| p-s\|^z,"Equation 1 defines the cost for (k,z)-clustering as the sum over all points \(p \in P\) of the \(z\)-th power of the distance to the nearest center in the solution set \(S\)."
ICML_2024_oral_66,2,P(M(P)\in S)\leq\exp(\varepsilon)\cdotP( M(P^{\prime})\in S)+\delta,,"cost(S)\leq M\cdot\textsc{opt}_{k,z}+A","The condition that a solution \(S\) has multiplicative approximation \(M\) and additive error \(A\) for the \((k,z)\)-clustering problem."
ICML_2024_oral_66,3,\sum_{p\in P}\|p-\mu\|^{z}\leq 2^{z}\sum_{p\in P}\|p-\mu_{z}\|^{z},,\sum_{p\in P}\|p-\mu_2\|^z\leq 2^{z}\sum_{p\in P}\|p-\mu_z\|^z,The cost of using the mean as the center for the z-cost is at most 2^z times the optimal z-cost.
ICML_2024_oral_66,4,"cost(E,\mu(E))=\sum_{p\in E}\|p\|_{2}^{2}-\frac{\|\sum_{p\in E }p\|_{2}^{2}}{|E|}",,\sum_{p\in E}\| p-\mu\|^2=\sum_{p\in E}\| p\|^2-\frac{1}{|E|}\left\|\sum_{p\in E} p\right\|^2,The optimal k-means cost for a cluster E equals the sum of squared norms of points in E minus the squared norm of their vector sum divided by the cluster size.
ICML_2024_oral_72,1,"L_{mask}=\underset{X\inD,t\in[0,T]}{ E}-\sum_{i=1}^{N}m_{t,i}\cdot\log(p_{\theta}(x_{i}|X_{t},X^{p},C))",,"L=E_{t,M_t}\left[-\sum_{i=1}^{N} m_{t,i}\log p_{\theta}(x_i\midX_t,X^p,C)\right]",The loss function minimizes the expected negative log-likelihood of the masked tokens over time \(t\) and mask \(\mathbf{M}_t\).
ICML_2024_oral_72,2,"p(X_{t-\Delta t}|X_{t},X^{p},C)=\underset {X_{0}\sim p_{\theta}(X_{0}|X_{t},X^{p},C)}{E}q(X_{t-\Delta t}|\hat{X}_{0},X_{t})",,"p_{\theta}(X_{t-\Delta t} |X_{t},X^{p},C)=\left(\prod_{i: m_{t,i}=1} p_{\theta}(x_i |X_{t},X^{p},C)\right)\times\prod_{i: m_{t,i}=0}1_{\{x_i=x_{t,i}\}}",The reverse transition distribution is the product of the model's predicted distribution for masked tokens and indicators enforcing unmasked tokens to remain unchanged.
ICML_2024_oral_73,1,"\theta_{t+1}=\theta_{t}-\eta_{t}(\sum_{i=1}^{n}\nabla\ell(\theta_{t},z_{i})+N(0,\frac{G^{2}}{2\rho}I_{p}))",,\theta_{t+1}=\theta_t-\eta_t\left(\nablaL(\theta_t)+\xi_t\right),"The Noisy Gradient Descent update rule, where $\xi_t$ is isotropic Gaussian noise added to the gradient for differential privacy."
ICML_2024_oral_73,2,M=\sqrt{\frac{K}{K-1}}P(I_{K}-\frac{1}{K}1_{K}1_{K}^{T })\inR^{p\times K},"where \(P=[P_{1},\cdots,P_{K}]\in\mathbb{R}^{p\times K}\) is a partial orthogonal matrix such that \(P^{T}P=I_{K}\)",H^{\top} H=\frac{K}{K-1}\left( I_K-\frac{1}{K}1_K1_K^{\top}\right),"The Gram matrix condition for an equiangular tight frame matrix \(H \in \mathbb{R}^{p \times K}\) of class means, where \(K\) is the number of classes."
ICML_2024_oral_73,3,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}}) || +\exp(-\frac{n}{8(\beta^{4}p^{2}+\frac{1}{3}\beta^{2} p)}),,\Pr\left[ y\widehat{\theta}_{NoisyGD}^{T} x < 0\right]\leq\exp\left(-\frac{n}{2 p\beta^{2}}\right)+\exp\left(-\frac{n^{2}}{2 p\beta^{4}}\right),Bound on the misclassification error for the NoisyGD algorithm.
ICML_2024_oral_73,4,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}}) || +\exp(-\frac{n}{8(\beta^{4}p+\frac{1}{3}\beta^{2} )}),,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp\left(-\frac{n^{2}\rho{2(1+\beta^{2}p)^{2}}\right)+\exp\left(-\frac{n}{8(\beta^{4}p+\frac{1}{3}\beta^{2})}\right),Upper bound on the misclassification error for NoisyGD when the components of the feature shift vector are independent.
ICML_2024_oral_73,5,\nablaL(\theta)=\frac{n}{2}\cdot 0.5\cdot-(-e_{1}+v)+\frac{n}{2}\cdot 0.5\cdot(e_{1}+v)=\frac{n}{2}e_{1},,\sum_{i=1}^{n} y_i x_i=n (e_1+v),Sum of the products of labels and features over the training dataset.
ICML_2024_oral_75,1,"J(\pi)=E_{(s_{t},\tau)\inD}[E_{a_{t}=\pi} [Q^{\pi}(s_{t},a_{t},\tau)]-\etaD_{KL}[\pi,\tilde{\pi}|s_{t},\tau]]",where \(\eta\) is a hyperparameter determining the strength of the regularization towards the reference policy \(\tilde{\pi}\),"J(\pi)=E_{\tau\sim\pi}\left[\sum_{t=0}^{\infty}\gamma^t\left( r(s_t, a_t)-\alpha D_{KL}\left(\pi(\cdot|s_t)\|\tilde{\pi}(\cdot|s_t)\right)\right]",The KL-regularized objective function \( J(\pi) \) balances the expected discounted return with a penalty on the KL-divergence between the improved policy \(\pi\) and the reference policy \(\tilde{\pi}\) at each state.
ICML_2024_oral_75,2,"\pi_{imp}(a_{t}|s_{t},\tau)\propto\exp(Q^{\pi_{imp}(s_{t},a_{t},\tau)}/\eta)\tilde{\pi}(a_{t}|s_{t},\tau) || \propto\exp(A^{\pi_{imp}(s_{t},a_{t},\tau)}/\eta)\tilde{\pi}(a_{t}|s_{t},\tau)",,"\pi_{imp}(a_t | s_t,\tau)\propto\tilde{\pi}(a_t | s_t,\tau)\exp\left(\frac{Q(s_t, a_t,\tau)}{\eta}\right)","the improved policy \(\pi_{\text{imp}}\) is proportional to the reference policy \(\tilde{\pi}\) scaled by the exponential of the state-action value function \(Q(s_t, a_t, \tau)\) divided by the regularization strength \(\eta\)."
ICML_2024_oral_75,3,"L^{Q}(\theta)=E\Big{[} (1-\alpha)D_{KL}[\pi_{imp},\pi_{\theta}|s_ {t},\tau,\tilde{\pi}=\pi_{\theta^{\prime}}] || +\alphaD_{KL}[b,\pi_{\theta}|s_{t},\tau] || +\betaD_{KL}[\Gamma_{\theta^{\prime}}(q|s_{t},a_{t },\tau),p_{\theta}(q|s_{t},a_{t},\tau)]\Big{]} || =-E\Big{[} (1-\alpha)\operatorname*{E}_{d^{\prime}\sim\pi_{\theta^{\prime}}}[w(a^{\prime},s_{t},\tau)\log\pi_{\theta}(a^{\prime}|s_{t},\tau)] || +\alpha\log\pi_{\theta}(a_{t}|s_{t},\tau) || +\beta\operatorname*{E}_{q\sim\Gamma_{\theta^{\prime}}}\log p_{\theta}(q|s_{t},a_{t},\tau)\Big{]}+K_{H}",,"L_{total}=E_{(s_t,\tau)\simD}\Bigl[\alpha D_{KL}\bigl[\pi_{imp}(\cdot|s_t,\tau)\parallel\pi_{\theta}(\cdot|s_t,\tau)\bigr]+\beta D_{KL}\bigl[\pi_{\theta}(\cdot|s_t,\tau)\parallel\pi_{\theta'}(\cdot|s_t,\tau)\bigr]\Bigr]+\gammaE_{(s_t,a_t,\tau)\simD}\Bigl[ D_{KL}\bigl[\Gamma_{\theta'}(\cdot|s_t,a_t,\tau)\parallel p_{\theta}(\cdot|s_t,a_t,\tau)\bigr]\Bigr]","The total loss \(\mathcal{L}_{\text{total}}\) combines weighted KL divergences for policy improvement, behavior cloning regularization, and Q-value distribution fitting, with \(\alpha\), \(\beta\), \(\gamma\) as balancing coefficients."
ICML_2024_oral_75,4,"N(C)=N_{0}*C^{a},\;\;\;D(C)=D_{0}*C^{b}",,"N\propto C^{0.5},\quad D\propto C^{0.5}",The number of parameters \(N\) and the number of tokens \(D\) for performance-optimal models scale as the square root of the compute \(C\) in FLOPs.
ICML_2024_oral_79,1,"L_{dyn}[\theta_{F,G,P}](o_{t,T},a_{t})= || -\bf cos\_sim\big{(}Q(P(T(z_{t},e_{t}))), stopgrad(P(z_{t+1}))\big{)}",,"\min_{G,T}E_{(o_{t-T+1:t+1}, a_t)\simD}\left[\left\|T(G(o_{t-T+1:t}), a_t)-sg\left(G_{target}(o_{t-T+2:t+1})\right)\right\|_2^2\right]","Minimize the mean squared error between the predicted next latent state from the forward transition model and the target next latent state produced by the target observation embedding, with the target detached via stop-gradient."
ICML_2024_oral_79,2,"L[\theta_{F,G,G,P,\psi}]=L_{dyn}[\theta_{F,G,P}]+\betaL_{act\_decode}[\theta_{F,G,\psi}]",,"L_{total}[\theta_{F,G,P,\psi}](o_{t,T},a_{t})=L_{dyn}[\theta_{F,G,P}](o_{t,T},a_{t})+L_{act\_decode}[\theta_{F,G,\psi}](o_{t,T},a_{t})","The combined loss function for pretraining the state encoder and action quantization module, which sums the dynamic loss and the action decoding loss."
ICML_2024_oral_79,3,"L_{\textbf{CE}}(\pi(stopgrad(z_{t})),\xi_{t})[\theta_{\pi}]",,"L_{ce}[\theta_{\pi}](z_{t},\xi_{t})=-\log\pi(\xi_{t}|z_{t})",The cross-entropy loss for training the skill-token policy π at a single timestep given the latent state and target token.
ICML_2024_oral_79,4,"L_{\textbf{FT\_DECODER}}[\theta_{\pi,\psi}]=E_{\xi_{t}\sim\pi(stopgrad(z_{t}))}\Big{[}L[\theta_{\psi}](\xi_{t})\Big{]} || L[\theta_{\psi}](\xi_{t})=\sum_{i=0}^{\hat{K}}L_{ action}(\psi(stopgrad(z_{t+i}),\xi_{t}[i]),a_{t+i})","where

\[\mathcal{L}[\theta_{\psi}](\xi_{t})=\sum_{i=0}^{\hat{K}}\mathcal{L}_{\text{ action}}(\psi(\text{stopgrad}(z_{t+i}),\xi_{t}[i]),a_{t+i}) \tag{5}\]

In this equation, \(\hat{K}=\min(K,L_{\xi})\), where \(K\) is a hyperparameter, the motivation behind which is explained at the end of Section 3","L_{\psi}=\|\psi(z_t, e_t)-a_t\|_1","The loss function for the action decoder $\psi$ during downstream adaptation, defined as the L1 norm of the difference between the decoded action and the expert action at a single timestep."
ICML_2024_oral_79,5,"L[\theta_{\pi,\psi}]=L_{\textbf{CE}}(\pi(stopgrad(z _{t})),\xi_{t})+L_{\textbf{FT\_DECODER}}[\theta_{\pi,\psi}]",,L_{total}=L_{\textbf{FT\_DECODER}}+L_{\textbf{CE}}},"The overall loss function for downstream adaptation, combining the finetuning decoder loss and the cross-entropy loss for the skill-token policy."
ICML_2024_oral_84,1,\max_{\pi}E_{\hat{e}\sim\hat{p}(e)}J(\pi;\hat{e}),,"\max_{\pi}E_{e\sim\hat{p}(e)}\left[ J(\pi, e)\right]",The objective is to maximize the expected performance metric \(J\) under the target environment distribution \(\hat{p}(e)\) by optimizing the policy \(\pi\).
ICML_2024_oral_84,2,\hat{e}\sim\hat{p}(e),,\hat{e}\sim\hat{p}(e),The sample environment \(\hat{e}\) is a specific instance drawn from the oracle environment distribution \(\hat{p}(e)\).
ICML_2024_oral_84,3,"E^{test}=\{\langle\hat{e}_{sim,i},r\rangle\}_{i=1,\cdots,n}",where the generated behavior \(\pi\) will be evaluated in,"E^{test}=\left\{\left(\hat{e}_{sim,1}, r\right),\left(\hat{e}_{sim,2}, r\right),\dots,\left(\hat{e}_{sim,n}, r\right)\right\}","The test environment \(\mathcal{E}^{\text{test}}\) is a set of tuples, each consisting of a simulated sample environment and the task specification."
ICML_2024_oral_84,4,f:E^{ref}arrowE^{shaped},,E^{shaped}=f(E^{ref}),The transformation function \( f \) maps the reference environment to the shaped environment.
ICML_2024_oral_84,5,"\max_{\pi}E_{\tau\sim\pi}[\sum_{t=0}^{T}\gamma^{t}r _{t}(s_{t},a_{t}))] || s.t.\\\s_{t+1}\sim p(s_{t},a_{t};E^{shaped })",,"\max_{\pi}E_{\langle e, r\rangle\simU(E^{shaped})}\left[ J(\pi; e, r)\right]",The optimization problem for training the policy $\pi$ to maximize the expected performance over environments and task specifications uniformly sampled from the shaped environment set.
ICML_2024_oral_84,6,H:f_{k}\times J(\pi^{\star}_{k};E^{test})\to f_{k+1},,"f_{k+1}=H(\pi_k^\star,E^{test})",The reflection process \(\mathcal{H}\) updates the shaping function \(f\) for the next iteration based on the current optimal behavior \(\pi^*_k\) and the test environment \(\mathcal{E}^{\text{test}}\).
ICML_2024_oral_84,7,"f_{k+1}=H(f_{k},J(\pi^{\star}_{k};E^{test})) || where\\\pi^{\star}_{k}=\underset{\pi}{argmax}\J(\pi;E^{shaped}_{k}) || E^{shaped}_{k}=f_{k}(E^{ref}),\f_{0}=I_{identity}",,\max_{f} J(\pi^{\star}_f;E^{test}),The objective of the iterative optimization process is to find the environment shaping function \( f \) that maximizes the performance of the trained behavior \( \pi^{\star}_f \) on the test environment \( \mathcal{E}^{\text{test}} \).
ICML_2024_oral_84,8,"\max_{f\inF} J(\pi^{\star};E^{test}) || s.t.\\\\pi^{\star}\in\arg\max_{\pi}J(\pi;E^{shaped }),\\E^{shaped}=f(E^{ref})",,\max_{f\inF} J(\pi^{\star};E^{test}),The bi-level optimization problem for the shaping function \(f\) to maximize test performance of the policy \(\pi^\star\) trained on the shaped environment.
ICML_2024_oral_93,1,c(\pi)=\|x_{\pi_{n}}-x_{\pi_{1}}\|_{2}+\sum_{i=1}^{n-1}\| x_{\pi_{i}}-x_{\pi_{i+1}}\|_{2},where \(\|\cdot\|_{2}\) denotes the \(\ell_{2}\) norm,"c(\pi)=\sum_{t=1}^{n}\|x_{\pi_t}-x_{\pi_{t+1}}\|_2,\quadwith\quad\pi_{n+1}=\pi_1",The total Euclidean length of the tour defined by permutation $\mathbf{\pi}$.
ICML_2024_oral_93,2,"L(\theta)=E_{\pi\simS}[E_{\Phi\sim f_{\theta}(s)}[E_{\pi\sim g(s,\Phi)}[c(\bm {\pi})]]]","where \(s\) represents an instance from distribution \(\mathcal{S}\), \(\theta\) is the trainable parameters of model \(f\), \(\mathbf{\pi}\) is the solution outputed by post-hoc search algorithm \(g\) given \(\Phi\), and \(c(\mathbf{\pi})\) is calculated based on Equation 1","\max_{\pi}\left(\Phi_{\pi_n,\pi_1}+\sum_{i=1}^{n-1}\Phi_{\pi_i,\pi_{i+1}}\right)","where \(\Phi_{\pi_i, \pi_j}\) is the heatmap value indicating the suitability of including the edge from vertex \(\pi_i\) to vertex \(\pi_j\) in the solution."
ICML_2024_oral_93,3,"L_{\textit{surrogate}}(\theta)=E_{s\simS}[E_{\Phi\sim f_{\theta}(s)}[\ell(s,\Phi)]]",,"L_{surr}(\theta)=E_{s\simS}\left[E_{\Phi\sim f_{\theta}(s)}\left[\ell(s,\Phi)\right]\right]","The surrogate objective \(\mathcal{L}_{\text{surr}}\) is the expectation of the differentiable surrogate loss \(\ell(s, \Phi)\) over instances \(s\) from distribution \(\mathcal{S}\) and heatmaps \(\Phi\) generated by model \(f_{\theta}(s)\)."
ICML_2024_oral_93,4,"p(\pi_{i}|\pi_{i-1})=\frac{Z_{\pi_{i-1},\pi_{i}}}{\sum_{l\inX_{\pi_{ i-1}}}Z_{\pi_{i-1},l}}",,"p(\pi_i\mid\pi_{i-1})=\frac{\exp(Z_{\pi_{i-1},\pi_i})}{\sum_{v\in V\setminus\{\pi_1,\dots,\pi_{i-1}\}}\exp(Z_{\pi_{i-1}, v})}","where \(V \setminus \{\pi_1, \dots, \pi_{i-1}\}\) denotes the set of unvisited vertices at step \(i\)"
ICML_2024_oral_93,5,"\Phi_{i,j}=\frac{e^{-d_{i,j}/\tau}}{\sum_{k\neq i}e^{-d_{i,k}/\tau}}","where \(d_{i,j}=\left\|x_{i}-x_{j}\right\|_{2}\), and \(\tau\) is a parameter controlling the smoothness of the score distribution in \(\Phi\)","\Phi_{i,j}=\frac{\exp(-d_{i,j})}{\sum_{k\neq i}\exp(-d_{i,k})},\quad i\neq j","where \(d_{i,j} = \|x_i - x_j\|_2\) is the Euclidean distance between vertex \(i\) and vertex \(j\), and the heatmap entry \(\Phi_{i,j}\) for edge \((i,j)\) is computed by applying the softmax function to the negative exponentiated distances from node \(i\) to all other nodes."
ICML_2024_oral_93,6,\textit{Score}=\frac{\textit{Gap}_{LKH-3}}{\textit{Gap}_{MCTS}},where \(\textit{Gap}_{\text{LKH-3}}=\frac{L_{\text{LKH-3}}}{L^{*}}-1\) and \(\textit{Gap}_{\text{MCTS}}=\frac{L_{\text{MCTS}}}{L^{*}}-1\),Score=\frac{c_{LKH-3}-c_{opt}}{c_{MCTS}-c_{opt}},"where \( c_{\text{LKH-3}} \), \( c_{\text{MCTS}} \), and \( c_{\text{opt}} \) denote the solution costs of LKH-3, MCTS, and the optimal solution, respectively."
ICML_2024_oral_95,1,"K_{img}(i,j)=\langle f_{img}(x_{i}),f_{img}(x_{j})\rangle || K_{text}(i,j)=\langle f_{text}(y_{i}),f_{text}(y_{j})\rangle",,"align(f_{text}, f_{ing})=\frac{\langle K^c, L^c\rangle_F}{\|K^c\|_F\|L^c\|_F}",The alignment between the language model \(f_{\text{text}}\) and vision model \(f_{\text{ing}}\) is defined as the normalized Frobenius inner product of their centered kernel matrices computed over the paired image-caption dataset.
ICML_2024_oral_95,2,"P_{\texttt{coor}}(x_{a},x_{b})\propto\sum_{(t,t^{\prime})\colon|t-t^{\prime}|\leq T_{\texttt{ window}}}P(X_{t}=x_{a},X_{t^{\prime}}=x_{b})",,"P_{cooccur}(x_a, x_b)=P\left( x_I=x_a, x_J=x_b\mid |I-J|\leq T_{window}\right)","The cooccurrence probability of observations \(x_a\) and \(x_b\) within a window of size \(T_{\text{window}}\), defined as the joint probability that a randomly selected pair of observations within the window are \(x_a\) and \(x_b\)."
ICML_2024_oral_95,3,"\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle\approx\log\frac{P(\texttt{pos}\mid x_{a},x_{b})}{ P(\texttt{neg}\mid x_{a},x_{b})}+\tilde{c}_{X}(x_{a}) || =\log\frac{P_{\texttt{coor}}(x_{a}\mid x_{b})}{P_{\texttt{coor}} (x_{a})}+c_{X}(x_{a})",,"\langle f_X(x_a), f_X(x_b)\rangle\approx\log\frac{P_{\texttt{coor}}(x_a, x_b)}{P(X=x_a)P(X=x_b)}+c","The dot product of the representations for two observations \(x_a\) and \(x_b\) approximates the log ratio of their cooccurrence probability to the product of their marginal probabilities, plus a constant \(c\)."
ICML_2024_oral_95,4,"=K_{\texttt{PMI}}(x_{a},x_{b})+c_{X}(x_{a})","where \(K_{\texttt{PMI}}\) is the pointwise mutual information (PMI) kernel, and \(c_{X}(x_{a})\) is constant in \(x_{b}\)","\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle\approx\log\frac{P_{\texttt{cooccur}}(z_{a}, z_{b})}{P_{\texttt{cooccur}}(z_{a}) P_{\texttt{cooccur}}(z_{b})}",The dot product of the learned representations for two observations approximates the pointwise mutual information of their corresponding underlying events.
ICML_2024_oral_95,5,"\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle=K_{\texttt{PMI}}(x_{a},x_{b})+c_{X}",where we observed that \(c_{X}(x_{a})\) from Eq,"\langle f_{X}(x_{a}), f_{X}(x_{b})\rangle=K_{\texttt{PMI}}(x_{a}, x_{b})",The inner product of the representation vectors for two observations equals their pointwise mutual information (PMI) kernel.
ICML_2024_oral_95,6,"P_{\texttt{coor}}(x_{a},x_{b})=P_{\texttt{coor}}(x_{a},x_{b}),\,K_{\texttt{PMI }}(x_{a},x_{b})=K_{\texttt{PMI}}(z_{a},z_{b})",where we use \(P_{\texttt{coor}}\) and \(K_{\texttt{PMI}}\) modality-agnostically to emphasize that different modalities share these same quantities,"\langle f_X(\texttt{obs}(z_a)), f_X(\texttt{obs}(z_b))\rangle=K_{\texttt{PMI}}(z_a, z_b)+c_X",The inner product of the representations of the observations of two events equals the pointwise mutual information of the events plus a constant.
ICML_2024_oral_95,7,"K_{\texttt{PMI}}(z_{a},z_{b})=\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle-c_{X} || =\langle f_{Y}(y_{a}),f_{Y}(y_{b})\rangle-c_{Y}",,"\langle f_{Y}(y_{a}), f_{Y}(y_{b})\rangle=K_{\texttt{PMI}}(y_{a}, y_{b})+c_{Y}","This equation states that the inner product for the text modality similarly equals the pointwise mutual information kernel plus a constant, extending the convergence result to any bijective discrete modality."
ICML_2024_oral_99,1,"\min_{(\pi,\hat{\Delta})}\max_{\nu\inE_{0}}(R_{\nu}(n,\pi),\max_{1\leq j\leq M}e_{\nu}(n,\hat{\Delta}(X_{j})))",where we use the subscript \(\nu\) to denote the contextual bandit instance,"\min_{(\pi,\hat{\Delta})}\max_{E\inE_0}\left[R(n,\pi)+\sum_{j=1}^{M} e\left(n,\hat{\Delta}(X_j)\right)\right]","This equation formulates the minimax multi-objective optimization problem for adaptive experiment design, minimizing the worst-case sum of cumulative regret and total mean squared error of CATE estimators across all features."
ICML_2024_oral_99,2,"\inf_{(\pi,\hat{\Delta}_{n})}\max_{\nu\inE_{0}}[e_{\nu}(n,\hat{\Delta}_{n})R_{\nu}(n,\pi)]\geq\Omega (M)",,"\min_{(\pi,\hat{\Delta})}\max_{\nu\inE_0}R_{\nu}(n,\pi)\cdot\max_{1\leq j\leq M} e_{\nu}(n,\hat{\Delta}(X_j))\geq\Omega(M)",The minimax lower bound on the product of regret and maximum mean squared error of CATE estimation over all features is \(\Omega(M)\).
ICML_2024_oral_99,3,"e_{\nu}(n,\hat{\Delta}_{n})=\max_{1\leq j\leq M}E[(\hat{\Delta}_{n}(X_{j})-\Delta(X_{j}))^{2}]=O(\frac{1}{ f_{\min}(n)})",,"\max_{1\leq j\leq M} e\left(n,\hat{\Delta}(X_{j})\right)\leq\frac{4\max_{1\leq j\leq M}\left(\sigma_{j1}^2+\sigma_{j0}^2\right)}{f_{\min}(n)}",Upper bound on the worst-case mean squared error under random control trials.
ICML_2024_oral_99,4,"R_{\nu}(n,\pi)\leqO(M\max\{f_{min}(n)^{1-\alpha},\log n\}) || e_{\nu}(n,\hat{\Delta}_{n})\leqO(\frac{1}{\max\{f_{min}(n)^{1-\alpha},\log n\}})",,"R_{\nu}(n,\pi)=O\left( M\cdot\left(\log n+[f_{\min}(n)]^{1-\alpha}\right)\right)",Regret of the ConSE algorithm for any instance \(\nu\) is bounded by \(\mathcal{O}\left( M \cdot \left( \log n + [f_{\min}(n)]^{1-\alpha} \right) \right)\).
ICML_2024_oral_99,5,"e_{\nu}(n,\hat{\Delta}_{n})R_{\nu}(n,\pi)\leqO(M)",,"\max_{\nu\inE_{0}}R_{\nu}(n,\pi)e_{\nu}(n,\hat{\Delta}_{n})\leq O(M)",The worst-case product of regret and maximum mean squared error is bounded by O(M).
ICML_2024_oral_99,6,O((\log n_{j}+\log\log(1/\Delta(X_{j})))(\frac{ 1}{\Delta(X_{j})^{2}}+\frac{1}{\varepsilon\Delta(X_{j})})),,O\left(\frac{\log n}{\Delta_j^2}+\frac{\log n}{\varepsilon\Delta_j}\right),The maximum number of pulls of the suboptimal arm for any feature \(X_j\) in the first half periods of the DP-ConSE algorithm.
ICML_2024_oral_99,7,"e(n,\hat{\Delta})=O(\frac{1}{\max\{f_{min}(n)^{1-\alpha},\frac{\log n}{\varepsilon}\}})",,O\left(\left(\log n_j+\log\log\frac{1}{\Delta(X_j)}\right)\left(\frac{1}{\Delta(X_j)^2}+\frac{1}{\varepsilon\Delta(X_j)}\right)\right),Upper bound on the number of pulls of the suboptimal arm for feature \(X_j\) in the first half of the experiment.
naacl_2024_short_14,1,p_{lm}(x_{t}|c)=f\circg\circenc(c),"where \(f\) is the last linear layer with softmax activation, \(g\) is the two-layer MLP network with a residual connection in the last Transformer layer, and \(\mathrm{enc}\) includes the earlier layers of the model",P(x_t\mid c),Equation 1 represents the conditional probability distribution of the next token \(x_t\) given the context \(c = \{x_i\}_{i=1}^{t-1}\).
naacl_2024_short_14,2,p_{knnlm}(x_{t}|c)=\lambda p_{lm}(x_{t}|c)+(1-\lambda)p_{\text {knn}}(x_{t}|c),where \(\lambda\) is a hyperparameter for interpolation,p(x_{t}|c)=(1-\lambda) p_{lm}(x_{t}|c)+\lambda p_{knn}(x_{t}|c),"The next token distribution is a weighted interpolation of the base LM distribution and the kNN distribution, with \(\lambda\) controlling the interpolation weight."
naacl_2024_short_14,3,"z^{*}\in\operatorname*{arg\,min}_{z\inR^{d}}KL[f(z)\|p_{knnlm}]",where \(f\) is the last layer of the model with its trained parameters fixed (definition in Eq 1),\min_{h}KL\left( p_{knnlm}(\cdot|c)\parallel f(h)\right),"where \(\mathbf{h}\) is the representation vector, and we minimize the KL divergence between the kNN-LM distribution and the distribution generated by the last layer \(f\) given \(\mathbf{h}\)"
naacl_2024_short_16,1,"g(x)=\operatorname*{arg\,max}_{c\inY}P_{x\sim\phi(x,m)}(f(M(x,s))=c)",,"g(x)=\arg\max_{y\inY}\underset{s\sim\phi(x, m)}{P}\left( f(M(x,s)=y\right)","The smoothed model \(g\) predicts the class \(y \in \mathcal{Y}\) that maximizes the probability of the original model \(f\) outputting \(y\) when the input \(\mathbf{x}\) is masked by a random mask \(\mathbf{s}\) from the scheme \(\phi(\mathbf{x}, m)\)."
naacl_2024_short_16,2,"g^{\prime}(x)=\operatorname*{arg\,max}_{e\inY}P_{s \sim\phi(x,m)}(f(D(M(x,s)))=c)",,"g(x)=\operatorname*{arg\,max}_{c\inY}P_{s\sim\phi(x,m)}\left(f(D(M(x,s)))=c\right)",The smoothed model \(g(\mathbf{x})\) uses a denoiser \(D\) to fill masked tokens before passing the input to the base model \(f\).
naacl_2024_short_22,1,"R_{LM}(X,\tau,a^{*})=LM(a^{*}|X,\tau)",,"R_{LM}(X,\tau, a^*)=1 &if  f_{LM}(X,\tau)=a^*\\0 &otherwise","The sparse reward function \(R_{\text{LM}}\) assigns 1 if the language model \(f_{\text{LM}}\) predicts the target action \(a^*\) given state description \(X\) and task \(\tau\), and 0 otherwise."
naacl_2024_short_22,2,"L(X,S,\tau,a^{*})=\\\sum_{t=0}^{|X|}(V_{\theta}(X_{:t},\tau)-\gamma^{|X|-t}R_{LM}( X,\tau,a^{*}))^{2}",,"L=\left( V_{\theta}(X,\tau)-R_{LM}(X,\tau, a^{*})\right)^2",The loss function for a single state description is the squared error between the value function's prediction and the language model reward.
naacl_2024_short_22,3,"L_{V_{\theta}}=\underset{{c}S,\tau,a^{*}\sim D\\X\sim\pi|S,\tau}{E}[L(X,S,\tau,a^{*})+\phi]","where \(\gamma\) is a discount factor and \(\phi\) is a Kullback-Leibler penalty for normalizing \(V_{\theta}\), common when finetuning LMs with RL (Stiennon et al","L_{\theta}=\frac{1}{|D|}\sum_{(S,\tau,a^{*})\in D}L(X, S,\tau, a^{*})",The overall loss function for \(V_{\theta}\) averages the state description loss over the training set \(D\).
naacl_2024_short_23,1,"\hat{C}_{m},\hat{S}_{m},\hat{F}_{m}=\textsc{attributePredictor}(m,M) || \hat{E}=\textsc{CandidateGenerator}(m,E) || f(m|T,M,E)=\textsc{Constrainer}(\hat{E},\hat{C}_{m},\hat{S}_{m},\hat{F}_{ m})",,"f(m | T, M, E)=\arg\min_{e\in Q(m)}\left(1_{\{country(e)\neq\hat{c}\}}+1_{\{state(e)\neq\hat{s}\}}+1_{\{feature(e)\neq\hat{f}\}}\right)","The geocoding function $f$ selects the candidate entry $e$ from the ontology query results $Q(m)$ that minimizes the number of constraint violations with respect to the predicted country $\hat{c}$, state $\hat{s}$, and feature $\hat{f}$ for mention $m$."
naacl_2024_short_23,2,"Z=\textsc{transformer}(\textsc{Toinput}(m,M)) || \hat{C}_{m}=softmax(Z_{c}W_{c}) || \hat{S}_{m}=softmax(Z_{s}W_{s}) || \hat{F}_{m}=softmax(Z_{f}W_{f})",,"\hat{C}_{m} &=\arg\max_{c\inC} P(c\midprompt(m, M))\\\hat{S}_{m} &=\arg\max_{s\inS} P(s\midprompt(m, M))\\\hat{F}_{m} &=\arg\max_{f\inF} P(f\midprompt(m, M))","The AttributePredictor function predicts country \(\hat{C}_{m}\), state \(\hat{S}_{m}\), and feature class \(\hat{F}_{m}\) by maximizing the probability of each attribute given a prompt constructed from mention \(m\) and its context \(M\)."
naacl_2024_short_23,3,L=C_{m}log(\hat{C}_{m})+S_{m}log(\hat{S}_{m})+F_{m}log(\hat{F}_{m}),"where \(C_{m}\), \(S_{m}\), and \(F_{m}\) are one-hot vectors of size \(N\) representing the true country, state, and feature class for mention \(m\)","L=-\log\hat{C}_{m, c_m}-\log\hat{S}_{m, s_m}-\log\hat{F}_{m, f_m}","The cross-entropy loss for training the attribute predictor, where \(c_m\), \(s_m\), and \(f_m\) are the true country, state, and feature class labels for mention \(m\), and \(\hat{C}_{m, c_m}\), \(\hat{S}_{m, s_m}\), and \(\hat{F}_{m, f_m}\) are the predicted probabilities for the true classes."
naacl_2024_short_25,1,"f(q,d_{i})=\frac{\exp(s_{i,1})}{\exp(s_{i,1})+\exp(s_{i,0})}",,"f(q,d_i)=\frac{\exp(s_{i,1})}{\exp(s_{i,1})+\exp(s_{i,0})}","The ranking score for document $d_i$ is computed as the softmax probability of the ""Yes"" response given the query $q$ and document $d_i$."
naacl_2024_short_25,2,"s_{i,k}=LLM(l_{k}|q,d_{i})",,"f(q, d_i)=\frac{\exp(s_{i,1})+2\exp(s_{i,2})}{\exp(s_{i,0})+\exp(s_{i,1})+\exp(s_{i,2})}","The ranking score for document \(d_i\) is the expected relevance level, computed as the weighted average of relevance labels (0 for \(l_0\), 1 for \(l_1\), 2 for \(l_2\)) using softmax probabilities derived from the log-likelihoods \(s_{i,j}\)."
naacl_2024_short_25,3,"f(q,d_{i})=\sum p_{i,k}\cdot y_{k} || where p_{i,k}=\frac{\exp(s_{i,k})}{\sum_{k^{\prime}}\exp(s_{i,k^{\prime}})}",,"ER(q, d_i)=\sum_{k} y_k\cdot\frac{\exp(s_{i,k})}{\sum_{j}\exp(s_{i,j})}","The expected relevance value for document \(d_i\) given query \(q\) is computed as the weighted sum of the assigned relevance values \(y_k\) for each label \(l_k\), with weights being the softmax probabilities derived from the log-likelihood scores \(s_{i,k}\)."
naacl_2024_short_25,4,"f(q,d_{i})=s_{i,k^{*}}",,"f(q,d_{i})=s_{i, k^*}",The ranking score for the Peak Relevance (PR) method is the log-likelihood of the peak relevance label \( l_{k^*} \).
naacl_2024_short_26,1,"f(x,t,k;\theta)=y",,"P(y\mid x, t, k;\theta)","The conditional probability of stance label \(y\) given text \(x\), target \(t\), and knowledge \(k\), parameterized by \(\theta\)."
naacl_2024_short_26,2,"L_{gen}=-\sum_{i=1}^{|u|}\log p(u_{i}|,u_{< i},h(x,t,k);\theta)","where \(p(u_{i}|,\boldsymbol{u}_{<i},h(x,t,k);\theta)\) is the probability to select a token \(u_{i}\) at step \(i\) given the input \(h(x,t,k)\) and previously generated tokens \(\boldsymbol{u}_{<i}\)","\log P(u | h(x,t,k);\theta)","The log-likelihood of the output sequence u given the input h(x,t,k) and model parameters θ."
naacl_2024_short_26,3,v_{c}arrowNormalize(\betav_{c}+(1-\beta)v_{c}^{\prime}),"where \(\beta\) is a momentum coefficient, \(\text{Normalize}(\cdot)\) is the normalization function, and \(\boldsymbol{v}_{c}^{\prime}\) is the centroid of embeddings belonging to class \(c\) in the batch",v_{c}\leftarrow\betav_{c}+(1-\beta)\cdot\bar{z}_c,where \(\boldsymbol{\bar{z}}_c\) is the mean of the projected stance embeddings for class \(c\) in the current batch and \(\beta\) is the momentum hyperparameter.
naacl_2024_short_26,4,L_{con}=-\sum_{c=1}^{C}y_{c}\log\frac{exp(\frac{s_{c}}{\gamma})}{\sum_{j=1}^{C}exp(\frac{s_{j}}{\gamma})},where \(\gamma\) is a scalar temperature parameter and \(\boldsymbol{y}\) is the one-hot label for the current sample,L_{cont}=-\log\frac{\exp(s_c)}{\sum_{j\in S}\exp(s_j)},"where \(c\) is the correct stance class for the instance, and \(s_j\) is the cosine similarity between the projected stance embedding \(\boldsymbol{\hat{z}}\) and the prototype \(\boldsymbol{v}_j\) for class \(j\)."
naacl_2024_short_26,5,L=\lambda_{l}\cdotL_{gen}+(1-\lambda_{l})\cdotL _{con},where \(\lambda_{l}\) is involved to balance the optimization,L=L_{gen}+L_{con},The overall loss function of LKI-BART is the sum of the generation loss and the contrastive loss.
naacl_2024_short_27,1,"[sim_{A}^{j},sim_{B}^{j}]=X_{i}\cdot[X_{A}^{j},X_{B}^{j}]",,"s_{i,a}=X_i\cdotA_a","The similarity score \(s_{i,a}\) between the representation of example \(X_i\) and the representation of attribute \(a\) is computed as the dot product of their respective vector representations."
naacl_2024_short_27,2,"d_{sim}^{j}=\sigma(sim_{A}^{j},sim_{B}^{j})",,"p_j=\left(\frac{\exp(sim_A^j)}{\exp(sim_A^j)+\exp(sim_B^j)},\frac{\exp(sim_B^j)}{\exp(sim_A^j)+\exp(sim_B^j)}\right)",The similarity distribution \(p_j\) for attribute \(j\) is computed as the softmax of the similarity scores \(sim_A^j\) and \(sim_B^j\).
naacl_2024_short_27,3,"L_{kl}=\sum_{j=1}^{K}D_{KL}(d_{sim}^{j},d_{uni})",,L_{KL}=\frac{1}{J}\sum_{j=1}^{J} D_{KL}(d_{sim}^{j}\parallel d_{uni}),The overall KL loss is the average KL divergence between each similarity distribution and the uniform distribution over all attribute pairs.
naacl_2024_short_27,4,L_{total}=L_{ce}+\lambda L_{kl},where \(L_{ce}\) is the usual cross-entropy loss,L_{total}=L_{kl},The total loss is defined as the KL divergence loss.
naacl_2024_short_28,1,"S(y)=-\frac{1}{|H(x)|}\sum_{y^{\prime}\in H(x)}L(y^{\prime},y)",,"s(y)=-\frac{1}{|H(x)|}\sum_{y'\in H(x)} L(y,y')",The score (negative Bayes risk) for a candidate translation $\mathbf{y}$ is computed as the negative average of the loss (or utility) function $L$ over all sampled translations in $H(\mathbf{x})$.
naacl_2024_short_28,2,"y^{*}=\operatorname*{arg\,max}_{y\in H(x)}S(y)",,\hat{y}=\arg\max_{y\in H(x)} S(y),The MBR hypothesis \(\hat{\mathbf{y}}\) is the candidate translation in the set \(H(\mathbf{x})\) that maximizes the score \(S(\mathbf{y})\).
naacl_2024_short_28,3,"\max_{\pi_{\theta}}E_{x\sim D,y\sim\pi_{\theta}( y|x)}[r_{\phi}(x,y)] || -\betaD_{KL}[\pi_{\theta}(y|x)\parallel\pi_{ref}(y|x)]",,"L_{RM}(\phi)=-E_{(x, y_w, y_l)\sim D}\left[\log\sigma\left( r_{\phi}(x, y_w)-r_{\phi}(x, y_l)\right)\right]",The loss function for the reward model parameterized by $\phi$ is the negative expected value of the log sigmoid of the difference in rewards between the preferred completion $y_w$ and the dispreferred completion $y_l$.
naacl_2024_short_28,4,"L_{DPO}=-E_{(x,y_{w},y_{l})\sim D}[log\sigma(M(y_{w},y_{l},x,\theta))] || \beta(log\frac{\pi_{\theta}(y_{w}|x)}{\pi_{ref}(y_{w}|x)}-log\frac{\pi_{\theta}( y_{l}|x)}{\pi_{ref}(y_{l}|x)})","where the reward margin \(M(\mathbf{y}_{w},\mathbf{y}_{l},\mathbf{x},\theta)\) is

\[\beta\left(\text{log}\frac{\pi_{\theta}(\mathbf{y}_{w}|\mathbf{x})}{\pi_{ \text{ref}}(\mathbf{y}_{w}|\mathbf{x})}-\text{log}\frac{\pi_{\theta}(\mathbf{ y}_{l}|\mathbf{x})}{\pi_{\text{ref}}(\mathbf{y}_{l}|\mathbf{x})}\right) \tag{5}\]

### Related Work in Translation

Previous work has explored the effectiveness of enhancing the translation performance of LLMs via Reinforcement Learning (RL) algorithms or supervised fine-tuning","\max_{\theta}E_{(x,y_w,y_l)\simD}\left[\log\sigma\left(\beta\log\frac{\pi_{\theta}(y_w |x)}{\pi_{ref}(y_w |x)}-\beta\log\frac{\pi_{\theta}(y_l |x)}{\pi_{ref}(y_l |x)}\right)\right]",The DPO training objective maximizes the expected log-sigmoid of the reward margin between winning and losing responses.
naacl_2024_short_32,1,"y^{*}=\operatorname*{arg\,max}_{y\inY}E_{r\sim P_{ human}(\cdot|x)}[u(y,r)]",,"\hat{y}=\arg\max_{y\inY}E_{r\sim P_{R}}[u(y, r)]",The candidate translation $\hat{y}$ is selected by maximizing the expected utility over the reference distribution.
naacl_2024_short_32,2,"y^{*}=\operatorname*{arg\,max}_{y\inY}\frac{1}{|R^{\prime}|}\sum_{r^{\prime}\inR^{\prime}}u(y,r^{\prime})",,"y^{*}=\operatorname*{arg\,max}_{y\inY}\frac{1}{|R|}\sum_{r'\inR} u(y, r')",Equation 2 approximates the true expected utility in MBR decoding by averaging over a finite set of pseudo-references \(\mathcal{R}\) drawn from the model distribution \(P_{\mathrm{model}}(\cdot|x)\).
naacl_2024_short_33,1,"\min_{P_{n},v_{n}}-\sum_{x_{n},y_{n}}\log p(y_{n}|x_{n},P^{\prime}_{n},\theta)-\sum_{x_{n}}\cos(x_{n},v_{n})",,"\min_{P_n, v_n}\left[L_{CE}-\gamma\cos(v_n, x_n)\right]",The training objective for task $T_n$ minimizes the cross-entropy loss $\mathcal{L}_{\text{CE}}$ and maximizes the cosine similarity between the task feature vector $v_n$ and input embeddings $x_n$ with a trade-off parameter $\gamma$.
naacl_2024_short_33,2,"FWT=\frac{1}{N-1}\sum_{j=2}^{N}(a_{i,i}-\tilde{a}_{i})","where \(N\) is the number of tasks in the continual learning sequence, \(a_{i,i}\) denotes the performance evaluated on the \(i\)-th task after incremental learning on the first \(i\) tasks, \(\tilde{a}_{i}\) is the task performance of a randomly initialized reference model trained with dataset \(D_{i}\)",FWT=\frac{1}{T-1}\sum_{i=2}^{T}\left( R_{i}^{(i-1)}-b_i\right),"The forward transfer score (FWT) is the average influence of all previous tasks on the current task, where $T$ is the total number of tasks, $R_{i}^{(i-1)}$ is the accuracy on task $i$ after training on tasks $1$ to $i-1$, and $b_i$ is the accuracy of a random model on task $i$ before any training."
naacl_2024_short_34,1,x_{k}&=A_{k}x_{k-1}+Bu_{k}\\y_{k}&=h(x_{k}),,h_t=A h_{t-1}+B x_t,"Here, $h_t \in \mathbb{R}^d$ is the hidden state at time step $t$, $x_t \in \mathbb{R}^m$ is the input at time $t$, $\mathbf{A} \in \mathbb{R}^{d \times d}$ is the state transition matrix, and $\mathbf{B} \in \mathbb{R}^{d \times m}$ is the input projection matrix."
naacl_2024_short_34,2,x_{k}=Ax_{k-1}+Bu_{k},,x_k=A x_{k-1}+B u_k,"This equation represents the recurrence relation for input-independent linear recurrent neural networks, where the state transition matrix \(A\) is constant."
naacl_2024_short_34,3,"x_{0-1}&=A^{3}z+A^{2}u_{0}+Au_{-}+u_{ 1},\\for ""0-1""\\x_{1-0}&=A^{3}z+A^{2}u_{1}+Au_{-}+u_{0},\\for ""1-0""",,x_{3} &=A^{3} z+A^{2} B u_{0}+A B u_{-}+B u_{1}\\x_{3}' &=A^{3} z+A^{2} B u_{1}+A B u_{-}+B u_{0},"The states \(x_3\) and \(x_3'\) for the sequences ""0-1"" and ""1-0"" after three steps, respectively, where \(z\) is the initial state, \(u_0\), \(u_{-}\), \(u_1\) are input vectors for the characters 0, '-', 1, and \(A\) and \(B\) are the recurrence parameters."
naacl_2024_short_34,4,A^{2}u_{0}+Au_{-}+u_{1}\neq A^{2}u_{1}+Au_{-}+u_{0},,x_{0-1}-x_{1-0}=(A^2-I)(u_0-u_1),"Difference between the state vectors for the sequences ""0-1"" and ""1-0""."
naacl_2024_short_34,5,x_{0-0-1}&=A^{3}x_{0-}+A^{2}u_{0}+Au_ {-}+u_{1}\\x_{0-1-0}&=A^{3}x_{0-}+A^{2}u_{1}+Au_{-}+u_{0},,x_{0-0-1} &=A^{5}z+A^{4}u_{0}+A^{3}u_{-}+A^{2}u_{0}+A u_{-}+u_{1}\\x_{0-1-0} &=A^{5}z+A^{4}u_{0}+A^{3}u_{-}+A^{2}u_{1}+A u_{-}+u_{0},"Vector representations for the sequences ""0-0-1"" and ""0-1-0""."
naacl_2024_short_34,6,A^{2}u_{0}+Au_{-}+u_{1}=A^{2}u_{1}+Au_{-}+u_{0},,A^{2}u_{0}+Au_{-}+u_{1}=A^{2}u_{1}+Au_{-}+u_{0},"The condition derived from enforcing the state vectors for the sequences ""0-0-1"" and ""0-1-0"" to be equal."
naacl_2024_short_34,7,x_{k}=diag(v_{k})x_{k-1}+Bu_{k},where \(v_{k}=f(u_{k})\) is a vector that depends on \(u_{k}\),"x_k=diag(g(u_k))\, x_{k-1}+B u_k",The recurrence relation for a diagonal input-dependent linear recurrent neural network.
naacl_2024_short_34,8,x_{k}&=Ax_{k-1}+(Bu_{k})\odot x_{k-1}+Bu_{k}\\&=(A+diag(Bu_{k}))x_{k-1}+Bu_{k},where \(\odot\) denotes the Hadamard product and \(\text{diag}(w)\) constructs a diagonal matrix from \(w\),x_k=\bar{A}_k x_{k-1}+\bar{B}_k u_k,"The recurrence relation for liquid-S4, where \(\bar{A}_k\) and \(\bar{B}_k\) are input-dependent matrices derived through discretization."
naacl_2024_short_34,9,x_{k}=A_{k}x_{k-1}+Bu_{k},where \(A_{k}=g(u_{k})\) is a block diagonal matrix in practice for the sake of efficiency,x_k=A_k^{(1)} & &\\&\ddots &\\& & A_k^{(m)} x_{k-1}+B u_k,"where \( A_k^{(1)}, \dots, A_k^{(m)} \) are input-dependent block matrices forming a block-diagonal transition matrix."
naacl_2024_short_34,10,"& A_{k}=diag(A_{k}^{(1)},...,A_{k}^{(h)} )\inR^{bh\timesbh}\\& A_{k}^{(i)}=[v_{k}^{(i,1)}\quad\ldots\quad v_{k}^{(i,b)} ]\inR^{b\times b}\\&\|v_{k}^{(i,j)}\|_{p}\leq 1,\\i\in[1,...,h],\\j\in[1,...,b]","where \(\|\cdot\|_{p}\) denotes the vector p-norm and \(v_{k}^{(i,j)}\) is a column vector that depends on \(u_{k}\)","\|A_k[:,j]\|_1=1\quad\forall j",The L1 norm of each column in the input-dependent transition matrix \(A_k\) is constrained to 1 for numerical stability.
naacl_2024_short_34,11,&[\|v^{(1)}\|_{1}\quad\ldots\quad\|v^{(b)}\|_{1} ]=1^{\top}|A_{k+1}^{(i)}A_{k}^{(i)}|\\&\leq1^{\top}|A_{k+1}^{(i)} || A_{k}^{(i)} |\leq1^{\top}|A_{k}^{(i)}|\leq1^{\top},,"v^{(j)}=A_{k+1}^{(i)} v_{k}^{(i,j)}",The j-th column of the matrix product \(A_{k+1}^{(i)} A_{k}^{(i)}\) is computed as \(A_{k+1}^{(i)}\) multiplied by the j-th column vector of \(A_{k}^{(i)}\).
naacl_2024_short_38,1,"f(C,P,N_{1},N_{2})=1&if s(C,P)>s(C,N_{1} )\\&and s(C,P)>s(C,N_{2} )\\0&otherwise",where \(s(,"f(C,P,N_1,N_2)=1\left[ s(C,P) >\max\left( s(C,N_1), s(C,N_2)\right)\right]","The evaluation metric $f$ returns 1 if the similarity score between the compound noun prompt $\mathcal{C}$ and the positive image $\mathcal{P}$ is greater than the similarity scores with both negative images $\mathcal{N}_1$ and $\mathcal{N}_2$, and 0 otherwise."
naacl_2024_short_38,2,"Mean Similarity=\frac{1}{n}\sum_{i=1}^{5}s(c,p_{i})","where \(p_{i}\in P\) denotes the generated prompts, \(s(","\frac{1}{5}\sum_{k=1}^{5} s(T_k, c)",The mean similarity for an image \(c\) is computed by averaging the cosine similarities between the image and each of the five generated text prompts \(T_k\).
naacl_2024_short_39,1,"\underset{\theta_{P}}{\max}\underset{i}{\sum}\log p_{\theta,\theta_{P}}(y_{i}|[P;x_{i}])",,\max_{\Theta}\sum_{i}^{N}\log p_{\Theta}(y_{i} | x_{i}),The training objective maximizes the sum of the log-likelihoods of the target sequences \(y_i\) given the input sequences \(x_i\) over the training set.
naacl_2024_short_39,2,\frac{(Zero-shot\correct)\cap(PoT\incorrect)}{Zero-shot\correct},"where _Zero-shot correct_ is the case of correct responses in a zero-shot setting, and _PoT incorrect_ is the case of incorrect answers after prompt transfer in the target task",CF_{s\rightarrow t}=\frac{EM_{s}-EM_{s\rightarrow t}}{EM_{s}},The catastrophic forgetting metric \(\mathrm{CF}_{s \rightarrow t}\) is the relative decrease in EM score on the source task \(s\) after prompt tuning on the target task \(t\).
naacl_2024_short_43,1,"I_{c,i}\sim f(c_{\ell})",,"I_i=f(c_{\ell}, i)",\(I_i\) is the \(i\)-th image generated by the T2I model \(f\) for the concept phrase \(c_{\ell}\).
naacl_2024_short_43,2,"X_{c}=\frac{1}{n^{2}}\sum_{i=0}^{n}\sum_{j=0}^{n}SIM_{F}(I_{c_{\ell}, i},I_{c_{\ell_{s}},j})","where we sample \(n\) images per-concept per-language (we use 9), and \(\mathrm{SIM}_{F}(\cdot,\cdot)\) measures the cosine similarity in feature space by image feature extractor \(F\)","X_c(f, c_{\ell}, c_{\ell_s})=\frac{1}{N}\sum_{i=1}^{N}sim\left(I_{c,i}^{(\ell)}, I_{c,ref}^{(\ell_s)}\right)",The cross-consistency score \(X_c\) for concept \(c\) is the average similarity between each image generated in the target language \(\ell\) and a reference image in the source language \(\ell_s\).
naacl_2024_short_43,3,"\Delta X_{c}(c,\ell)=X_{c}(f,c^{\prime}_{\ell},c_{\ell_{s}})-X_{c}(f,c_{\ell}, c_{\ell_{s}})",,"\Delta X_{c}=X_{c}(f, c'_{\ell}, c_{\ell_s})-X_{c}(f, c_{\ell}, c_{\ell_s})",\(\Delta X_{c}\) is the change in cross-consistency score for concept \(c\) when replacing the original translation \(c_{\ell}\) with the corrected translation \(c'_{\ell}\).
naacl_2024_short_43,4,"\DeltaSEM=SIM_{Ft}(c_{\ell_{s}},c^{\prime}_{\ell})- SIM_{Ft}(c_{\ell_{s}},c_{\ell})",,"\DeltaSEM(c_{\ell_s}, c_{\ell}, c^{\prime}_{\ell})=SIM(F_t(c_{\ell_s}), F_t(c^{\prime}_{\ell}))-SIM(F_t(c_{\ell_s}), F_t(c_{\ell}))",\(\Delta\mathrm{SEM}\) quantifies the improvement in semantic similarity when replacing the original translation \(c_{\ell}\) with the corrected translation \(c^{\prime}_{\ell}\) by the difference in their cosine similarities to the source concept \(c_{\ell_s}\) in the text feature space.
naacl_2024_short_45,1,\ell=softmax(affine(ReLU(u_{s}))) || \ell_{i}=softmax(affine(ReLU(u_{i}))) || \nabla_{i}=\ell-\ell_{i},,rel(x_i)=P(\hat{y}\midX)-P(\hat{y}\midX\setminus\{x_i\}),The relevance score of token \(x_i\) is the difference in the predicted probability of class \(\mathbf{\hat{y}}\) between the original input \(\mathbf{X}\) and the input with token \(x_i\) removed.
naacl_2024_short_45,2,L_{dialect-classifier}=-\sum_{i}\log\ell[y_{i}^{*}],where \(y_{i}^{*}\) is the correct label for instance \(i\),L=-\sum_{j}\log\ell^{(j)}_{y^{(j)}},The total loss \(\mathcal{L}\) is the sum over all training instances \(j\) of the negative log probability of the true label \(y^{(j)}\) under the predicted distribution \(\boldsymbol{\ell}^{(j)}\).
naacl_2024_short_45,3,s_{j}=softmax(affine(ReLU(u_{s})-ReLU(u_{j}))) || loss=L_{{{dialect-classifier}}}+\alpha_{1}L_{{{LII}}},,z_{\setminus i}=W (u_{s}-u_{j})+b,The output logits for the input without feature \(x_i\) are computed by applying a linear transformation to the difference between the original representation \(\mathbf{u}_{s}\) and the MLM representation \(\mathbf{u}_{j}\) of feature \(x_i\).
naacl_2024_short_45,4,r_{j}=[\ell]_{y_{i}^{*}}-[s_{j}]_{y_{i}^{*}},"where higher \(r_{j}\) signifies more relevant features to the prediction, serving as better explanations","attribution(x_i)=P(y\midX)-s_{j,y}","Attribution score for feature \(x_i\) is the difference between the probability of the correct label \(y\) given the full input \(\mathbf{X}\) and the \(y\)-th element of \(\mathbf{s}_j\), the output distribution without \(x_i\)."
naacl_2024_short_45,5,E^{\prime}=\{e\in E\midisCorrect(e)\landisUnique(e)\},,S(w)=\sum_{e\in E'}\sum_{\substack{j\\x_j=w in  e}} r_j^{(e)},The global importance score \( S(w) \) for word \( w \) is the sum of relevance scores \( r_j^{(e)} \) across all occurrences \( j \) of \( w \) in every filtered explanation \( e \) within \( E' \).
naacl_2024_short_45,6,"TF-IDF(t,d,D)=TF(t,d)\timesIDF(t,D)",,"TF-IDF(t,d,D)=\left(\frac{f_{t,d}}{\sum_{t'\in d} f_{t',d}}\right)\times\log\left(\frac{|D|}{|\{d'\in D : t\in d'\}|}\right)","The TF-IDF score for term \( t \) in document \( d \) from corpus \( D \), where \( f_{t,d} \) is the frequency of term \( t \) in document \( d \), \( \sum_{t' \in d} f_{t',d} \) is the total number of terms in \( d \), \( |D| \) is the total number of documents in the corpus, and \( |\{d' \in D : t \in d'\}| \) is the number of documents in \( D \) that contain term \( t \)."
naacl_2024_short_45,7,"F=\{TF-IDF(t,d,E^{\prime})\mid t\in d,d\in E^{\prime}\}",,"F=\arg\max_{t\inV}^{(M)}\left(\max_{d\in D}TF-IDF(t, d, D)\right)",The final set of extracted features F consists of the top-M terms with the highest maximum TF-IDF scores across documents in the filtered explanation set D.
naacl_2024_short_46,1,"[x^{i},Q^{k}]=BERT([x^{i},Q^{k}])","where \(\mathbf{x}^{i}\) and \(\mathbf{Q}^{k}\) are the representations of \(x^{i}\) and \(\mathcal{Q}^{k}\), respectively",H=BERT\left(\left[Q^{k};E(x^{i})\right]\right),The contextual representation \(\mathbf{H}\) is obtained by feeding the concatenation of accumulated soft prompts \(\mathcal{Q}^{k}\) and token embeddings of input text \(x^{i}\) to the frozen BERT model.
naacl_2024_short_46,2,"Z^{i}_{t}=Linear(FFN([x^{i}_{m},x^{i}_{n}]))","where \(\overline{\mathbf{x}}^{i}_{t}=\text{FFN}([\mathbf{x}^{i}_{m},\mathbf{x}^{i}_{ n}])\) is the span representation, \(m\) and \(n\) denote the start and end index of the span, respectively",o^{i}_{t}=W\cdotFFN\left(\left[h_{start}\left(\overline{x}^{i}_{t}\right) ;h_{end}\left(\overline{x}^{i}_{t}\right)\right]\right)+b,"where \(\mathbf{o}^{i}_{t}\) are the event type logits for span \(\overline{x}^{i}_{t}\), \(\mathbf{h}_{\text{start}}\) and \(\mathbf{h}_{\text{end}}\) denote BERT representations of the span's start/end tokens, and \(\mathbf{W}\), \(\mathbf{b}\) are learnable parameters."
naacl_2024_short_46,3,"L_{new}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\in D^{k}_{train}}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})",,"L=-\log\frac{\exp( Z^{i}_{t,y}+Z_{q,y} )}{\sum_{c=1}^{|Q^{k}|}\exp( Z^{i}_{t,c}+Z_{q,c} )}","where \(y\) is the ground truth event type index for the span \(\overline{x}^{i}_{t}\), and \(c\) iterates over all event types in \(\mathcal{Q}^{k}\)"
naacl_2024_short_46,4,"L_{mem}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\in M}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})",,"L_{old}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inM}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})",where \(\mathcal{L}_{\text{old}}\) is the memory replay loss computed over the memory module \(\mathcal{M}\)
naacl_2024_short_46,5,"L_{sim}=\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inD^ {k}_{train}}\sum_{e_{t}\inE^{k-1}}\max(0,g(\overline {x}^{i}_{t},e_{t})-m_{1})","where \(\mathcal{E}^{k-1}\) is the prototype set of previous \(k-1\) tasks, \(g(,)\) is the similarity function (cosine similarity) and \(m_{1}\) is the margin for \(\mathcal{L}_{\text{sim}}\)","L_{margin}=\sum_{(\overline{x}^{i}_{t}, y^{i}_{t})\inD^{k}_{train}}}\sum_{c\in\bigcup_{j=1}^{k-1}C^{j}}\max(0,\overline{x}^{i}_{t}\cdotp_c-\delta)","where \(\mathcal{L}_{\text{margin}}\) is the margin-based loss, \(\overline{\mathbf{x}}^{i}_{t}\) is the span representation for the new training example, \(\mathbf{p}_c\) is the prototype for event type \(c\) from previous tasks, and \(\delta\) is a margin hyperparameter."
naacl_2024_short_46,6,"L_{cal}=-\sum_{(\overline{x}_{t}^{i},\overline{x}_{t}^{i})\inM}\log\frac{\exp g(\overline{x}_{t}^{i},e_{t}) }{\sum_{j=1}^{|e^{k-1}|}\exp g(\overline{x}_{t}^{i}, e_{j})}",where \(\mathbf{e}_{t}\) is the prototype of \(y_{t}^{i}\),"L_{cal}=\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inM}(1-g(\overline{x}^{i}_{t},e_{y^{i}_{t}}))","where \(\mathcal{L}_{\text{cal}}\) is the memory calibration loss, \(\mathbf{e}_{y^{i}_{t}}\) is the prototype of the event type \(y^{i}_{t}\) from the prototype set \(\mathcal{E}^{k-1}\), and \(g(\cdot,\cdot)\) is the similarity function (cosine similarity)"
naacl_2024_short_46,7,L_{total}=L_{new}+\lambda_{1}L_{sim}+\lambda_{2}(L_{mem}+L_{cal}),where \(\lambda_{1}\) and \(\lambda_{2}\) are loss weights,L_{total}=L_{new}+L_{mem}+\lambda_1L_{sim}+\lambda_2L_{cal}},"The total loss \(\mathcal{L}_{\text{total}}\) for learning task \(\mathcal{T}^{k}\) combines the new task loss, memory replay loss, and weighted separation and calibration losses."
naacl_2024_short_46,8,"e_{j}=\frac{1}{|M_{e_{j}}|}\sum_{(\overline{x}_{t}^{i},\overline{x}_{t}^{i})\inM_{e_{j}}}\overline{x}_{t}^{i}","where \(\mathcal{M}_{e_{j}}=\{(\overline{x}_{t}^{i},y_{t}^{i})|(\overline{x}_{t}^{i}, y_{t}^{i})\in\mathcal{M},y_{t}^{i}=e_{j}\}\)","e_{j}=\frac{1}{|M_j|}\sum_{(\overline{x}_t^i, y_t^i)\inM_j}\overline{x}_t^i","where \(\mathcal{M}_j\) is the set of memory samples in \(\mathcal{M}\) labeled as event type \(e_j\), and \(|\mathcal{M}_j|\) is the number of such samples"
naacl_2024_short_5,1,"L^{unsup}_{simce}=-\log\frac{e^{sim(h_{i},h_{i}^{\prime})/\tau}}{\sum_{j=1}^{N}e^{ sim(h_{i},h_{j}^{\prime})/\tau}} || L^{unsup}_{skice}=-\log\frac{e^{sim(h_{i},h_{i}^{ski})/\tau}}{\sum_{j=1}^{N}e^{sim(h_{i},h_{j}^{ski})/\tau}}",,"L_{unsup}=-\log\frac{\exp(sim(h,h^{\prime})/\tau)}{\sum_{h_j\inN}\exp(sim(h,h_j)/\tau)}-\log\frac{\exp(sim(h,h^{ski})/\tau)}{\sum_{h_j\inN}\exp(sim(h,h_j)/\tau)}","The unsupervised loss $\mathcal{L}_{\text{unsup}}$ combines two contrastive objectives: one between the anchor embedding $\mathbf{h}$ and its dropout-augmented variant $\mathbf{h}^{\prime}$, and another between $\mathbf{h}$ and its SKI-induced positive $\mathbf{h}^{\text{ski}}$, using cosine similarity $\text{sim}$, temperature $\tau$, and negative embeddings $\mathbf{h}_j$ from set $\mathcal{N}$."
naacl_2024_short_5,2,L^{unsup}=(1-\lambda)L^{unsup}_{ simce}+\lambdaL^{unsup}_{skice},where the weight \(\lambda\) is a balanced hyperparameter and reflects the importance of SKI,L^{unsup}=\alphaL^{unsup}_{simce}+\betaL^{unsup}_{skice},"The final unsupervised objective function is the weighted sum of the SimCSE loss and the SKICSE loss, with weights α and β."
naacl_2024_short_5,3,"L^{sup}_{simce}=-\log\frac{e^{sim(h_{i},h_{i}^{+})/\tau}}{\sum_{j=1}^{N}(e^{ sim(h_{i},h_{j}^{+})/\tau}+e^{sim(h_{i},h_{j}^{-})/\tau})} || L^{sup}_{skice_{1}}=-\log\frac{e^{sim(h_{i}^{ski},h_{i}^{+})/\tau}}{\sum_{j=1}^{N} (e^{sim(h_{i}^{ski},h_{j}^{+})/\tau}+e^{sim(h_{i}^{ski},h_{j}^{-})/\tau})} || L^{sup}_{skice_{2}}=-\log\frac{e^{sim(h_{i},h_{i}^{ski})/\tau}}{\sum_{j=1}^{N}(e ^{sim(h_{i},h_{j}^{+})/\tau}+e^{sim (h_{i},h_{j}^{-})/\tau})}",,"L^{sup}_{simce}=-\log\frac{e^{sim(h_{i},h_{i}^{+})/\tau}}{\sum_{j=1}^{N}e^{ sim(h_{i},h_{j}^{+})/\tau}+\sum_{j=1}^{N}e^{ sim(h_{i},h_{j}^{-})/\tau}}",The supervised contrastive loss for entailment pairs with in-batch negatives from entailment and contradiction examples.
naacl_2024_short_5,4,L^{sup}=(1-\lambda_{1}-\lambda_{2})L^{sup}_{simce}+\lambda_{1}L^{sup}_{skice_{1}}+\lambda_ {2}L^{sup}_{skice_{2}},,L^{sup}=(1-\lambda)L^{sup}_{simce}+\lambdaL^{sup}_{skice_{1}}+\lambdaL^{sup}_{skice_{2}},where \(\lambda\) is a hyperparameter balancing the importance of the SKI losses against the SimCSE loss.
naacl_2024_short_51,1,"R_{d}(w)=\frac{tf(w,d)}{\sum_{d^{\prime}}tf(w,d ^{\prime})}\cdot\log\frac{N}{df(w)}","where \(\operatorname{tf}(w,d)\) is the number of times the word \(w\) occurs in the day \(d\), \(\operatorname{df}(w)\) is the number of days in which the word \(w\) occurs, and \(N\) is the total number of days in the dataset",R_d(t)=\log\left(\frac{|D_d|}{|\{a\in D_d\mid t\in a\}|}\right),The relevance \( R_d(t) \) of token \( t \) on day \( d \) is the logarithm of the ratio of the total number of articles \( |D_d| \) to the number of articles containing token \( t \) in day \( d \).
naacl_2024_short_51,2,"sim(x,x^{\prime})=\frac{\sum_{w\in x^{\prime}x^{\prime}}R_{d}(w)}{max(\hat{R}_{d}(x),\hat{R}_{d}(x^{\prime}))}",,"S(x, y)=\frac{\sum_{w\in x\cap y} R_d(w)}{\max\left(\hat{R}_{d}(x),\hat{R}_{d}(y)\right)}","The similarity \(S(x, y)\) between two articles \(x\) and \(y\) is the ratio of the sum of relevance scores \(R_d(w)\) for words \(w\) present in both titles to the maximum article relevance score \(\max(\hat{R}_{d}(x), \hat{R}_{d}(y))\)."
naacl_2024_short_52,1,"& L_{discrete}(y_{i}=t;y_{<i},x)=-\log p(y_{i}=t\midy_{<i},x)\\&\quad=-\langleE(t),h\rangle+\log\sum_{t^{\prime}\in V }\exp\langleE(t^{\prime}),h\rangle","where \(t\) is a token index, \(V\) is the vocabulary, \(\mathbf{E}:V\rightarrow\mathbb{R}^{d}\) is an embedding lookup, and \(\mathbf{h}\) is a transformer hidden state calculated in terms of \(\mathbf{x}\) and the output prefix \(\mathbf{y}_{<i}\)","L_{CE}=-\sum_{t=1}^{n}\log P(y_t |y_{<t},x)","The cross-entropy loss for discrete-output NMT, which minimizes the negative log probability of each target token given the input sequence and preceding target tokens."
naacl_2024_short_52,2,"L_{cos}(y_{i}=t;y_{<i},x)=1-\cos(E(t),h)",,"L_{continuous}(y_i=t;y_{<i},x)=\lVertE(t)-h\rVert^2",The continuous-output loss minimizes the squared Euclidean distance between the transformer hidden state \(\mathbf{h}\) and the embedding vector \(\mathbf{E}(t)\) of target token \(t\).
naacl_2024_short_52,3,"E(y_{i})=u_{i}/\|u_{i}\|;\quadu_{i}\simNormal( 0,I_{d})",,"E(y_i)=\frac{z}{\|z\|_2},\quadz\simN(0,I_d)",A random embedding vector for token \(y_i\) is generated by sampling from a standard multivariate normal distribution and normalizing to unit Euclidean norm.
naacl_2024_short_52,4,E(y_{i})=r_{i}/\sqrt{d};\quadr_{i}\simRademacher(d),,"E(y_i)=\frac{1}{\sqrt{d}}r_i;\quad r_{i,j}\stackrel{i.i.d.}{\sim}Rademacher, j=1,\dots,d","where \(\mathbf{r}_i\) is a random vector for token \(y_i\), with each component \(r_{i,j}\) independently drawn from the Rademacher distribution (uniform on \(\{-1,1\}\)), and \(d\) is the embedding dimension."
naacl_2024_short_52,5,E_{cmb}(y_{i})=\frac{\alphaE_{pre}(y_{i})+(1-\alpha)E_{rand}(y_{i})}{\|\alphaE_{pre}(y_{i})+(1-\alpha)\bm {E}_{rand}(y_{i})\|},,E_{combined}(t)=\frac{\alphaE_{pre}(t)+(1-\alpha)E_{rand}(t) }{\|\alphaE_{pre}(t)+(1-\alpha)E_{rand}(t)\| },"The combined embedding for token \(t\) is a normalized linear combination of the pre-trained embedding \(\mathbf{E}_{\text{pre}}(t)\) and a random embedding \(\mathbf{E}_{\text{rand}}(t)\), with mixing parameter \(\alpha\)."
naacl_2024_short_53,1,"S(y,\bar{y};x)>S(y,\hat{y};x)",where \(\mathbf{y}\) is the reference sequence,\delta_{1:L}^*=\arg\max_{\delta_{1:L}}S\left(f(e_{1:L}+\delta_{1:L};\phi_{d})\right),The optimal perturbation sequence \(\mathbf{\delta}_{1:L}^*\) maximizes the score \(\mathcal{S}\) of the decoder output generated from the perturbed encoder embeddings.
naacl_2024_short_53,2,\delta_{i}=\alpha|e_{i}|\bigg{|}\frac{\partial f(e_{1:L};\phi_{nap})}{\partiale_{i}}\bigg{|}^{-1}\frac{\partial f(e_{1:L};\phi_{nap})}{\partiale_{i}},"where \(i=1,\ldots,L\)",\delta_{1:L}=\alpha\nabla_{e_{1:L}} f(e_{1:L};\phi_{nap}),The perturbation \(\mathbf{\delta}_{1:L}\) is computed as the scaled gradient of the Non-Autoregressive Proxy (NAP) with respect to the encoder outputs.
naacl_2024_short_56,1,X_{all}=L\[SEP]\X_{ori}\[SEP]\P_{C}\[SEP]\P_{L},,I=L\oplus[SEP]\oplus X_{ori}\oplus[SEP]\oplus P_C\oplus[SEP]\oplus P_L,"The input instance \( I \) is formed by concatenating the correct label \( L \), original sentence \( X_{ori} \), context prompt \( P_C \), and label prompt \( P_L \) with [SEP] tokens."
naacl_2024_short_56,2,L_{MLM}=-{\sum}_{n=1}^{M}\log P(x_{n}),where \(M\) is the number of masked tokens and \(P(x_{n})\) is the predicted probability of token \(x_{n}\) over the vocabulary size,L_{PromptMLM}=-\sum_{i\in M}\log P(x_i |X_{masked}),The loss function for the Prompt MLM task is the negative sum of the log probabilities of the original tokens at masked positions given the masked input sequence.
naacl_2024_short_56,3,"L_{s}=\frac{1}{N}\sum_{p=1}^{N}-\frac{1}{N_{y_{p}}-1}\sum_{q=1}^{N_ {y_{p}}}\log\frac{e^{sim(h_{p},h_{q}^{+})/\tau}}{\sum_{k=1}^{N}1_{p\neq k}e^{sim(h_{p},h_{k})/\tau}}",where \(N\) is the total number of examples in the batch and \(N_{y_{p}}\) is the number of positive pairs in the batch,L_{RCD}=\sum_{i\in I}\frac{-1}{|P(i)|}\sum_{p\in P(i)}\log\frac{\exp(h_i^\toph_p/\tau)}{\sum_{a\in A(i)}\exp(h_i^\toph_a/\tau)},"where \(I\) is the set of indices in the batch, \(P(i)\) is the set of indices of positive samples for anchor \(i\), \(A(i)\) is the set of indices of all positive and negative samples for anchor \(i\), \(\mathbf{h}_i\) is the representation of the anchor, \(\mathbf{h}_p\) is the representation of a positive sample, \(\mathbf{h}_a\) is the representation of a sample in \(A(i)\), and \(\tau\) is the temperature parameter, with negatives including other batch samples and hard negatives from similar relations."
naacl_2024_short_56,4,L_{final}=\alphaL_{s}+(1-\alpha)L_{MLM},,L_{final}=L_{MLM}+\alpha\cdotL_{s},where \(\alpha\) is a hyperparameter that weights the relation contrastive discrimination loss.
naacl_2024_short_62,1,"P_{ATTN}(n_{i}|Q,A)=softmax(\sum_{t=1}^{T}\alpha_{t} || v_{t} || _{2})",where \(T\) represents the total token count in \(n_{i}\),p(n_i)=\frac{\exp(s_i)}{\sum_{j=1}^{k}\exp(s_j)},"The softmax distribution over question-relevant documents \(D_n\) for document \(n_i\), where \(s_i\) is the relevance score of document \(n_i\) computed from self-attention scores and value vector norms."
naacl_2024_short_62,2,"P_{RETR}(n_{i}|Q)=\frac{exp(s(n_{i},Q)/\theta)}{\sum_{k=1}^{K}exp(s(n_{k},Q)/\theta)}","where \(s\) denotes the dot-product between the representation vectors of the input question \(Q\) and document candidate \(n_{i}\), and \(\theta\) is the temperature hyper-parameter","p_{RETR}(n_i | Q)=\frac{\exp(s(n_i, Q))}{\sum_{n_j\in D_n}\exp(s(n_j, Q))}","where \(s(n_i, Q)\) denotes the relevance score of document \(n_i\) for question \(Q\) computed by the retriever."
naacl_2024_short_66,1,"y_{t}\sim p_{\theta}(y_{t}\midc,x,y_{ct}) || \propto\explogit_{\theta}(y_{t}\midc,x,y _{ct})",,"p(y\midx,c)=\prod_{t=1}^{T} p(y_t\midy_{<t},x,c)","The probability distribution of the response \(\mathbf{y}\) is autoregressively factorized as the product of token-level probabilities conditioned on the query \(\mathbf{x}\), context \(\mathbf{c}\), and preceding tokens \(\mathbf{y}_{<t}\), where \(T\) is the sequence length."
naacl_2024_short_66,2,"y_{t}\sim\tilde{p}_{\theta}(y_{t}\midc,x,y_{ct}) || \propto p_{\theta}(y_{t}\midc,x,y_{ct})\bigg{(}\frac{p_{\theta}(y_{t}\midc,x,y_{ct})}{p_{\theta}(y_{t}\mid\bm {x},y_{ct})}\bigg{)}^{\alpha}",,"p_{CAD}(y_{t}\midc,x,y_{ct})\propto\frac{ p_{\theta}(y_{t}\midc,x,y_{ct}) }{ p_{\theta}(y_{t}\midx,y_{ct}) }",The context-aware decoding distribution for the next token is defined as the ratio of the model's conditional probability given the context to the conditional probability without the context.
naacl_2024_short_66,3,"y_{t}\simsoftmax[(1+\alpha)\,logit_{\theta}(y_{t}\midc,x,y_{ct}) || \qquad\qquad-\alpha\,logit_{\theta}(y_{t}\midx,y _{ct})]",,"\tilde{p}_{\theta}(y_{t}\midc,x,y_{ct})=\frac{ p_{\theta}(y_{t}\midc,x,y_{ct})\left(\frac{p_{\theta}(y_{t}\midc,x,y_{ct})}{p_{\theta}(y_{t}\midx,y_{ct})}\right)^{\alpha} }{\sum_{y'} p_{\theta}(y'\midc,x,y_{ct})\left(\frac{p_{\theta}(y'\midc,x,y_{ct})}{p_{\theta}(y'\midx,y_{ct})}\right)^{\alpha} }",The normalized context-aware decoding distribution.
naacl_2024_short_67,1,"h_{0}^{x},h_{1}^{x},...,h_{n}^{x}=\textbf{BERT}(w_{0}^{x},w_{1}^{x},...,w_{n}^{x}) || x^{c}=h_{0}^{x},x^{h}=h_{[E_{h}]}^{x},x^{t}=h_{[E_{t}]}^{x}",,"\[h_{ent_h}=Encoder(x)_{[E_h]},\quadh_{ent_t}=Encoder(x)_{[E_t]},\quadh_{ctx}=Encoder(x)_{[CLS]}\]","The head entity representation \(\mathbf{h}_{ent_h}\), tail entity representation \(\mathbf{h}_{ent_t}\), and context representation \(\mathbf{h}_{ctx}\) are the encoder's output hidden states corresponding to the special tokens [E_h], [E_t], and [CLS], respectively."
naacl_2024_short_67,2,x^{vec}=x^{c}\oplus x^{h}\oplus x^{t},where \(d\) is the hidden dimension of the encoder and \(\oplus\) denotes the concatenation operator,x^{vec}=[x^{h}; x^{t}; x^{c}],"The comprehensive representation \(x^{vec}\) is formed by concatenating the head entity, tail entity, and contextual information vectors."
naacl_2024_short_67,3,"h_{0}^{d},h_{1}^{d},...,h_{n}^{d}=\textbf{BERT}(w_{0}^{d},w_{1}^{d},...,w_{n}^ {d}) || d^{c}=h_{0}^{d} || d^{h}=\textit{WeightPooling}_{1}(h_{1}^{d},...,h_{n}^{d}) || d^{t}=\textit{WeightPooling}_{2}(h_{1}^{d},...,h_{n}^{d}) || d^{vec}=d^{c}\oplus d^{h}\oplus d^{t}",,d^{vec}=d^{c}\oplus d^{h}\oplus d^{t},"where \(d^{c}\), \(d^{h}\), and \(d^{t}\) are the contextual, virtual head entity, and virtual tail entity representations of the relation description, respectively."
naacl_2024_short_67,4,"H=(h_{1}^{d},...,h_{n}^{d}) || A=\textit{softmax}(HW+b) || d^{*}=AH",,\alpha_i &=\frac{\exp(u^\top\tanh(Wh_i^d))}{\sum_{j=1}^{n}\exp(u^\top\tanh(Wh_j^d)))}\\d &=\sum_{i=1}^{n}\alpha_ih_i^d,"where \(\mathbf{h}_i^d\) is the hidden state of the i-th token in the relation description (excluding [CLS]), \(\mathbf{W} \in \mathbb{R}^{d \times d}\) and \(\mathbf{u} \in \mathbb{R}^{d}\) are learnable parameters, and \(\mathbf{d}\) represents the virtual entity representation with separate parameters used for head (\(d^h\)) and tail (\(d^t\))."
naacl_2024_short_67,5,"L_{i}=-\log\frac{e^{sim(x_{i}^{vec},d_{i}^{vec})/\tau}}{\sum_ {j=1}^{N}e^{sim(x_{i}^{vec},d_{j}^{vec})/\tau}}",where \(\tau\) is a temperature hyperparameter and \(\text{sim}(\cdot)\) is the cosine similarity,"L_{cl}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{\exp\left(\frac{sim(x_i^{vec}, d_i^{vec})}{\tau}\right)}{\sum_{j=1}^{N}\exp\left(\frac{sim(x_i^{vec}, d_j^{vec})}{\tau}\right)}","The contrastive loss function based on infoNCE, where \(N\) is the batch size, \(\text{sim}\) denotes cosine similarity, and \(\tau\) is the temperature hyperparameter."
naacl_2024_short_67,6,O_{i}=\textit{Pooling}(BERT(\langle x\oplus d_{j}\rangle)) || \hat{y}=\textit{MLP}(O_{0}\oplus O_{1}\oplus...O_{k}) || L_{c}=-log(\frac{e^{\hat{y}_{+}}}{\sum_{i=1}^{k}e^{\hat{y}_{i}}}),,"L_{class}=-\log\frac{\exp(sim(x, d_{+}))}{\sum_{d\in D}\exp(sim(x, d))}","where \(\text{sim}(\cdot)\) is the cosine similarity, \(d_{+}\) is the positive relation description, and \(D\) is the set of candidate relation descriptions."
naacl_2024_short_69,1,ATE=E[Y^{a=1}-Y^{a=0}],,ATE=E[Y^{a=1}]-E[Y^{a=0}],The average treatment effect (ATE) quantifies the difference between expected counterfactual outcomes under antibiotic treatment versus no treatment.
naacl_2024_short_69,2,A=a\\Rightarrow\Y^{a}=Y,,Y=A\cdot Y^{a=1}+(1-A)\cdot Y^{a=0},The consistency assumption requires that the observed outcome Y equals the counterfactual outcome corresponding to the actual treatment assignment A.
naacl_2024_short_69,3,"Y^{a}\perp A\mid C\quad\forall a\in\{0,1\}",,Y^{a}\perp\!\!\!\perp A\mid C,Conditional exchangeability requires that the counterfactual outcome \(Y^{a}\) is independent of the treatment assignment \(A\) given the confounders \(C\).
naacl_2024_short_69,4,"E[Y^{a}]=\sum_{C}E[Y^{a}\mid C]P(C) || \overset{\eqref{eq:constraint}}{=}\sum_{C}E[Y^{a}\mid A=a,C]P(C)",,"E[Y^{a}]=E\left[E[Y\mid A=a, C]\right]",The counterfactual mean \(\mathbb{E}[Y^{a}]\) is identified by the expectation over the confounders \(C\) of the conditional mean of the observed outcome \(Y\) given treatment \(A=a\) and confounders \(C\).
naacl_2024_short_69,5,"\overset{\eqref{eq:constraint}}{=}\sum_{C}E[Y\mid A=a,C]P(C)",,"E[Y^{a}]=\sum_{C}E[Y\mid A=a, C]P(C)",This equation identifies the counterfactual mean \(\mathbb{E}[Y^{a}]\) by averaging the conditional expectation of the observed outcome \(Y\) given treatment \(A=a\) and confounders \(C\) over the distribution of \(C\).
naacl_2024_short_69,6,E[Y^{a}]=\frac{1}{N}\sum_{i\in[N]}Y_{i}\frac{\mathds{1}(A_{i}=a)}{P(A_{i}=a\mid T)},,E[Y^{a}]\approx\frac{1}{N}\sum_{i=1}^{N}\frac{Y_i\cdot1(A_i=a)}{\hat{P}(A_i=a\mid T_i)},The IPTW estimator for the counterfactual outcome \(\mathbb{E}[Y^{a}]\) using propensity scores derived from the text representation.
naacl_2024_short_7,1,"\underset{\theta}{min}\,E_{S^{i}}[\frac{1}{k+1}\sum_{i=0}^{k}l( M_{\theta}(S^{i}),f(x_{i+1}))]",,"\[ l\left( M_{\theta}(S^{i}), f(x_{i+1})\right)=\left( M_{\theta}(S^{i})-f(x_{i+1})\right)^2\]",The loss function \( l \) is the squared error between the model's prediction \( M_{\theta}(S^{i}) \) and the ground-truth value \( f(x_{i+1}) \).
naacl_2024_short_7,2,"f(x)=\varphi(\langle x,w\rangle)",,"f(x)=\frac{1}{\sqrt{k!}}He_k(\beta^\top x),\quadwhere \|\beta\|_2=1","The function \(f\) is a single-index function defined by the normalized probabilist's Hermite polynomial of degree \(k\) applied to the projection \(\beta^\top x\), with \(\beta\) being a unit vector in \(\mathbb{R}^d\)."
naacl_2024_short_7,3,\varphi_{linear}(t)=t || \varphi_{quadratic}(t)=\frac{1}{\sqrt{2}}(t+\frac{1}{\sqrt{2}}(t^{2}-1)) || \varphi_{cubic}(t)=\frac{1}{\sqrt{3}}(t+\frac{1}{\sqrt{ 2}}(t^{2}-1)+\frac{1}{\sqrt{6}}(t^{3}-3t)),,"\varphi_{linear}(t)=t,\quad\varphi_{quadratic}(t)=\frac{1}{\sqrt{2}} (t^{2}-1),\quad\varphi_{cubic}(t)=\frac{1}{\sqrt{6}} (t^{3}-3t)","Definitions of the linear, quadratic, and cubic activation functions for the three function classes \(\mathcal{F}_1\), \(\mathcal{F}_2\), \(\mathcal{F}_3\) based on normalized Hermite polynomials with constants removed."
naacl_2024_short_7,4,f\simF_{1}&1\leq t<\frac{T}{3}\\F_{2}&\frac{T}{3}\leq t<\frac{2T}{3}\\F_{3}&\frac{2T}{3}\leq t<T,,"I_k=\left\{ t\mid\left\lfloor\frac{(k-1) T}{K}\right\rfloor+1\leq t\leq\left\lfloor\frac{k T}{K}\right\rfloor\right\},\quad k=1,2,\ldots,K",The set of training steps allocated to the k-th function class in the sequential curriculum.
naacl_2024_short_7,5,f\simF_{1}&1\leq t<\frac{T}{3}\\\sum_{s=1}^{2}1(\xi=s)F_{s}&\frac{T}{3}\leq t<\frac{2T}{3}\\\sum_{s=1}^{3}1(\zeta=s)F_{s}&\frac{2T}{3}\leq t<T,,"f\simF_J,\quad J\simUniform\{1,\ldots, k(t)\}","In mixed curriculum, $f$ is uniformly sampled from the function classes $\mathcal{F}_1$ to $\mathcal{F}_{k(t)}$."
naacl_2024_short_7,6,"f\sim\sum_{s=1}^{3}1(\zeta=s)F_{s},\quad 1\leq t<T",,f\sim\sum_{k=1}^{K}1(\zeta=k)F_{k},"At each training step \( t \), the function \( f \) is sampled from one of the \( K \) function classes by drawing the class index \( \zeta \) uniformly from \( \{1,2,\dots,K\} \)."
naacl_2024_short_8,1,"s_{m}(q,d)=T_{\texttt{[CLS]}}W+b","where \(T_{\texttt{[CLS]}}\in\mathbf{R}^{D}\) is the [CLS] representation on the final layer, and \(W\in\mathbf{R}^{D\times 1}\) and \(b\in\mathbf{R}\) are the weight and bias for classification","s_{q,d}=w^{\top}h_{[CLS]}","The relevance score \( s_{q,d} \) is computed as the dot product between a weight vector \( \mathbf{w} \) and the hidden state of the [CLS] token from the final layer of BERT."
naacl_2024_short_8,2,"s_{m}(q,d)=\frac{1}{n}\sum_{i}^{n}(T_{tok_{i}}W+b)","where \(T_{tok_{i}}\) is the final-layer representation of the \(i\)-th token, and \(n\) is the total number of tokens in the input sequence","s_{mean}(q,d)=\left(\frac{1}{L}\sum_{i=1}^{L} T_i\right) W+b","where \( T_i \in \mathbf{R}^{D} \) is the representation of the \( i \)-th token, \( L \) is the number of tokens, and \( W \in \mathbf{R}^{D \times 1} \) and \( b \in \mathbf{R} \) are the weight and bias for classification as defined in Eq. (1)."
naacl_2024_short_8,3,v_{q_{i}}=T_{q_{i}}W+b;\quad v_{d_{j}}=T_{d_{j}}W+b,"where \(q_{i}\) and \(d_{j}\) represent the \(i\)-th token of query \(q\) and the \(j\)-th token of document \(d\), respectively","T^{(q)}_j=Encoder(q)_j,\quad T^{(d)}_k=Encoder(d)_k","where \( T^{(q)}_j \in \mathbf{R}^D \) is the final-layer representation of the j-th token in the query, and \( T^{(d)}_k \in \mathbf{R}^D \) is the final-layer representation of the k-th token in the document."
naacl_2024_short_8,4,"s_{l}(q,d)=\sum_{q_{i}}\max_{d_{j}}(v_{q_{i}}^{T}v_{d_{j}})",,"s_{celi}(q,d)=\sum_{i}\max_{j}\left( v_{q_i}\cdot v_{d_j}\right)","where \(i\) indexes query tokens, \(j\) indexes document tokens, and \(v_{q_i}\) and \(v_{d_j}\) are the token representations defined in Equation 3."
naacl_2024_short_8,5,"L=lce(s_{m}(q,d^{+}),s_{m}(q,d_{1}^{-}),...,s_{m}(q,d_{n}^ {-})) || +lce(s_{l}(q,d^{+}),s_{l}(q,d_{1}^{-}),...,s_{l}(q,d_{n}^ {-}))",,"L(s)=-\log\frac{\exp(s(q, d^+))}{\sum_{d\in D}\exp(s(q, d))}","where \(d^+\) is a relevant document for query \(q\), and \(D\) is the set of candidate documents including \(d^+\) and negatives"
naacl_2024_short_9,1,"L_{ir}(q,p_{i})=-\log(\frac{e^{q\cdot p_{t}}}{\sum_{i=1}^{N}e^{q\cdot p_{ i}}})",,L=-\log\frac{\exp(q^\topp_t)}{\sum_{i=1}^{N}\exp(q^\topp_i)},"The loss function for Dense Passage Retrieval, defined as the negative log likelihood of the correct passage given the query."
naacl_2024_short_9,2,"L_{c}(q_{s},q_{t})=-\log(\frac{e^{q_{s}\cdot q_{t}}}{\sum_{j=1}^{N}e^{q_ {s}\cdot q_{j}}})",,"L_{c}(q_{s},q_{t})=-\log\left(\frac{e^{q_{s}\cdot q_{t}}}{\sum_{j=1}^{N} e^{q_{s}\cdot q_{j}}}\right)",The contrastive loss term aligns the English query embedding with its code-mixed counterpart by maximizing their similarity relative to other code-mixed queries in the batch.
naacl_2024_short_9,3,L=L_{ir}+wL_{c},where \(w\) is a hyperparameter for weighting the contrastive loss,L=L_{ir}+\lambda L_{c},The entire training objective combines the information retrieval loss and the contrastive loss with a weighting hyperparameter λ.
neurips_2024_oral_10,1,"q(x_{1:T}|x_{0})\coloneqq\prod_{t=1}^{T}q(x_{t}|x_{t-1}) || q(x_{t}|x_{t-1})\coloneqqN(x_{t};\sqrt{1-\beta_{t}}x _{t-1},\beta_{t}I)",,"x_t=\sqrt{\bar{\alpha}_t} x_0+\sqrt{1-\bar{\alpha}_t}\epsilon,\quad\epsilon\simN(0, I)","Equation 1 defines the noisy feature \( x_t \) at diffusion step \( t \) as a combination of the initial clean feature \( x_0 \) and Gaussian noise \( \epsilon \), scaled by the cumulative noise schedule \( \bar{\alpha}_t \)."
neurips_2024_oral_10,2,"p_{\theta}(x_{0:T})\coloneqq p(x_{T})\prod_{t=1}^{T}p_{\theta}(x_{t-1}|x_{t}) || p_{\theta}(x_{t-1}|x_{t})\coloneqqN(x_{t-1};\mu_{\theta}(x_{t },t),\Sigma_{\theta}(x_{t},t))",,p_\theta(x_{0:T})\coloneqq p(x_T)\prod_{t=1}^{T} p_\theta(x_{t-1} |x_t),The reverse diffusion process defines the joint distribution for denoising noisy features to clean features over T steps.
neurips_2024_oral_10,3,"X_{t-1}=\frac{1}{\sqrt{a_{t}}}(X_{t}-\frac{1-a_{t}}{\sqrt{1-\tilde{a_{t}}}}D_{\theta}(X_{t},t))+\sigma_{t}z","where \(a_{t}=1-\beta_{t}\), \(D_{\theta}\) are the parameters of the prediction noise network",W_{fused}=W_e+W_d,"The fused weight matrix $\mathbf{W}_{\text{fused}}$ and bias vector $\mathbf{b}_{\text{fused}}$ are obtained by summing the original embedding layer parameters ($\mathbf{W}_e$, $\mathbf{b}_e$) and denoising layer parameters ($\mathbf{W}_d$, $\mathbf{b}_d$)."
neurips_2024_oral_10,4,Y&=WX+b\\\frac{1}{\sqrt{a_{t}}}X_{t}-X_{t-1}&=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}D_{\theta}X_{t}-\sigma_{t}z\\\frac{1}{\sqrt{a_{t}}}Y_{t}-Y_{t-1}&=\frac{1-a_{t} }{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}D_{\theta}Y_{t}-\sigma_{t}z,,y=(W_{embed}+W_{denoise})x+(b_{embed}+b_{denoise}),"where \(\mathbf{W}_{\text{embed}}\) and \(\mathbf{b}_{\text{embed}}\) are the weight and bias of the original embedding layer, \(\mathbf{W}_{\text{denoise}}\) and \(\mathbf{b}_{\text{denoise}}\) are the weight and bias of the denoising layer, and \(\mathbf{x}\) is the input feature."
neurips_2024_oral_10,5,"Y_{t-1}=[W-C_{1}(t)WW_{D}]X_{t}+WC_{2}(t)C_{3}+b\\C_{1}(t)=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}\qquad C _{2}(t)=\frac{1-a_{t-1}^{-}}{1-\tilde{a_{t}}}\beta_{t}\qquad C_{3}=Z\sim N(0,I)","where \(W_{D}\) denotes the parameters of \(D_{\theta}(X_{t},t)\), \(X_{t}\) denotes the input of this linear layer, \(Y_{t}\) denotes the output of this linear layer, and \(Y_{t-1}\) denotes the result after denoising in one step of \(Y_{t}\)","\frac{1}{\sqrt{a_{t}}} (Y_t-b)-(Y_{t-1}-b)=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}} W D_{\theta}(X_{t},t)-W\sigma_{t} z",The transformed equation for the denoising step of embedded features \(Y\) after applying linear weights \(W\) and bias \(b\) to the original feature denoising equation.
neurips_2024_oral_10,6,\frac{1}{\sqrt{a_{t}}}Y_{t}-Y_{t-1}=C_{1}(t)D_{\theta}Y_{t}-\sigma_{t}z || \frac{1}{\sqrt{a_{t-1}}}Y_{t-1}-Y_{t-2}=C_{1}(t-1)D_{\theta}Y_{t-1}-\sigma_{t-1}z,,Y_{t-2}=\left[ W-\left( C_1(t)+C_1(t-1)\right) W W_D+C_1(t) C_1(t-1) W W_D^2\right] X_t+b,"This equation extends the one-step denoising to two steps, where \(Y_{t-2}\) is the two-step denoised output and \(C_1(t)\), \(C_1(t-1)\) are step-dependent coefficients from Eq. (5)."
neurips_2024_oral_10,7,Y_{t-2}=W^{\prime\prime}X_{t}+C^{\prime\prime}\\W^{\prime\prime}=\frac{1}{\sqrt{a_{t}-1}}\{\frac{W}{\sqrt{a_{t} }}-[C_{1}(t)+C_{1}(t-1)]WW_{D}+\sqrt{a_{t}}C_{1}(t-1)C_{1}(t)WW_{D}W_{D}\}\\C^{\prime\prime}=\frac{1}{\sqrt{a_{t}-1}}[WC_{2}(t)+\sqrt{a_{t}}WC_{ 2}(t-1)-\sqrt{a_{t}}C_{1}(t-1)C_{2}(t)WW_{D}]Z+b,,Y_{t-2}=&\frac{1}{\sqrt{a_{t-1} a_t}} (WX_t+b)-\frac{C_1(t)}{\sqrt{a_{t-1}}} D_{\theta}(WX_t+b)+\frac{\sigma_t}{\sqrt{a_{t-1}}} z\\&-C_1(t-1) D_{\theta}\left(\frac{1}{\sqrt{a_t}} (WX_t+b)-C_1(t) D_{\theta}(WX_t+b)+\sigma_t z\right)+\sigma_{t-1} z,"where \(Y_{t-2}\) is the feature after two denoising steps, \(W\) and \(b\) are the parameters of the linear layer, \(X_t\) is the input, \(D_{\theta}\) is the denoising network, \(C_1(t)\) and \(C_1(t-1)\) are coefficients, and \(z\) is random noise."
neurips_2024_oral_10,8,"Loss_{p}=\sum_{i=1}^{N}|\epsilon_{i}-D_{\theta_{i}}(X_{t_{i}},t_{i})|","where \(\epsilon\) denotes the sampled noise, \(N\) denotes the number of denoising layers, \(X_{t}\) denotes the noise sample, \(t\) denotes the diffusion step, and \(D_{\theta}(X_{t},t)\) denotes the noise predicted by the denoising layer","Loss_p=E_{t\sim [1,T],x_0,\epsilon\simN(0,I)}\left\|\epsilon-D_{\theta}(x_t, t)\right\|^2","The training loss \( Loss_p \) is the mean squared error between the true noise \( \epsilon \) and the predicted noise \( D_{\theta}(\mathbf{x}_t, t) \), averaged over timesteps \( t \), data samples \( \mathbf{x}_0 \), and noise \( \epsilon \)."
neurips_2024_oral_10,9,Loss=(1-\lambda)Loss_{l}+\lambda Loss_{p},,Loss=Loss_{p}+\lambda Loss_{l},"The total loss combining unsupervised denoising loss and supervised task loss, where \(\lambda\) balances their contributions."
neurips_2024_oral_11,1,"sim(f,g)=\int_{x\in D(f)}\frac{\mathds{1}[f(x)=g(x)]}{|D(f)|}\\\approx\sum_{x\in X|X\sim D(f)}\frac{\mathds{1}[f(x)=g(x)]}{|X|}",,"sim(f, g)=\frac{1}{|D|}\sum_{x\in D}1_{f(x)=g(x)}",The functionality similarity between two functions \(f\) and \(g\) is defined as the average agreement of their outputs over the entire input domain \(D\).
neurips_2024_oral_11,2,"f^{*}=\textsc{FunConsensus}(F)=\operatorname*{arg\,max}_{f_{(i)}\in F}\sum_{ f_{(j)}\in F\setminus\{f_{(i)}\}}sim(f_{(i)},f_{(j)})",,"f^*=\argmax_{f_i\in F}\sum_{f_j\in F\setminus\{f_i\}}sim(f_i, f_j)",The consensus function \(f^*\) is the candidate in the set \(F\) that maximizes the sum of pairwise similarities to all other functions.
neurips_2024_oral_12,1,"P(X_{1},\ldots,X_{d})=\prod_{i=1}^{d}P(X_{i}\midPA_{i})",,"P(X_1,\ldots, X_d)=\prod_{j=1}^{d} P(X_j\midPA_j)",The joint distribution of observable variables factorizes into the product of each variable's conditional probability given its parents in the graph $\mathcal{G}$.
neurips_2024_oral_12,2,"P(X_{1},\ldots,X_{d}|do(X=x))=\prod_{i:X_{i}\not\inX }P(X_{i}|PA_{i})\big{|}_{X=x}","where \(|_{\mathbf{X}=\mathbf{x}}\) enforces \(X_{1},\ldots,X_{d}\) to be consistent with realizations of \(\mathbf{X}\) else Eq","P(Y|do(X=x))=\sum_{PA_{X}}} P(Y|x,PA_{X}}) P(PA_{X}})",The causal effect \(P(\mathbf{Y}|do(\mathbf{X}=\mathbf{x}))\) is computed by adjusting for the parent set \(\mathbf{PA}_{\mathbf{X}}}\) of \(\mathbf{X}\) in the graph \(\mathcal{G}\).
neurips_2024_oral_12,3,"P(X_{\sigma(1)},\ldots,X_{\sigma(N)})=P(X_{1},\ldots,X_{N})",,"P(X_1, X_2,\dots, X_N)=P(X_{\sigma(1)}, X_{\sigma(2)},\dots, X_{\sigma(N)})",The joint distribution of the sequence is invariant under any finite permutation of the indices.
neurips_2024_oral_12,4,"P(X_{::[N]}=x_{:,[N]})=\int\int\prod_{n=1}^{N}\prod_{i=1}^{ d}p(x_{i;n}\mida_{i;n}^{G},\theta_{i})d\nu_{1}(\theta_{1})\ldots d\nu_{d}(\theta_{d})",,"P(X_{::N})=\int\left(\prod_{i=1}^{d}\prod_{n=1}^{N} P(X_{i;n}\midPA_{i;n},\theta_i)\right)\prod_{i=1}^{d} d\pi_i(\theta_i)","The joint distribution of the exchangeable sequence under the ICM generative process as a mixture of conditionally independent products, with independent priors on the parameters of each causal mechanism."
neurips_2024_oral_12,5,"P(Y=y|do(X=x))=p(y|x,\psi_{0})=P(Y=y|x),\psi_{0}\inR",,P(Y_{:[N]}\mid do(X=x))=\prod_{n=1}^{N} P(Y_{n}\mid X_{n}=x),The joint distribution of the response array \(\mathbf{Y}_{:[N]}\) under the intervention \(do(X=x)\) equals the product of the conditional distributions for each unit \(n\).
neurips_2024_oral_12,6,"P(Y=y|do(X=x))=\int p(y|x,\psi)p(\psi)d\psi=P(Y=y|x)",,"P(Y=y|do(X=x))=\int p(y|x,\psi) d\nu(\psi)","The causal effect \(P(Y=y|do(X=x))\) in the ICM generative process is the expectation of the conditional distribution \(p(y|x,\psi)\) over the parameter \(\psi\)'s measure \(\nu\)."
neurips_2024_oral_12,7,"\textbf{i.i.d. generative process}:P(X_{1},Y_{1},\ldots,X_{N},Y_{N})\stackrel{{ ind}}{{=}}\prod_{n=1}^{N}P(X_{n},Y_{n})\stackrel{{ idc}}{{=}}[P(X,Y)]^{N}",,"P(X_{J}\mid do(X_{I}=x_{I}))=\int\prod_{i\in J} p(X_i\midPA_i^{G},\theta_i)\left(\prod_{i\in J} p(\theta_i)\right) d\theta_{J}\Big|_{X_{I}=x_{I}}","The causal effect distribution for the non-intervened variables \(\mathbf{X}_J\) given an intervention setting \(\mathbf{X}_I = \mathbf{x}_I\) in an exchangeable data generating process, where \(J\) is the complement of \(I\)."
neurips_2024_oral_12,8,"\textbf{ICM gen. process}:P(x_{1},y_{1},\ldots,x_{N},y_{N})=\int\int\prod_{n=1} ^{N}p(y_{n}|x_{n},\psi)p(x_{n}|\theta)d\mu(\theta)d\nu(\psi)",,"P(X_{::[N]})=\int\int\prod_{n=1}^{N}\prod_{i=1}^{2} p(x_{i;n}\mida_{i;n}^{G},\theta_i) d\nu_{1}(\theta_{1}) d\nu_{2}(\theta_{2})",The joint distribution for the bivariate exchangeable sequence generated by an ICM generative process with respect to a DAG \(\mathcal{G}\).
neurips_2024_oral_12,9,"P(X_{J;n}\mid do(X_{I;n}=x))=P(X_{J;m}\mid do (X_{I;m}=x)),\forall n\neq m",,"P(X_{J;n}\mid do(X_{I;n}=x_{I}))=P(X_{J;m}\mid do(X_{I;m}=x_{I})),\quad\forall n, m",The distribution of \(\mathbf{X}_{\mathbf{J};n}\) under an intervention on \(\mathbf{X}_{\mathbf{I};n}\) is invariant to the position index \(n\).
neurips_2024_oral_12,10,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=P(y_{1}|\hat{x})P(y_{2}|x_{2})P(x _{2})1_{x_{1}=\hat{x}}",,"P(X_1, Y_1, X_2, Y_2\mid do(X_1=\hat{x}))=\delta(X_1=\hat{x})\cdot P(Y_1\mid X_1=\hat{x})\cdot P(X_2)\cdot P(Y_2\mid X_2)",The result of applying the i.i.d. truncated factorization to the two-unit bivariate system after intervention on \(X_1\).
neurips_2024_oral_12,11,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=\int p(y_{1}|\hat{x},\psi)p(y_{2 }|x_{2},\psi)p(\psi)d\psi p(x_{2})1_{x_{1}=\hat{x}}",,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=\delta(x_{1}=\hat{x})\int\int p(y_{1}|\hat{x},\psi) p(x_{2}|\theta) p(y_{2}|x_{2},\psi) d\nu(\theta) d\mu(\psi)","The joint distribution after intervening on \(X_1\) in the ICM generative process, accounting for shared parameters and without assuming independence between data points."
neurips_2024_oral_12,12,"p(x_{:,1},\ldots,x_{:,N}|do(X=\hat{x}))=\prod_{i\in I_{X}}p(x_{i;[-N_{i}]}|pa_{i;[-N_{i}]}^{G})\prod_{i\not\in I_{ X}}p(x_{i;[N]}|pa_{i;[N]}^{G})\big{|}_{X=\hat{x}}",,"p(x_{::[N]}\mid do(X=\hat{x}))=\left(\prod_{(i,n): X_{i;n}\inX}1_{\{x_{i;n}=\hat{x}_{i;n}\}}\right)\int\prod_{i=1}^{d} d\nu_i(\theta_i)\prod_{(i,n): X_{i;n}\not\inX} p(x_{i;n}\midpa_{i;n}^{G},\theta_i)","The post-interventional density for the entire sequence after intervening on set \(\mathbf{X}\) at specific positions, with \(\mathbf{x}_{::[N]}\) denoting all variables at positions 1 to N, \(\mathbf{X}\) being the set of intervened variables, \(\hat{\mathbf{x}}\) the intervened values, and the integral over causal de Finetti parameters."
neurips_2024_oral_12,13,"P(X_{\negI;n}|do(X_{I;n}=\hat{x} ),X_{\negS})=\prod_{i\not\inI}P(X_{i;n}|X_{i;S},PA_{i;S\cup\{n\}})|_{ X_{I;n}=\hat{x}}",,"P(X_{[\negI];n}\mid do(X_{I;n}=\hat{x}),X_{::S})=P(X_{[\negI];n}\mid\hat{x},X_{::S})",The conditional interventional distribution of non-intervened variables at position \(n\) given the intervention on \(\mathbf{X}_{\mathbf{I};n}\) and observations at positions in \(\mathbf{S}\) equals the conditional distribution of the non-intervened variables given the intervened values and the observations.
neurips_2024_oral_12,14,"\int\int\prod_{n}p(y_{n}\mid x_{n},\psi)p(x_{n}\mid\theta)p(\theta)p(\psi)d\theta d\psi","where \(p(\theta),p(\psi)\) are Beta distributions and \(p(y_{n}\mid x_{n},\psi),p(x_{n}\mid\theta)\) are Bernoulli distributions","P(x_1,y_1,\ldots,x_N,y_N)=\int\int\prod_{n=1}^{N} p(x_n\mid\theta_1) p(y_n\mid x_n,\theta_2) d\nu_1(\theta_1) d\nu_2(\theta_2)","The joint distribution of the observed sequence in the causal Polya urn model, where \(\theta_1\) and \(\theta_2\) are the causal de Finetti parameters for the marginal of \(X\) and the conditional of \(Y\) given \(X\), respectively."
neurips_2024_oral_13,1,"X_{q}=clamp(\,\lfloor\frac{X}{\Delta}\rceil\!+\!z,0,2^{b}-1),where \Delta=\frac{\max(X)-\min(X)}{2^{b}-1},z=-\lfloor\frac{\min(X)}{\Delta}\rfloor",,"X_{q}=clip\left(\left\lfloor\frac{X}{s}\right\rceil,-2^{b-1}, 2^{b-1}-1\right)","$\mathbf{X}_{q}$ is the $b$-bit quantized tensor obtained by scaling $\mathbf{X}$ by $s$, rounding to the nearest integer, and clipping to the symmetric integer range $[-2^{b-1}, 2^{b-1}-1]$."
neurips_2024_oral_13,2,"R^{1}=E_{d^{(1)}}\hat{R}QE_{d^{(1)}},\qquadQ=1&Q\\O&Q^{\prime}\!",,"\hat{R}_{i,j}=\frac{\sqrt{2}}{2} &if  (i,j)=(1,1) or  (d^{(1)},d^{(1)})\\\frac{\sqrt{2}}{2} &if  (i,j)=(1,d^{(1)})\\-\frac{\sqrt{2}}{2} &if  (i,j)=(d^{(1)},1)\\1 &if  i=j and  i\notin\{1, d^{(1)}\}\\0 &otherwise",The rotation matrix \(\hat{\mathbf{R}}\) is constructed as a Givens rotation between dimension 1 and the outlier-concentrated dimension \(d^{(1)}\) with a fixed 45-degree angle.
neurips_2024_oral_13,3,"\hat{R}= BlockDiag(\hat{R}_{b_{1}},...,\hat{R}_{b_{K}})","where \(\hat{\mathbf{R}}_{b_{i}}\in\mathbb{R}^{2^{n}\times 2^{n}}\) denotes a square matrix of the \(i\)-th block, which is constructed following the three steps mentioned above",\hat{R}=R_1 &0 &\cdots &0\\0 &R_2 &\cdots &0\\\vdots &\vdots &\ddots &\vdots\\0 &0 &\cdots &R_K,"The approximated rotation matrix \(\hat{\mathbf{R}}\) is a block diagonal matrix with orthogonal blocks \(\mathbf{R}_1, \mathbf{R}_2, \ldots, \mathbf{R}_K\)."
neurips_2024_oral_13,4,"Var([M_{b_{1}},M_{b_{2}},...,M_{b_{K}}])",,Var=\frac{1}{K}\sum_{i=1}^{K}\left( M_{b_i}-\frac{1}{K}\sum_{j=1}^{K} M_{b_j}\right)^2,The variance of the block means \(M_{b_i}\) of the largest outliers per dimension in each block.
neurips_2024_oral_13,5,Y=X\cdotW=[(X\cdot\underbrace{A^ {-1}}_{G})\hat{R}_{(1)}\cdotP\cdot\hat{R }_{(2)}]\cdot[\underbrace{\hat{R}_{(2)}^{\top}\cdotP^{\top}\cdot\hat{R}_{(1)}^{\top}(A}_{G^{-1}}\cdotW)],"where the notation \(\mathbf{P}\) denotes the orthogonal permutation matrix learned via the zigzag manner, the \(\hat{\mathbf{R}}_{(1)}\) and \(\hat{\mathbf{R}}_{(2)}\) represent the first and second block-diagonal rotation matrix, respectively",Y=\left(X\Lambda^{-1}\hat{R}P\hat{R}'\right)\cdot\left( (\hat{R}')^{\top}P^{\top}\hat{R}^{\top}\LambdaW\right),"The linear layer reformulated by DuQuant after smooth, rotation, permutation, and second rotation transformations."
neurips_2024_oral_13,6,\max_{1\leq j\leq 2^{n}}\O_{j}(X_{b_{i}}\hat{R}_{b_{i}})\leq\max_{1\leq j\leq 2^{n}}\O_{j}(X_{b_{i}}),,\max_{j} O_j(X^{(b_i)}\hat{R}_{b_i})\leq\max_{j} O_j(X^{(b_i)}),The maximum outlier in the block after rotation is less than or equal to the maximum outlier in the block before rotation.
neurips_2024_oral_13,7,"M_{b_{i}}\leq O^{(1)}+\frac{(2^{n}K-1)(2^{n-1}-1)}{2^{n}}\delta,\qquad i=1,2, 3,...,K",,M_{b_i}\leq\frac{1}{K}\sum_{j=1}^{K} O^{(j)}+\delta\cdot (2^{n}-1),"Upper bound on the mean value of max outliers in the i-th block after zigzag permutation, where K is the number of blocks, O^{(j)} is the j-th largest sorted outlier, δ is the maximum gap between consecutive sorted outliers, and n defines the block size as 2^n."
neurips_2024_oral_15,1,"\forall x\inX\colonP[c_{x }=1]=\frac{1}{1+\exp(-2ax^{\top}\theta^{*})},\\E[c_{x}]=\tanh(ax^{\top}\theta^{*})\\V[c_{x}]=1-\tanh^{2}(ax^{\top}\theta^{*}),\\E[t_{x}]=\frac{a}{x^{\top}\theta^{*}}\tanh(ax^ {\top}\theta^{*})&if x^{\top}\theta^{*}\neq 0\\a^{2}&if x^{\top}\theta^{*}=0",,"E_{x,\tau}=x^\top\theta^*\cdot\tau+B(\tau)",The evidence for query $x$ at decision time $\tau$ combines a linear drift term and Brownian motion noise.
neurips_2024_oral_15,2,\forall x\inX\colon x^{\top}\frac{\theta^{*}}{a}=\frac{E [c_{x}]}{E[t_{x}]},,E[t_x]\cdot (x^\top\theta^*)=a\cdotE[c_x]\quad\forall x\inX,"For any query \(x\), the product of the expected decision time and utility difference equals the barrier multiplied by the expected choice."
neurips_2024_oral_15,3,"\widehat{\theta}_{CH,DT}\coloneqq(\sum_{x\inX_{ sample}}n_{x}\;xx^{\top})^{-1}\sum_{x\inX_{sample}}n_{x}\;x\;\frac{\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}",,"\widehat{\theta}_{CH,DT}=\left(\sum_{x\inX_{sample}} x x^{\top}\right)^{-1}\sum_{x\inX_{sample}} x\cdot\frac{\bar{c}_x}{\bar{t}_x}",The choice-decision-time estimator for \(\theta^*/a\) computed via ordinary least squares on the aggregated choice and decision time ratios per query.
neurips_2024_oral_15,4,"\widehat{\theta}_{CH}\coloneqq\operatorname*{arg\,max}_{\theta\inR^{d}}\sum_{x\inX_{sample}}\sum_{i=1}^{n_{x}}\log\mu(c_{x,s_{x,i}}\,x^{\top}\theta)",where \(\mu(y)\coloneqq 1/[1+\exp(-y)]\) is the standard logistic function,"\widehat{\theta}_{CH}\coloneqq\arg\min_{\beta\inR^d}\sum_{x\inX_{sample}}\sum_{i=1}^{n_{x}}\log\left(1+\exp\left(-c_{x,s_{x,i}} (x^{\top}\beta)\right)\right)",The choice-only estimator \(\widehat{\theta}_{\text{CH}}\) is the maximum likelihood estimator for \(2a\theta^{*}\) via logistic regression.
neurips_2024_oral_15,5,"\sqrt{n}\;y^{\top}(\widehat{\theta}_{CHD,n}-\theta^{*}/a)\overset{D}{\longrightarrow}N(0,\zeta^{2}/a^{2})",,"\sqrt{n}\left( y^{\top}\widehat{\theta}_{CHD}-y^{\top}\frac{\theta^{*}}{a}\right)\overset{d}{\to}N\left(0, y^{\top}\left(\sum_{x\inX_{sample}}\frac{n_{x}}{n} x x^{\top}\right)^{-1}\left(\sum_{x\inX_{sample}}\frac{n_{x}}{n}\sigma_{x}^{2} x x^{\top}\right)\left(\sum_{x\inX_{sample}}\frac{n_{x}}{n} x x^{\top}\right)^{-1} y\right)",Asymptotic distribution of the linear functional for the choice-decision-time estimator.
neurips_2024_oral_15,6,\zeta^{2}\leq\|y\|_{(\sum_{x\inX_{sample}} [\min_{x^{\prime}\inX_{sample}}E[t_{x^{\prime}}]]\cdot xx^{\top})^{-1}}^{-1},,\zeta^{2}\leq\frac{\kappa}{a^{2}\min_{x\inX} (x^{\top}\theta^{*})^{2}},"Upper bound on the asymptotic variance constant \zeta^{2}, where \kappa is a positive constant."
neurips_2024_oral_15,7,"\sqrt{n}y^{\top}(\widehat{\theta}_{CH,n}-2a\theta^{*})\overset{D}{\longrightarrow}N(0,4a^{2}\|y\|_{(\sum_{x\inX_{sample}}[a^{2}\,V[c_{x}] ]\cdot xx^{\top})^{-1}}^{-1})",,"\sqrt{n} y^{\top} (\widehat{\theta}_{CH}-2a\theta^{*})\overset{D}{\longrightarrow}N\left(0, y^{\top}\left(\sum_{x\inX_{sample}}V[c_x]\cdot x x^{\top}\right)^{-1} y\right)",The asymptotic normality of the linear functional of the choice-only estimator error for \(2a\theta^{*}\).
neurips_2024_oral_15,8,"\widehat{u}_{x,CH,DT}\coloneqq\frac{\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}",,"\widehat{\left(\frac{u_x}{a}\right)}_{CH,DT}=\frac{\sum_{i=1}^{n_x} c_{x,s_{x,i}}}{\sum_{i=1}^{n_x} t_{x,s_{x,i}}}",The choice-decision-time estimator of the scaled utility difference \( u_x / a \) for a single query \( x \) using \( n_x \) samples.
neurips_2024_oral_15,9,"\widehat{u}_{x,CH}\coloneqq\mu^{-1}(\frac{1}{n_{x}}\sum_{i=1}^{n _{x}}\frac{c_{x,s_{x,i}}+1}{2})","where \((c_{x,s_{x,i}}+1)/2\) is the binary choice coded as 0 or 1, and \(\mu^{-1}(p)\coloneqq\log\left(p/(1-p)\right)\) is the logit function (inverse of \(\mu\) introduced in eq","\widehat{2a u_x}_{CH}=\log\left(\frac{\sum_{i=1}^{n_x}1\{c_{x,s_{x,i}}=1\} }{\sum_{i=1}^{n_x}1\{c_{x,s_{x,i}}=-1\} }\right)",The choice-only estimator for \(2a u_x\) using the log-odds of the ratio of positive to negative choices for query \(x\).
neurips_2024_oral_15,10,"P(|\widehat{u}_{x,CH,DT}-\frac{u_{x}}{a}|>\epsilon)\leq 4\exp(-[m_{CH,DT}^{non-axym}(x^{\top}\theta^{*})]^{2}\,n_{x}\,[\epsilon\cdot a]^{2} )",,"P\left(\left|\widehat{u}_{x,CH,DT}-\frac{u_x}{a}\right|\geq\epsilon\right)\leq 2\exp\left(-\frac{n_x\epsilon^2 (E[t_x])^2}{4 a^2}\right)",Non-asymptotic concentration bound showing exponential decay in sample size for the choice-decision-time utility difference estimator's deviation from the true normalized utility difference.
neurips_2024_oral_15,11,"P(|\widehat{u}_{x,CH}-2au_{x}|>\epsilon)\leq 6\exp(-[m_{CH}^{non-asym}(x^{\top}\theta^{*} )]^{2}\,n_{x}\,[\epsilon/(2a)]^{2})",,"m_{CH,DT}^{non-axym}(x^{\top}\theta^{*})\coloneqq\frac{E[t_{x}]}{(2+2\sqrt{2})a}","The weight in the non-asymptotic concentration bound for the choice-decision-time estimator, defined as the expected decision time normalized by a barrier-dependent constant."
neurips_2024_oral_16,1,"H=GNN(A,X)=\tilde{A}XW^{\prime},h_{i}=\sum_{j\inN_{i}}\alpha_{ij}x_{j}\cdotW^{\prime}=\sum_{j\inN_{i}}\frac{1}{d_{ i}}x_{j}\cdotW^{\prime}","where \(\mathbf{W}^{\prime}=\xi(\mathbf{W}),\mathbf{W}\in\mathbb{R}^{D\times K}\) with \(\xi\) being an activation function like ReLU [22] for ease of understanding, \(\mathcal{N}_{i}\) denotes the set of first-order neighbors of node \(v_{i}\), inclusive of \(v_{i}\) itself",H=\sigma\left(\tilde{A}XW\right),"Node embeddings computed by a single-layer GNN with row-normalized adjacency matrix, input features, weight parameters, and activation function."
neurips_2024_oral_16,2,"E[h_{i}]&=E [\sum_{j\inN(i)}\alpha_{ij}x_{j}\cdotW^{\prime}]=\sum_{j\inN(i)}\alpha_{ij}E[x_{j}]\cdotW^{\prime}=\sum_{j\inN(i)}\alpha_{ij}\mu_{i}\cdotW^{\prime},\\Var(h_{i})&=Var(\sum_{ j\inN(i)}\alpha_{ij}x_{j}\cdotW^{\prime})=\sum_{j\inN(i)}\alpha_{ij}Var(x_{j})\cdotW ^{\prime 2}=\sigma_{i}^{2}\sum_{j\inN(i)}\alpha_{ij}^{2}\cdotW^{\prime 2}",,"E[h_{i}] &=\mu_{i}W^{\prime},\\Var(h_{i}) &=\frac{\sigma_{i}^{2}}{d_{i}}\|W^{\prime}\|_{F}^{2}","The mean of the aggregated representation $\mathbf{h}_i$ is $\mu_{i} \mathbf{W}^{\prime}$, and the variance is $\frac{\sigma_{i}^{2}}{d_{i}} \|\mathbf{W}^{\prime}\|_{F}^{2}$."
neurips_2024_oral_16,3,"\tilde{h}_{i}=Trans_{R^{d}\toS^{k}}(h_{i})=\frac{h_{i}}{Max(\|h_{i}\|_{2},\varepsilon)},\quadS^{k}=\{\tilde{h}_{i}:\|\tilde{h }_{i}\|_{2}=1\}","where \(\mathbf{h}_{i}\) is representation for node \(v_{i}\in\mathcal{V}\), generated by the target encoder, \(\|\tilde{\mathbf{h}}_{i}\|_{2}=(\sum_{j=1}^{k}\tilde{\mathbf{h}}_{ij}^{2})^{ \frac{1}{2}}\), and \(\epsilon\) is a small value to avoid division by zero","h_{i}\sim p_{i}^{\prime}(\mu_{i}\cdotW^{\prime},\sigma_{i}^{2}\cdotW^{\prime 2})\quadand\quad\hat{h}_{i}\sim p_{data}^{\prime}(\mu\cdotW^{\prime},\sigma^{2}\cdotW^{\prime 2})",The distributions of the aggregated representations for node \(v_i\) in the original graph and the corrupted graph.
neurips_2024_oral_16,4,"L_{scattering}=-\frac{1}{n}\sum\nolimits_{i=1}^{n}\|\tilde{h}_{i}-c\|_{2}^{2},\quadc=\frac{1}{n}\sum\nolimits _{i=1}^{n}\tilde{h}_{i}",,"c=\frac{1}{n}\sum_{i=1}^{n}\tilde{h}_{i},\quadL_{scattering}=\left\|c\right\|_{2}^{2}","The scattered center $\mathbf{c}$ is the mean of the normalized node representations in the graph, and $\mathcal{L}_{\text{scattering}}$ is the squared $\ell_2$ norm of $\mathbf{c}$."
neurips_2024_oral_16,5,H_{online}^{topology}=\hat{A}^{k}H_{online}+H_{online},where k represents the order of neighbors and \(\hat{\mathbf{A}}=\mathbf{A}+\mathbf{I}\) is the adjacency matrix with self-loops,H_{online}^{topology}=H_{online}+\hat{A}^{k}H_{online},"\(\mathbf{H}_{\text{online}}^{\text{topology}}\) is the topologically enhanced representation, computed as the sum of the original online representation \(\mathbf{H}_{\text{online}}\) and the k-hop neighbor aggregated representation \(\hat{\mathbf{A}}^{k}\mathbf{H}_{\text{online}}\)."
neurips_2024_oral_16,6,"L_{alignment}=-\frac{1}{N}\sum_{i=1}^{N}\frac{Z_{(online,i)}^{\top}H_{(target,i)}}{\|Z_{(\text {online},i)}\|\|H_{(target,i)}\|}","where \(\mathbf{Z}_{\text{online}}\) and \(\mathbf{H}_{\text{target}}\) represent the predicted and scattered representations, respectively",L_{alignment}=\frac{1}{n}\sum_{i=1}^{n}\|z_{online}^{(i)}-h_{target}^{(i)}\|_{2}^{2},The alignment loss between the predicted representations from the online encoder and the scattered representations from the target encoder.
neurips_2024_oral_16,7,\phiarrow\tau\phi+(1-\tau)\theta,"where \(\tau\) is a target decay rate and \(\tau\in[0,1]\)","L_{alignment}=-\frac{1}{N}\sum_{i=1}^{N}\frac{Z_{(online,i)}^{\top}H_{(target,i)}}{\|Z_{(online,i)}\|\|H_{(target,i)}\|}","where \(\mathbf{Z}_{(\text{online},i)}\) and \(\mathbf{H}_{(\text{target},i)}\) represent the predicted and scattered representations for node \(v_i\), respectively."
neurips_2024_oral_17,1,"L_{cons}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}H\Big{(}p_{m}(y\mid f_{\theta}(\alpha(x))),p_{m}(y\mid f_{\theta}(A(x)))\Big{)}",,L_{cons}=\frac{1}{|U|}\sum_{x\inU}1\left(\max_{c}T(w(x))_c\geq\tau\right)\cdot\left(-\logS(s(x))_{\arg\max_{c}T(w(x))_c}\right),"The consistency loss $\mathcal{L}_{\text{cons}}$ averages over unlabeled data the negative log probability assigned by the student model (on strong augmentations) to the pseudo-label class predicted by the teacher model (on weak augmentations), weighted by an indicator for teacher confidence exceeding threshold $\tau$."
neurips_2024_oral_17,2,"L_{cons}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}d\Big{(}p_{m}(y\mid f_{\theta}(\alpha(x ))-\Delta\Re),p_{m}(y\mid f_{\theta}(A(x)) )\Big{)}",,L_{align}=\frac{1}{|D_U|}\sum_{x\inD_U}\left\| f_{\theta}(\alpha(x))-f_{\theta}(A(x))\right\|^2,This loss minimizes the mean squared difference between the teacher and student model logits to reduce representation discrepancy.
neurips_2024_oral_17,3,"E(\xi;X)=\frac{1}{2}\xi^{\top}\xi-\rm{lse}(X^{\top}\xi,\beta)+c,\quadwith \rm{lse}(v,\beta):=\beta^{-1}\log(\sum_{i=1}^{N}\exp(v_{i}))",,E(\xi)=-\frac{1}{2}\xi^\top\xi-\log\left(\sum_{i=1}^{N}\exp(\xi^\topx_i)\right),The energy function \( E \) for a query pattern \( \mathbf{\xi} \) given stored key patterns \( \{\mathbf{x}_i\}_{i=1}^N \).
neurips_2024_oral_17,4,\xiarrow\xi-\eta\nabla_{\xi}E(\xi;X)=\xi-\rm{sm}(\beta\xi^{\top}X)X^{\top},,\xi^{(t+1)}=X\cdotsoftmax\left(\betaX^{\top}\xi^{(t)}\right),"The update rule for the state pattern ξ via gradient descent on the Hopfield energy, moving it closer to the most similar stored pattern."
neurips_2024_oral_17,5,"E(Q_{s};K_{t})=\frac{\alpha}{2}diag(K_{t}K_{t}^{T})-\sum_{i=1}^{N}\rm{lse}(Q_{s}k_{t,i}^{T},\beta)+c || E(K_{t})=\rm{lse}(\frac{1}{2}diag(K_{t}K_{t}^{T}),1)=\log\sum_{i=1}^{N}\exp(\frac{ 1}{2}k_{t,i}k_{t,i}^{T})+c",,"E_{s\to t}=\frac{1}{M}\sum_{i=1}^{M}\left[\frac{1}{2}q_{s,i}^{\top}q_{s,i}-\beta^{-1}\rm{lse}\left(K_{t}^{\top}q_{s,i},\beta\right)\right]","The cross-attention energy from student queries to teacher keys, averaged over all student query tokens."
neurips_2024_oral_17,6,p(K_{t}|Q_{s})=\frac{p(Q_{s}|K_{t})p(K_{t})}{p(Q_{s})},,"E_{total}(K_{t};Q_{s})=\frac{\alpha}{2}\sum_{i=1}^{N}k_{t,i}^{\top}k_{t,i}-\sum_{i=1}^{N}\rm{lse}(Q_{s}k_{t,i}^{\top},\beta)+\log\sum_{i=1}^{N}\exp\left(\frac{1}{2}k_{t,i}^{\top}k_{t,i}\right)+c'",The total energy function for the MAP estimate of teacher keys \(\mathbf{K}_{t}\) given student queries \(\mathbf{Q}_{s}\).
neurips_2024_oral_17,7,\nabla_{K_{t}}\log p(K_{t}|Q_{s})&=-(\nabla_{K_{t}}E(Q_{s};K_{t})+\nabla_{K_{t}}E(K_{t}))\\&=sm(\betaQ_{s}K_{t}^{T})Q_ {s}-(\alphaI+D(sm(\frac{1}{2}diag(K_{t}K_{t}^{T}))))K_{t},,"\nabla_{K_t}\log p(K_t\midQ_s)=-\alphaK_t-Q_s^\topsoftmax\left(\betaQ_sK_t^\top, 0\right)-K_t\cdotdiag\left(softmax\left(\frac{1}{2}diag(K_t^\topK_t)\right)\right)","The gradient of the log posterior of teacher keys given student queries with respect to teacher keys, facilitating attention alignment via gradient-based updates."
neurips_2024_oral_17,8,"K_{t}^{update}=K_{t}+\gamma_{update}[\,(sm(\betaKQ^{T})QW_{K}^{T})-\gamma_{reg }(\alphaI+D(sm(\frac{1}{2}diag (KK^{T})))KW_{K}^{T})\, ]",,K_{t}\leftarrowK_{t}+sm\left(\betaQ_{s}K_{t}^{\top}\right)Q_{s}-\alphaK_{t}-D\left(sm\left(\frac{1}{2}diag\left(K_{t}K_{t}^{\top}\right)\right)\right)K_{t},Update rule for teacher keys \(\mathbf{K}_{t}\) to minimize energy and align with student queries \(\mathbf{Q}_{s}\) by combining gradient-based adjustments from the posterior estimate.
neurips_2024_oral_17,9,L_{rep}^{s}=\frac{1}{|B^{\prime}|}\sum_{i\inB^{\prime}}\frac{1}{|N_{i}|}\sum_{q\inN_{i}}-\log\frac{\exp(z_{i}^{T}z_{q}^{\prime}/\tau_{c})}{\sum_{i^{\prime}\neq i }\exp(z_{i}^{T}z_{i^{\prime}}^{\prime}/\tau_{c})} || L_{rep}^{u}=\frac{1}{|B|}\sum_{i\inB}-\log\frac{\exp(z_{i}^{T}z_{i}^{\prime}/\tau_{u} )}{\sum_{i^{\prime}\neq i}\exp(z_{i}^{T}z_{i^{\prime}}^{\prime}/\tau_ {u})},,"L_{con}=\frac{1}{|B_l|}\sum_{i\in B_l}\frac{-1}{|P_i|}\sum_{p\in P_i}\log\frac{\exp(z_i\cdotz_p/\tau )}{\sum_{k\in B, k\neq i}\exp(z_i\cdotz_k/\tau )}+\frac{\lambda}{|B_u|}\sum_{i\in B_u}-\log\frac{\exp(z_i\cdotz_{i'}/\tau )}{\sum_{k\in B, k\neq i}\exp(z_i\cdotz_k/\tau )}","The combined contrastive loss \(\mathcal{L}_{\text{con}}\) integrates supervised contrastive learning for labeled data and self-supervised learning for unlabeled data, utilizing two augmented views per image to enhance representation learning."
neurips_2024_oral_17,10,"L_{cons}=\frac{1}{|B|}\sum_{i\inB }\ell(q^{\prime}_{i},p_{i})-\varepsilon H(\bar{p})&for unlabeled,\\\frac{1}{|B|}\sum_{i\inB}\ell(y_{i},p_{i})&for labeled.",,"L_{cons}=\frac{1}{|D_L|}\sum_{x\inD_L}\ell(y, p(y|f_\theta(A(x))))+\frac{1}{|D_U|}\sum_{x\inD_U}\ell(p_{m}(y|f_\theta(\alpha(x))), p(y|f_\theta(A(x))))","The consistency loss $\mathcal{L}_{\text{cons}}$ combines supervised cross-entropy for labeled data and unsupervised consistency regularization for unlabeled data using ground-truth labels and teacher-generated pseudo-labels, respectively."
neurips_2024_oral_18,1,G(x)=\exp(-\frac{1}{2}(x-\mu_{0})^{T}\Sigma_{0}^{-1}(x-\mu_{0})),"where \(\Sigma_{0}\) can be factorized as \(\Sigma_{0}=R_{0}S_{0}S_{0}^{T}R_{0}^{T}\), in which \(R_{0}\) is a rotation matrix represented by a quaternion vector \(r_{0}\in\mathbb{R}^{4}\), and \(S_{0}\) is a a diagonal scaling matrix characterized by a 3D vector \(s_{0}\in\mathbb{R}^{3}\)","\[ G=\left(\mu_0,\Sigma_0,\sigma, c\right)\]","Each 3D Gaussian point is represented by a tuple of center \(\mu_0\), covariance matrix \(\Sigma_0\), density \(\sigma\), and color \(c\)."
neurips_2024_oral_18,2,"I(u)=\sum_{i\in N}T_{i}\alpha_{i}c_{i},\qquad A(u)=\sum_{i\in N}T_{i}\alpha_{i },\qquad D(u)=\sum_{i\in N}T_{i}\alpha_{i}d_{i}","where \(T_{i}=\prod_{j=1}^{i-1}(1-\alpha_{j})\) is the accumulated transmittance, \(\alpha_{i}\) is the probability of termination at point \(i\), and \(d_{i}\) is the depth of the Gaussian point at the specific view",D(u)=\frac{\sum_{i=1}^{N} d_i\alpha_i\prod_{j=1}^{i-1} (1-\alpha_j) }{\sum_{i=1}^{N}\alpha_i\prod_{j=1}^{i-1} (1-\alpha_j) },"The depth \( D(u) \) at pixel \( u \) is computed as the weighted average of the depths \( d_i \) of the ordered Gaussians, with weights \( \alpha_i \prod_{j=1}^{i-1} (1 - \alpha_j) \) normalized by their sum."
neurips_2024_oral_18,3,"\mu(t)=\mu_{0}+\sum_{i=1}^{N_{m}}w_{i}(\mu_{0},t)d\mu_{i}(t),\qquad s(t)=s_{0}+\sum_{i=1}^{N_{m}}w_{i}(\mu_{0},t)ds_{i}(t)",,"\mu(t)=\mu_0+\sum_{i=1}^{N_m} w_i(\mu_0, t) d\mu_i(t),\qquad s(t)=s_0+\sum_{i=1}^{N_m} w_i(\mu_0, t) ds_i(t)","where \(\mu(t)\) and \(s(t)\) are the deformed position and scale at time \(t\), \(\mu_0\) and \(s_0\) are the canonical position and scale, \(w_i(\mu_0, t)\) is the motion coefficient for the \(i\)-th basis, and \(d\mu_i(t)\) and \(ds_i(t)\) are the deformation vectors for position and scale from the \(i\)-th motion basis at time \(t\)."
neurips_2024_oral_18,4,"L_{gs}=L_{1}(I,\tilde{I})+\lambda_{1}L_{ssim}(I,\tilde{I})+\lambda_{2}L_{1}(s(t))",where \(\lambda_{1}\) and \(\lambda_{2}\) are balancing hyperparameters,"L=\sum_{u} |I(u)-\tilde{I}(u)|+\lambda_{SSIM} (1-SSIM(I,\tilde{I}))+\lambda_{scale}\sum_{k} |s_{0,k}|","The overall loss function \(\mathcal{L}\) consists of a pixel-wise L1 loss and an SSIM term for image reconstruction, and an L1 regularization on the canonical scales of all Gaussians."
neurips_2024_oral_18,5,"P_{\tilde{P}}=\{(\tilde{p},s_{\Delta x},\sigma_{F})\}","where \(\tilde{p}\in\tilde{P}\), \(s_{\Delta x}=\Delta x/2^{n_{u}}\), and \(\sigma_{F}=F[Discretize(\tilde{p})]\) (we neglect \(t\) in the notation for simplicity)","\tilde{P}(t)=\left\{\left(\hat{p}, F(t,\hat{p}),\Delta x_{fine}\right)\mid\hat{p}\in\hat{P}(t)\right\}","where \(F(t, \hat{p})\) is the value of the density field at position \(\hat{p}\), and \(\Delta x_{\text{fine}}\) is the grid size of the finest grid."
neurips_2024_oral_18,6,"L_{ppe}=\frac{1}{m}\sum_{i=1}^{m}[L_{CD}(S(t_{i}),\tilde{S} (t_{i}))+\frac{1}{n}\sum_{j=1}^{n}L_{1}(A_{j}(t_{i}),\bar{A}_{j}(t_{ i}))]","where \(\mathcal{L}_{CD}\) and \(\mathcal{L}_{1}\) are chamfer distance and L1 norm respectively, \(S(t_{i})\) denotes the simulated surface at time \(t_{i}\), \(A_{j}(t_{i})\) is the rendered mask at view \(j\), and \(\bar{A}_{j}(t_{i})\) represents the object mask of the image extracted from video \(V_{j}\) at time \(t_{i}\)","L_{sim}=\sum_{t}\left(\lambda_{3}\cdotD_{CD}\left(\tilde{S}(t), S(t)\right)+\lambda_{4}\cdot\sum_{i=1}^{n}\left\|\tilde{A}_{i}(t)-A_{i}(t)\right\|_{1}\right)","The simulation loss \(\mathcal{L}_{sim}\) is the weighted sum over time of the Chamfer distance between the extracted surfaces \(\tilde{S}(t)\) and the simulated surfaces \(S(t)\), and the L1 norm of the difference between the rendered masks \(\tilde{A}_{i}(t)\) and \(A_{i}(t)\) across all \(n\) views."
neurips_2024_oral_2,1,"\operatorname*{minimize}_{\theta}L(\theta;D_{SFT})=-E_{(x,y)\simD_{SFT}}[\log\pi_{\theta}(y|x)]",,"\max_{\theta}E_{(x,y)\simD_{SFT}}\left[\sum_{t=1}^{|y|}\log\pi_{\theta}(y_t |x,y_{<t})\right]",The supervised fine-tuning objective maximizes the expected log-likelihood of each token \(y_t\) in the target response \(\mathbf{y}\) conditioned on the input \(\mathbf{x}\) and preceding tokens \(\mathbf{y}_{<t}\) over the dataset \(\mathcal{D}_{\text{SFT}}\).
neurips_2024_oral_2,2,"\pi^{\prime}(y_{c}|x)=\sum_{y_{k}}\mu_{\phi}(y_{c}|y_{k},x)\pi_{\theta}(y_{k}|x)\geqslant\mu_{\phi} (y_{c}|y_{o},x)\pi_{\theta}(y_{o}|x)",where \(\mathbf{y}_{k}\) is a possible answer generated by upstream LLM \(\pi_{\mathbf{\theta}}\),"\operatorname*{minimize}_{\phi}L(\phi;M)=-E_{(x,y_{o},y_{c})\simM}[\log\mu_{\phi}(y_{c}|y_{o},x)]","The loss function for training the Aligner model \(\mu_{\mathbf{\phi}}\), where \(\mathbf{\phi}\) are the model parameters, \(\mathcal{M}\) is the preference dataset, and \(\mu_{\mathbf{\phi}}(\mathbf{y}_{c}|\mathbf{y}_{o},\mathbf{x})\) models the conditional distribution of corrected answers \(\mathbf{y}_{c}\) given original answers \(\mathbf{y}_{o}\) and inputs \(\mathbf{x}\)."
neurips_2024_oral_2,3,"-E_{M}[\log\pi^{\prime}(y_{c}|x)]\leqslant-E_{M}[\log\mu_{\phi}(y_{c}|y_{o},x)]-E_{M}[\log\pi_{\theta}(y_{o}|x)]",,"\operatorname*{minimize}_{\phi}L(\phi;M)=-E_{(x,y_{o},y_{c})\simM}[\log\mu_{\phi}(y_{c}|y_{o},x)]",The training objective for the Aligner model \(\mu_{\mathbf{\phi}}\) to minimize the negative log-likelihood of corrected responses given original responses and inputs.
neurips_2024_oral_2,4,"\operatorname*{minimize}_{\phi}L_{Aligner}(\phi,M)=-E_{M}[\log\mu_{\phi}(y_{c} |y_{o},x)]",,"\operatorname*{minimize}_{\phi}L(\phi;M)=-E_{(x,y_{o},y_{c})\simM}[\log\mu_{\phi}(y_{c}|y_{o},x)]",The training objective for Aligner minimizes the negative log-likelihood of the corrected answer \(\mathbf{y}_{c}\) given the original answer \(\mathbf{y}_{o}\) and the query \(\mathbf{x}\).
neurips_2024_oral_21,1,"q(X_{V}^{t}\midX_{V}^{t-1})=Cat(X_{V}^{t};p=X_{V}^{t-1}Q_{V}^{t}),\\q(X_{E}^{t}\midX_{E}^{t-1})=Cat(X_{E}^ {t};p=X_{E}^{t-1}Q_{E}^{t})",where \(\mathrm{Cat}(\mathbf{X};\mathbf{p})\) denotes sampling from a categorical distribution with probability \(\mathbf{p}\),"q(G^t\mid G^{t-1})=\prod_{i=1}^{N}\left(x_{V,i}^{t-1}Q_V\right)_{x_{V,i}^t}\times\prod_{1\leq i,j\leq N}\left(x_{E,ij}^{t-1}Q_E\right)_{x_{E,ij}^t}","The equation defines the conditional probability of the graph state at diffusion step t given the previous state, factoring into node and edge transitions via categorical distributions parameterized by the transition matrices."
neurips_2024_oral_21,2,p_{\theta}(\tilde{G}^{0}\mid G^{t})=\prod_{v\in V}p_{\theta}(v^{t-1}\mid G^{t})\prod_{e\in E}p_{\theta}(e^{t-1}\mid G^{t}),,p_{\theta}(\tilde{G}^{0}\mid G^{t})=\left(\prod_{i=1}^{n} p_{\theta}(\tilde{x}_i^{0}\mid G^{t})\right)\left(\prod_{1\leq i < j\leq n} p_{\theta}(\tilde{e}_{ij}^{0}\mid G^{t})\right),The reverse process models the clean graph \(\tilde{G}^{0}\) given \(G^{t}\) as independent categorical distributions per node \(\tilde{\mathbf{x}}_i^{0}\) and per edge \(\tilde{\mathbf{e}}_{ij}^{0}\).
neurips_2024_oral_21,3,"p_{\theta}(v^{t-1}\mid G^{t})=\sum_{\tilde{v}\in\tilde{x}_{v}}q(v^{t-1 }\mid\tilde{v},G^{t})p_{\theta}(\tilde{v}\mid G^{t})",,"p_{\theta}(v^{t-1}\mid G^{t})=\sum_{\tilde{v}} q(v^{t-1}\mid v^t,\tilde{v}) p_{\theta}(\tilde{v}\mid G^{t})",The reverse distribution for a node at time \(t-1\) given the graph at time \(t\) is obtained by marginalizing over predicted initial node types \(\tilde{v}\).
neurips_2024_oral_21,4,L=E_{q(G^{0})}E_{q(G^{t}|G^{0})}[-E_{x\in G^{0}}\log p_{\theta}(x\mid G^{t})],,"L=E_{t\simU\{1,T\}, G^0\sim q(G^0), G^t\sim q(G^t|G^0)}\left[\sum_{v\in V}-\log p_\theta(\tilde{v}=v^0\mid G^t)+\sum_{e\in E}-\log p_\theta(\tilde{e}=e^0\mid G^t)\right]",The loss function \(\mathcal{L}\) minimizes the expected negative log-likelihood of true node and edge types over timesteps and data distribution.
neurips_2024_oral_21,5,Q_{G}=Q_{V}&1_{N}^{\prime}\otimesQ_{VE}\\1_{N}\otimesQ_{EV}&1_{N\times N}\otimesQ_{ E},"where \(\otimes\) denotes the Kronecker product, \(\mathbf{1}_{N}\), \(\mathbf{1}_{N}^{\prime}\), and \(\mathbf{1}_{N\times N}\) represent the column vector, row vector, and matrix with all 1 elements, respectively","q(X_G^t\midX_G^{t-1})=\prod_{i=1}^{N}Cat\left(X_{G,i}^{t};p=X_{G,i}^{t-1}Q_G^{t}\right)","The diffusion process for the joint graph representation, where each graph token is independently diffused using the joint transition matrix \(\mathbf{Q}_G\)."
neurips_2024_oral_21,6,q(X_{G}^{t}\midX_{G}^{t-1})=\widetilde{Cat}(X_{G}^{t};\tilde{p}=X_{G}^{t-1}Q_{G}^{t} ),"where \(\tilde{\mathbf{p}}\) is the unnormalized probability and \(\widetilde{\mathrm{Cat}}\) denotes categorical sampling: The first \(F_{V}\) columns of \(\tilde{\mathbf{p}}\) are normalized to sample \(\mathbf{X}_{V}^{t}\), while the remaining \(N\cdot E\) dimensions are reshaped and normalized to sample edges \(\mathbf{X}_{E}^{t}\)",q(X_G^t\midX_G^{t-1})=Cat(X_G^t;p=X_G^{t-1}Q_G^t),where \(\mathrm{Cat}(\mathbf{X}_G; \mathbf{p})\) denotes sampling the graph tokens from a categorical distribution with probability \(\mathbf{p}\).
neurips_2024_oral_21,7,"\hat{p}_{\theta}(G^{t-1}\mid G^{t},C)=\log p_{\theta}(G^{t-1}\mid G^{ t})+s(\log p_{\theta}(G^{t-1}\mid G^{t},C)-\log p_{\theta}(G^{t-1}\mid G^{t}))",where \(s\) denotes the scale of conditional guidance,"\log\hat{p}_{\theta}(G^{t-1}\mid G^{t},C)=(1+w)\log p_{\theta}(G^{t-1}\mid G^{t},C)-w\log p_{\theta}(G^{t-1}\mid G^{t})",The log probability for the guided reverse process is a linear combination of the conditional and unconditional log probabilities.
neurips_2024_oral_21,8,"AdaLN(h,c)=\gamma_{\theta}(c)\odot\frac{h-\mu(h)}{\sigma(h )}+\beta_{\theta}(c)",where \(\mu(\cdot)\) and \(\sigma(\cdot)\) are mean and variance values,"AdaLN(h,c)=\gamma(c)\odot\frac{h-\mu_{h}}{\sigma_{h}}+\beta(c)","where \(\mu_{\mathbf{h}}\) and \(\sigma_{\mathbf{h}}\) are the mean and standard deviation of the elements of \(\mathbf{h}\), and \(\gamma(\mathbf{c}) = \mathrm{Linear}_{\gamma}(\mathbf{c})\) and \(\beta(\mathbf{c}) = \mathrm{Linear}_{\beta}(\mathbf{c})\) are linear projections of the condition embedding \(\mathbf{c}\)."
neurips_2024_oral_21,9,"AdaLN_{gate}(h,c)=\alpha_{\theta}(c)\odotAdaLN(h,c)",,"AdaLN_{gate}(h,c)=h+\sigma(g_{\theta}(c))\odot\left(\gamma_{\theta}(c)\odot\frac{h-\mu(h)}{\sigma(h)}+\beta_{\theta}(c)\right)","where \(\sigma\) is the sigmoid function, and \(\mathbf{g}_{\theta}\) is a neural network module in \(f_{\theta}(\cdot)\) that produces a gate vector of the same dimension as \(\mathbf{h}\)."
neurips_2024_oral_21,10,"\tilde{X}_{G}^{0}=AdaLN(MLP(H),c)",,"\tilde{X}_{V}^{0}=softmax\left(O_{V}\right),\quad\tilde{X}_{E}^{0}=softmax\left(reshape\left(O_{E}, (N, N, F_E)\right)\right)\quadwhere\quad\left[O_{V},O_{E}\right]=MLP\left(H\right)","The final MLP processes the hidden states to produce logits for nodes and edges, which are then normalized by softmax to yield the predicted node and edge probabilities at timestep zero."
neurips_2024_oral_22,1,"dx_{\sigma}\,=\,-\sigma\nabla_{x_{\sigma}}\!\log p (x_{\sigma};\sigma)\;d\sigma",,\frac{dx}{dt}=-\dot{\sigma}(t)\sigma(t)\nabla_{x}\log p(x;\sigma(t)),The probability flow ODE that evolves samples backward from high to low noise levels during denoising diffusion.
neurips_2024_oral_22,2,"\theta\,=\,\arg\min_{\theta}E_{y\sim p_{data},\sigma\sim p_{train},n\simN(0,\sigma^{2}I)}\|D_{\theta}(y+n;\sigma)-y\|_{2}^ {2}",where \(p_{\text{train}}\) controls the noise level distribution during training,\nabla_{x}\log p(x;\sigma)\approx D_{\theta}(x;\sigma),The neural network \(D_{\theta}\) approximates the score function and is trained for denoising.
neurips_2024_oral_22,3,"D_{w}(x;\sigma,c)\,=\,wD_{1}(x;\sigma,c)+( 1-w)D_{0}(x;\sigma,c)",,"D_{guided}\,=\,(1+w)\,D_{1}(x;\sigma,c)\,-\,w\,D_{0}(x;\sigma,c)",The guided denoiser is computed by extrapolating between the outputs of the two denoiser networks \(D_0\) and \(D_1\) with a factor \(w\).
neurips_2024_oral_22,4,"D_{w}(x;\sigma,c)\approxx+\sigma^{2}\nabla_{x}\log\underbrace{(p_ {0}(x|c;\sigma)[\frac{p_{1}(x|c;\sigma)}{p_{0}(x|c;\sigma)}]^{w})}_{\propto:\p_{w}(x|c;\sigma)}",,"\nabla_{x}\log p_{w}(x;\sigma,c)=(1-w)\nabla_{x}\log p_{0}(x;\sigma,c)+w\nabla_{x}\log p_{1}(x;\sigma,c)",The score for the guided model is a weighted sum of the scores of the two denoiser networks.
neurips_2024_oral_22,5,\nabla_{x}\log p_{w}(x|c;\sigma)=\nabla_{x}\log p_{1}(x|c;\sigma)+(w-1)\nabla_{x}\log\frac{p_{1}(x|c;\sigma)}{p_{0}(x|c;\sigma)},,\nabla_{x}\log p_{w}(x\midc;\sigma)=(1-w)\nabla_{x}\log p_{0}(x\midc;\sigma)+w\nabla_{x}\log p_{1}(x\midc;\sigma),The guided score function decomposes into a weighted sum of the base score functions for distributions \(p_0\) and \(p_1\).
neurips_2024_oral_23,1,"|Cov(f(X),Y\mid X\in S)|\leq\alpha",,"\left|E\left[ (Y-f(X))\cdot1\{X\in S\}\right]\right|\leq\alpha,\quad\forall f\inF","The set $S$ is $\alpha$-indistinguishable if, for every predictor $f$ in $\mathcal{F}$, the absolute value of the expectation of the residual $(Y - f(X))$ restricted to $S$ is at most $\alpha$."
neurips_2024_oral_23,2,"\gamma^{*},\beta^{*}\in\operatorname*{arg\,min}_{\gamma\inR^{K},\beta\inR^{K}}\;E[(Y-\gamma_{J(X)}+\beta_{J(X)}\hat{Y})^{2}]",,"\gamma_k^*=E_k[Y]-\beta_k^*E_k[\hat{Y}],\quad\beta_k^*=\frac{Cov_k(Y,\hat{Y})}{Var_k(\hat{Y})}\quad\forall k\in [K]","The coefficients $\gamma_k^*$ and $\beta_k^*$ are the intercept and slope, respectively, of the best linear predictor of $Y$ given $\hat{Y}$ within each indistinguishable subset $S_k$."
neurips_2024_oral_23,3,"E_{k}[(Y-\gamma_{k}^{*}-\beta_{k}^{*}\hat{Y})^{2} ]+4Cov_{k}(Y,\hat{Y})^{2}\leqE_{k}[(Y-f(X) )^{2}]+2\alpha",,"E[(Y-f(X))^{2}\mid X\in S_{k}]\geq\min_{\gamma_{k},\beta_{k}}E[(Y-\gamma_{k}-\beta_{k}\hat{Y})^{2}\mid X\in S_{k}]-2\alpha","For any model \(f \in \mathcal{F}\) and any subset \(S_k\) of the multicalibrated partition, the conditional mean squared error of \(f\) given \(X \in S_k\) is at least the minimal conditional mean squared error achievable by an affine function of \(\hat{Y}\) in \(S_k\) minus \(2\alpha\)."
neurips_2024_oral_23,4,E_{S}[(Y-g(H))^{2}]\leqE_{S}[(Y-\gamma-\beta g(H))^{2}]+\eta,,"\inf_{\beta,\gamma}E_{S}\left[\left(Y-\gamma-\beta g(H)\right)^{2}\right]\leq\eta",The function g satisfies that the infimum over β and γ of the expected squared error of predicting Y with a linear function of g(H) in the subset S is at most η.
neurips_2024_oral_23,5,"E_{S}[(Y-g(H))^{2}]+4Cov_{S}(Y,g(H))^{2}\leqE_ {S}[(Y-f(X))^{2}]+2\alpha+\eta",,"E_{S}[(Y-g(H))^{2}]+4Cov_{S}(Y, g(H))^{2}\leqE_{S}[(Y-f(X))^{2}]+2\alpha+\eta",The squared error of the predictor \(g(H)\) plus four times the squared covariance between \(Y\) and \(g(H)\) in subset \(S\) is bounded by the squared error of any model \(f \in \mathcal{F}\) plus \(2\alpha\) and \(\eta\).
neurips_2024_oral_23,6,"|Cov_{k}(Y,\hat{Y})|\leq\sqrt{\frac{\alpha}{2}}",,"|Cov_{k}(Y,\hat{Y})|\leq\alpha",The absolute value of the covariance between the outcome and the expert prediction within each subset \(S_k\) is bounded by \(\alpha\).
neurips_2024_oral_24,1,y^{\prime}=y+\Delta y=W_{0}x+BAx,where \(y\in R\)d is the output and the \(x\in R\)k denotes the input,h=W_0 x+B A x,"Forward computation of a layer in LoRA, with \( W_0 \) as frozen weights and \( A \), \( B \) as low-rank adaptation matrices."
neurips_2024_oral_24,2,"W&=\,W_{0}+\Delta\,W\\&=\,W_{0}+\sum_{i=1}^{N}\omega_{i}\cdot B_{i}A",,y^{\prime}=W_{0} x+\sum_{i=1}^{n} B_i A x,"where \( y^{\prime} \in \mathbb{R}^d \) is the output, \( x \in \mathbb{R}^k \) is the input, \( A \in \mathbb{R}^{r \times k} \) is the shared low-rank matrix, and \( B_i \in \mathbb{R}^{d \times r} \) for \( i=1,\dots,n \) are the distinct matrices for \( n \) heads."
neurips_2024_oral_24,3,y=W_{0}x+\sum_{i=1}^{N}\omega_{i}E_{i}Ax\quad(MoE),"where \(N\) denotes the number of experts, i",y=W_{0}x+\sum_{i=1}^{N} g_i(x)\cdot (B_i A x),"The output \( y \) is computed as the sum of the pretrained weight matrix applied to the input \( x \) and a weighted combination of the outputs from multiple LoRA experts, where the weights \( g_i(x) \) are determined by a gating mechanism for each input."
neurips_2024_oral_24,4,\omega_{i}=softmax(W_{g}^{T}x)\quad(Router),,\omega=softmax(W_g^\top x),"where \(\omega \in \mathbb{R}^N\) is the vector of gating scores, \(W_g \in \mathbb{R}^{r \times N}\) is the router weight matrix, and \(x \in \mathbb{R}^r\) is the intermediate token representation."
neurips_2024_oral_25,1,"{l}X=Y\beta_{Y\to X}+G^{\intercal}\gamma_{X}+\varepsilon_{X},\\Y=X\beta_{X\to Y}+G^{\intercal}\gamma_{Y}+\varepsilon_{Y}",where \(\beta_{Y\to X}\) is the causal effect of \(Y\) on \(X\) and \(\beta_{X\to Y}\) is that of \(X\) on \(Y\),"X_i &=\alpha Y_i+\gamma^{\intercal}G_i+\varepsilon_{X_i},\\Y_i &=\beta X_i+\delta^{\intercal}G_i+\varepsilon_{Y_i}","The bi-directional MR model equations: for each sample \(i\), phenotype \(X_i\) is a linear function of \(Y_i\) and genetic variants \(\mathbf{G}_i\), while phenotype \(Y_i\) is a linear function of \(X_i\) and genetic variants \(\mathbf{G}_i\)."
neurips_2024_oral_25,2,"{l}X=(G^{\intercal}\gamma_{X}+G ^{\intercal}\gamma_{Y}\beta_{Y\to X}+\varepsilon_{X}+\varepsilon_{Y}\beta_{Y\to X})\Delta,\\Y=(G^{\intercal}\gamma_{X}\beta_{X\to Y}+G^{\intercal}\gamma_{Y}+\varepsilon_{X}\beta_{X\to Y}+\varepsilon_{Y})\Delta",,"{l} X=G^{\intercal}\Delta (\gamma_{X}+\beta_{Y\to X}\gamma_{Y})+\Delta (\varepsilon_{X}+\beta_{Y\to X}\varepsilon_{Y}),\\Y=G^{\intercal}\Delta (\gamma_{Y}+\beta_{X\to Y}\gamma_{X})+\Delta (\varepsilon_{Y}+\beta_{X\to Y}\varepsilon_{X})",The non-recursive formulations of \(X\) and \(Y\) derived from Equation (1).
neurips_2024_oral_25,3,\hat{\beta}_{X\to Y}=[X^{\intercal}PX]^{-1}X^{\intercal}PY=\beta_{X\to Y},,\beta_{X\to Y}=\left(E\left[ X (G_{V}^{X\to Y})^{\intercal}\right]\left(E\left[G_{V}^{X\to Y} (G_{V}^{X\to Y})^{\intercal}\right]\right)^{-1}E\left[G_{V}^{X\to Y} X\right]\right)^{-1}E\left[ X (G_{V}^{X\to Y})^{\intercal}\right]\left(E\left[G_{V}^{X\to Y} (G_{V}^{X\to Y})^{\intercal}\right]\right)^{-1}E\left[G_{V}^{X\to Y} Y\right],The causal effect of X on Y is identified by the TSLS estimator using the valid instrumental variables for the direction X→Y.
neurips_2024_oral_25,4,\hat{\beta}_{X\to Y}=[X^{\intercal}\tilde{P}X]^{-1}X^{\intercal}\tilde{P}Y=\beta_{X\to Y}+\underbrace{[X^{\intercal}\tilde{P}X ]^{-1}X^{\intercal}\tilde{P}(G^{\intercal}\gamma_{Y}+\varepsilon_{Y})}_{\beta_{bias}},,\hat{\beta}_{X\to Y}=\left[ X^{\intercal}P_{I} X\right]^{-1} X^{\intercal}P_{I} Y,the causal effect of \(X\) on \(Y\) estimated by TSLS when using the invalid IV set \(\mathbf{G}_{\mathcal{I}}^{X\to Y}\).
neurips_2024_oral_25,5,"corr(Y-X\omega_{\{G_{3}\}},G_{1})=0,\qquadcorr(Y-X\omega_{\{ G_{1}\}},G_{3})=0","where \(\mathrm{corr}(\cdot)\) denotes the Pearson's correlation coefficient between two random variables, and \(\omega_{\{G_{i}\}}=\mathrm{TSLS}(X,Y,\{G_{i}\})\) with \(i\in\{1,3\}\)","Cov(G_j, Y)=\beta_{X\to Y}Cov(G_j, X)\quadfor all\quad G_j\inG_{V}^{X\to Y}",The covariance condition that each valid IV for the causal effect of \(X\) on \(Y\) satisfies.
neurips_2024_oral_25,6,"corr(Y-X\omega_{\{G_{4},G_{5}\}},G_{2})\neq 0,corr(Y-X\omega_{\{ G_{2},G_{5}\}},G_{4})\neq 0,corr(Y-X\omega_{\{G_{2},G_{4}\}},G_{5})\neq 0","where \(\omega_{\{G_{i},G_{j}\}}=\mathrm{TSLS}(X,Y,\{G_{i},G_{j}\})\) with \(i\neq j\) and \(i,j\in\{2,4,5\}\)","corr(Y-X\omega_{\{G_{4}\}}, G_{2})\neq 0,\qquadcorr(Y-X\omega_{\{G_{2}\}}, G_{4})\neq 0","For the invalid IVs \(G_2\) and \(G_4\), the correlations analogous to those in Observation 1 are non-zero."
neurips_2024_oral_25,7,"PR_{(X,Y\,|\,G)}:=Y-X\omega_{G}",,r_{G}=Y-X\omega_{G},The pseudo-residual \( r_{\mathbb{G}} \) is defined as the difference between the outcome \( Y \) and the exposure \( X \) multiplied by the TSLS estimate of the causal effect of \( X \) on \( Y \) using the genetic variant set \( \mathbb{G} \).
neurips_2024_oral_25,8,"corr(PR_{\langle X,Y\,|\,\{G_{j}\}\rangle},G_{j })\neq 0",,"PR_{(X,Y\,|\,G)}:=Y-X\omega_{G}","The pseudo-residual for the pair (X, Y) given a set of genetic variants \(\mathbb{G}\), where \(\omega_{\mathbb{G}}\) is the TSLS estimate using \(\mathbb{G}\)."
neurips_2024_oral_25,9,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=0",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{1})\neq 0",the correlation between the pseudo-residual for the set containing only \(G_{1}\) and \(G_{1}\) is non-zero.
neurips_2024_oral_25,10,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle}),G_{ 2})=0",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2})=0",The correlation between the pseudo-residual using IV set \(\{G_1\}\) and genetic variant \(G_2\) is zero.
neurips_2024_oral_25,11,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=\frac{\gamma_{Y,1}\gamma_{X,2}-\gamma_{Y,2}\gamma_{X,1}}{\beta_{Y\to X }\gamma_{Y,2}+\gamma_{X,2}}",,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1})=0",The correlation between the pseudo-residual for the set \(\{G_2\}\) and \(G_1\) is zero.
neurips_2024_oral_25,12,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2} )=\frac{\gamma_{Y,2}\gamma_{X,1}-\gamma_{Y,1}\gamma_{X,2}}{\beta_{Y\to X }\gamma_{Y,1}+\gamma_{X,1}}",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2} )=\frac{\gamma_{Y,2}\gamma_{X,1}-\gamma_{Y,1}\gamma_{X,2}}{\beta_{Y\to X }\gamma_{Y,1}+\gamma_{X,1}}",the correlation between the pseudo-residual (using TSLS with \{G_1\}) and G_2
neurips_2024_oral_25,13,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=0,\qquadcorr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle },G_{2})=0",,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1})=0\quadand\quadcorr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2})=0","The correlations of the pseudo-residuals with the genetic variants are zero under the condition that \(\gamma_{X,1}\gamma_{Y,2}=\gamma_{Y,1}\gamma_{X,2}\)."
neurips_2024_oral_25,14,"corr(PR_{(X,Y\midG\setminus G_{j})},G_{j})=0",,"corr\left(PR_{\langle X,Y\,|\,G\setminus\{G_j\}\rangle},G_j\right)=0,\quad\forall G_j\inG","For each genetic variant \(G_j\) in the set \(\mathbb{G}\), the correlation between the pseudo-residual computed using the set \(\mathbb{G}\) excluding \(G_j\) and \(G_j\) itself is zero."
neurips_2024_oral_26,1,"s_{real}(x_{t},t)=\nabla_{x_{t}}\log p_{real,t}(x_{t})=-\frac{x_ {t}-\alpha_{t}\mu_{real}(x_{t},t)}{\sigma_{t}^{2}}",,"s_t(x_t)=\nabla_{x_t}\log p_{real,t}(x_t)","The score function of the diffused distribution at timestep t, defined as the gradient of the log probability density."
neurips_2024_oral_26,2,"\nablaL_{BMD}=E_{t}(\nabla_{\theta}KL( p_{fake,t}\|p_{real,t}))=-E_{t}(\int(s_{real}(F(G_{\theta}(z),t),t)-s_{fake}(F(G_{\theta}(z),t),t) )\frac{dG_{\theta}(z)}{d\theta}\,dz)","where \(z\sim\mathcal{N}(0,\mathbf{I})\) is a random Gaussian noise input, \(\theta\) are the generator parameters, \(F\) is the forward diffusion process (i","\nabla_{\theta}L=E_{t}\left[\sigma_t^2\left( s_{real}(x_t, t)-s_{fake}(x_t, t)\right)\nabla_{\theta} x_t\right]",The gradient of the DMD loss with respect to generator parameters $\theta$ is the expectation over timestep $t$ of the difference between the real and fake score functions scaled by $\sigma_t^2$ and multiplied by the gradient of the diffused sample $x_t$ with respect to $\theta$.
neurips_2024_oral_26,3,"L_{reg}=E_{(z,y)}d(G_{\theta}(z),y)","where \(d\) is a distance function, such as LPIPS [54] in their implementation","L_{reg}=E_{z\simN(0,I)}\left[\| G_{\theta}(z)-y\|^2\right]",The regression loss \(\mathcal{L}_{\text{reg}}\) is the expected squared distance between the generator output \(G_{\theta}(z)\) and the teacher diffusion model's output \(y\) given the same noise input \(z\).
neurips_2024_oral_26,4,"L_{GAN}=E_{x\sim p_{noise},t\sim[0,T]}[\log D (F(x,t))]+E_{z\sim p_{noise},t\sim[0,T]}[-\log(D(F(G_{\theta}(z ),t)))]","where \(D\) is the discriminator, and \(F\) is the forward diffusion process (i","\max_{D}E_{x\sim p_{real}}\left[\log D(x)\right]+E_{z\simN(0,I)}\left[\log (1-D(G_{\theta}(z)))\right]",The discriminator $D$ is trained to maximize the expected log-likelihood for real images and the log-likelihood of the complement for generated samples.
neurips_2024_oral_27,1,"\langle S,A,O,I,T,R,\gamma,\Theta\rangle","where \(S\), \(A\) and \(O\) are the sets of states, actions, and observations, respectively","\langleS,A,\Omega,T,O,R,\gamma,\rho_0,\Xi\rangle","The tuple defining an Underspecified POMDP (UPOMDP) includes the state space, action space, observation space, transition function, observation function, reward function, discount factor, initial state distribution, and the set of environment parameters."
neurips_2024_oral_27,2,"PVL^{\theta}(\pi)=\frac{1}{T}\sum_{t=0}^{T}\max(\sum_{k=t}^{T}(\gamma\lambda)^{k-t}\delta_{k}^{\theta},0)","where \(\lambda\) and \(T\) are the GAE discount factor and MDP horizon, respectively","PVL=\max(0,\hat{A})",The Positive Value Loss (PVL) approximates regret as the maximum of zero and the Generalized Advantage Estimation (GAE) advantage \(\hat{A}\).
neurips_2024_oral_27,3,"P(\Gamma\mid\lambda_{\Gamma})=\prod_{j=1}^{J}\sum_{k=1}^{K}\alpha_{k}N (x_{j}\mid\mu_{k},\Sigma_{k})",where \(x_{j}\) is a state-action pair sample from \(\Gamma\),"p(\Gamma\mid\lambda_{\Gamma})=\prod_{x\in\Gamma}\sum_{k=1}^{K}\alpha_{k}N(x\mid\mu_{k},\Sigma_{k})",The joint likelihood of the state-action pairs in buffer $\Gamma$ given the Gaussian mixture model parameters $\lambda_{\Gamma}$.
neurips_2024_oral_27,4,\textsc{Novelty}_{l_{\theta}}=-\frac{1}{|X_{\theta}|}\logL(X_{\theta}\mid\lambda_{\Gamma})=-\frac{1}{|X_{\theta}|}\sum_{t=1}^{T}\log p(x_{t}\mid\lambda_{\Gamma}),where \(x_{t}\) is a sample state-action pair from \(X_{\theta}\),"Novelty(l_{\theta})=-\frac{1}{|X_{\theta}|}\sum_{x\in X_{\theta}}\log\left(\sum_{k=1}^{K}\alpha_{k}N(x\mid\mu_{k},\Sigma_{k})\right)",The novelty of candidate level \( l_{\theta} \) is the average negative log-likelihood of state-action pairs in trajectory \( X_{\theta} \) under the Gaussian mixture model \( \lambda_{\Gamma} \).
neurips_2024_oral_27,5,P_{S}=\frac{h(S_{i})^{\beta}}{\sum_{j}h(S_{j})^{\beta}},where \(h\) is a prioritization function (e,P_{S}(l_{i})=\frac{\exp(\textsc{Regret}_{l_{i}}+\beta\cdot\textsc{Novelty}_{l_{i}})}{\sum_{l_{j}\inB}\exp(\textsc{Regret}_{l_{j}}+\beta\cdot\textsc{Novelty}_{l_{j}})},"The replay probability \( P_S(l_i) \) for level \( l_i \) is computed by applying softmax normalization to a weighted combination of its regret and novelty scores across the level buffer \( \mathcal{B} \), with \( \beta \) controlling the trade-off between objectives."
neurips_2024_oral_27,6,P_{replay}=\alpha\cdot P_{N}+(1-\alpha)\cdot P_{R},"where \(P_{N}\) and \(P_{R}\) are the novelty-prioritized probability and regret-prioritized probability respectively, and \(\alpha\) allows us to adjust the weightage of each probability",S_i=\textsc{Regret}_i\cdot\textsc{Novelty}_i,The composite score for level \(i\) is defined as the product of its regret and novelty scores.
neurips_2024_oral_31,1,y^{*}=y-f_{\theta}(y)\nabla f_{\theta}(y),"where, by definition, \(f_{\theta}(\mathbf{y})\) is the distance between \(\mathbf{y}\) and \(\mathbf{y}^{*}\), and the gradient \(\nabla f_{\theta}(\mathbf{y})\) points in the opposite direction of the shortest path from \(\mathbf{y}\) to the surface of the object and is unit-norm",y^{*}=y-f_{\theta}(y)\frac{\nabla f_{\theta}(y)}{\|\nabla f_{\theta}(y)\|},The closest point \(\mathbf{y}^{*}\) on the object surface is computed by displacing the query point \(\mathbf{y}\) by the signed distance \(f_{\theta}(\mathbf{y})\) along the normalized gradient of the SDF.
neurips_2024_oral_31,2,c^{j}_{ik}=n_{ik}-d^{j}_{ik}T_{j}\Big{(}\nabla f_{\theta_{j}}(T^{-1}_{j}(n_{ik}))\Big{)},,c^{j}_{ik}=T_j\left(T^{-1}_{j}(n_{ik})-f_{\theta_j}(T^{-1}_{j}(n_{ik}))\nabla f_{\theta_j}(T^{-1}_{j}(n_{ik}))\right),"The closest point \(\mathbf{c}^{j}_{ik}\) on object \(O_j\)'s surface to node \(\mathbf{n}_{ik}\) is computed by transforming the node to \(O_j\)'s reference frame, applying the SDF-based closest point formula, and transforming back to simulation space."
neurips_2024_oral_34,1,"x_{0}\simN(0,I)\quadand\quadx_{t+1}=a_{t}x_{t}+\mu(x_{t},t)+\sigma_{t}\epsilon_{t}\quadfor\quad t=0,1,\dots,T-1","where \(\epsilon_{t}\sim\mathcal{N}(0,I)\) and \(\mu(\mathbf{x},t)\) is the output of a neural network","x_t=\sqrt{1-\beta_t}x_{t-1}+\sqrt{\beta_t}\epsilon_t,\quad\epsilon_t\simN(0,I)","This equation defines the forward diffusion process, where each step \(t\) corrupts the sample by adding Gaussian noise scaled by the variance schedule \(\beta_t\)."
neurips_2024_oral_34,2,"q(x)=\frac{1}{Z}\exp(-E(x)/\tau),\quad E:X\toR","where \(\tau>0\) is temperature, \(\mathcal{X}\) is the compact domain of data, and \(Z=\int_{\mathcal{X}}\exp(-E(\mathbf{x})/\tau)d\mathbf{x}<\infty\) is the normalization constant",q(x)=\frac{1}{Z}\exp(-E(x)),where \(E(\mathbf{x})\) is the energy function and \(Z\) is the partition function.
neurips_2024_oral_34,3,\min_{\pi\in\Pi}KL(\pi(x) || p(x))=\max_{\pi\in\Pi}E _{\pi}[\log p(x)]+H(\pi(x)),"where \(\Pi\) is the set of feasible \(\pi(\mathbf{x})\)'s, and \(\mathcal{H}(\pi)=-\int\pi(\mathbf{x})\log\pi(\mathbf{x})d\mathbf{x}\) is the differential entropy",KL(\pi\| p)=\int\pi(x)\log\frac{\pi(x)}{p(x)} dx,The reverse Kullback-Leibler divergence between the diffusion model distribution \(\pi(\mathbf{x})\) and the data distribution \(p(\mathbf{x})\).
neurips_2024_oral_34,4,\min_{\pi\in\Pi}KL(\pi(x) || q(x))\quadand\quad\min_{ q\inQ}KL(p(x) || q(x)),where \(\mathcal{Q}\) is the feasible set of EBMs,\min_{q} KL(p(x) || q(x)),minimizing the KL divergence from the data distribution \( p(\mathbf{x}) \) to the energy-based model \( q(\mathbf{x}) \)
neurips_2024_oral_34,5,\min_{q\inQ}\max_{\pi\in\Pi}KL(p(x) || q(x))-KL(\pi(x) || q(x)),,\min_{q\inQ}\max_{\pi\in\Pi}\left[E_{x\sim p} [E(x)]-E_{x\sim\pi} [E(x)]\right],"where $E(\mathbf{x})$ is the energy function of the EBM $q$, and $\pi$ is the diffusion model policy."
neurips_2024_oral_34,6,KL(\pi_{\phi}(x_{T}) || q_{\theta}(x_{T}))\leq KL(\pi_{\phi}(x_{0:T}) || q_{\theta}(x_{T})\tilde{q}(x_{0:T-1}|x_{T})),,KL(\pi_{\phi}(x_T)\| q_{\theta}(x_T))\leq KL(\pi_{\phi}(x_{0:T})\| r_{\theta}(x_{0:T})),where \( r_{\theta}(\mathbf{x}_{0:T}) \) is a joint distribution over the trajectory with marginal distribution \( r_{\theta}(\mathbf{x}_T) = q_{\theta}(\mathbf{x}_T) \).
neurips_2024_oral_34,7,"\tilde{q}(x_{0:T-1}|x_{T})=\prod_{t=0}^{T-1}\tilde{q}(x_{t}|x_{t+1}), where \tilde{q}(x_{t}|x_{t+1})=N(x_{t+1},s_{t}^{2}I),\quad s_{t}>0",,"\tilde{q}(x_{0:T-1}|x_{T})=\prod_{t=0}^{T-1}\tilde{q}(x_{t}|x_{t+1}),\quadwhere\quad\tilde{q}(x_{t}|x_{t+1})=N(x_{t};\mu_{t}(x_{t+1}),\sigma_{t}^2I)",The auxiliary distribution \(\tilde{q}\) is factorized into conditional Gaussians with mean \(\boldsymbol{\mu}_{t}(\mathbf{x}_{t+1})\) and variance \(\sigma_{t}^2 \mathbf{I}\).
neurips_2024_oral_34,8,\min_{\phi}\mathop{E}_{\pi_{\phi}(x_{0:T})}[E_{\theta}(x_{T})+\tau\sum_{t=0}^{T-1}\log\pi_{\phi}(x_{t+1}|x _{t})+\tau\sum_{t=0}^{T-1}\frac{1}{2s_{t}^{2}} || x_{t+1}-x_ {t} || ^{2}],,"\min_{\phi}E_{\pi_{\phi}(x_{0:T})}\left[ E_{\theta}(x_{T})+\sum_{t=0}^{T-1}\left(\frac{\tau}{2s_{t}^{2}}\|x_{t}-x_{t+1}\|^{2}-\frac{\tau}{2\sigma_{t}^{2}}\|x_{t+1}-a_{t}x_{t}-\mu(x_{t}, t)\|^{2}\right)\right]","The objective function for updating the diffusion model parameters \(\phi\) in DxDP, which includes the energy at the final state and per-step transition costs."
neurips_2024_oral_34,9,V_{\psi}^{t}(x_{t})=E_{\pi}[E_{\theta}(x_{T})+\tau\sum_{t^{\prime}=t}^{T-1}\log\pi_{\phi}(x_{t^{\prime}+1}| x_{t^{\prime}})+\sum_{t^{\prime}=t}^{T-1}\frac{\tau}{2s_{t^{\prime}}^{2}} || x_{t^{\prime}+1}-x_{t^{\prime}} || ^{2}\bigg{|}x_{t} ],,"V^{t}(x_{t})=E_{x_{t+1}\sim\pi_{\phi}(\cdot|x_{t})}\left[\tau\log\pi_{\phi}(x_{t+1}|x_{t})+\frac{\tau}{2s_{t}^{2}}\|x_{t+1}-x_{t}\|^{2}+V^{t+1}(x_{t+1})\right]\quadfor\quad t=0,1,\dots,T-1",The value function \(V^{t}(\mathbf{x}_{t})\) represents the expected cumulative cost from time \(t\) to \(T\) starting at state \(\mathbf{x}_{t}\) and following policy \(\pi_{\phi}\).
neurips_2024_oral_34,10,"\min_{\psi}E_{x_{t},x_{t+1}\sim\pi}[(sg[V_{\psi}^{t+1}(x_{t+1})]+\tau\log\pi_{\phi}(x_{t+1}|x _{t})+\frac{\tau}{2s_{t}^{2}} || x_{t}-x_{t+1} || ^{2}-V_{\psi}^ {t}(x_{t}))^{2}]",where \(\text{sg}[\cdot]\) denotes a stop-gradient operator indicating that gradient is not computed for the term,V_{\psi}^{t}(x_{t})=E_{x_{t+1}\sim\pi_{\phi}(\cdot|x_{t})\left[\tau\log\pi_{\phi}(x_{t+1}|x_{t})+\frac{\tau}{2s_{t}^{2}}\|x_{t+1}-x_{t}\|^{2}+V_{\psi}^{t+1}(x_{t+1})\right],"The Bellman equation for the value function at time step t, which decomposes the expected cumulative cost into the immediate cost and the value at the next state."
neurips_2024_oral_34,11,\min_{\phi}E_{\pi_{\phi}(x_{t+1}|x_{t})}[V_{\psi}^{t+1}(x_{t+1})+\tau\log\pi_{\phi}(x_{t+1}|x _{t})+\frac{\tau}{2s_{t}^{2}} || x_{t}-x_{t+1} || ^{2}\bigg{|}x_{t}],,\min_{\phi}\mathop{E}_{x_{0:T}\sim\pi_{\phi}}\left[\sum_{t=0}^{T-1}\left( V_{\psi}^{t+1}(x_{t+1})+\frac{\tau}{2s_{t}^{2}}\|x_{t+1}-x_{t}\|^{2}+\tau\log\pi_{\phi}(x_{t+1}|x_{t})\right)\right],"The policy improvement step minimizes the expected sum of the next-state value function, the velocity regularization term, and the conditional log probability scaled by temperature over the trajectory."
neurips_2024_oral_34,12,"\min_{\psi}E_{x_{t},x_{t+1}\sim\pi}[(sg[V_{\psi}(x_{t+1})]+R(t)-V_{\psi}(x_{t}))^{2}]",,"(s_{t}^{*})^{2}=E_{x_{t},x_{t+1}\sim\pi}[ || x_{t}-x_{t+1} || ^{2}]/D","The square of the optimal velocity regularization parameter \(s_t^{*}\) is the expected squared Euclidean distance between consecutive states \(\mathbf{x}_t\) and \(\mathbf{x}_{t+1}\) under the diffusion model, divided by the dimension \(D\)."
neurips_2024_oral_35,1,"varrowCrossAttention(Q=\{v\},K=\{p_{i}^{v}\}_{i=1}^{m}+\{v\},V=\{ p_{i}^{v}\}_{i=1}^{m}+\{v\})","Where \(v\) denotes a 3D voxel feature, and \(p_{i}^{v}\) denotes its projected 2D pixel feature from view \(i\), which is a concatenation of the RGB feature \(f_{i}^{v}\), the normal feature \(g_{i}^{v}\), and the RGB and normal values \(c_{i}^{v}\) and \(n_{i}^{v}\), respectively",v_{3d}'=\sum_{i=0}^{m}\frac{\exp\left(\frac{ (W_qv_{3d})^\top (W_kt_i) }{\sqrt{d_k} }\right) }{\sum_{j=0}^{m}\exp\left(\frac{ (W_qv_{3d})^\top (W_kt_j) }{\sqrt{d_k} }\right) } (W_vt_i),"The projection-aware cross-attention updates the 3D voxel feature $\mathbf{v}_{3d}$ to $\mathbf{v}_{3d}'$ by attending to tokens $\mathbf{t}_i$, where $\mathbf{t}_0$ is the voxel feature and $\mathbf{t}_i$ (for $i=1,\ldots,m$) are the 2D features from $m$ views."
neurips_2024_oral_35,2,L=\lambda_{1}L_{MSE}^{color}+\lambda_{2 }L_{LPIPS}^{color}+\lambda_{3}L_{MSE}^{normal}+\lambda_{4}L_{LPIPS}^{normal}+\lambda_{5}L_{occ}+\lambda_{6}L _{SDF},"where \(L_{\mathrm{occ}}\) and \(L_{\mathrm{SDF}}\) are MSE losses for occupancy and SDF volumes, and \(\lambda_{i}\) denotes the weight of each loss term",L=\lambda_{sdf}L_{sdf}+\lambda_{rgb}\left(L_{rgb}^{MSE}+L_{rgb}^{perc}\right)+\lambda_{normal}\left(L_{normal}^{MSE}+L_{normal}^{perc}\right),"The total training loss \(\mathcal{L}\) combines the SDF loss \(\mathcal{L}_{\text{sdf}}\) and the rendering losses for RGB and normal images, each rendering loss consisting of an MSE term and a perceptual loss term, balanced by weights \(\lambda_{\text{sdf}}\), \(\lambda_{\text{rgb}}\), and \(\lambda_{\text{normal}}\)."
neurips_2024_oral_40,1,"m_{Ada}(\varepsilon,\delta)=O\Bigg{(}\frac{d\ln(\frac{d}{\varepsilon\gamma})\ln(\frac{1}{\varepsilon\gamma})}{\gamma^{2}\varepsilon}+\frac{\ln(1/\delta)}{\varepsilon}\Bigg{)}",,"m_{Ada}(\varepsilon,\delta)=O\left(\frac{d}{\gamma^2\varepsilon}\log\frac{1}{\delta}\right)","The sample complexity of AdaBoost, where \(d\) is the VC-dimension of the hypothesis class, \(\gamma\) is the edge of the weak learner, \(\varepsilon\) is the target error, and \(\delta\) is the failure probability."
neurips_2024_oral_40,2,L_{D}(f)=O\bigg{(}\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},,L_{D}(f)=O\left(\frac{d\ln(dm)\ln m}{\gamma^{2} m}+\frac{\ln(1/\delta)}{m}\right),"The generalization error of the output classifier \(f\) as a function of the sample size \(m\), VC-dimension \(d\), edge \(\gamma\), and failure probability \(\delta\)."
neurips_2024_oral_40,3,p=O\bigg{(}\frac{\ln m}{\gamma^{2}R}\bigg{)}\qquadand\qquad t=e^{O(dR)}\cdot\ln\frac{\ln m}{\delta\gamma^{2}},,"p=O\left(\frac{\ln m}{\gamma^{2} R}\right)\quadand\quad t=\exp(O(d R))\cdotpolylog(m, 1/\gamma)","The parallel complexity parameters p and t for Algorithm 1, defining the number of rounds and queries per round."
neurips_2024_oral_40,4,L_{D}(A_{R}(S))=O\bigg{(}\frac {d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},,L_{D}(f)=O\bigg(\frac{d\ln m\ln(m/d)+\ln(1/\delta)}{\gamma^{2} m}\bigg),The expected loss of the classifier \(f\) on the distribution \(\mathcal{D}\).
neurips_2024_oral_40,5,p\ln t=O\bigg{(}\frac{d\ln m}{\gamma^{2}}\bigg{)},,p=O\bigg(\frac{\ln m}{\gamma^{2}R}\bigg)\quadand\quad t=e^{O(dR)},The clean tradeoff for the number of rounds \( p \) and the number of parallel queries per round \( t \) ignoring logarithmic factors.
neurips_2024_oral_40,6,"p\geq\frac{4\ln m}{\gamma^{2}R},\qquadand\qquad t\geq e^{16C_{ a}dR}\cdot R\ln\frac{pR}{\delta}",,p\ln t=\Omega\left(\frac{d\ln m}{\gamma^{2}}\right),The lower bound on the product of the number of rounds \(p\) and the logarithm of the number of parallel queries per round \(t\) is \(\Omega(d \ln m / \gamma^2)\).
neurips_2024_oral_40,7,L_{D}(sign(g))\leq C\cdot\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m},,"p\geq\frac{4\ln m}{\gamma^{2}R},\qquadand\qquad t\geq e^{16C_{a}dR}\cdot R\ln\frac{pR}{\delta}",The lower bounds on the number of rounds \( p \) and the number of parallel queries per round \( t \) required for Algorithm 1 to guarantee a margin of at least \( \gamma/8 \) on all training samples with probability at least \( 1-\delta \).
neurips_2024_oral_40,8,|L_{D}(h)-L_{T}(h)|\leq\varepsilon,where \(\mathcal{L}_{T}(h)\coloneqq\mathcal{L}_{\mathrm{Uniform}(T)}(h)\) is the empirical loss of \(h\) on \(T\),L_{D}(sign(g))\leq C\cdot\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m},Generalization error bound for the voting classifier sign(g) when the linear classifier g achieves a margin of at least γ on the training set.
neurips_2024_oral_40,9,"D_{\infty}(D_{r},D_{0})\coloneqq\ln\bigl{(}\sup_{x\inX}D_{ r}(x)/D_{0}(x)\bigr{)}",,|L_{D}(h)-L_{T}(h)|\leq\varepsilon,where \(\mathcal{L}_{T}(h) := \mathcal{L}_{\mathrm{Uniform}(T)}(h)\) is the empirical loss of \(h\) on \(T\).
neurips_2024_oral_40,10,KL(D_{r}\parallel D_{0})\coloneqq\sum_{x\inX}D_{r}(x)\ln\frac{D_{r}(x)}{D_{0}(x)},,"D_{\infty}(D_{r},D_{0})\coloneqq\ln\left(\sup_{x\inX}\frac{D_{r}(x)}{D_{0}(x)}\right)",The max-divergence from distribution \(D_r\) to \(D_0\) is defined as the natural logarithm of the supremum of the ratio \(D_r(x)/D_0(x)\) over \(x \in \mathcal{X}\).
neurips_2024_oral_40,11,\lnE_{P}\big{[}e^{X}\big{]}\geqE_{Q}[X]-KL(Q\parallel P),,KL(D_{r}\parallel D_{0})\coloneqq\sum_{x\inX}D_{r}(x)\ln\frac{D_{r}(x)}{D_{0}(x)},This equation defines the Kullback-Leibler divergence between distributions \(D_r\) and \(D_0\).
neurips_2024_oral_40,12,KL(D\parallel\tilde{D})\leq 4\gamma^{2}R,,KL(D\parallel\tilde{D})\leq\frac{\gamma^{2} n}{8C_{n}}-\frac{2d\ln(2en/d)+\ln(1/\delta)}{C_{n}},Condition on KL divergence between $D$ and $\tilde{D}$ for a sample from $\tilde{D}$ to be a $\gamma/2$-approximation for $D$ with probability at least $1-\delta$.
neurips_2024_oral_40,13,\Pr_{T\sim\tilde{D}^{n}}[T\inG]\geq\exp(-16C_{n}dR),,\Pr_{T\sim\tilde{D}^{n}}\left[T\inG\right]\geq\frac{1}{2},Probability that a sample $\mathbf{T}$ drawn from $\tilde{D}$ is a $\gamma/2$-approximation for $D$.
neurips_2024_oral_40,14,\prod_{r=1}^{R}Z_{kR+r}<\exp(-\gamma^{2}R/2),,\Pr_{T\sim\tilde{D}^{n}}[T\inG]\geq\exp(-16C_{n}dR),The probability that a sample $\mathbf{T}$ drawn from $\tilde{D}^n$ is in the family $\mathcal{G}$ of $\gamma/2$-approximations for distribution $D$ is at least $\exp(-16C_{\mathrm{n}}dR)$.
neurips_2024_oral_41,1,\min_{x\inR^{d}_{c}}\phi(x),where \(\phi:\mathbb{R}^{d}\rightarrow\mathbb{R}\) is a differentiable function bounded from below (e,\min_{w}\phi(w),Minimization of the loss function \(\phi\) with respect to parameters \(\mathbf{w}\).
neurips_2024_oral_41,2,x_{i}=x_{j}\quad\Leftrightarrow\quad\exists k\;:\;i\in P_{k} and j\in P_{k},,P(x)=\left\{\{ j\in [d] : x_j=v\}\mid v\in V(x)\right\},\(P(x)\) is the partition of \([d]\) into subsets where each subset contains indices corresponding to a distinct value in the vector \(x\).
neurips_2024_oral_41,3,"M_{P}(x)=M_{P,\phi}(x):=\arg\min_{y\inR^{d}}\{\phi(y)\,:\,P(y)\sqsupseteq P (x)\}",,y=\mathop{argmin}_{y\inR^{d}}\phi(y)\quadsubject to\quad P(y)\sqsupseteq P(x),The P step minimizes \(\phi(y)\) over all \(y\) satisfying \(P(y) \sqsupseteq P(x)\).
neurips_2024_oral_41,4,"M_{V}(y)=M_{V,\phi}(y):=\arg\min_{x\inR^{d}}\{\phi(x)\,:\,V(x)\subseteq V (y)\}",,"M_V(y)=M_{V,\phi}(y):=\arg\min_{z\inR^{d}}\left\{\phi(z)\;:\;z_i\in V(y)\quad\forall i\in[d]\right\}",The V step mapping minimizes the loss \(\phi\) over all vectors \(z\) with components restricted to the set of distinct values of \(y\).
neurips_2024_oral_41,5,"\phi(x)\approx\widetilde{\phi}_{y}(x):=\phi(y)+\langle\nabla\phi(y),x-y\rangle+\tfrac{L}{2}\norm{x-y}^{2}",where \(L>0\) is a sufficiently large constant,\phi(x)\approx\phi(y)+\nabla\phi(y)^{\top}(x-y),Linear approximation of the loss function \(\phi\) around point \(y\).
neurips_2024_oral_41,6,"M_{V,\phi}(y)\overset{\eqref{eq:v_def}}{\approx}M_{V,\widetilde{\phi}_{y}}(y )\overset{\eqref{eq:v_def}}{=}\arg\min_{x\inR^{d}}\{\widetilde{\phi}_{y}(x)\:\V(x)\subseteq V(y)\}",,\widehat{M}_{V}(y) :=\arg\min_{x\inR^d}\left\{\widetilde{\phi}_{y}(x) : V(x)\subseteq V(y)\right\},The approximate V mapping using the quadratic approximation \(\widetilde{\phi}_{y}\).
neurips_2024_oral_41,7,\widehat{\phi}_{y}(x):=\norm{x-(y-\tfrac{1}{L}\nabla\phi(y))}^{2}=\norm{x-y^{+}}^{2}=\sum\limits_{i=1}^{d}(x_{i}-y_{i}^{+})^{2},,\widehat{\phi}_{y}(x)=\left\| x-\left( y-\frac{1}{L}\nabla\phi(y)\right)\right\|^{2},The function \(\widehat{\phi}_{y}(x)\) is defined as the squared Euclidean distance between \(x\) and the gradient descent point \(y - \frac{1}{L} \nabla \phi(y)\).
neurips_2024_oral_41,8,"x:=M_{V,\phi}(y)\approx M_{V,\widehat{\phi}_{y}}(y):=\hat{x}",,M_{V}^{lin}(y)=\arg\min_{x\inR^d}\left\{\| x-y^{+}\|^2\:\V(x)\subseteq V(y)\right\},The linearized V step mapping that minimizes the squared Euclidean distance to the gradient-adjusted point \( y^+ \) subject to the constraint that the set of distinct values of \( x \) is a subset of the set of distinct values of \( y \).
neurips_2024_oral_41,9,"\phi(x)\leq\phi(y)+\langle\nabla\phi(y),x-y\rangle+\tfrac{L}{2}\norm{x-y}^{2},\qquad\forall x,y\inR^{d}_{\leq c}",,"\|\nabla\phi(x)-\nabla\phi(y)\|\leq L\|x-y\|,\quad\forall x, y\inR^{d}_{\leq c}","Condition for \(\phi\) being \(L\)-smooth on \(\mathbb{R}^{d}_{\leq c}\), requiring Lipschitz continuity of its gradient with constant \(L\)."
neurips_2024_oral_41,10,"x^{+}:=M_{V,\widehat{\phi}_{y,S^{k}}}(y):=\operatorname*{arg\,min} _{x\inR^{d}}\{\widehat{\phi}_{y,S^{k}}(x)\:\V(x)\subseteq V(y)\} || where\quad\widehat{\phi}_{y,S^{k}}(x):=\|x-(y-\frac {1}{L_{S^{k}}}Z^{k}(\nabla\phi(y)))\|^{2}",,"\widehat{\phi}_{y,S^{k}}(x) :=\left\| x-\left( y-\frac{1}{L} Z^{k}\left(\nabla\phi(y)\right)\right)\right\|^{2}","The quadratic approximation for the subspace V step, updating parameters in \(\mathcal{S}^k\) using a gradient step scaled by \(1/L\) while freezing other coordinates."
neurips_2024_oral_42,1,"\min_{Q}\max_{\pi}\alpha(E_{\hat{s}\simD_{img},\alpha\sim\pi(a|\hat{s})}[Q(\hat{s},a)]-E_{\hat{s},\hat{a}\simD_{img}}[Q(\hat{s},\hat{a})]+R(\pi)) || +E_{\hat{s},\hat{a}\simD_{img}}[(Q(\hat{s},\hat{a})-\hat{B}^{\pi}\hat{Q}(\hat{s},\hat{a}))^{2}]",,"L_{CQL}(Q)=\alpha\cdotE_{s\simD_{img}}\left[\log\sum_{a}\exp(Q(s,a))-E_{a\simD_{img}(\cdot|s)} [Q(s,a)]\right]+\frac{1}{2}E_{(s,a,s', r)\simD_{img}}}\left[\left( Q(s,a)-\left( r+\gammaE_{a'\sim\pi(\cdot|s')} [\bar{Q}(s',a')]\right)\right)^2\right]","The learning objective of Conservative Q-learning applied to the imaginary dataset \(\mathcal{D}_{\mathrm{img}}\), combining a conservative regularization term to prevent overestimation and a standard Bellman error minimization term."
neurips_2024_oral_42,2,"\hat{B}_{T}^{\pi}\hat{Q}(\hat{s},\hat{a}):=\hat{r}-\eta_{R }R_{R}(\hat{s},\hat{a})-\eta_{T}R_{T}(\hat{s},\hat{a})+\gammaE_{\hat{s}^{\prime}\simD_{img},a^{\prime}\sim\pi_{k}(a^{\prime}|\hat{s}^{\prime})}[Q(\hat{s}^{\prime},a^{\prime})]","where \(\hat{s}^{\prime}\sim\mathcal{D}_{\mathrm{img}}\) is to sample the next state given \(\hat{s},\hat{a}\), \(\eta_{R}\) and \(\eta_{T}\) are two hyper-parameters to control the weighting of the uncertainty terms","\hat{B}^{\pi}\hat{Q}^{k}(\hat{s},\hat{a})=\hat{r}(\hat{s},\hat{a})-R_{R}(\hat{s},\hat{a})+\gamma\left(E_{\hat{s}'\sim\hat{T}(\cdot|\hat{s},\hat{a}), a'\sim\pi}\left[\hat{Q}^{k}(\hat{s}',a')\right]-R_{T}(\hat{s},\hat{a})\right)","The modified Bellman backup operator \(\hat{\mathcal{B}}^{\pi}\hat{Q}^{k}\) incorporates regularization terms \(\mathcal{R}_{R}\) and \(\mathcal{R}_{T}\) for reward and transition uncertainty, respectively."
neurips_2024_oral_48,1,"x_{0}=x,\quadx_{\ell}=\sigma_{\ell}(W _{\ell}x_{\ell-1}+b_{\ell}),\quad u_{G,\theta}(x)=x_{L}","where \(L\): the number of layers, \(\mathbf{W}_{i}\in\mathbb{R}^{d_{\ell}\times d_{\ell-1}}\): the weights of the NN, \(\mathbf{b}_{i}\in\mathbb{R}^{d_{\ell}}\): the biases of the NN, \(d_{0}=d_{\text{in}}\), \(d_{L}=d_{\text{out}}\), \(\sigma_{\ell}:\mathbb{R}\to\mathbb{R}\) activation functions applied element-wise","u_{G,\theta}(x)=W^{(L)}\sigma\left(W^{(L-1)}\sigma\left(\cdots\sigma\left(W^{(1)}x+b^{(1)}\right)\cdots+b^{(L-1)}\right)+b^{(L)}","The feedforward neural network function $u_{G,\boldsymbol{\theta}}$ evaluated at input $\mathbf{x}$ is defined by a composition of linear transformations and element-wise non-linear activation functions $\sigma$, where $\mathbf{W}^{(l)}$ and $\mathbf{b}^{(l)}$ are the weight matrix and bias vector for layer $l$, respectively."
neurips_2024_oral_48,2,"W_{\ell}^{\prime}=P_{\ell}W_{\ell}P_{\ell-1}^{-1},\,b_{\ell}^{\prime}=P_{\ell}b_{\ell}\Longrightarrow(W_{\ell}^{\prime},b_{\ell}^{\prime})_ {\ell=1}^{L}=\theta^{\prime}\simeq\theta=(W_ {\ell},b_{\ell})_{\ell=1}^{L}","where \(\ell\in\{1,\ldots,L\}\), \(\mathbf{P}_{0}=\mathbf{P}_{L}=\mathbf{I}\) and \(\mathbf{P}_{\ell}\in\mathbb{R}^{d_{\ell}\times d_{\ell}}\) are arbitrary permutation matrices","u_{G,\theta}=u_{\psi(G,\theta)}",This equation states that the neural network function is invariant under any hidden layer permutation symmetry transformation $\psi$.
neurips_2024_oral_48,3,"h_{V}^{0}(i)=INIT_{V}(x_{V}(i )),\quadh_{E}^{0}(i,j)=INIT_{E}(x_{ E}(i,j))",,"h_i^{(0)} &=(x_V)_i,\quade_{i,j}=(x_E)_{i,j}\quadfor all  i\inV, (i,j)\inE\\m_i^{(t)} &=\sum_{j: (i,j)\inE} M_t\left(h_i^{(t-1)},h_j^{(t-1)},e_{i,j}\right)\\h_i^{(t)} &=U_t\left(h_i^{(t-1)},m_i^{(t)}\right)\quadfor  t=1,\ldots,T","where $\mathbf{h}_i^{(t)}$: the feature vector of vertex $i$ at iteration $t$, $\mathbf{e}_{i,j}$: the feature vector of edge $(i,j)$ (directed from $j$ to $i$), $M_t$: the message function at iteration $t$, $U_t$: the update function at iteration $t$, and the sum is over all $j$ such that $(i,j) \in \mathcal{E}$."
neurips_2024_oral_48,4,"m_{V}^{t}(i)=\bigoplus_{j\inN(i)}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!where\(h_{V}^{i},h_{E}^{i}\) are vertex and edge representations at iteration\(t\) and\(h_{G}\) is the overall graph (NN) representation. INIT, MSG, UPD are general function approximators (e.g. MLPs), while READ is a permutation invariant aggregator (e.g. DeepSets [81]). The above equations have appeared with several variations in the literature, e.g. in some cases the edge representations are not updated or the readout input involve edge representations as well. Another frequent strategy is to use _positional encodings_\(p_{V},p_{E}\) to break undesired symmetries. In FFNNs, Eq. (2) reveals that input and output vertices are not permutable, while vertices cannot be permuted across layers. Therefore, vertices (or edges) that are permutable share the same positional encoding (see Appendix A.1.2 for more details).**Remark:**Although, typically, the neighbourhood\(N(i)\) contains both incoming and outgoing edges, in Section 5 we will illustrate our method using only incoming edges: _forward neighbourhood_\(N_{FW}(i)=\{j\inV\midlayer\,(i)- layer\,(j)=1\}\) and _backward_ where layer\((i)\) gives the layer neuron\(i\) belongs. Backward neighbourhoods\(N_{BW}(i)\) are defined defined similarly. In Appendix A.2, we show a more elaborate _bidirectional version_ of our method, with both neighbourhoods considered. ## 4 Scaling symmetries in Feedforward Neural Networks**Scaling symmetries (activation functions).**Intuitively, permutation symmetries stem from the _graph structure_ of neural networks, or put differently, from the fact that hidden neurons do not possess any inherent ordering. Apart from the affine layers\(W_{\ell}\) that give rise to the graph structure, it is frequently the case that**activation functions**\(\sigma_{\ell}\) have inherent symmetries that are bestowed to the NN. Let us dive into certain illustrative examples: for the ReLU activation\(\sigma(x)=\max(x,0)\) it holds that\(\sigma(ax)=\max(ax,0)=a\max(x,0),\\forall a>0\). For the tanh and sine activations\(\sigma(x)=\tanh(x)\),\(\sigma(x)=\sin(x)\) respectively, it holds that\(\sigma(ax)=a\sigma(x),\\forall a\in\{-1,1\}\). In a slightly more complex example, polynomial activations\(\sigma(x)=x^{k}\), we have\(\sigma(ax)=a^{d}\sigma(x)\), i.e. the multiplier differs between input and output. In general, we will be talking about _scaling symmetries_ whenever there exist pairs\((a,b)\) for which it holds that\(\sigma(ax)=b\sigma(x)\). To see how such properties affect NN symmetries, let us focus on FFNNs (see Appendix A.3 for CNNs): for a neuron\(i\) (we omit layer subscripts) we have\(\sigma\big{(}aW(i,:)x+ab(i)\big{)}=\textit{b}\big{(}W(i,:)x+b(i)\big{)}\), i.e. _multiplying its bias and all incoming weights with a constant a results in scaling its output with a corresponding constant\(b\)_. Generalising this to linear transformations, we may ask the following: which are the pairs of matrices\((A,B)\) for which we have\(\sigma\big{(}AWx+Ab\big{)}=B\sigma\big{(}Wx+b\big{)}\)? Godfrey et al. [25] provide an answer for _any activation that respects certain conditions_. We restate here their most important results:**Proposition 4.1**(Lemma 3.1. and Theorem E.14 from [25]).: _Consider an activation function\(\sigma:R\toR\). Under mild conditions,5 the following hold:_ Footnote 5: See Appendix A.7.1 for the precise statement and more details about\(\phi_{\sigma,d}\).*_For any_\(d\inN^{+}\)_, there exists a (non-empty) group of invertible matrices defined as:_\(I_{\sigma,d}=\{A\inR^{d\times d}: invertible\mid\exists\B\inR^{d\times d} invertible, such that: \sigma(Ax)=B\sigma(x)\}\) _(_intertwiner group_)_, and a mapping function_\(\phi_{\sigma,d}\) _such that_\(B=\phi_{\sigma,d}(A)\)_._*_Every_\(A\in I_{\sigma,d}\) _is of the form_\(PQ\)_, where_\(P\)_: permutation matrix and_\(Q=\textit{diag}\big{(}q_{1},\ldots q_{d}\big{)}\) _diagonal, with_\(q_{i}\in D_{\sigma}=\{a\inR\setminus\{0\}\mid\sigma(ax)=\phi_{\sigma,1}(a)\sigma(x)\}\)_: the 1-dimensional group, and_\(\phi_{\sigma,d}(A)=P\textit{diag}\big{(}\phi_{\sigma,1}(q_{1} ),\ldots\phi_{\sigma,1}(q_{d})\big{)}\)_._ This is a powerful result that completely answers the question above for most practical activation functions. Importantly, not only does it recover permutation symmetries, but also reveals symmetries to diagonal matrix groups, which can be identified by solely examining\(\phi_{\sigma,1}\), i.e. the one-dimensional case and the set\(D_{\sigma}\) (easily proved to be a group) we have already discussed in our examples above. Using this statement, Godfrey et al. [25] characterised various activation functions (or recovered existing results), e.g. ReLU:\(I_{\sigma,d}\) contains**generalised permutation matrices with positive entries**of the form\(PQ\),\(Q=diag(q_{1},\ldots,q_{d})\),\(q_{i}>0\) and\(\phi_{\sigma,d}(PQ)=PQ\)[56]. Additionally, here we characterise the intertwiner group of sine (used in the popular SIREN architecture [70] for INRs). Not surprisingly, it has the same intertwiner group with tanh [11, 21] (we also recover this here using Proposition 4.1). Formally, (proof in Appendix A.7.1):**Corollary 4.2**.: _Hyperbolic tangent\(\sigma(x)=\tanh(x)\) and sine activation\(\sigma(x)=\sin(\omega x)\), satisfy the conditions of Proposition 4.1, when (for the latter)\(\omega\neq k\pi,k\inZ\). Additionally,\(I_{\sigma,d}\) contains**signed permutation matrices**of the form\(PQ\), with\(Q=diag(q_{1},\ldots,q_{d})\),\(q_{i}=\pm 1\) and\(\phi_{\sigma_{d}}(PQ)=PQ\)._It is straightforward to see that the symmetries of Proposition 4.1, induce equivalent parameterisations for FNNs. In particular, it follows directly from Proposition 3.4. in [25], that for activation functions\(\sigma_{\ell}\) satisfying the conditions of Proposition 4.1 and when\(\phi_{\sigma,\ell}(Q)=Q\), we have that:\[W^{\prime}_{\ell}=P_{\ell}Q_{\ell}W_{\ell}Q_{\ell-1}^{-1}P_{\ell-1}^{-1},\;b^{\prime}_{\ell}=P_{\ell}Q_{\ell}b_{\ell}\implies(W^{\prime }_{\ell},b^{\prime}_{\ell})_{\ell=1}^{L}=\theta^{\prime}\simeq\theta=(W_{\ell},b_{\ell})_{\ell=1}^{L}","where again \(\ell\in\{1,\ldots,L\}\), \(\mathbf{P}_{0}=\mathbf{Q}_{0}=\mathbf{P}_{L}=\mathbf{Q}_{L}=\mathbf{I}\)","h_{E}^{t}(i,j)=\phi_{E}\left(h_{E}^{t-1}(i,j),h_{V}^{t-1}(i),h_{V}^{t-1}(j)\right),\quadh_{V}^{t}(i)=\phi_{V}\left(h_{V}^{t-1}(i),\sum_{k: (i,k)\inE}h_{E}^{t}(i,k)\right)","where \(t \in \{1,\ldots,T\}\) is the iteration index, \(\phi_{E}\) and \(\phi_{V}\) are edge and vertex update functions, and the sum aggregates updated edge features over all incoming edges \((i,k)\) to vertex \(i\)."
neurips_2024_oral_48,5,"h^{\prime}_{V}(i)=q_{\ell}(\pi_{\ell}(i))h_{V} (\pi_{\ell}(i)),\quad\ell=layer(i)\in\{1,\ldots,L-1\} || h^{\prime}_{E}(i,j)=q_{\ell}(\pi_{\ell}(i))h_{E} (\pi_{\ell}(i),\pi_{\ell-1}(j))q_{\ell-1}^{-1}(\pi_{\ell-1}(j)),\;\ell=layer(i)\in\{2,\ldots,L-1\}",,"h'_V(P_l(i))=q_ih_V(i),\quadh'_E(P_l(i), P_{l-1}(j))=\left(q_i\cdot q_j^{-1}\right)h_E(i,j)","where \(\mathbf{h}'_V, \mathbf{h}'_E\) are transformed vertex and edge representations, \(\mathbf{h}_V, \mathbf{h}_E\) are original representations, \(q_i, q_j\) are scaling factors for neurons \(i\) and \(j\), and \(P_l, P_{l-1}\) are permutation matrices for layers \(l\) and \(l-1\)."
neurips_2024_oral_48,6,"g_{i}\big{(}q_{1}x_{1},\ldots,q_{n}x_{n}\big{)}=q_{i}g_{i}(x_{1},\ldots,x_{n}\big{)},\forall q_{i}\in D_{i},i\in\{1,\ldots,n\}",where \(D_{i}\) a 1-dimensional scaling group as defined in Proposition 4,"m_{V}^{t}(i)=\sum_{j\inN_{FW}(i)}h_{E}^{t-1}(i,j)\odoth_{V}^{t-1}(j),\quadh_{V}^{t}(i)=h_{V}^{t-1}(i)+W^{t}m_{V}^{t}(i)","Scale-equivariant message $\mathbf{m}_{V}^{t}(i)$ aggregates elementwise products of edge features and sender vertex features over the forward neighborhood $\mathcal{N}_{\text{FW}}(i)$, and vertex representation $\mathbf{h}_{V}^{t}(i)$ updates via a linear combination with learnable matrix $\mathbf{W}^{t}$."
neurips_2024_oral_48,7,"ScaleInv^{k}(X)=\rho^{k}(\tilde{x }_{1},\ldots,\tilde{x}_{n})",,"g_i(x_1,\ldots,x_n)=x_i\odot I_i(x_1,\ldots,x_n)",where \( I_i \) is a scale invariant function of the inputs and \( \mathbf{x}_i \) is the input corresponding to the central vertex.
neurips_2024_oral_48,8,"ScaleEq=f^{K}\circ\cdots\circf^{1},\;f^{k}(X)=\big{(}\Gamma^{k}_{1}x_{1},\ldots,\Gamma^{k}_{n}x_{n}\big{)}\odotScalelInv^{k }(X)",,h_{V}^{k}(i)=q_{i}\cdotL^{k}\left(ScaleInv^{k}\left(\left\{x_{j} : j\inN(i)\right\}\right)\right),Vertex representation at layer \( k \) for vertex \( i \) obtained by applying linear transformation \(\mathbf{L}^{k}\) to scale-invariant neighborhood aggregation and multiplying by vertex scaling factor \( q_i \).
neurips_2024_oral_48,9,"g\big{(}q_{1}x_{1},\ldots q_{n}x_{n}\big{)}=g(x_{1},\ldotsx_{n})\prod_{i=1}^{n}q_{i},\forall q_{i}\in D_{i}",,"ScaleEq=f^{K}\circ\cdots\circf^{1},\;f^{k}(X)=\big{(}\Gamma^{k}_{1}x_{1},\ldots,\Gamma^{k}_{n}x_{n}\big{)}\odotScaleInv^{k}(X)","The scale equivariant network is defined as a composition of K layers, where each layer k applies a linear transformation to each input vector and then multiplies element-wise by the output of a scale invariant network applied to the entire input set."
neurips_2024_oral_48,10,"ReScaleEq(x_{1},\ldotsx_{n})=ScaleEq\big{(}vec(\textbf{X}_{n})\big{)}",,"RescaleEquivNet(x_1,\ldots,x_n)=\bigotimes_{i=1}^{n}x_i",The rescale-equivariant network defined as the outer product of the input vectors.
neurips_2024_oral_48,11,"MSG_{V}(x,y,e)=ScaleEq ([x,ReScaleEq(y,e) ])","where \([\cdot,\cdot]\) denotes concatenation, \(\mathsf{ReScaleEq}(q_{y}\mathbf{y},q_{x}q_{y}^{-1}\mathbf{e})=q_{x}\mathsf{ ReScaleEq}(\mathbf{y},\mathbf{e})\)","m_{V}^{t}(i)=\bigoplus_{j\inN(i)}\left(\Gamma_{2}h_{V}^{t-1}(j)\odot\Gamma_{3}h_{E}^{t-1}(i,j)\right)",The message vector at vertex i and iteration t is obtained by aggregating over neighbours j the element-wise product of the linearly transformed neighbour vertex feature and the linearly transformed edge feature.
neurips_2024_oral_48,12,"UPD_{V}(x,m)=ScaleEq( [x,m])",,"h_V^{t}(i)=ScaleEq\left(\left[h_V^{t-1}(i),m_V^{t}(i)\right]\right)",Vertex update: $\mathsf{ScaleEq}$ is a scale-equivariant network applied to the concatenation of the previous vertex state $\mathbf{h}_V^{t-1}(i)$ and the incoming message $\mathbf{m}_V^{t}(i)$.
neurips_2024_oral_48,13,"READ_{V}(X):=DeepSets(\tilde{x}_{1},\ldots,\tilde{x}_{n}),\quad\tilde{x}_{ i}=canon_{i}(x_{i}) or \tilde{x}_{i}=symm_{i}(x_{i})",,"h_G=READ\left(\left\{\tilde{h}_V(i)\right\}_{i\inV_{hidden}}\right),\quad\tilde{h}_V(i)=inv(h_V(i))",The graph representation \(\mathbf{h}_G\) is computed via a permutation-invariant readout applied to scale-invariant (via canonicalisation or symmetrisation) vertex representations of hidden neurons.
neurips_2024_oral_54,1,"V^{\pi}(s):=E[\sum_{t=0}^{\infty}\gamma^{t}r(s_{t},a_{t})| s_{0}=s];\quad Q^{\pi}(s,a):=E[\sum_{t=0}^{\infty}\gamma^{t}r (s_{t},a_{t})|s_{0}=s,a_{0}=a]","where \(a_{t}\sim\pi(\cdot|s_{t})\) and \(s_{t+1}\sim P(\,\cdot\,|s_{t},a_{t})\) for all \(t\geq 0\)","V^{\pi}(s) &=E\left[\sum_{t=0}^{\infty}\gamma^{t} r(s_{t}, a_{t})\mid s_{0}=s\right],\\Q^{\pi}(s, a) &=E\left[\sum_{t=0}^{\infty}\gamma^{t} r(s_{t}, a_{t})\mid s_{0}=s, a_{0}=a\right]","The state value function \( V^{\pi}(s) \) represents the expected discounted cumulative reward starting from state \( s \) under policy \( \pi \), while the state-action value function \( Q^{\pi}(s,a) \) represents the expected discounted cumulative reward starting from state \( s \) and action \( a \) under policy \( \pi \)."
neurips_2024_oral_54,2,"(TQ)(s,a)=r(s,a)+\gamma\cdotE_{s^{\prime}\sim P(\cdot|s,a) }[\max_{a^{\prime}\inA}Q(s^{\prime},a^{\prime})]",,"(TQ)(s, a)=r(s, a)+\gammaE_{s'\sim P(\cdot|s,a)}\left[\max_{a'\inA} Q(s', a')\right]","The Bellman operator \(\mathcal{T}\) applied to a Q-function \(Q\) at a state-action pair \((s,a)\) is defined as the immediate reward plus the discounted expected maximum Q-value of the next state."
neurips_2024_oral_54,3,"(T_{Z}Q)(s,a)=r(s,a)+\gamma V(Z(s,a))","where \(V(s^{\prime})=\max_{a^{\prime}\in\mathcal{A}}Q(s^{\prime},a^{\prime})\)","(T_{Z}Q)(s,a)=r(s,a)+\gamma\max_{a'\inA} Q(Z(s,a), a')","For each state-action pair \((s,a)\), the random operator \(\mathcal{T}_{Z}\) computes the Bellman update using the sampled next state \(Z(s,a)\)."
neurips_2024_oral_54,4,"ER(A;N,M):=\sup_{M=(P,r)}E[\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty }]",where the expectation is taken over the samples and any randomness in the algorithm,"ER(A;N,M) :=\sup_{M}E\left[\left\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\right\|_{\infty}\right]","The minimax error rate \(\mathsf{ER}(\mathscr{A};N,M)\) is defined as the supremum over MDPs \(\mathcal{M}\) of the expected \(\ell_\infty\) error between the estimated Q-function and the optimal Q-function."
neurips_2024_oral_54,5,"SC(A;\varepsilon,M):=|S || A|\cdot\min\{N\inN:ER(A;N,M)\leq\varepsilon\}",,"SC(A;\varepsilon,M) :=\min\left\{ N\inN :ER(A;N,M)\leq\varepsilon\right\}","The sample complexity \(\mathsf{SC}(\mathscr{A};\varepsilon,M)\) is the minimum number of samples \(N\) per state-action pair per agent required by algorithm \(\mathscr{A}\) with \(M\) agents to achieve \(\mathsf{ER}(\mathscr{A};N,M) \leq \varepsilon\)."
neurips_2024_oral_54,6,"SC(A;\varepsilon,M,\delta):=|S || A|\cdot\min\{N\inN:\Pr(\sup_{M}\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty}\leq\varepsilon)\geq 1-\delta\}",,"SC_{\delta}(A;\varepsilon,M):=|S || A|\cdot\min\left\{ N\inN :\sup_{M}P\left(\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty} >\varepsilon\right)\leq\delta\right\}",where \(\delta\) is the failure probability and the probability is taken over the samples and any randomness in the algorithm
neurips_2024_oral_54,7,CC_{round}(A;N):=\frac{1}{M}\sum_{m=1}^{M}C^{m}_{round}(A;N);\quadCC_{bit}(A;N ):=\frac{1}{M}\sum_{m=1}^{M}C^{m}_{bit}(A;N),,"CC_{round}(A;N,M) :=\max_{m\in[M]} C^{m}_{round}(A;N),\quadCC_{bit}(A;N,M) :=\sum_{m=1}^{M} C^{m}_{bit}(A;N)","\(\mathsf{CC}_{\mathsf{round}}\) is the maximum number of communication rounds over agents, and \(\mathsf{CC}_{\mathsf{bit}}\) is the total number of bits uploaded by all agents."
neurips_2024_oral_54,8,Q_{t-\frac{1}{2}}^{m}=(1-\eta_{t})Q_{t-1}^{m}+\frac{\eta_{t}}{B}\sum_{b=1}^{B}T_{Zs}(Q_{t-1}^{m}),,"Q_{t}^{m}=(1-\eta_{t}) Q_{t-1}^{m}+\eta_{t}\cdot\frac{1}{B}\sum_{b=1}^{B}\widehat{T}_{Z_{t,b}^{m}} Q_{t-1}^{m}","where \(\widehat{\mathcal{T}}_{Z_{t,b}^{m}}\) is the sample Bellman operator for the b-th sample in the minibatch at iteration \(t\) for agent \(m\), and \(\eta_t\) is the step size at iteration \(t\)."
neurips_2024_oral_54,9,"Q_{t}^{m}=\frac{1}{M}\sum_{j=1}^{M}Q_{t-\frac{1}{2}}^{j}& if t\inC,\\Q_{t-\frac{1}{2}}^{m}& otherwise.",,Q_{t}^{m}=\frac{1}{M}\sum_{m'=1}^{M} Q_{t-\frac{1}{2}}^{m'},"At each communication round \(t \in \mathcal{C}\), the Q-function estimate for agent \(m\) is updated to the average of all agents' intermediate estimates \(Q_{t-\frac{1}{2}}^{m'}\)."
neurips_2024_oral_54,10,R=\textsf{CC}_{\textsf{round}}(A;N)\leq\frac{c_{0}}{(1-\gamma)\log ^{2}N}; or\textsf{CC}_{\textsf{left}}(A;N)\leq\frac{c_{1}|S || A|}{(1-\gamma)\log^{2}N},,R\leq\frac{1}{32}\sqrt{\frac{T}{(1-\gamma)\log(|S || A|) }},"where \( R \) is the number of communication rounds, \( T \) is the total number of updates, and \( |\mathcal{S}|, |\mathcal{A}| \) are the sizes of the state and action spaces respectively."
neurips_2024_oral_54,11,"\textsf{ER}(A;N,M)\geq\frac{C_{\gamma}}{\log^{3}N\sqrt{N}}",,"ER(A;N,M)\geq c_2",where \(c_2 > 0\) is a universal constant.
neurips_2024_oral_56,1,"B_{Acc=K_{1}}(t|m)=\sup_{d}\{d|Acc(t|d,m)\leq K_{1}\}","where \(Acc(t|d,m)\) represents the accuracy of the model's accuracy on task \(t\) with difficulty \(d\)","RB(m, t)=\max\left\{ d\midaccuracy(m, t, d)\geq K_1\right\}","Reasoning boundary \(\text{RB}(m, t)\) for model \(m\) and task \(t\), defined as the maximum problem difficulty \(d\) where the model's accuracy meets or exceeds threshold \(K_1\)."
neurips_2024_oral_56,2,"B_{Acc=K_{1}}(t_{1},t_{2},\dots,t_{n}|m)\approx\frac{1}{\sum _{i=1}^{n}\frac{N_{i}}{B_{Acc=K_{1}}(t_{i}|m)-b_{i}}}",where \(\mathcal{B}_{\text{Acc}=K_{1}}(t_{i}|m)\) denotes the reasoning boundary of model \(m\) for task \(t_{i}\),"B_{Acc=K_{1}}(t_{1},t_{2},\dots,t_{n}|m)=\min_{i\in\{1,\dots, n\}}B_{Acc=K_{1}}(t_i|m)",The unified reasoning boundary for multiple tasks is the minimum of the individual reasoning boundaries for each task.
neurips_2024_oral_56,3,"B^{\texttt{CGT}}(c,p)=\frac{1}{\frac{N_{1}}{(B(c)-b_{1})}+\frac{N_{2}}{(B(p)-b_{2})}}",,"B(p, c)\approx\frac{1}{\frac{N_p}{B(p)-b_p}+\frac{N_c}{B(c)-b_c} }","where \(\mathcal{B}(p, c)\) is the combined reasoning boundary for mathematical reasoning tasks, \(\mathcal{B}(p)\) is the reasoning boundary for step planning, \(\mathcal{B}(c)\) is for step calculation, and \(N_p\), \(b_p\), \(N_c\), \(b_c\) are task-specific scaling factors."
neurips_2024_oral_56,4,"B^{Tool}(c,p)=\lim_{B(c)arrow+\infty}\frac{ 1}{\frac{N_{1}}{(B(c)-b_{1})}+\frac{N_{2}}{(B(p)-b_{2})}}=\frac{B(p)-b_{2}}{N_{2}}",,"B^{\texttt{CGT}}(c,p)=\frac{B(p)-b_2}{N_2}",the combined reasoning boundary when the step calculation boundary tends to infinity due to tool usage
neurips_2024_oral_57,1,"E_{t\simU[1,T],\;X^{0},C\sim q( X^{0},C)}(\|X^{0}-H(X^{t},t,C)\|^{2})","where \(t\) denotes the time step, \(\mathbf{X}^{0}=\mathbf{X}\) is the raw motion latent sequence, and \(\mathbf{X}^{t}\) is the noisy inputs generated by the diffusion forward process \(q(\mathbf{X}^{t}|\mathbf{X}^{t-1})=\mathcal{N}(\mathbf{X}^{t};\sqrt{1-\beta_{ t}}\mathbf{X}^{t-1},\beta_{t}\text{I})\)","L=E_{t,X,\epsilon,A}\left[\|\epsilon-\epsilon_\theta(X_t, t,A)\|^2\right]","Simplified loss function for the diffusion model, where $\epsilon$ is the noise, $\epsilon_\theta$ is the denoising network, $\mathbf{X}_t$ is the noisy motion sequence at timestep $t$, and $\mathbf{A}$ is the audio features."
neurips_2024_oral_57,2,"\hat{X}^{0}=(1+\sum_{e\inC}\lambda_{e})\cdotH(X^{t},t,C)-\sum_{e\inC}\lambda_{c}\cdotH(X^{t},t,C|_{e=\emptyset})",,"\tilde{X}^0=H(X^t, t,\emptyset)+s\cdot\left(H(X^t, t,C)-H(X^t, t,\emptyset)\right)","Classifier-free guidance formulation for the predicted raw signal \(\tilde{\mathbf{X}}^0\) at inference, where \(s\) is the guidance scale, \(\mathcal{H}\) is the transformer network, \(\mathbf{C}\) is the condition signal, and \(\emptyset\) represents the dropped condition."
neurips_2024_oral_58,1,"p(x_{1},x_{2},\dots,x_{T})=\prod_{t=1}^{T}p(x_{t}\mid x_{1},x_{2},\dots,x_{t-1 })",,p(x)=\prod_{t=1}^{T} p(x_t\mid x_{<t}),The equation factorizes the sequence likelihood into the product of conditional probabilities for each token given its preceding prefix.
neurips_2024_oral_58,2,"f=E(im),\\\\\q=Q(f)","where \(im\) denotes the raw image, \(\mathcal{E}(\cdot)\) a encoder, and \(\mathcal{Q}(\cdot)\) a quantizer",q=Quantize(f)\in [V]^{h\times w},Equation 2 represents the tokenization of image feature map \(f\) into discrete tokens \(q\) via quantization.
neurips_2024_oral_58,3,"q^{(i,j)}=(\operatorname*{arg\,min}_{v\in[V]}\|lookup(Z,v)-f^{(i,j)}\|_{2})\in[V]","where \(\text{lookup}(Z,v)\) means taking the \(v\)-th vector in codebook \(Z\)","q^{(i,j)}=\arg\min_{k\in [V]}\left\| f^{(i,j)}-Z_k\right\|_2","Each entry \(q^{(i,j)}\) is the index of the nearest code vector in the codebook \(Z\) for the feature vector \(f^{(i,j)}\) based on Euclidean distance."
neurips_2024_oral_58,4,"\hat{f}=lookup(Z,q),\\\\\\\\\hat{im}=D(\hat{f}) || L=\|im-\hat{im}\|_{2}+\|f-\hat{f}\|_{2}+\lambda_{P}L_{P}(\hat{im})+\lambda_{G}L_{G}(\hat{im})",,"\hat{f}^{(i,j)}=lookup(Z, q^{(i,j)}),\quad\hat{im}=D(\hat{f}),\quadL=\| im-\hat{im}\|_2^2+\beta\| f-\hat{f}\|_2^2","\(\hat{f}^{(i,j)}\) is the approximated feature vector at position (i,j) obtained by codebook lookup, \(\hat{im}\) is the reconstructed image, and \(\mathcal{L}\) is the compound loss combining image reconstruction and feature commitment terms."
neurips_2024_oral_58,5,"p(r_{1},r_{2},\dots,r_{K})=\prod_{k=1}^{K}p(r_{k}\mid r_{1},r_{2},\dots,r_{k-1 })","where each autoregressive unit \(r_{k}\in[V]^{h_{k}\times w_{k}}\) is the token map at scale \(k\) containing \(h_{k}\times w_{k}\) tokens, and the sequence \((r_{1},r_{2},\dots,r_{k-1})\) serves as the the ""prefix"" for \(r_{k}\)","p(r_1, r_2,\dots, r_K)=\prod_{k=1}^{K} p(r_k\mid r_1, r_2,\dots, r_{k-1})","The joint probability of multi-scale token maps \((r_1, r_2, \dots, r_K)\) is factorized into conditional probabilities where each token map \(r_k\) depends on all previous token maps \(r_1\) to \(r_{k-1}\)."
neurips_2024_oral_58,6,"w=64d,\qquad h=d,\qquad dr=0.1\cdot d/24",,"w &=\alpha_w d+\beta_w,\\h &=\alpha_h d+\beta_h,\\dr &=\alpha_{dr} d+\beta_{dr}","where \(d\) is the transformer depth, \(w\) the model width, \(h\) the number of attention heads, \(dr\) the dropout rate, and \(\alpha_w, \beta_w, \alpha_h, \beta_h, \alpha_{dr}, \beta_{dr}\) are scaling coefficients."
neurips_2024_oral_58,7,"N(d)=\underbrace{d\cdot 4w^{2}}_{self-attention}+\underbrace{d\cdot 8w^{2}} _{feed-forward}+\underbrace{d\cdot 6w^{2}}_{adaptive layernorm}=18\,dw^{2}=73728\,d^{3}",,N=12d w^{2}+6w^{2},"where \(N\) is the total number of parameters, \(d\) is the depth, and \(w\) is the width of the transformer."
neurips_2024_oral_59,1,"c^{(t+1)}(v)\gets f^{(t+1)}(c^{(t)}(v),g^{(t+1)}(\{\{c ^{(t)}(u)\mid u\inN(v)\}\}))",,"c_v^{(t)}=\phi\left( c_v^{(t-1)},\psi\left(\left\{ c_u^{(t-1)}\mid u\inN(v)\right\}\right)\right)",The color of node $v$ at iteration $t$ is updated by applying a function $\phi$ to its previous color and an aggregation function $\psi$ over the multiset of neighbor colors from iteration $t-1$.
neurips_2024_oral_59,2,c^{(t)}(G)\coloneqq h(\{\{c^{(t)}(v)\mid v\in V(G)\}\} ),,h_G^{(t)}=READOUT^{(t)}\left(\{\{ c^{(t)}(v)\mid v\in V(G)\}\}\right),The graph representation \( h_G^{(t)} \) at iteration \( t \) is computed by applying a readout function to the multiset of node representations \( c^{(t)}(v) \) for all nodes \( v \) in the graph.
neurips_2024_oral_59,3,"N_{r}(v)\coloneqq\{p\midp simple path of length r,\,p_{1},p_{r+1}\inN(v),v\notinp\}\",,N_r(v)=\left\{ u\in V(G)\midthere exists a simple path p of length  r from  v to  u\right\},The \(r\)-neighborhood of node \(v\) is the set of nodes \(u\) for which there exists a simple path of length \(r\) from \(v\) to \(u\).
neurips_2024_oral_59,4,"c_{r}^{(t+1)}(v)arrowHASH_{r}(c_{r}^{(t)}(v),\{\{c _{r}^{(t)}(p)\midp\inN_{0}(v)\}\},\ldots,\{\{c_{r}^{(t)}(p)\midp\inN_{r}(v )\}\})",,"c^{(t+1)}(v)\gets f^{(t+1)}\left( c^{(t)}(v), g^{(t+1)}\left(\{\{ (c^{(t)}(p_1), c^{(t)}(p_2),\dots, c^{(t)}(p_{r+1})\midp=(p_1, p_2,\dots, p_{r+1})\inN_r(v)\}\}\right)\right)",The updated color of node \(v\) at step \(t+1\) is computed by applying \(f^{(t+1)}\) to the current color of \(v\) and the aggregation \(g^{(t+1)}\) of the multiset of tuples of the current colors of the nodes in each simple path of the \(r\)-neighborhood of \(v\).
neurips_2024_oral_59,5,c_{r}^{(t)}(G)=HASH_{r}(\{\{c_{r}^{(t)}(v)\mid v\in V(G)\}\}\}),,c_{r}^{(t)}(G)\coloneqq h_{r}\left(\left\{\!\left\{ c_{r}^{(t)}(v)\mid v\in V(G)\right\}\!\right\}\right),The graph output of \(r\)-\(\ell\)WL after \(t\) iterations is defined as a multiset aggregation of node colors.
neurips_2024_oral_59,6,"m_{k}^{(t+1)}(v)&=f_{k}^{(t+1)}(\{\{c_{k}^{(t)}(p)\midp\inN_{k}(v)\}\}),\\c_{r}^{(t+1)}(v)&=g^{(t+1)}(c_{r}^{(t)}(v),\,m_{0 }^{(t+1)}(v),\ldots,m_{r}^{(t+1)}(v))",,"h_v^{(t+1)}=\psi^{(t)}\left( h_v^{(t)},\left(AGG_k^{(t)}\left(\left\{\phi_k^{(t)}\left( h_{p_1}^{(t)}, h_{p_2}^{(t)},\ldots, h_{p_{k+1}}^{(t)}\right)\midp\inN_k(v)\right\}\right)_{k=0}^{r}\right)",The update function for node \(v\) at iteration \(t+1\) in the \(r\)-\(\ell\)MPNN.
neurips_2024_oral_59,7,f_{k}^{(t+1)}(\{\{c_{k}^{(t)}(p)\midp\inN_{k}(v)\}\}):=f(\sum_{p\inN_{k}(v)}g(p)),,m_{k}^{(t+1)}(v)=\varphi_k^{(t+1)}\left(\sum_{p\inN_{k}(v)}\rho_k^{(t+1)}\left( c_{r}^{(t)}(p)\right)\right),"The message for node \(v\) at iteration \(t+1\) and neighborhood index \(k\) is computed by transforming each path representation with \(\rho_k^{(t+1)}\), summing the results, and applying \(\varphi_k^{(t+1)}\)."
neurips_2024_oral_59,8,x_{r}^{(t+1)}(v):=MLP(x_{r}^{(t)}(v)+(1+\varepsilon_{0})\sum_{u\inN_{0}(v)}x_{r}^{(t)}(u)+\sum_{k=1}^{r}(1+\varepsilon_{k})\sum_{p\inN_{k}(v)}GIN_{k}(p)),,"c_{r}^{(t+1)}(v)=MLP^{(t+1)}\left(\left[ c_{r}^{(t)}(v), m_{0}^{(t+1)}(v), m_{1}^{(t+1)}(v),\dots, m_{r}^{(t+1)}(v)\right]\right)",The updated node feature at iteration \(t+1\) for node \(v\) is computed by applying a multi-layer perceptron to the concatenation of the previous node feature and the aggregated messages from each neighborhood level \(k=0\) to \(r\).
neurips_2024_oral_6,1,"f_{z}(a_{1},a_{2})=E_{i\simS(z)\,,\,A_{1}\simB(a_{1})\,,\,A_{2}\simB(a_{2})}\Big{[}g_{i}(A_{1},A_{2 })\Big{]}=\sum_{i=0}^{15}\frac{\exp(z_{i})}{\sum_{j}\exp(z_{j})}\cdot g_{i}(a_ {1},a_{2})\",,"y=\sum_{k=0}^{15}\frac{\exp(z_k)}{\sum_{j=0}^{15}\exp(z_j)} g_k(a_1, a_2)","The output of a differentiable logic gate node is the expectation over all 16 possible logic gate operations applied to inputs $a_1$ and $a_2$, weighted by softmax probabilities derived from trainable parameters $\mathbf{z}$."
neurips_2024_oral_6,2,"f_{3}(\,f_{1}(a_{1},a_{2}),f_{2}(a_{3},a_{4})\,)",,"K(a_1, a_2, a_3, a_4)=f_3\left( f_1(a_1, a_2), f_2(a_3, a_4)\right)","The convolutional logic kernel function for a binary tree of depth 2, which maps four input activations to the output via three differentiable logic gates."
neurips_2024_oral_6,3,"A^{\prime}[k,i,j]=f_{3}^{k}\big{(}f_{1}^{k}\big{(}A\big{[}C_{M}[k,\!1]\!,C_{H}[k,\!1]\!+\!i,C_{W}[k,\!1]\!+\! j\big{]},A\big{[}C_{M}[k,\!2]\!,C_{H}[k,\!2]\!+\!i,C_{W}[k,\!2]\!+\!j\big{]}\big{)} || \qquad\qquad\qquad f_{2}^{k}\big{(}A\big{[}C_{M} [k,\!3]\!,C_{H}[k,\!3]\!+\!i,C_{W}[k,\!3]\!+\!j\big{]},A\big{[}C_{M}[k,\!4]\!,C_{H}[k,\!4]\!+\!i,C _{W}[k,\!4]\!+\!j\big{]}\big{)}\big{)}",,"O_{k,i,j}=f_{z_{3,k}}\left( f_{z_{1,k}}\left( A_{C_{M}[k,1], i+C_{H}[k,1]-1, j+C_{W}[k,1]-1}, A_{C_{M}[k,2], i+C_{H}[k,2]-1, j+C_{W}[k,2]-1}\right), f_{z_{2,k}}\left( A_{C_{M}[k,3], i+C_{H}[k,3]-1, j+C_{W}[k,3]-1}, A_{C_{M}[k,4], i+C_{H}[k,4]-1, j+C_{W}[k,4]-1}\right)\right)","The output \(O_{k,i,j}\) at channel \(k\) and spatial location \((i,j)\) is computed by evaluating the logic tree kernel (with parameters \(\mathbf{z}_{1,k}, \mathbf{z}_{2,k}, \mathbf{z}_{3,k}\)) on four inputs selected from tensor \(\mathbf{A}\) via connection indices \(\mathbf{C}_{M}, \mathbf{C}_{H}, \mathbf{C}_{W}\)."
neurips_2024_oral_60,1,Y^{l}=ESA(LN(X^{l}))+X^{l} || X^{l+1}=SwiGLU(LN(Y^{l}))+Y^{l},,X^{\nicefrac{L}{2}}=SelfDecoder(X^{0}),Equation 1 computes the intermediate vector representation \(X^{\nicefrac{L}{2}}\) from input embeddings \(X^{0}\) using the Self-Decoder module.
neurips_2024_oral_60,2,"\hat{K}=LN(X^{\nicefrac{{L}}{{2}}})W_{K},\quad\hat{V}=LN(X^ {\nicefrac{{L}}{{2}}})W_{V}","where \(W_{K},W_{V}\in\mathbb{R}^{d\times d}\) are learnable","\hat{K}=W_K X^{\nicefrac{L}{2}},\quad\hat{V}=W_V X^{\nicefrac{L}{2}}",The global key and value caches are generated by linear projections of the self-decoder output.
neurips_2024_oral_60,3,"Q^{l}=LN(X^{l})W_{Q}^{l} || Y^{l}=Attention(Q^{l},\hat{K},\hat{V})+X^{l} || X^{l+1}=SwiGLU(LN(Y^{l}))+Y^{l}",,"Y^{l}=CA(LN(X^{l}),\hat{K},\hat{V})+X^{l}",where \(\mathrm{CA}\) denotes cross-attention using the fixed key-value caches \(\hat{K}\) and \(\hat{V}\).
neurips_2024_oral_60,4,"Q=XW_{Q},\quad K=XW_{K},\quad V=XW_{V}\\head_{i}=softmax(Q_{[i]}K_{[i]}^{\intercal}+B)V,\quad B_{ij}=0,&i-C<j\leq i\\-\infty,&otherwise\\SWA(X)=Concat(head_{1},\cdots,head_{h})W_ {O}","where \(W_{Q},W_{K},W_{V},W_{O}\in\mathbb{R}^{d\times d}\) are learnable matrices, and the window causal mask \(B\) controls each query only attends to the previous keys whose distances are less than \(C\)","SlidingWindowAttention(Q, K, V)=softmax\left(\frac{QK^{\top}}{\sqrt{d}}+M_C\right) V",The sliding-window attention computes the output by applying a causal mask with window size \( C \) to restrict attention to the most recent tokens.
neurips_2024_oral_60,5,"Q=(XW_{Q})\odot\Theta,\quad K=(XW_{K})\odot\overline{\Theta},\quad V=XW_{V},\quad\Theta_{n}=e^{in\theta}\\\gamma=sigmoid(XW_{\gamma})^{1/\tau},\quad D_{nm}=\prod\nolimits_{i=m+1}^{n}\gamma_{i},&n\geq m\\0,&n<m\\gRet(X)=(QK^{\intercal}\odot D)V","where \(W_{Q},W_{K},W_{V}\in\mathbb{R}^{d\times d}\) and \(W_{\gamma}\in\mathbb{R}^{d\times 1}\) are learnable weights, and the temperature term \(\tau\) encourages \(\gamma\) to 1 for better memorization [46]","Q &=X W_Q,\quad K=X W_K,\quad V=X W_V\\Retention &=\left( Q K^\top\odot D\right) V\\gRet(X) &=GroupNorm\left(Retention\right)\odot\left(1+swish\left(X W_G\right)\right)","where \(W_Q, W_K, W_V, W_G \in \mathbb{R}^{d \times d}\) are learnable matrices, \(D\) is the decay matrix with exponential decay and causal masking, and \(\text{swish}\) is the Swish activation function."
neurips_2024_oral_60,6,"S_{n}=\gamma_{n}S_{n-1}+K_{n}^{\intercal}V_{n}\\gRet(X_{n})=Q_{n}S_{n},\quad n=1,\cdots,|x|","where \(Q,K,V,\gamma\) are the same as in Equation (5)",Q_{n} &=(x_{n} W_{Q})\odot\theta_{n}\\K_{n} &=(x_{n} W_{K})\odot\overline{\theta_{n}}\\V_{n} &=x_{n} W_{V}\\\gamma_{n} &=sigmoid(x_{n} W_{\gamma})^{1/\tau}\\S_{n} &=\gamma_{n}\cdot S_{n-1}+K_{n}^{\intercal} V_{n}\\head_{n} &=Q_{n} S_{n},"For the n-th timestep, the equations compute the head output \(\mathrm{head}_n\) and updated state \(S_n\) from the input \(x_n\), previous state \(S_{n-1}\), learnable weights \(W_Q, W_K, W_V \in \mathbb{R}^{d \times d}\) and \(W_\gamma \in \mathbb{R}^{d \times 1}\), rotary embedding \(\theta_n\), its complex conjugate \(\overline{\theta_n}\), and temperature \(\tau\)."
neurips_2024_oral_60,7,"\beta_{(i-1)B+j}&=\prod\limits_{k=(i-1)B+1}^{(i-1)B+j}\gamma_{k},\quad D_{[i]}(j,k)=\frac{\beta_{(i-1)B+k}}{\beta_{ (i-1)B+j}}\\if\\j\leq k\\else\\0\\R_{i}&=K_{[i]}^{\intercal}(V_{[i]}\odot\frac{\beta_{iB}}{\beta_{[i]}})+\beta_{iB}R_{i-1},\\\beta_{[i]}(j,k)=\beta_{(i-1)B+j}\\gRet(X)&=\underbrace{(Q_{[i]}K_{[i]}^{\intercal}\odot D_{[i]})V_{[i]}}_{Inner-Chunk}+\underbrace{(Q_{[i]}R_{i-1})\odot\beta_{[i]}}_{Cross-Chunk}","where \(R_{i}\) is the intermediate state of the \(i\)-th chunk, and \(\beta\) summarizes the data-controlled decay \(\gamma\)","\Gamma_{[i],j} &=\prod_{k=(i-1)B+1}^{(i-1)B+j}\gamma_k\quadfor  j=1,\dots,B\\D_{[i],n,m} &=\prod_{k=m+1}^{n}\gamma_{(i-1)B+k}, & n\geq m\\0, & n < m\\gRet(X_{[i]}) &=\left( Q_{[i]}\odot\Gamma_{[i]}\right) S_{[i-1]}+\left( Q_{[i]} K_{[i]}^{\intercal}\odot D_{[i]}\right) V_{[i]}","where \(\Gamma_{[i]}\) is the vector of cumulative decay factors from the previous state to each token in the chunk, \(D_{[i]}\) is the decay matrix for inner-chunk attention, and \(S_{[i-1]}\) is the state from the previous chunk."
neurips_2024_oral_60,8,"head_{i}=gRet(X) || Y=GroupNorm_{h}(Concat(head_{1},\cdots,head_{n})) || MHGR(X)=(swish(XW_{G})\odot Y)W_{O}",,"Q_{i} &=(X W_{Q}^{(i)})\odot\Theta,\quad K_{i}=(X W_{K}^{(i)})\odot\overline{\Theta},\quad V_{i}=X W_{V}^{(i)}\\\gamma_{i} &=sigmoid(X W_{\gamma}^{(i)})^{1/\tau}\\D_{i,nm} &=\prod_{k=m+1}^{n}\gamma_{i,k}, & n\geq m\\0, & n < m\\head_{i} &=(Q_{i} K_{i}^{\intercal}\odot D_{i}) V_{i}\\MgRet(X) &=Concat(head_{1},\cdots,head_{h}) W_{O}","where \(W_{Q}^{(i)}, W_{K}^{(i)}, W_{V}^{(i)} \in \mathbb{R}^{d \times d_{h}}\) and \(W_{\gamma}^{(i)} \in \mathbb{R}^{d \times 1}\) are learnable weights for the \(i\)-th head, \(d_{h}\) is the head dimension, \(W_{O} \in \mathbb{R}^{(h d_{h}) \times d}\) is the output projection matrix, and \(\Theta\) is the rotary embedding from Equation (5)."
neurips_2024_oral_8,1,w_{i}^{t}=\alpha^{t}W^{t-1}+(1-\alpha^{t})\hat{w}_{i}^{t},where \(\alpha^{t}\) is the fusion factor used to control the quality of the fused global model \(\mathcal{W}^{t-1}\),w_{i}^{t}=\betaW^{t-1}+(1-\beta)\hat{w}_{i}^{t},The fused model \(\mathbf{w}_{i}^{t}\) combines the global model \(\mathcal{W}^{t-1}\) and the locally fine-tuned model \(\hat{\mathbf{w}}_{i}^{t}\) using a fusion coefficient \(\beta\).
neurips_2024_oral_8,2,"\alpha^{t}=\max\{(1-\epsilon)^{t-1}\alpha_{0},\alpha_{min}\}",,"\alpha^{t}=\max\left(\alpha_{\min},\alpha_{0} (1-\epsilon)^{t}\right)","\(\alpha^{t}\) is the dynamically adjusted fusion factor at round \(t\), where \(\alpha_{0}\) is the initial fusion factor, \(\epsilon\) is the sensitivity factor controlling decay speed, and \(\alpha_{\min}\) is the minimum fusion factor."
neurips_2024_oral_8,3,L^{DAR}_{i}= || g_{e}(w_{e}\odotM_{e};x_{i}) || _{2}^{2},,"M_{i}^{t}=I\left(\|w_{i,c}^{t}\|_1\geq\tau_i^t\right) for each channel  c","where \(\tau_i^t\) is the threshold chosen such that the proportion of parameters pruned (set to 0) in \(\mathbf{M}_{i}^{t}\) equals the pruning ratio \(\rho_i\), with \(\| \cdot \|_1\) denoting the channel-wise L1 norm."
neurips_2024_oral_8,4,"L^{CE}_{i}=-\frac{1}{|K_{i}|}\sum_{k\inK_{i}}y_{ i,k}\log(\hat{y}_{i,k})","where \(\mathcal{K}_{i}\) denotes the set of possible labels on the client \(i\), \(\hat{y}_{i,k}\) denotes predicting label, and \(y_{i,k}\) denotes ground-truth label","L^{CE}_{i}=-\sum_{c=1}^{C} y_{i,c}\log(\hat{y}_{i,c})","where \(\hat{y}_{i,c}\) is the predicted probability for class \(c\) and \(y_{i,c}\) is the one-hot encoded ground truth label for a sample from client \(i\)."
neurips_2024_oral_8,5,L_{i}=L^{CE}_{i}+\gammaL^{DAR}_{i},where the \(\gamma\) is a pre-defined coefficient controlling the importance of \(\mathcal{L}^{DAR}_{i}\) relative to \(\mathcal{L}^{CE}_{i}\),L_i=L^{CE}_i+\lambdaL^{DAR}_i,"\(\mathcal{L}_i\) is the overall training objective for client \(i\), defined as the sum of the cross-entropy loss \(\mathcal{L}^{CE}_i\) and the domain adaptive regularization loss \(\mathcal{L}^{DAR}_i\) scaled by hyperparameter \(\lambda\)."
neurips_2024_oral_8,6,w^{t}_{i}:=\underbrace{w^{t}_{i}\odotM^{t}_{i}}_{local knowledge}+\underbrace{W^{t-1}\odot\overline{M}^{t}_{i}}_{global knowledge},"where \(\mathcal{W}^{t-1}\) is the global model aggregated at the \((t-1)\)-th round, and \(\overline{\mathbf{M}}^{t}_{i}\) denotes the logical NOT operation applied to \(\mathbf{M}^{t}_{i}\)","w_{i,recovered}^{t}=w_{i}^{t}\odotM_{i}^{t}+W^{t-1}\odot (1-M_{i}^{t})","The recovered model \(\mathbf{w}_{i,recovered}^{t}\) is constructed by combining the locally updated weights for the retained channels and the global model weights for the pruned channels."
neurips_2024_oral_8,7,W^{t}=\sum_{i\inC}\frac{|D_{i}|}{|D|}w_{i}^{t},"where \(|\mathcal{D}_{i}|\) is the sample number in the local dataset on client \(i\), and \(|\mathcal{D}|\) is the total number of samples in the entire FL system",W^{t}=\frac{1}{|C|}\sum_{i\inC}w_{i}^{t},"where \(\mathcal{W}^{t}\) is the global model at round \(t\), and \(\mathbf{w}_{i}^{t}\) is the recovered local model of client \(i\)."
neurips_2024_oral_9,1,"lh_{Q}=(Q_{i}^{d},subqs^{i})(i=1,2,...,K)",,"sim(Q, Q_i^d)=\frac{Q\cdotQ_i^d}{\left\|Q\right\|\left\|Q_i^d\right\|}",The cosine similarity between the vector representation of the current question $Q$ and the vector representation of the $i$-th example question $Q_i^d$.
neurips_2024_oral_9,2,"\{q_{t+1}^{j},j=1,...,J\}\gets Decompose(p_{\theta},\;h_{1},\;lh_{Q},\;q_ {t})",,"\{ q_{t+1}^{j}\}_{j=1}^{J}=LLM(h_1, lh_Q, q_t)",This equation formulates the decomposition of sub-question \( q_t \) at level \( t \) into sub-questions \( \{ q_{t+1}^j \}_{j=1}^J \) at level \( t+1 \) using a large language model (LLM) prompted with the heuristic-enhanced input comprising prompt head \( h_1 \) and logic heuristics \( lh_Q \).
neurips_2024_oral_9,3,"r_{t+1}^{j}\gets Solve(p_{\theta},\;h_{2},\;q_{t+1}^{j})",,"r_{t+1}^{j}\gets Analyze(p_{\theta},\; h_{2},\; q_{t+1}^{j})\quadfor  j=1,\dots,J","The rationale \( r_{t+1}^{j} \) for each sub-question \( q_{t+1}^{j} \) is generated by the Analyze function using the language model \( p_{\theta} \), prompt head \( h_2 \), and the sub-question."
neurips_2024_oral_9,4,"\hat{r}_{t+1}^{j}\gets Self\_Check(p_{\theta},\;h_{3},\;q_{t+1}^{j},\;r_{t+1}^{j})",,"\hat{r}_{t+1}^{j}\getsSelfCheck(p_{\theta}, h_{3}, r_{t+1}^{j})",The corrected rationale for sub-question \(q_{t+1}^{j}\) after self-check and potential error correction using prompt head \(h_{3}\).
neurips_2024_oral_9,5,"s_{t+1}^{j}\gets Score(p_{\theta},\;h_{4},\;q_{t+1}^{j},\;\hat{r}_{t+1}^{j })",,"s_{t+1}^{j}\gets Evaluate\_Coherence(p_{\theta},\; h_{4},\; q_{t+1}^{j},\;\hat{r}_{t+1}^{j})",The coherence score \( s_{t+1}^{j} \) is generated by evaluating the logical coherence between the sub-question \( q_{t+1}^{j} \) and the refined rationale \( \hat{r}_{t+1}^{j} \) using the LLM with prompt head \( h_4 \).
neurips_2024_oral_9,6,"n_{t+1}^{j}=(q_{t+1}^{j},\hat{r}_{t+1}^{j},s_{t+1}^{j})",where \(s_{t+1}^{j}\) can support the current or subsequent cycles in _Rethink_ (4,"n_{t+1}^{j}\gets (q_{t+1}^{j},\hat{r}_{t+1}^{j}, s_{t+1}^{j})","The node \(n_{t+1}^{j}\) is filled with the sub-question \(q_{t+1}^{j}\), refined rationale \(\hat{r}_{t+1}^{j}\), and coherence score \(s_{t+1}^{j}\)."
neurips_2024_oral_9,7,"L_{k}\gets Extract(p_{\theta},\h_{5},\L,q_{t+1}^{j}),\L_{k}\subseteq L",where \(h_{5}\) is a prompt head (_Appendix_ A,"L_{k}\gets Extract\_Related(p_{\theta},\; L,\; q_{t+1}^{j},\; k)",\( L_k \) is the set of \( k \) most related nodes extracted from ancestral nodes \( L \triangleq \{n_l \mid l \leq t\} \) for sub-question \( q_{t+1}^{j} \).
neurips_2024_oral_9,8,"r^{\prime}\gets Update(p_{\theta},\h_{6},\n_{e}(q,r,s),\\hat{r}_{t+1}^{j})",,"\hat{r}_e'\gets Update(p_{\theta}, h_6, n_e,\hat{r}_{t+1}^{j})",The updated rationale for the extracted node \(n_{e}\) using the rationale of the current node \(n_{t+1}^{j}\).
neurips_2024_oral_9,9,"n_{e}(q,r^{\prime},s)\gets n_{e}(q,r,s)",,"n_e\leftarrow (q, r', s)",The node \(n_e\) is updated by replacing its rationale with \(r'\) while retaining its original question and score.
