paper_id,equation_id,ground_truth_eq,ground_truth_description,generated_equation,generated_description
2024.acl-short.12,1,ECE=\sum_{i=1}^{B}\frac{n_{b_{i}}}{N}|acc(b_{i})-conf(b_{i})|,"where \(i\) denotes \(i\)-th bin, \(N\) is the total instance count of the dataset, \(acc(b_{i})\) and \(conf(b_{i})\) represent the accuracy and confidence of the bin \(b_{i}\), and \(n_{b_{i}}\) is the instance number of the bin \(b_{i}\)",ECE=\sum_{i=1}^n\frac{|B_i|}{n} |acc(B_i)-conf(B_i)|,The Expected Calibration Error (ECE) measures the difference between a model's estimated probabilities and true probabilities.
2024.acl-short.12,2,"GECE=\frac{|M(pred,ref)-\frac{1}{n}\sum_{i=1}^{n}p(t_{i})|}{\alpha\cdot[E(\bigtriangledown_{ins})\cdot\bigtriangledown_{ins}]}","where \(pred\) and \(ref\) represent the generated text and the referenced ground truth, respectively",GECE=\frac{1}{B}\sum_{b=1}^{B}\left|\frac{\sum_{i=1}^{n_b} (p_i-\hat{p_i})}{n_b}\right|\cdot\frac{1}{n_b}\sum_{i=1}^{n_b} (METEOR(i)+\alpha\cdot wf(i)+\beta\cdot dp(i)),"The GECE metric combines the expected calibration error with METEOR score, average word frequency, and dot product of gradients to detect long-tailness in text generation."
2024.acl-short.14,1,"P(cot,T|KG) || =P((s_{1},t_{1}),\cdots,(s_{n},t_{n}),T|KG) || =\prod_{i=1}^{n}P((s_{i},t_{i})|(s_{1},t_{1}),\cdots,(s_{i-1},t_ {i-1}),KG)\cdot || P(T|(s_{1},t_{1}),\cdots,(s_{n},t_{n}),KG) || =\prod_{i=1}^{n}P(t_{i}|(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}),KG)\cdot || \prod_{i=1}^{n}P(s_{i})|t_{i},(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}),KG)\cdot || P(T|(s_{1},t_{1}),\cdots,(s_{n},t_{n}),KG)",,p(y |G)=\prod_{i=1}^{N} p(y_i |G_i),"The probability of generating a text $\mathbf{y}$ given a knowledge graph $\mathbf{G}$, where $\mathbf{y}_i$ is the $i$-th sentence and $\mathbf{G}_i$ is the subset of triples corresponding to the $i$-th sentence."
2024.acl-short.14,2,"L_{seq}=-logP((s_{1},t_{1}),\cdots,(s_{n},t_{n}),T|KG) || =-\sum_{i=1}^{n}logP(t_{i}|(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}) || KG)-\sum_{i=1}^{n}logP(s_{i})|t_{i},(s_{1},t_{1 }),\cdots,(s_{i-1} || t_{i-1}),KG)-\sum_{i=1}^{n}logP(T|(s_{1},t_{1 }),\cdots,(s_{n} || t_{n}),KG)",,"L=-\sum_{i=1}^{n}\log P(t_{i}|(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}),KG)-\sum_{i=1}^{n}\log P(s_{i}|t_{i},(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}),KG)-\log P(T|(s_{1},t_{1}),\cdots,(s_{n},t_{n}),KG)",The cross-entropy loss function L is used to optimize the model by minimizing the difference between predicted and actual probabilities.
2024.acl-short.14,3,"L_{re}=-\textbf{log}P(r|h,t,T) || =-\textbf{log}\prod_{i=1}^{m}P(r_{i}|r_{<i},h,t,T)",,"L_{rel}=-\sum_{i=1}^{m}logP(r_{i}|h_{i},t_{i},KG)","The variable \(r_{i}\) represents the relation between the head entity \(h_{i}\) and the tail entity \(t_{i}\) in the \(i\)-th triple, and \(m\) is the number of sampled triples."
2024.acl-short.14,4,L=\alpha_{1}L_{seq}+\alpha_{2}L_{re},where \(\alpha_{1}\) and \(\alpha_{2}\) are parameters to tune,L=L_{seq}+\alpha L_{re},"The total loss L is the sum of the sequential sentence-level generation loss and the backward relation extraction loss, where α is a hyperparameter that controls the weight of the backward relation extraction loss."
2024.acl-short.15,1,"(o^{I},o^{S})=f(x)",where \(f(\cdot)\) is the joint model; \(\mathbf{o}^{I}\) and \(\mathbf{o}^{S}\) denotes an intent label and a slot sequence,"x=(x_1, x_2, ..., x_n)",\( \mathbf{x} \) represents the input sentence in the target language.
2024.acl-short.15,2,"\hat{Q}_{[i,j]}=norm(Q_{[i,j]})","where \(\mathrm{norm}(\cdot)\) denotes row normalization, which constrains the values to lie between 0 and 1","L_{C}=\sum_{[i,j]}C_{[i,j]}Q_{[i,j]}","where \(\mathcal{L}_{\mathbf{C}}\) represents the loss function for optimal transport, \(\mathbf{C}\) is the transport cost matrix, and \(\mathbf{Q}\) is the alignment matrix."
2024.acl-short.15,3,"L_{RLA}=-\sum_{[i,j]}\hat{Q}_{[i,j]}\log(\sigma(1-C_{[i,j]}))","where \(\sigma\) denotes the sigmoid function, and \(1-\mathbf{C}_{[i,j]}\) denotes the cosine similarity between \(\mathbf{h}_{i}\) and \(\mathbf{h}^{\prime}_{j}\)","L_{align}=\sum_{i,j}\hat{Q}_{[i,j]}\cdot\left\lVerth_i-h'_j\right\rVert_2^2",where \(\left\lVert \mathbf{h}_i - \mathbf{h}'_j \right\rVert_2^2\) denotes the squared Euclidean distance between the representations of the original and code-switched sentences.
2024.acl-short.15,4,P^{I}_{x}=softmax(W^{I}h_{CLS}+b^{I}) || P^{I}_{x^{\prime}}=softmax(W^{I}h^{\prime}_{CLS}+b^{I}),,o^{I}=decoder^{I}(h_{CLS}),where \(\mathbf{o}^{I}\) denotes the predicted intent label.
2024.acl-short.15,5,P^{S}_{x}=softmax(W^{S}h_{[1:-1]}+b^{ S}) || P^{S}_{x^{\prime}}=softmax(W^{S}h^{\prime}_{[1:-1]}+b^{S}),,P^{S}_{x}=softmax(W^{S}h_{[1:-1]}+ b^{S}),where \(\mathbf{W}^{S}\) and \(\mathbf{b}^{S}\) are learnable parameters for the slot filling task.
2024.acl-short.15,6,"L_{I}=CE(P^{I}_{x},P^{I}) || L_{S}=\frac{1}{L}\sum_{i=1}^{L}CE(P^{S}_{[x,i]},P^{S}_{i})",,L_{I}=-\sum_{x\inD}y^{I}_{x}\logP^{I}_{x},"where \(\mathbf{y}^{I}_{\mathbf{x}}\) and \(\mathbf{y}^{S}_{\mathbf{x},t}\) denote the ground truth intent label and slot label at position \(t\), respectively."
2024.acl-short.15,7,L_{PLA}=\underbrace{KL(P^{I}_{x^{\prime}} || P^{I}_{x})}_{Intent PLA}+\underbrace{KL(P^{S}_{x^{\prime}} || P^{S}_{x}) }_{Slot PLA},"where \(\mathrm{KL}(\cdot)\) denotes Kullback-Leibler divergence (Kullback and Leibler, 1951) to measure the difference between two distributions",L_{PLA}^{I}=KL(P^{I}_{x} || P^{I}_{x^{\prime}})+KL(P^{I}_{x^{\prime}} || P^{I}_{x}),"where \(\mathrm{KL}(\cdot || \cdot)\) denotes the Kullback-Leibler divergence, measuring the difference between two probability distributions."
2024.acl-short.15,8,"L_{SD}=\underbrace{KL(P^{[I,t-1]}_{ kT} || P^{[I,t]}_{latent SD})}_{Intent SD}+\underbrace{\frac{1}{L}\sum_{i=1}^{L}KL(P^{[S,t-1]}_{[x,i]} || P^{[S,t]}_{[x,i]}) }_{Slot SD}","where \(\mathbf{P}^{[I,t]}_{\mathbf{x}}\) denotes the probability distribution of intent, \(\mathbf{P}^{[S,t]}_{[\mathbf{x},i]}\) of slot at \(i\)-th token",L_{SD}=KL(P^{t}_{x} || P^{t-1}_{x})+KL(P^{t}_{x^{\prime}} || P^{t-1}_{x^{\prime}}),"where \(\mathbf{P}^{t}_{\mathbf{x}}\) and \(\mathbf{P}^{t}_{\mathbf{x}^{\prime}}\) denote the predicted probability distributions of the original and code-switched sentences at the \(t\)-th epoch, respectively."
2024.acl-short.15,9,L=L_{I}+L_{S}+L_{RLA}+L _{PLA}+L_{SD},,L=L_{I}+L_{S}+\lambda_{1}L_{RLA}+\lambda_{2}L_{PLA}+\lambda_{3}L_{SD},"where \(\lambda_{1}\), \(\lambda_{2}\), and \(\lambda_{3}\) are hyperparameters to balance the importance of each loss component"
2024.acl-short.16,1,Y=W_{0}^{l}X+\Lambda_{b}^{l}B^{l}\Lambda_{d}^{l}A^{l}X,,Y=lora_{B}\cdot (s_{b}\cdot (lora_{A}\cdot (s_{d}\cdot X))),"The equation represents the complete operation for a layer l in the LoRA module, where X is the input, Y is the output, and lora_A, lora_B, s_d, and s_b are the down-projection linear layer, up-projection linear layer, and feature transform vectors, respectively."
2024.acl-short.16,2,"I_{A^{l}}=|\nablaL(\theta)|,\overline{T}^{(t)}_{A^{l }}=\beta_{1}\overline{T}^{(t-1)}_{A^{l}}+(1-\beta_{1})I^{(t)}_{A^{l}} || U^{(t)}_{A^{l}}=|I^{(t)}_{A^{l}}-\overline{I}^{(t)}_{A^{l}}|,\overline{U}^{(t)}_{A^{l}}=\beta_{2}\overline{U}^{(t-1)}_{A^{l}}+(1-\beta_{2} )U^{(t)}_{A^{l}} || s^{(t)}_{A^{l}}=mean(\overline{T}^{(t)}_{A^{l}}\circ\overline{U}^{(t)}_{A^{l}})",,F_{score}(A^{l})=\frac{1}{T}\sum_{t=1}^{T}\left\|\frac{\partial L}{\partial A^{l}}\right\|_{2},The freezing score \(F_{score}(A^{l})\) is calculated as the average of the L2 norm of the gradients of the loss \(L\) with respect to the low-rank tensor \(A^{l}\) over \(T\) training steps.
2024.acl-short.16,3,r(t)=\{{ll}0&0\leq t<t_{i}\\1-(1-\frac{t-t_{i}}{T-t_{i}-t_{f}})^{3}&t_{i}\leq t<T-t_{f}\\1&otherwise,"where \(t\) refers to current #step, \(T\) is the total number of fine-tuning steps",r(t)=0 & t\leq t_{i}\\\left(\frac{t-t_{i}}{T-t_{i}-t_{f}}\right)^3 & t_{i} < t < T-t_{f}\\1 & t\geq T-t_{f},"The freezing fraction r(t) is calculated based on the current training step t, the initial training steps t_i, the total training steps T, and the final freezing steps t_f."
2024.acl-short.20,1,"E(h,r,t)=\sum_{i=1}^{k}w_{i}(q)M_{i}(h,r,t)","where \(\mathtt{E}(\mathtt{h},\mathbf{r},\mathbf{t})\) is the ensemble score for \(\mathbf{t}\) given query \(\mathtt{q}=(\mathbf{h},\mathbf{r},?)\)","E=\sum_{i=1}^{k} w_iM_{i}(h,r,t)","The ensemble E is a weighted sum of the scores from each model \(\mathtt{M}_{\mathtt{i}}\), where \(w_i\) represents the weight assigned to model \(\mathtt{M}_{\mathtt{i}}\)."
2024.acl-short.20,2,"M_{i}(h,r,t)\getsM_ {i}(h,r,t)-\min_{t^{\prime}\inE}M_{i}(h,r,t^{\prime}) || M_{i}(h,r,t)arrow\frac{M_{i}(h,r,t)}{\max_{t^{\prime}\inE}M_{i}(h,r,t^{\prime})}",,"\bar{M}_{i}(h,r,t)=\frac{M_{i}(h,r,t)-\min_{t'\inE}M_{i}(h,r,t')}{\max_{t'\inE}M_{i}(h,r,t')-\min_{t'\inE}M_{i}(h,r,t')}","The normalized score for model \(\mathtt{M}_{\mathtt{i}}\) given query \(\mathtt{q}=(\mathbf{h},\mathbf{r},?)\) and candidate tail \(\mathbf{t}\)."
2024.acl-short.20,3,"f(M_{i},q)=\underset{t^{\prime}\inE}{mean}(M_{i}(h,r,t^{\prime})) || \underset{t^{\prime}\inE}{ var}(M_{i}(h,r,t^{\prime}))",,"f_{i}(q)=\left[M_{i}(h,r,t^{gt}),\frac{1}{|E|}\sum_{t\inE}M_{i}(h,r,t)\right]",The feature vector \(\mathbf{f}_{\mathtt{i}}(\mathtt{q})\) for model \(\mathtt{M}_{\mathtt{i}}\) given query \(\mathtt{q}\) includes the score of the ground truth tail \(\mathtt{t}^{\mathtt{gt}}\) and the average score of all candidate tails.
2024.acl-short.20,4,"w_{1}(q)=MLP_{1}(f(M_{1},q) || f(M_{2},q) ||  || f(M_ {k},q))",,"w_{i}=MLP_{i}(f(M_{1},q) || f(M_{2},q) ||  || f(M_{k},q))",The weight \(\mathbf{w}_{\mathtt{i}}\) for model \(\mathtt{M}_{\mathtt{i}}\) is obtained by passing the concatenated feature vector through a 2-layer MLP.
2024.acl-short.20,5,"L=\sum_{t\inN}\max(E(h,r,t)-E(h,r,t^{*})+m,0)",where \(\mathtt{m}\) is the margin hyperparameter,"L(q)=\max(0,\gamma-(E(h,r,t^{\ast})-\max_{t\inN}E(h,r,t)))","The loss function $\mathcal{L}$ for query $\mathtt{q}=(\mathtt{h},\mathtt{r},?)$ is defined as the margin loss between the score of the gold entity $\mathtt{t}^{\ast}$ and the maximum score of the negative samples $\mathtt{N}$."
2024.acl-short.25,1,"s_{i}=\sigma(\frac{1}{\beta_{i}}(log\frac{\mu_{i}}{1-\mu_{i}}+\textit{log}\alpha_{i})) || m_{i}=min(1,max(0,s_{i}(\zeta-\gamma)+\gamma))",,"m_{i}\simHardConcrete(\log\alpha_{i},\beta_{i})","The variable \(m_{i}\) represents the mask corresponding to each neuron, which follows a hard concrete distribution with parameters \(\log \alpha_{i}\) and \(\beta_{i}\)."
2024.acl-short.25,2,"min(1,max(0,\sigma(log\alpha_{i})(\zeta-\gamma)+\gamma))",,m_{i}=I[\log\alpha_{i} > 0]\,"\(m_{i}\) represents the discrete mask value of each neuron, where \(\mathbb{I}\) denotes the indicator function."
2024.acl-short.25,3,"L_{m}(f(m\odot\theta),x)=\sum_{i=1}^{I}log(P(x_{p+i}|x_{<p+i}))",,"L_{m}(f(m\odot\theta),x)=-\sum_{t=p}^{p+I}logf(m\odot\theta)(x_{t})",\(\mathcal{L}_{m}\) represents the training loss for localizing PII-specific neurons.
2024.acl-short.25,4,"L_{adv}(f(m\odot\theta),x)=-\sum_{t=1}^{T}log(P(x_{t}|x_{<t}))",,"L_{adv}(f(m\odot\theta),x)=-\sum_{i=1}^{T}log(P(x_{i}|x_{<i}))",\(\mathcal{L}_{adv}\) denotes the adversarial loss for preserving language modeling ability.
2024.acl-short.25,5,R(m)=-\frac{1}{|m|}\sum_{i=1}^{|m|}\sigma(log\alpha_{i}-\beta_{i}log \frac{-\gamma}{\zeta}),,R(m)=\sum_{i=1}^{N}I(m_i <\gamma),The regularization term \(R(m)\) is used to penalize the number of localized neurons by minimizing the \(L_{0}\) complexity of mask scores.
2024.acl-short.3,1,"\Delta(G_{1},G_{2})=\min_{ops}\sum_{i=1}^{n}w(op_{i})",,"\Delta=APTED(G_{1}, G_{2})",\(\Delta\) represents the tree edit distance between the predicted code's AST and the ground-truth AST.
2024.acl-short.3,2,"TSED=\max\{1-\frac{\delta}{MaxNodes(G_{1},G_{2})},0\}",,"\Delta_{norm}(G_{1},G_{2})=\frac{\Delta(G_{1},G_{2})}{\max(|G_{1}|,|G_{2}|)+\alpha\cdot\sigma(|G_{1}|,|G_{2}|)}","\(\Delta_{norm}(G_{1},G_{2})\) represents the normalized tree edit distance between the predicted code's AST \(G_{1}\) and the ground-truth code's AST \(G_{2}\), where \(\alpha\) is a hyperparameter and \(\sigma(|G_{1}|,|G_{2}|)\) is a ramp function."
2024.acl-short.39,1,"Bio(m,co(m))=f_{gen}(m,co(m))",where biography is generated by the model \(f_{gen}\) given the personal attribute of interest (\(m\)) and the co-occurring attributes (\(co(m)\)),"x=(a_1, a_2, ..., a_n)",x represents the input infobox containing n personal attributes
2024.acl-short.39,2,"Bio(\phi,co(m))=f_{gen}(\phi,co(m))",,"S=\frac{1}{N}\sum_{i=1}^{N} (S_{match}(Bio(m,co(m)))+S_{sent}(Bio(m,co(m))))","where S represents the overall score, N is the total number of biographies, S_match is the semantic matching score, and S_sent is the sentiment score."
2024.acl-short.39,3,"Bio(f,co(m))=f_{gen}(f,co(m)),do(m\to f)","where \(do(m\to f)\) denotes the do operator (Pearl, 2009), e","Bio(m',co(m))=f_{gen}(m',co(m))",where biography is generated by the model \(f_{gen}\) given the counterfactual personal attribute of interest (\(m'\)) and the co-occurring attributes (\(co(m)\))
2024.acl-short.40,1,"L_{e}=\frac{1}{N}\sum_{i=1}^{N}(\cos(S_{1,i},S_{2,i})-\cos(E_{1,i},E_{2,i}))^{2}","where \(N\) is the batch size, and \(S\) and \(E\) contain the target text SEM vectors and the predicted output SEM vectors respectively",L=\frac{1}{2} (d-s)^2,The loss L is calculated as the minimum squared error (MSE) between the distance d and the similarity score s.
2024.acl-short.40,2,"L_{o}=CE(T,O)=-\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{M} (T_{ij}\cdot\log(O_{ij}))","where \(N\) is the batch size, \(M\) the vocabulary size, \(T\) is the target text and \(O\) is the output text","L_{t}=-\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{M}y_{i,j}\log(p_{i,j})","where \(N\) is the batch size, \(M\) is the sequence length, \(y_{i,j}\) is the true label, and \(p_{i,j}\) is the predicted probability."
2024.acl-short.41,1,E(y)=h(\beta+\sum_{j=1}^{J}f_{j}(x_{j})),"where \(h(\cdot)\) is the activation function used in the output layer, e",y=\beta_0+\beta_1 z+\beta_2 t+\epsilon,"The equation represents a general form of a NAM, where y is the target variable, z is the topic, t is the additional tabular variable, and ε is the error term."
2024.acl-short.41,2,h(E[y])=\beta+\sum_{j=1}^{J}f_{j}(x_{j(tab)})+\sum_{k=1}^{ K}f_{k}(x_{k(top)}),,"z\equiv(x_{tab},x_{top})",where \(\mathbf{z}\) is a combination of tabular features \(\mathbf{x}_{tab}\) and topical features \(\mathbf{x}_{top}\).
2024.acl-short.43,1,P(c|s)=\frac{\exp(b_{c}\cdot\frac{1}{T}\sum_{t=1}^{T}x_{t})}{\sum_{c^{\prime}=1}^{N}\exp(b_{c^{\prime}}\cdot\frac{1}{T}\sum_{t=1}^ {T}x_{t})},,p(c|s)=\frac{\exp(w_c^T\cdot\frac{1}{T}\sum_{t=1}^{T}x_t+b_c)}{\sum_{k=1}^{N}\exp(w_k^T\cdot\frac{1}{T}\sum_{t=1}^{T}x_t+b_k)},"The posterior probability of language c given sentence s, where \(\mathbf{w}_c\) and \(b_c\) are learnable weights and bias for language c, and N is the total number of languages."
2024.acl-short.43,2,"V_{c,t}(s)=b_{c}\cdotx_{t}",,"V_{c,t}(s)=b_{c}\cdotx_{t}","\(\mathbf{V}_{c,t}(s)\) represents the logits for language \(c\) and word-level feature \(\mathbf{x}_{t}\)."
2024.acl-short.49,1,CEF=\frac{\sum_{i=0}^{n}(I_{i}-\overline{I} )(M_{i}-\overline{M})}{\sqrt{\sum_{i=1}^ {n}(I_{i}-\overline{I})^{2}}\sqrt{\sum_{i=1}^ {n}(M_{i}-\overline{M})^{2}}},where \(\overline{x}=\frac{1}{n}\sum_{i=1}^{n}x_{i}\) (the sample mean),"\rho=\frac{\cov(I,M)}{\sigma_{I}\sigma_{M}}","The Pearson correlation coefficient, denoted as \(\rho\), measures the linear correlation between the prediction impact \(\mathcal{I}\) and the mention importance \(\mathcal{M}\)."
2024.acl-short.49,2,"TVD(P,Q)=\frac{1}{2}\sum_{x}|P(x)-Q(x)|",where P and Q are probability distributions over discrete classes,TVD=\frac{1}{2}\sum_{c=1}^{C}|P(c|x)-P(c|x_{IA})|,The total variation distance measures the difference between the model's predictions for the original input and the input with the inserted IA.
2024.acl-short.49,3,CCT=\frac{E_{M}(TVD)-E_{-M}(TVD)}{STD(TVD)}\sqrt{\frac{|M || \neg M|}{|M\cup\neg M|^{2}}},"where \(M\) indicates that the explanation mentions the IA, and \(|M|\) indicates the number of examples with explanation mentions",CCT=\frac{\sum_{i=0}^{n}(TVD_{i}-\overline{TVD})(M_{i}-\overline{M})}{\sqrt{\sum_{i=1}^{n}(TVD_{i}-\overline{TVD})^{2}}\sqrt{\sum_{i=1}^{n}(M_{i}-\overline{M})^{2}}},where TVD represents the total variation distance and \(\mathcal{M}\) represents the mention importance
2024.acl-short.5,1,"s_{ori}(x_{i}|x_{<i})= || \{{ll}\log P_{M_{e}}(x_{i}|x_{<i})-\log P_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{ori,i}^{\alpha}\\-\infty,&x_{i}\notinV_{ori,i}^{\alpha}\\s_{imp}(x_{i}|x_{<i})=\\\{{ll}(1+\beta)Y_{M_{a}}(x_{i}|x_{<i})-\beta Y_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{imp,i}^{\alpha}\\-\infty,&x_{i}\notinV_{imp,i} || s_{int}(x_{i}|x_{<i})= || \{{ll}(1+\beta)Y_{M_{e}}(x_{i}|x_{< i})-\beta Y_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{imp,i}^{\alpha}\\-\infty,&x_{i}\notinV_{imp,i}",,s_{ori}(x_{i}|x_{<i})=\log\frac{p_{exp}(x_{i}|x_{<i})}{p_{ama}(x_{i}|x_{<i})},The original contrastive decoding logit score \(s_{\text{ori}}(x_{i}|x_{<i})\) represents the logarithm of the ratio of the expert language model probability to the amateur language model probability.
2024.acl-short.5,2,"V_{ori,i}^{\alpha}=\{w|P_{M_{e}}(w|x_{<i})>\alpha\max_{w\inV}P_{M_{e}}(w|x_{<i})\} || V_{imp,i}^{\alpha}=\{w|Y_{M_{e}}(w| x_{<i})>\log\alpha+\max_{w\inV}Y_{M_{e}}(w|x_{<i})\}",,"V_{ori,i}^{\alpha}=\{x_{i}|\log P_{M_{e}}(x_{i}|x_{<i})\geq\alpha\}","\(\mathcal{V}_{\text{ori},i}^{\alpha}\) represents the set of tokens that satisfy the adaptive plausibility constraint for the original contrastive decoding."
2024.acl-short.53,1,"L_{FT}=\frac{1}{|D_{M}|}\sum_{d\inD_{M}}L(d;\Phi _{0},\Delta\Phi)","where \(\mathcal{D}_{M}\) is the KE dataset and \(d\) is a fact edit example, \(L\) is the cross entropy loss function applied to autoregressive models, \(\Phi_{0}\) denotes the set of original weights of the language model that are kept frozen, and \(\Delta\Phi\) denotes the additional parameters used by the PEFT adapters",L=\frac{1}{N}\sum_{i=1}^{N} (y_i-\hat{y_i})^2,The loss function L measures the mean squared error between predicted and actual values.
2024.acl-short.53,2,h=W_{0}x+BAx=(W_{0}+BA)x,,L_{LoRA}=\frac{1}{|D_{M}|}\sum_{d\inD_{M}}L(d;(\Phi _{0}+BA)\Delta\Phi),"The loss function for LoRA, where low-rank matrices B and A are used to update the model parameters."
2024.acl-short.56,1,h^{\prime}=SoftMax(h\cdoth^{\prime T})\cdoth^{\prime},,"H=(z^{\prime}_{s}+M[1],\cdots,z^{\prime}_{s}+M[K])",The hybrid latent variable H is a combination of continuous and discrete latent variables.
2024.acl-short.56,2,"\mu^{\prime}_{1},...,\mu^{\prime}_{n}\\\log(\sigma^{\prime 2}_{1}),...,\log(\sigma^{\prime 2}_{n})=[h_{1};h^{\prime}_{1}]\\\cdots\\[h_{n};h^{\prime}_{n}]W^{\prime}_{u}\","where \(W^{\prime}_{u}\) is trainable parameters of \(q_{\phi}(z|r,c)\)","q_{\phi}(z|c,r)=N(\mu^{\prime},\sigma^{\prime 2}I)","\(q_{\phi}(z|c,r)\) represents the recognition network that estimates the isotropic Gaussian distribution of the continuous latent variable \(z\) given the user input \(c\) and the character result \(r\)."
2024.acl-short.57,1,"a_{k}^{pred}=\operatorname*{arg\,max}_{a_{k}}\!P(a_{k}|q_{k},H_{k},D)",,"a_{k}^{pred}=f(q_{k}, D, H_{k})","The predicted answer at dialog turn k is a function of the current question, the document, and the conversation history."
2024.acl-short.57,2,"P(a_{k}|q_{k},H_{k},D)=P(a_{k}|q_{k},H_{k}^{\star},D)",,"P(a_{k}|q_{k},H_{k},D)=P(a_{k}|q_{k},H_{k}^{\star},D)","The probability of the answer given the question, history, and document should be the same whether using the original or augmented history."
2024.acl-short.57,3,"L_{CE}=CE(QA_{\theta^{\prime}}(q_{k},H_{k},D),a_{k}^{gold}) || L_{Cons}=D_{KL}(QA_{\theta^{\prime}}(q_{k},H_{k},D) || QA_{\theta^{\prime}}(q_{k},H_{k}^{\star},D)) || L_{T}=L_{CE}+\lambda L_{Cons}",,L_{T}=L_{CE}+\lambda L_{Cons},"The total loss function used to train the QA network, which combines cross-entropy loss and consistency loss."
2024.acl-short.62,1,R(\tau)=\frac{1}{T}\sum_{t=1}^{T}r_{t},,R(\tau)=\frac{1}{T}\sum_{t=1}^{T} r_{t},The reward of the whole trajectory is defined as the average of rewards assigned to each token.
2024.acl-short.62,2,p(\tau^{i}\succ\tau^{j})&=\frac{\exp(R(\tau^{i}))}{\exp(R(\tau^{i}))+\exp(R(\tau^{j}))}\\&=\sigma(R(\tau^{i})-R(\tau^{j})),where \(\tau^{i}\) and \(\tau^{j}\) represent two different responses generated from the same prompt,p(y_{i}>y_{j}|\phi)=\frac{\exp(R(\tau_{i}))}{\exp(R(\tau_{i}))+\exp(R(\tau_{j}))},The probability of preferring response $y_{i}$ over $y_{j}$ given the model parameters $\phi$.
2024.acl-short.62,3,"&L=-E_{(\tau^{i},\tau^{j})\simD}[\log\sigma(R(\tau^{i})-R(\tau^{j}))]\\&=-E_{(\tau^{i},\tau^{j})\simD}[\log\sigma((\frac{1}{T^{i}}-\frac{1}{T^{j}})\sum_{t\in U_{0}}r_{t}\\&+\frac{1}{T^{i}}\sum_{t\in U_{1}}r_{t}^{i}-\frac{1}{T^{j}}\sum_ {t\in U_{1}}r_{t}^{j})]",,L=-\log p(\tau^{i}\succ\tau^{j})=-\log\sigma(R(\tau^{i})-R(\tau^{j}))=-\log\frac{1}{1+\exp(R(\tau^{j})-R(\tau^{i}))},The loss function for training the reward model as a binary classifier.
2024.acl-short.62,4,"L\approx-E_{(\tau^{i},\tau^{j} )\simD}[\log\sigma(\frac{1}{T^{i}}\sum_{t\in U_{1}}r_{t}^{i}-\frac{ 1}{T^{j}}\sum_{t\in U_{1}}r_{t}^{j})]",,"L=-E_{(\tau^{i},\tau^{j})\simD}[\log\sigma(\frac{1}{T}\sum_{t\in U_{1}}(r_{t}^{i}-r_{t}^{j}))]",The loss function simplifies to only consider the difference in rewards for the changed parts between two responses of equal length.
2024.acl-short.66,1,"H(t,a)=\mathds{1}[\{(i,t)\in a\}=\varnothing]",,\hat{y}_{t}\inHallucination\iff\not\exists x_{j} s.t.  a(\hat{y}_{t})=x_{j},The equation defines a hallucination in SiMT as a target word with no alignment to any source word.
2024.acl-short.66,2,"HR(x,\hat{y},a)=\frac{1}{|\hat{y}|}\sum_{t=1}^{|\hat{y}|}H(t,a)",,"HR=\frac{1}{T}\sum_{t=1}^{T} H(t,a)",The Hallucination Rate (HR) is the average of hallucination metrics over all target words.
2024.acl-short.66,3,"H_{wait-k}(t,a)=\mathds{1}[\{(s,t)\in a\mid s\geq t+k\}=\varnothing]",,"G(t,k,a)=\mathds{1}[\{(i,t)\in a\,|\, i\leq t+k\}=\varnothing]",The GHall function measures whether a target word is a hallucination based on its alignment with the current source words within a certain window size defined by Wait-k models.
2024.acl-short.66,4,"R(y_{i},x_{j})=P(y_{i}\midy_{<i},x_{\leq i+k-1}) || \quad-P(y_{i}\midy_{<i},x_{\leq i+k-1, (j,\textbf{0})}) || R(y_{i},y_{j})=P(y_{i}\midy_{<i},x_{\leq i+k-1}) || \quad-P(y_{i}\midy_{<i,(j,\textbf{0} )},x_{\leq i+k-1})",,"R(y_{i},x_{j})=\frac{\partial\log p(y_{i}|y_{<i},x_{\leq i+k-1})}{\partialx_{j}}",The relevance of source word x_j to the next target word y_i.
2024.acl-short.66,5,"R(y_{i})_{source-side}=\max\{|R(y_{i},x_ {j})|\} || R(y_{i})_{target-side}=\max\{|R(y_{i},y _{j})|\}",,"R_{s}(y_{i})=\max_{j} |R(y_{i},x_{j})|",The variables \(R_{s}(\text{y}_{i})\) and \(R_{t}(\text{y}_{i})\) represent the maximum absolute relevance of the source-side and target-side words to the next word \(\text{y}_{i}\) to be generated.
2024.acl-short.66,6,TSSR(y_{i})=\frac{R(y_{i})_{target-side}}{R(y_{i} )_{source-side}},,TSSR=\frac{R(y_{i})_{target-side}}{R(y_{i})_{source-side}},"TSSR represents the ratio of target-side relevance to source-side relevance, indicating the usage of target-side context in generating the next word."
2024.acl-short.68,1,"T_{i}=\operatorname*{Top\_}{d\inM}k\f(s_{i},d)",,"f(q,d)=R_{Q}(q)^{\top}R_{D}(d)",The function f calculates the similarity between a query q and a passage d using the dot product of their embeddings from the query encoder R_Q and the passage encoder R_D.
2024.acl-short.68,2,"e_{i}=LLM([Prompt,t_{i,1},\cdots,t_{i,k}])",where \(t_{i}\in\mathcal{T}_{i}\) stands for the retrieved passages in Eq,e_{i}=LLM(T_{i}),The summarized knowledge \(e_{i}\) for medical code \(c_{i}\) is generated using an off-the-shelf Large Language Model (LLM).
2024.acl-short.68,3,"h_{i}^{k}=PLM(X_{i}^{k}),\;\;\widehat{y}_{i,1}=MLP ( || _{k\inS}h_{i}^{k})",,"X_{i}^{d}=\{[CLS],D_{t},D_{t-1},\ldots,D_{1}\}","where \(D_{i}=||_{c\in D_{i}}(c,e)\) represents the concatenation of disease code and its summarized knowledge within the \(i\)-th visit."
2024.acl-short.68,4,"e_{i}=HyGT(G,V_{i}),\widehat{y}_{i,2}=MLP(e_{i})",where \(\mathbf{e}_{i}\) is the representation of patient \(i\) after hypergraph transformer,"\widehat{y}_{i,2}=f_{\theta}(G)","where \(\widehat{y}_{i,2}\) is the prediction for the target task using the local model \(f_{\theta}\) with visit information."
2024.acl-short.68,5,"L_{aug}=E_{(V_{i},y_{i})\simP}\;\ell(\widehat{y}_{i,1},y_{i})+\lambdaD_{KL}(\widehat{y}_{i,1},\widetilde{y}) || L_{loc}=E_{(V_{i},y_{i})\simP}\;\ell(\widehat{y}_{i,2},y_{i})+\lambdaD_{KL}(\widehat{y}_{i,2},\widetilde{y})",,L=L_{g_{\phi}}+L_{f_{\theta}}+\lambda\cdotL_{consistency},"where \(\mathcal{L}_{g_{\phi}}\) is the loss for the global model, \(\mathcal{L}_{f_{\theta}}\) is the loss for the local model, and \(\mathcal{L}_{\text{consistency}}\) is the consistency loss between the two models with a hyperparameter \(\lambda\)."
2024.acl-short.71,1,"hyp^{*}=\operatorname*{arg\,max}_{hyp\inhyps}utility(hyp)",,U(hyp^{*})=\max_{hyp_{i}\inhyp} U(hyp_{i}),The equation represents the utility function U for selecting the best translation hypothesis.
2024.acl-short.71,2,"utility(hyp)\approx\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}} metric(hyp,\textit{ref})",,"refs\sim p(refs|src)=\{ref_{1},\ldots,ref_{m}\}",The set of pseudo-references refs is sampled from the model distribution given the source src.
2024.acl-short.71,3,\overline{\textit{ref}}=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textit{ ref},,\overline{\textit{ref}}=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textit{ref},The aggregate representation of the set of references refs.
2024.acl-short.71,4,"utility(hyp)\approxmetric(hyp,\overline{\textit{ref}})",,"utility(\textit{hyp})\approxmetric(\textit{hyp},\overline{\textit{ref}})",The utility of a hypothesis is approximated by calculating the metric score against the aggregate reference representation.
2024.acl-short.71,5,ChrF_{\beta}=\frac{(1+\beta^{2})\cdotChrP\cdotChrR}{\beta^{2}\cdotChrP+ChrR} || ChrP=\frac{|hyp\cap\textit{ref}|}{|hyp|} and ChrR=\frac{|hyp\cap\textit{ref}|}{|\textit{ref}|},"where

\[\text{ChrP}=\frac{|hyp\cap\textit{ref}|}{|hyp|}\text{ and }\text{ChrR}=\frac{|hyp \cap\textit{ref}|}{|\textit{ref}|},\]

and the parameter \(\beta\) controls the relative importance of precision and recall",ChrF=\frac{2\cdotP\cdotR}{P+R},where P is the precision of character n-grams and R is the recall of character n-grams.
2024.acl-short.71,6,\overline{\textit{ref}}=\frac{1}{m}\underbrace{\biguplus}_{\textit{ref}\in\textit{refs}}\textit{ref},where \(\biguplus\) is an operation that sums up the counts of each n-gram,\overline{ref}(n-gram)=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textit{ref}(n-gram),The equation represents the average count of n-grams across all references.
2024.acl-short.71,7,"\textbf{{hyp}},\\textbf{{ref}},\\textbf{{src}}=emb(\textbf{{hyp}}),\emb(\textbf{{ref}}),\emb(\textbf{{src}})",,"COMET(hyp,ref,src)=\sigma(g(h_{hyp},h_{ref},h_{src}))","where $\sigma$ is the sigmoid function, $g$ is a multilayer perceptron and $h_{hyp}$, $h_{ref}$ and $h_{src}$ are the embeddings of the hypothesis, reference and source sequence respectively."
2024.acl-short.71,8,"comet(\textbf{{hyp}})=score(\textbf{{hyp}},\\textbf{{ref}},\\textbf{{src}})",,s=FFN([\textbf{{hyp}};\textbf{{ref}};\textbf{{src}}]),The variable s represents the scalar score output by the feed-forward module of the COMET Estimator model.
2024.acl-short.71,9,\overline{\textbf{{ref}}}=\frac{1}{m}\sum_{\textbf{{ref}}\in\textbf{{ref}}}emb(\textbf{{ref}}),,\overline{\textbf{ref}}=\frac{1}{m}\sum_{\textbf{ref}\in\textbf{refs}}\textbf{ref},The reference aggregation for COMET is performed by averaging the reference embeddings.
2024.acl-short.71,10,"comet(\textbf{{hyp}})\approxscore(\textbf{{hyp}},\\overline{\textbf{{ref}}},\\textbf{{src}})",,"comet(\textbf{{hyp}})=score(\textbf{{hyp}},\\overline{\textbf{{ref}}},\\textbf{{src}})",where the reference embedding is replaced with the averaged reference embedding.
2024.acl-short.72,1,h_{i}=XLMRoberta-Layer^{1}(x_{i}),"where \(h_{i}\) is the representation of the ""[CLS]"" token",x_{i}\rightarrow h_{i}=XLM-Roberta(x_{i}),The equation represents the encoding of the text representation \(x_{i}\) of the \(i\)-th DOM node into a 768-dimensional node representation \(h_{i}\) using the XLM-Roberta model.
2024.acl-short.72,2,\hat{h}_{i}=Transformer(Linear(h_{i})),where the linear layer projects \(h_{i}\) to 256-dimensional embeddings for efficient modeling,H'=Transformer(H),where \(H'\) represents the encoded node representations after passing through the transformer model
2024.acl-short.72,3,P(y^{k}_{i}=1|x_{i})=Sigmoid(MLP(\hat{h}_{i})),,P(y^{k}_{i}=1|x_{i})=\sigma(\hat{h}_{i}W^{k}+b^{k}),"where \(\sigma\) is the sigmoid function, \(W^{k}\) and \(b^{k}\) are learnable weights and bias for the \(k\)-th category label."
2024.acl-short.72,4,"L=\sum_{k=1}^{6}\sum_{i=1}^{n}CrossEntropy(P(y^{k}_{i}|x_{i}), Y^{k}_{i})",where \(\mathcal{Y}^{k}_{i}\) is the ground truth label,L=-\sum_{i=1}^{n}\sum_{k=1}^{6} y_{i}^{k}\log P(y_{i}^{k}=1|x_{i})+(1-y_{i}^{k})\log (1-P(y_{i}^{k}=1|x_{i})),where \(L\) is the binary cross-entropy loss function for training NeuScraper.
ICLR_2024_oral_1,1,I(\theta):=E_{\Upsilon\sim p_{\theta}} [\nabla_{\theta}\log p_{\theta}(\Upsilon)\cdot\nabla_{\bm {\theta}}\log p_{\theta}(\Upsilon)^{\top}],,I(\theta)=E_{p_{\theta}}\left[\left(\frac{\partial\log p_{\theta}}{\partial\theta}\right)\left(\frac{\partial\log p_{\theta}}{\partial\theta}\right)^{\top}\right],The Fisher information matrix measures the amount of information that a random variable (or a sample of data) carries about an unknown parameter.
ICLR_2024_oral_1,2,E_{D\sim p_{\theta^{\star}}}([\widehat{\theta} (D)-\theta^{\star})(\widehat{\theta}(D)-\theta^{\star})^{\top}]\succeq T^{-1}\cdotI(\theta^{\star})^ {-1},,Cov[\widehat{\theta}(D)]\succeq\frac{1}{T}I(\theta^{\star})^{-1},The covariance of the estimator is bounded by the inverse of the Fisher information matrix.
ICLR_2024_oral_1,3,E_{D\sim p_{\theta^{\star}}}[\|\widehat{\theta} (D)-\theta^{\star}\|_{2}^{2}]=tr(E_{ D\sim p_{\theta^{\star}}}[(\widehat{\theta}(D)-\theta^{\star})(\widehat{\theta}(D)-\theta^{\star})^{\top}])\geq T^{-1}\cdottr(I(\theta^{\star})^{-1}),,E_{D\sim p_{\theta^{\star}}}[\|\widehat{\theta} (D)-\theta^{\star}\|_{2}^{2}]\geqTr(T^{-1}\cdot I(\theta^{\star})^{-1}),The equation describes the relationship between the Fisher information matrix and the mean-squared error of an unbiased estimator.
ICLR_2024_oral_1,4,"I(\theta^{\star},\pi_{exp}):=E_{\tau\sim p_{\theta^{\star}}(\cdot\mid\pi_{exp})}[\nabla_{\theta}\log p_{\theta^{\star}}(\tau\mid\pi_{exp})\cdot\nabla_{\theta}\log p_{\theta^{\star}}(\tau\mid\pi_{ exp})^{\top}]",,I(\theta^{\star};\pi_{exp}):=E_{\tau_{real}\sim p_{\theta^{\star}}(\cdot\mid\pi_{exp})}[\nabla_{\theta}\log p_{\theta^{\star}}(\tau_{real}\mid\pi_{exp})\cdot\nabla_{\theta}\log p_{\theta^{\star}}(\tau_{real}\mid\pi_{exp})^{\top}],The Fisher information matrix $\mathcal{I}(\mathbf{\theta}^{\star};\pi_{\mathrm{exp}})$ represents the amount of information that the exploration policy $\pi_{\mathrm{exp}}$ provides about the true parameter $\mathbf{\theta}^{\star}$.
ICLR_2024_oral_1,5,"\arg\min_{\pi}tr(I(\theta^{\star},\pi)^{-1})",,"\pi_{exp}^{\star}\in\arg\min_{\pi_{exp}}tr(I(\theta^{\star},\pi_{exp})^{-1})",The optimal exploration policy is the one that minimizes the trace of the inverse Fisher information matrix.
ICLR_2024_oral_1,6,"s_{h+1}=f_{\theta}(s_{h},a_{h})+w_{h}","where \(s_{h}\) and \(a_{h}\) are the current state and action, \(w_{h}\sim\mathcal{N}(0,\sigma_{w}^{2}\cdot I)\) is Gaussian process noise, and \(f_{\mathbf{\theta}}\) are the nominal dynamics","s_{h+1}\sim f_{\theta}(s_{h}, a_{h})=N(\mu_{\theta}(s_{h}, a_{h}),\Sigma_{\theta}(s_{h}, a_{h}))","The equation represents the evolution of the next state in the environment, modeled as a Gaussian distribution with mean and covariance dependent on the current state, action, and unknown parameter."
ICLR_2024_oral_1,7,"I(\theta,\pi)=\sigma_{w}^{-2}\cdotE_{p_{\theta}(\cdot\mid\pi)}[\sum_{h=1}^{H}\nabla_{\theta}f_{\theta}(s_{h},a_ {h})\cdot\nabla_{\theta}f_{\theta}(s_{h},a_{h})^{\top}]",,"I(\theta,\pi)=\sum_{h=1}^{H}E_{(s_{h},a_{h})\sim p_{\theta}(\cdot\mid\pi)}[\nabla_{\theta}f_{\theta}(s_{h},a_{h})\cdot\nabla_{\theta}f_{\theta}(s_{h},a_{h})^{\top}]/\sigma_{w}^{2}",The Fisher information matrix under the assumed dynamics.
ICLR_2024_oral_1,8,"\pi_{exp}=\arg\min_{\pi}E_{\theta\sim q_{0}}[tr (I(\theta,\pi)^{-1})]",,"\arg\min_{\pi}E_{\theta\simU(\Theta)}[tr(I(\theta,\pi)^{-1})]",The equation represents the optimization problem for choosing an exploration policy that minimizes the expected trace of the inverse Fisher information matrix over a uniform distribution of parameters.
ICLR_2024_oral_1,9,E_{\theta\sim q_{\theta}}[E_{\tau_{ sim}\sim p_{\theta}(\cdot\midA(\uptau_{real}) )}[\|\uptau_{real}-\uptau_{sim}\|_{2}^{2}]],"where \(p_{\mathbf{\theta}}(\cdot\mid\mathcal{A}(\mathbf{\uptau}_{\mathrm{real}}))\) denotes the distribution over trajectories generated by the simulator with parameter \(\mathbf{\theta}\), and playing the same sequence of actions as were played in \(\mathbf{\uptau}_{\mathrm{real}}\)",\min_{q_{\phi}}D_{KL}(p_{\theta^{\star}}(\cdot\mid\pi_{exp})~ || ~q_{\phi}(\cdot\mid\pi_{exp})),The Kullback-Leibler divergence between the distribution over trajectories induced by the true environment and the distribution over trajectories induced by the simulator.
ICLR_2024_oral_10,1,"R=\{r_{1},\dots,r_{m}\}",where each ray \(\mathbf{r}_{i}\in\mathbb{R}^{6}\) is associated with a known pixel coordinate \(\mathbf{u}_{i}\),u=K[R\midT]x,The equation represents the camera projection from world coordinates to pixel coordinates.
ICLR_2024_oral_10,2,"r=\langled,m\rangle\inR^{6}","where \(\mathbf{m}=\mathbf{p}\times\mathbf{d}\in\mathbb{R}^{3}\) is the moment vector, and importantly, is agnostic to the specific point on the ray used to compute it",r=d\\p\timesd,The Plucker coordinates representation of a ray.
ICLR_2024_oral_10,3,"d=R^{\top}K^{-1}u,\qquadm=(-R^{\top}t)\timesd",,m=c\timesd,where \(\mathbf{c}\) is the camera center and \(\mathbf{d}\) is the direction of the ray
ICLR_2024_oral_10,4,"c=\operatorname*{arg\,min}_{p\inR^{3}}\\sum_{\langled,m\rangle\inR}\lVertp\timesd-m\rVert^{2}",,"c=\frac{1}{m}\sum_{i=1}^{m}\frac{r_{i,m}\timesr_{i,d}}{\|r_{i,d}\|}","where \(\mathbf{r}_{i,\mathbf{m}}\) and \(\mathbf{r}_{i,\mathbf{d}}\) represent the moment and direction vectors of the \(i\)-th ray, respectively."
ICLR_2024_oral_10,5,"P=\operatorname*{arg\,min}_{\|H\|=1}\sum_{i=1}^{m}\|Hd_{i}\timesu_{i}\|",,"P=\operatorname*{arg\,min}_{P\inR^{3\times 3}}\\sum_{\langled,m\rangle\inR}\lVertPd-d_{identity}\rVert^{2}",The homography matrix $\mathbf{P}$ transforms per-pixel ray directions from the predicted ones to those of an 'identity' camera.
ICLR_2024_oral_10,6,f_{feat}(I)=f\inR^{p\times p\times d},,t=-Rc,The translation vector t is computed as the negative product of the rotation matrix R and the camera center c.
ICLR_2024_oral_10,7,"\{\hat{R}\}_{i=1}^{N}=f_{Regress}(\{f_{i},u_{i}\}_{i=1}^{N\cdot p^{2}})",,"f_{ray}(f,u)=r\inR^{6}",The function $f_{\text{ray}}$ predicts a ray $\mathbf{r}$ given a spatial feature $\mathbf{f}$ and pixel coordinate $\mathbf{u}$.
ICLR_2024_oral_10,8,L_{recon}=\sum_{i=1}^{N}\|\hat{R}_{i}- R_{i}\|_{2}^{2},,L=\sum_{i=1}^{N}\sum_{j=1}^{p^{2}}\lVert\hat{r}_{ij}-r_{ij}\rVert^{2},The loss function measures the difference between the predicted and ground truth camera rays.
ICLR_2024_oral_10,9,x_{t}=\sqrt{\alpha_{t}}x_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,"where \(\epsilon\sim\mathcal{N}(0,\mathbf{I})\) and \(\alpha_{t}\) is a hyper-parameter schedule of noise weights such that \(x_{T}\) can be approximated as a standard Gaussian distribution",x_{t}=\sqrt{\bar{\alpha}_{t}}x_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,"The equation represents the noising process in a denoising diffusion model, where $x_{t}$ is the noisy sample at time step $t$, $x_{0}$ is the original sample, $\bar{\alpha}_{t}$ is the cumulative product of the noise schedule, and $\epsilon$ is a standard Gaussian noise vector."
ICLR_2024_oral_10,10,"L(\theta)=E_{t,x_{0},\epsilon}\|x_{0}-f_{\theta }(x_{t},t)\|^{2}",,"f_{\theta}(x_{t})=\operatorname*{arg\,max}_{x_{0}}p_{\theta}(x_{0}|x_{t})",where \(p_{\theta}(\mathbf{x}_{0}|\mathbf{x}_{t})\) is the conditional probability of the original sample given the noisy sample.
ICLR_2024_oral_10,11,"\{\hat{R}\}_{i=1}^{N}=f_{Diffusion}(\{f_{i},u_{i},r_{i,t}\}_{i=1}^{N\cdot p^{2}},t) || r_{i,t}=\sqrt{\bar{\alpha}_{t}}r_{i}+\sqrt{1-\bar{\alpha}_{t}}\epsilon","where the noisy rays \(\mathbf{r}_{i,t}\) can be computed as:

\[\mathbf{r}_{i,t}=\sqrt{\bar{\alpha}_{t}}\mathbf{r}_{i}+\sqrt{1-\bar{\alpha}_{t}}\epsilon","\{\hat{R}\}_{i=1}^{N}=f_{Diffuse}(\{f_{i},u_{i},r_{i}^{(t)}, t\}_{i=1}^{N\cdot p^{2}})","where \(\mathbf{r}_{i}^{(t)}\) represents the noisy ray at time step \(t\), and \(f_{\text{Diffuse}}\) is the denoising diffusion network."
ICLR_2024_oral_11,1,"O_{ij}=\sum_{v=1}^{k}I[y_{ij}\neq y_{ij}^{(v)}],\forall j\in Y_{i}",where \(\mathbb{I}[\cdot]\) is the indicator function and \(y_{ij}\) is the \(j\)-th candidate label of \(\mathbf{x}_{i}\),"O_{ij}=\frac{1}{k}\sum_{(x_{i}^{(l)}, Y_{i}^{(l)})\in k-NN(x_{i})}I(j\notin Y_{i}^{(l)})",\(O_{ij}\) measures the frequency of the \(j\)-th candidate label not appearing in the \(k\)-NN instances' candidate label sets of the \(i\)-th instance.
ICLR_2024_oral_11,2,\gamma_{i}=\lceil\tau(|Y_{i}|-1)\rceil,where \(\lceil\cdot\rceil\) is the ceiling function that returns the least integer greater than or equal to the given number,"min(\lfloor |Y_{i}|\cdot\tau\rfloor,\sum_{j=1}^{|Y_{i}|}I[O_{ij} >\theta])","The number of eliminated candidate labels of \(\mathbf{x}_{i}\) is determined by the minimum between the floor of the product of the size of the candidate label set \(Y_{i}\) and the pruning extent parameter \(\tau\), and the sum of indicator functions for \(O_{ij}\) greater than a threshold \(\theta\)."
ICLR_2024_oral_11,3,\widetilde{Y}_{i}=Top-\gamma_{i}-argmax_{j\in Y_{i}}(O_{ij}),where \(\mathrm{Top}\text{-}\gamma_{i}\text{-}\mathrm{argmax}_{i}\) returns a subset of indices (i,\hat{Y}_{i}=Y_{i}\backslash\{y_{ij}:O_{ij}>\theta_{i}\},"where \(\hat{Y}_{i}\) is the updated candidate label set for instance \(\mathbf{x}_{i}\) after pruning, and \(\theta_{i}\) is the threshold value for the down-voting metric \(O_{ij}\) of instance \(\mathbf{x}_{i}\)."
ICLR_2024_oral_11,4,"P(O_{iy^{\prime}}^{(\xi_{i})}<O_{iy})\leq\sum_{j=1}^{k}\sum_{m=\xi_{i}} ^{|Y_{i}^{\prime}|}\binom{|Y_{i}^{\prime}|}{m}\eta^{m}(1-\eta)^{(|Y_{i}^{\prime }|-m)}b_{\delta_{k}}(k,j)",,P(O_{iy^{\prime}}^{(|Y_{i}^{\prime}|-\gamma_{i}+1)}<O_{iy})\leq\sum_{j=0}^{k}\binom{k}{j}(1-t)^{j}t^{k-j}\sum_{l=j+1}^{k}\binom{|Y_{i}^{\prime}|+\gamma_{i}-1}{l}(1-q)^{l}q^{|Y_{i}^{\prime}|+\gamma_{i}-1-l},The probability of getting an incorrect pruning event is upper bounded by the summation of binomial probabilities.
ICLR_2024_oral_11,5,"P(O_{iy}^{(\xi_{i}^{2})}<O_{iy})-P(O_{iy}^{(\xi_{i}^{1})}<O _{iy})\leqslant\sum_{j=1}^{k}\sum_{m=\xi_{i}^{2}}^{\xi_{i}^{1}-1}\binom{|Y^{\prime}_{i}|}{m}\eta^{m}(1-\eta)^{|Y^{\prime}_{i}|-m}b_{\delta_{k}}(k,j)",,"P(O_{iy^{\prime}}^{(\xi_{i}^{2})}<O_{iy})-P(O_{iy^{\prime}}^{(\xi_{i}^{1})}<O_{iy})\leq\sum_{j=1}^{k}\sum_{m=\xi_{i}^{2}}^{\xi_{i}^{1}-1}\binom{|Y_{i}^{\prime}|}{m}\eta^{m}(1-\eta)^{(|Y_{i}^{\prime}|-m)}b_{\delta_{k}}(k,j)",The extra pruning error is bounded when increasing the number of eliminated candidate labels.
ICLR_2024_oral_13,1,"q(x_{t}|x_{t-1})=N(x_{t};\sqrt{1-\beta_{t}}x_{t},\beta_{t}I ),\quadfor t\in\{1,...,T\}","where \(\beta_{t}\in(0,1)\) is the scheduled variance at step \(t\)",q(x_{0}),The real data distribution from which a data point \(x_{0}\) is drawn.
ICLR_2024_oral_13,2,x_{t}=\sqrt{\bar{\alpha}_{t}}x_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,"where, \(\bar{\alpha}_{t}=\prod_{i=1}^{t}(1-\beta_{t})\)","q(x_{t}|x_{0})=N(x_{t};\sqrt{\bar{\alpha}_{t}}x_{0},(1-\bar{\alpha}_{t})I)",where \(\bar{\alpha}_{t}=\prod_{i=1}^{t}(1-\beta_{i})\) represents the cumulative product of noise schedules up to step \(t\)
ICLR_2024_oral_13,3,\hat{x}_{0}^{t}=\frac{x_{t}-\sqrt{1-\bar{\alpha}_{t}}\epsilon_{\theta}(x_{t}) }{\sqrt{\bar{\alpha}_{t}}},,x_{t-1}=\frac{1}{\sqrt{1-\beta_{t}}}\left(x_{t}-\epsilon_{\theta}(x_{t})\right),where \(x_{t-1}\) is the estimation of \(x_{0}\) at step \(t-1\) using the trained noise-predictor \(\epsilon_{\theta}\).
ICLR_2024_oral_13,4,"x_{t-1}=\sqrt{\bar{\alpha}_{t-1}}\hat{x}_{0}^{t}+\sqrt{1-\Text-conditional diffusion models, such as Stable Diffusion (Rombach et al., 2022), employ classifier-free diffusion guidance (Rombach et al., 2022) to steer the sampling process. Given a text prompt\(p\), its embedding\(e_{p}=f(p)\) is computed using a pre-trained CLIP text encoder\(f(\cdot)\)(Radford et al., 2021; Cherti et al., 2023). In the reverse process, the conditional sampling adheres to Eq. (3) and Eq. (4), but the predicted noise\(\epsilon_{\theta}(x_{t})\) is changed to:\[\epsilon_{\theta}(x_{t},e_{\theta})+s(\underbrace{\epsilon_{\theta}(x_{t},e_ {p})-\epsilon_{\theta}(x_{t},e_{\theta})}_{text-conditional noise prediction})","where, \(e_{\theta}\) represents the prompt embedding of an empty string, and \(s\) determines the guidance strength, controlling the alignment of the generation to the prompt",\hat{x}_{t-1}=\frac{\hat{x}_{0}^{t}-\sqrt{1-\bar{\alpha}_{t-1}}\epsilon_{\theta}(x_{t})}{\sqrt{\bar{\alpha}_{t-1}}}\cdot\sqrt{1-\beta_{t}}+\sqrt{1-\bar{\alpha}_{t}}\cdot\frac{\epsilon_{\theta}(x_{t})}{\sqrt{\beta_{t}}},where \(\hat{x}_{t-1}\) represents the predicted value of \(x_{t-1}\) based on the estimated \(x_{0}\) and the noise predictor \(\epsilon_{\theta}(x_{t})\)
ICLR_2024_oral_13,5,"d=\frac{1}{T}\sum_{t=1}^{T}\|\epsilon_{\theta}(x_{t},e_{p})-\epsilon_{\theta} (x_{t},e_{\theta})\|_{2}",,"M(p)=\frac{1}{T}\sum_{t=1}^{T}\left\lVert\epsilon_{\theta}(x_{t},e_{p})-\epsilon_{\theta}(x_{t},e_{\theta})\right\rVert_{2}",where \(M(p)\) represents the average magnitude of text-conditional noise predictions over all sampling steps for a given prompt embedding \(p\).
ICLR_2024_oral_13,6,"L(x_{t},e)=\|\epsilon_{\theta}(x_{t},e)-\epsilon_{\theta}(x_{t},e_{\emptyset})\|_{2}",,"\min_{\delta}\|\epsilon_{\theta}(x_{t},e_{p}+\delta)-\epsilon_{\theta}(x_{t},e_{\theta})\|_{2}","where \(\delta\) represents the change applied to each token in the prompt embedding \(e_{p}\), and the objective is to minimize the magnitude of the text-conditional noise prediction."
ICLR_2024_oral_13,7,"SS_{e^{i}}=\frac{1}{T}\sum_{t=1}^{T}\|\nabla_{e^{i}}L(x_{t}, e)\|_{2}",,"S_{i}=\frac{1}{T}\sum_{t=1}^{T}\|\epsilon_{\theta}(x_{t},e_{p}^{i})-\epsilon_{\theta}(x_{t},e_{p})\|_{2}","where \(\mathcal{S}_{i}\) represents the significance score for the token at position \(i\), \(e_{p}^{i}\) denotes the embedding of the prompt with the \(i\)-th token removed, and \(e_{p}\) is the embedding of the original prompt."
ICLR_2024_oral_14,1,"F^{*}&=\operatorname*{argmax}_{F}p(F|D _{src},D_{tgt})=\operatorname*{argmax}_{F}p(D_{src},D_{tgt}|F)\cdot p(F)\\&=\operatorname*{argmax}_{F}\{\underbrace{\log p(D_{src},D _{tgt}|F)}_{data term}+\underbrace{\log p(F)}_{prior term}\}",,"p(F|D_{src},D_{tgt})\propto p(D_{src},D_{tgt}|F)\cdot p(F)",The equation represents the probabilistic interpretation of dense correspondence using Bayes' theorem to decompose the posterior probability.
ICLR_2024_oral_14,2,"X_{t}=\sqrt{\alpha_{t}}X_{0}+\sqrt{1-\alpha_{t}}Z,\quad Z\simN(0,I)",where \(\alpha_{t}=\prod_{i=1}^{t}(1-\beta_{i})\),"q(X_{t}|X_{t-1}):=N(\sqrt{1-\beta_{t}}X_{t-1},\beta_{t}I)","The conditional diffusion model transforms a sample \(X_{0}\) to \(X_{t}\) through the forward diffusion process at a time step \(t\), following a Gaussian transition at each time step with variance schedule \(\beta_{t}\)."
ICLR_2024_oral_14,3,"X_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(X_{t},t;K)+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t}}}\Big{(}X_{t}-\sqrt{\alpha_{ t}}F_{\theta}(X_{t},t;K)\Big{)}+\sigma_{t}Z",where \(\sigma_{t}\) is the covariance value of Gaussian distribution at time step \(t\),"X_{t-1}=\mu_{\theta}(X_{t},t)+\sigma_{\theta}(X_{t},t)Z,\quad Z\simN(0,I)","where \(\mu_{\theta}(X_{t},t)\) and \(\sigma_{\theta}(X_{t},t)\) are the mean and variance of the Gaussian transition at time step \(t\), respectively."
ICLR_2024_oral_14,4,"F^{*}=F_{\theta}(D_{src},D_{tgt})\approx\underset{F }{argmax}\\underbrace{\log p(D_{src},D_{tgt}|F)}_{data term}","where \(\mathcal{F}_{\theta}(\cdot)\) and \(\theta\) represent a feed-forward network and its parameters, respectively","F^{*}=\operatorname*{argmax}_{F}\log p(D_{src},D_{tgt}|F)=F(D_{src},D_{tgt})",where \(\mathcal{F}(\cdot)\) denotes a deep neural network that approximates the data term.
ICLR_2024_oral_14,5,"F^{*}=F_{\theta}(D_{src},D_{tgt})\approx\underset{F}{argmax}\p(F|D_{src},D_{tgt}) || =\underset{F}{argmax}\{\underbrace{\log p(D_{ src},D_{tgt}|F)}_{data term}+\underbrace{\log p(F)}_{prior term}\}",,"F^{*}&=\operatorname*{argmax}_{F}p(F|D_{src},D_{tgt})\\&=\operatorname*{argmax}_{F}\{\underbrace{\log p(D_{src},D_{tgt}|F)}_{data term}+\underbrace{\log p(F)}_{prior term}\}",where \(F^{*}\) represents the optimal correspondence field that maximizes the posterior probability given the source and target feature descriptors \(D_{\text{src}}\) and \(D_{\text{tgt}}\).
ICLR_2024_oral_14,6,"F_{t}=\sqrt{\alpha_{t}}F_{0}+\sqrt{1-\alpha_{t}}Z,\quad Z\simN(0,I)",where \(F_{0}\) is the ground-truth correspondence,"F_{t}=\sqrt{\alpha_{t}}F_{0}+\sqrt{1-\alpha_{t}}Z,\quad Z\simN(0,I)",where \(\alpha_{t}=\prod_{i=1}^{t}(1-\beta_{i})\)
ICLR_2024_oral_14,7,"F_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(X_{t},t;D_{src},D_{tgt})+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t }}}\Big{(}X_{t}-\sqrt{\alpha_{t}}F_{\theta}(F_{t},t;D_{src },D_{tgt})\Big{)}+\sigma_{t}Z","where \(\mathcal{F}_{\theta}(F_{t},t;D_{\mathrm{src}},D_{\mathrm{tgt}})\) directly predicts the denoised correspondence \(\hat{F}_{0,t}\) with source and target features, \(D_{\mathrm{src}}\) and \(D_{\mathrm{tgt}}\), as conditions","F_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(F_{t},t;D_{src},D_{tgt})+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t}}}\Big{(}F_{t}-\sqrt{\alpha_{t}}F_{\theta}(F_{t},t;D_{src},D_{tgt})\Big{)}+\sigma_{t}Z",where \(\sigma_{t}\) is the covariance value of Gaussian distribution at time step \(t\)
ICLR_2024_oral_14,8,"C(i,j)=\frac{D_{src}(i)\cdot D_{tgt}(j)}{\|D_{src}(i)\|\|D_{tgt}(j)\|}","where \(i\in[0,h_{\text{src}})\times[0,w_{\text{src}})\), \(j\in[0,h_{\text{tgt}})\times[0,w_{\text{tgt}})\), and \(\|\cdot\|\) denotes \(l\)-2 normalization","C^{l}(i,j)=\frac{D_{src}(i)\cdot D_{tgt}(j)}{\|D_{src}(i)\|\|D_{tgt}(j)\|}","where \(C^{l}(i,j)\) represents the cosine similarity between the \(i\)-th location in the source feature and the \(j\)-th location in the target feature."
ICLR_2024_oral_14,9,"L=E_{F_{0},t,Z\simN(0,I),D_{src},D_{tgt}}[\|F_{0}-F_{\theta}(F_{t},t;F_{init },C^{l})\|^{2}]",,"L=E_{t,Z}\left[\left\|F_{\theta}(F_{t},t;F_{init},C^{l})-\hat{F}_{0,t}\right\|^{2}\right]","where \(\hat{F}_{0,t}=\frac{1}{\sqrt{\alpha_{t}}}\left(F_{t}-\sqrt{1-\alpha_{t}}Z\right)"
ICLR_2024_oral_15,1,"\nabla_{\Theta}L_{SDS}=E_{t,p,\epsilon}[w(t)(\epsilon_{\phi}(I_{RGB}^{p};t,\tilde{I}_{RGB}^{r},\Delta p)-\epsilon)\frac{\partial I_{RGB}^{p}}{\partial\Theta}]","where \(w(t)\) is a weighting function, \(\epsilon_{\phi}(\cdot)\) is the predicted noise by the 2D diffusion prior \(\phi\), and \(\Delta p\) is the relative camera pose change from the reference camera \(r\)",L_{SDS}=\sum_{p}\left\| I_{RGB}^{p}-\tilde{I}_{RGB}^{p}\right\|_{2}+\lambda\left\| I_{A}^{p}-\tilde{I}_{A}^{p}\right\|_{2},"The SDS loss measures the difference between the rendered RGB image and the target image, as well as the difference between the rendered transparency and the target transparency."
ICLR_2024_oral_15,2,L_{Ref}=\lambda_{RGB} || I_{RGB}^{r}-\tilde{I}_ {RGB}^{r} || _{2}^{2}+\lambda_{A} || I_{A}^{r}-\tilde{I}_{A}^{r} || _{2}^{2},where \(\lambda_{\text{RGB}}\) and \(\lambda_{\text{A}}\) are the weights which are linearly increased during training,L_{ref}=E_{r}[\lVert I_{RGB}^{r}-\tilde{I}_{RGB}^{r}\rVert_{2}+\lVert I_{A}^{r}-\tilde{I}_{A}^{r}\rVert_{2}],The reference view loss optimizes the reference view image and transparency to match the input image and foreground mask.
ICLR_2024_oral_15,3,"\nabla_{\Theta}L_{SDS}=E_{t,p,\epsilon}[w(t)(\epsilon_{\phi}(I_{RGB}^{p};t,e)-\epsilon)\frac{\partial I_{RGB }^{p}}{\partial\Theta}]",where \(e\) is the CLIP embeddings of the input text description,L_{Total}=L_{SDS}+L_{Ref}+L_{Reg},"The total loss is a weighted sum of the SDS loss, reference loss, and regularization loss."
ICLR_2024_oral_15,4,d(x)=\sum_{i}\alpha_{i}\exp(-\frac{1}{2}(x-x_{i})^ {T}\Sigma_{i}^{-1}(x-x_{i})),where \(\Sigma_{i}\) is the covariance matrix built from scaling \(\mathbf{s}_{i}\) and rotation \(\mathbf{q}_{i}\),"\rho(x)=\sum_{i}\alpha_{i}N(x;x_{i},s_{i})",The local density at position \mathbf{x} is calculated by summing the weighted opacity of each 3D Gaussian.
ICLR_2024_oral_15,5,"I^{p}_{fine}=f_{\phi}(I^{p}_{coarse}+\epsilon(t_{start}) ;t_{start},c)","where \(\epsilon(t_{\text{start}})\) is a random noise at timestep \(t_{\text{start}}\), \(c\) is \(\Delta p\) for image-to-3D and \(e\) for text-to-3D respectively",I^{p}_{refine}=f_{\phi}(I^{p}_{coarse}+\epsilon),The refined image is obtained by applying a multi-step denoising process to the blurry image perturbed with random noise.
ICLR_2024_oral_15,6,L_{MSE}= || I^{p}_{fine}-I^{p}_{coarse} || ^{2}_{2},,L_{tex}=E_{p}[ || I^{p}_{fine}-I^{p}_{coarse} || _{2}^{2}],The texture refinement loss is defined as the expected pixel-wise MSE between the refined image and the coarse image.
ICLR_2024_oral_16,1,"H(x_{t})=\{{cc}\max\{H(\hat{x}_{t}),R_{t}(s_{t},a_{t })\},&if\ || \hat{x}_{t}-x_{t} || _{2}<\delta\\R_{t}(s_{t},a_{t}),&otherwise\","where \(R_{t}(s_{t},\mathbf{a_{t}})\) is the return of a given \((s_{t},\mathbf{a_{t}})\); \(\delta\) is a threshold value of state-embedding difference; and \(\hat{x}_{t}=f_{\phi}(\hat{s}_{t})\) is \(x_{t}=f_{\phi}(s_{t})\)'s nearest neighbor in \(\mathcal{D}_{E}\)","H(x_{t})\leftarrow\max(H(x_{t}), G_{t})","The update rule for the highest return of a given global state \(s_{t}\), where \(H(x_{t})\) is the current highest return and \(G_{t}\) is the return at timestep \(t\)."
ICLR_2024_oral_16,2,"Q_{EC}(f_{\phi}(s_{t}),a_{t})=r_{t}(s_{t},a_{t})+\gamma H(f_{\phi}(s_ {t+1}))",,"Q_{EC}(f_{\phi}(s_{t}),a_{t})=R_{t}(s_{t},a_{t})+\gamma H(f_{\phi}(s_{t+1}))","where \(Q_{EC}(f_{\phi}(s_{t}),\mathbf{a_{t}})\) represents the one-step TD memory target for episodic control."
ICLR_2024_oral_16,3,"L_{\theta}^{EC}=(y(s,a)-Q_{tot}(s,a;\theta))^{2}+\lambda(Q_{EC}(f_{\phi}(s),a)-Q_{tot}(s,a;\theta))^{2}","where \(y(s,\mathbf{a})\) is one-step TD target; \(Q_{tot}\) is the joint Q-value function parameterized by \(\theta\); and \(\lambda\) is a scale factor","L_{\theta}^{EC}=(r_{t}(s_{t},a_{t})+\gamma H(f_{\phi}(s_{t+1})))-Q(f_{\phi}(s_{t}),a_{t};\theta)","The loss function \(L_{\theta}^{EC}\) represents the difference between the one-step TD memory target \(Q_{EC}(f_{\phi}(s_{t}),\mathbf{a_{t}})\) and the predicted Q-value \(Q(f_{\phi}(s_{t}),\mathbf{a_{t}};\theta)\)."
ICLR_2024_oral_16,4,"L(\phi,\psi)=(H_{t}-f_{\psi}(f_{\phi}(s_{t})))^ {2}",,"L_{EmbNet}=(H_{t}-\bar{H}_{t})^{2}+\lambda_{reg}\cdot (Q_{EC}(x_{t},a_{t})-Q_{tot}(s_{t},a_{t};\theta))^{2}","where \(L_{EmbNet}\) is the loss function for training EmbNet, \(H_{t}\) is the highest return of state \(s_{t}\), \(\bar{H}_{t}\) is the predicted highest return, \(\lambda_{reg}\) is a regularization coefficient, \(Q_{EC}\) is the episodic control Q-value, \(Q_{tot}\) is the total Q-value, \(x_{t}\) is the embedded state, \(\mathbf{a_{t}}\) is the action, \(\theta\) is the parameter of the total Q-value function, and \(\lambda_{reg}\) controls the importance of the episodic control term."
ICLR_2024_oral_16,5,"L(\phi,\psi)=(H_{t}-f_{\psi}^{H}(f_{\phi}(s_{t}|t)|t ))^{2}+\lambda_{rcon} || s_{t}-f_{\psi}^{s}(f_{\phi}(s_{t}|t)|t) || _{2}^{2}",where \(f_{\psi}^{H}\) predicts the highest return; \(f_{\psi}^{s}\) reconstructs \(s_{t}\); \(\lambda_{rcon}\) is a scale factor,"L_{dCAE}(\phi,\psi,\omega)=(H_{t}-f_{\psi}(f_{\phi}(s_{t})))^{2}+(s_{t}-f_{\omega}(f_{\phi}(s_{t}),t))^{2}",The loss function for the deterministic conditional autoencoder (dCAE) combines the embedding loss and the reconstruction loss of the state conditioned on the timestep.
ICLR_2024_oral_16,6,"\eta^{*}(s^{\prime}):=V^{*}(s^{\prime})-\max_{a^{\prime}}\!Q_{\theta^{-}} (s^{\prime},a^{\prime})",,"\eta^{*}(s^{\prime})=V^{*}(s^{\prime})-\max_{a^{\prime}}Q_{\theta^{-}}(s^{\prime},a^{\prime})",The difference between the true value and the predicted value via target network.
ICLR_2024_oral_16,7,"r^{p}=\gamma\hat{\eta}(s^{\prime})=\gammaE_{\pi_{\theta}}[\eta(s^{\prime})]\simeq\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}\eta_{\max}(s^{\prime})=\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}(H(f_ {\phi}(s^{\prime}))-\max_{a^{\prime}}\!Q_{\theta^{-}}(s^{\prime},a^{\prime}))",where \(N_{call}(s^{\prime})\) is the number of visits on \(\hat{x}^{\prime}=\mathrm{NN}(f_{\phi}(s^{\prime}))\in\mathcal{D}_{E}\); and \(N_{\xi}\) is the number of desirable transition from \(\hat{x}^{\prime}\),r^{p}:=\gamma\hat{\eta}(s^{\prime})=\gamma\frac{\sum_{i=1}^{N}\eta(s_{i}^{\prime})}{N},where \(N\) is the number of episodes that have visited \(s^{\prime}\) and \(\eta(s_{i}^{\prime})\) is the estimated value difference for the \(i\)-th episode.
ICLR_2024_oral_16,8,"L_{\theta}^{p}=(r(s,a)+r^{p}+\gamma\!\max_{a^{\prime}}\!Q_{\theta^{-} }(s^{\prime},a^{\prime})-Q_{\theta}(s,a))^{2}",,"L_{\theta}:=(y(s,a)+r^{p}-Q_{tot}(s,a;\theta))^{2}=(y(s,a)+\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}(H(f_{\phi}(s^{\prime}))-\max_{a^{\prime}}\!Q_{\theta^{-}}(s^{\prime},a^{\prime}))-Q_{tot}(s,a;\theta))^{2}","The loss function for episodic control with an alternative transition reward $r^{p}$, which encourages desirable transitions while preventing local convergence towards undesirable trajectories."
ICLR_2024_oral_16,9,"\nabla_{\theta}L_{\theta}^{p}=-2\nabla_{\theta}Q_{\theta}(s,a)(\Delta\varepsilon _{TD}+r^{p})=-2\nabla_{\theta}Q_{\theta}(s,a)(\Delta\varepsilon_{TD}+\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}\eta_{\max}(s^{\prime}))",,"\nabla_{\theta}L_{\theta}^{p}=2(r(s,a)+r^{p}+\gamma\!\max_{a^{\prime}}\!Q_{\theta^{-}}(s^{\prime},a^{\prime})-Q_{\theta}(s,a))\nabla_{\theta}Q_{\theta}(s,a)",where \(r^{p}=\gamma\hat{\eta}(s^{\prime})\) is the episodic incentive.
ICLR_2024_oral_16,10,"L_{\theta}^{p}=(r(s,a)+r^{p}+\beta_{c}r^{c}+\gamma max_{a^{\prime}}Q_{tot}(s^{\prime},a^{\prime};\theta^{-})-Q_{tot}(s,a;\theta))^{2}",where \(\beta_{c}\) is a scale factor,"L_{\theta}=(r(s,a)+r^{p}+r^{c}+\gamma\max_{a^{\prime}}Q_{\theta^{-}}(s^{\prime},a^{\prime})-Q_{\theta}(s,a))^{2}","The overall learning objective for the action policy learning, incorporating the episodic incentive and any intrinsic reward."
ICLR_2024_oral_21,1,"g(G)=\operatorname*{arg\,max}_{c\in\{1,2,\cdots,C\}}N_{c}",where a label with a smaller index is taken by our ensemble classifier when there are ties,N_{c}=\sum_{t=1}^{N}I(f(G_{t})=c),The equation represents the number of sub-graphs predicted as class c by the base graph classifier f.
ICLR_2024_oral_21,2,"N_{c}-M\leq N_{c}^{p}\leq N_{c}+M,\,\forall c\in\{1,2,\cdots,C\}",,N_{c}^{p}=N_{c}-\Delta N_{c},"\(N_{c}^{p}\) measures the number of sub-graphs created from the perturbed graph \(G^{p}\) that are predicted as the class \(c\) by the base graph classifier \(f\), where \(\Delta N_{c}\) represents the change in the number of sub-graphs due to perturbations."
ICLR_2024_oral_21,3,"M\leq M^{p}=\lfloor\frac{N_{l}-\max_{c\in\{1,2,\cdots,C\}\setminus\{l\}}(N_{c }-I(l<c))}{2}\rfloor",,"N_{l}>\max_{c\in\{1,2,\cdots,C\}\setminus\{l\}}(N_{c}+M-I(l<c))",The condition under which the ensemble graph classifier g still predicts the label l for the perturbed graph G^p.
ICLR_2024_oral_23,1,"p_{\sigma}(y)=\int p(y|x)\,p(x)\,dx=\int g_{\sigma}(y-x)\,p(x)\,dx",where \(g_{\sigma}(z)\) is the density of \(z\),"p_{\sigma}(y)=\int p(x)N(y|x,\sigma^{2}Id) dx",The equation represents the relationship between the density of noisy images \(p_{\sigma}(y)\) and the original image density \(p(x)\) through marginalization over \(x\).
ICLR_2024_oral_23,2,"D_{KL}(p(x)\,\|\,p_{\theta}(x))\leq\int_{0}^{\infty}E_{y}\big{[}\|\nabla\log p_{\sigma}(y)-s_{\theta}(y)\|^{2}\big{]}\,\sigma\, d\sigma",,KL(p(x)\|p_{\theta}(x))=\int_{0}^{\infty}E_{p_{\sigma}(y)}\left[\frac{1}{2}\|s_{\theta}(y)-\nabla\log p_{\sigma}(y)\|^{2}\right]d\sigma,The KL divergence between the true data distribution $p(x)$ and the model distribution $p_{\theta}(x)$ is equal to the integrated score error across all noise levels.
ICLR_2024_oral_23,3,"\nabla\log p_{\sigma}(y)=(\mathop{E}_{x}[x\,|\,y]-y)/\sigma^{2}",,\nabla\log p_{\sigma}(y)=E_{x|y}\left[\nabla\log p(x)-\sigma^{-2}x\right],where \(\nabla\log p_{\sigma}(y)\) represents the score of the noisy image density and \(\mathbb{E}_{x|y}\) denotes the expectation over the posterior distribution of clean images given a noisy image.
ICLR_2024_oral_23,4,"MSE(f_{\theta},\sigma^{2})=\mathop{E}_{x,y}\Bigl{[}\|x-f_{\theta}(y)\|^{2}\Bigr{]}",,"\mathop{E}_{x,y}\left[\|f_{\theta}(y)-\mathop{E}_{x}[x\,|\,y]\|^{2}\right]",The mean squared error between the denoiser output and the posterior mean of the clean image given the noisy image.
ICLR_2024_oral_23,5,"D_{KL}(p(x)\ || \,p_{\theta}(x))\leq\int_{0}^{\infty}\Bigl{(} MSE(f_{\theta},\sigma^{2})-MSE(f^{\star},\sigma^{2})\Bigr{)}\,\sigma^{-3}\,d\sigma","where \(f^{\star}(y)=\mathop{\mathbb{E}}_{x}[x\,|\,y]\) is the optimal denoiser",s_{\theta}(y)=(f_{\theta}(y)-y)/\sigma^{2},The estimated score is calculated using the estimated conditional mean and the noise level.
ICLR_2024_oral_23,6,"f(y)=\nabla f(y)\,y=\sum_{k}\lambda_{k}(y)\langle y,e_{k}(y)\rangle e_{ k}(y)",,"f(y)=y+\sum_{k=1}^{d}\lambda_{k}(y)\langle e_{k}(y),y\rangle e_{k}(y)","The equation represents the denoiser mapping in terms of the Jacobian eigendecomposition, where the denoiser acts as a shrinkage operator in the adaptive basis defined by the eigenvectors of the Jacobian."
ICLR_2024_oral_23,7,"MSE(f,\sigma^{2})=\mathop{E}_{y}\![2\sigma^{2}\, tr\,\nabla f(y)+\|y-f(y)\|^{2}-\sigma^{2}d]",,"\mathop{argmin}_{f}MSE(f)=\mathop{argmin}_{f}E_{x,y}\Bigl{[}\|x-f(y)\|^{2}\Bigr{]}=\mathop{argmin}_{f}E_{y}\Bigl{[}\|f(y)\|^{2}\Bigr{]}-2E_{x,y}\Bigl{[}x^{T}f(y)\Bigr{]}+C","The equation represents the minimization of the mean squared error (MSE) for a denoiser function f, where the expectation is taken over the joint distribution of the clean image x and the noisy image y."
ICLR_2024_oral_23,8,"f^{\star}(y)=y+\sigma^{2}\nabla\log p_{\sigma}(y)=\operatorname*{E}_{ x}[x|y] || \nabla f^{\star}(y)=Id+\sigma^{2}\nabla^{2}\log p_{\sigma}(y)=\sigma^ {-2}Cov[x\,|\,y]",,"f(y)=\mathop{E}_{x}[x\,|\,y]",The optimal minimum MSE denoiser is given by the conditional mean of x given y
ICLR_2024_oral_23,9,"MSE(f^{\star},\sigma^{2})=\operatorname*{E}_{y}[tr \,Cov[x\,|\,y]]=\sigma^{2}\operatorname*{E}_{y}\bigl{[}tr\,\nabla f^{\star}(y)\bigr{]}=\sigma^{2}\operatorname*{E} _{y}\biggl{[}\sum_{k}\lambda_{k}^{\star}(y)\biggr{]}",,"MSE(f^{\star},\sigma^{2})=\mathop{E}_{y}\!\left[\|y-f^{\star}(y)\|^{2}\right]=\sigma^{2}\mathop{E}_{y}\!\left[tr\,\nabla f^{\star}(y)\right]=\sigma^{4}\mathop{E}_{y}\!\left[tr\,\nabla^{2}\log p_{\sigma}(y)\right]",The optimal denoising error is proportional to the expected trace of the Hessian of the log-density of the noisy image.
ICLR_2024_oral_23,10,"\operatorname*{E}_{x}\biggl{[}\sum_{k}\Bigl{(}(1-\lambda_{k}(x))^{2}\langle x,e_{k}\rangle^{2}+\lambda_{k}(x)^{2}\sigma^{2}\Bigr{)}\biggr{]}",,"MSE(f^{\star},\sigma^{2})=\sigma^{2}\sum_{k}\min(1,\sigma^{2}/\lambda_{k}^{2})","The minimum mean squared error (MMSE) of the optimal denoiser in a fixed basis, where the shrinkage factors depend on the unknown clean image x rather than the noisy observation y."
ICLR_2024_oral_23,11,"\sigma^{2}{\sum_{k}\lambda_{k}(x)}=\sum_{k}\frac{\sigma^{2}\langle x,e_{k}\rangle^{2}}{\langle x,e_{k}\rangle^{2}+\sigma^{2}}\sim\sum_{k}\min(\langle x,e_{k}\rangle^{2},\sigma^{2})=M\sigma^{2}+\|x-x_{M}\|^{2}","where \(x_{M}=\sum_{\langle x,e_{k}\rangle^{2}>\sigma^{2}}\langle x,e_{k}\rangle\,e_{k}\) is the \(M\)-term approximation of \(x\) with the \(M\) basis coefficients \(\langle x,e_{k}\rangle\) above the noise level, and \(\sim\) means that the two terms are of the same order up to multiplicative constants (here smaller than 2)","E_{x}\biggl{[}\sum_{k}\frac{\sigma^{2}\langle x,e_{k}\rangle^{2}}{\langle x,e_{k}\rangle^{2}+\sigma^{2}}\biggr{]}",the expected value of the oracle denoising error in a fixed basis.
ICLR_2024_oral_23,12,M\sigma^{2}+\|x-x_{M}\|^{2}\sim\sigma^{2\alpha/(\alpha+1)},,"MSE(f^{\star},\sigma^{2})\sim\sigma^{2\alpha/(1+\alpha)}+\sigma^{2}",where \(\alpha\) is a decay parameter that controls the sparsity of the representation of \(x\) in the basis \(e_{k}\).
ICLR_2024_oral_24,1,dx_{t}=f_{t}(x_{t})dt+g(t)d w_{t}\quadx_{0}\sim p_{data}(x),,"dx=\epsilon\, dw","The stochastic differential equation describing the diffusion process, where \(x\) represents the system's state, \(\epsilon\) is a noise coefficient, and \(w\) is a Wiener process (standard Brownian motion)."
ICLR_2024_oral_24,2,"dx_{t}=[f_{t}(x_{t})-g_{t}^{2}\nabla_{ x}\log p(x_{t},t)]dt+g(t)dw_{t},\quadx_{1}\simN(0,I_{d})","where \(p(\cdot,t)\) is the marginal density of (1) at time \(t\) and \(\nabla_{\mathbf{x}}\log p_{t}\) is known as the score function",dx_{t}=[f_{t}(x_{t})-g(t)g^{\top}(t)\nabla\log p_{t}(x_{t})]dt+g(t)dw_{t},The time-reversal of the given SDE results in another SDE with a modified drift term.
ICLR_2024_oral_24,3,"dx_{t}=[f_{t}(x_{t})-\frac{1}{2}g_{t}^{2}\nabla_{x}\log p(x_{t},t)]dt,\quad x_{1}\simN(0,I_{d})",,"\frac{dx_{t}}{dt}=f_{t}(x_{t})-g_{t}^{2}\nabla_{x}\log p(x_{t},t)",The ordinary differential equation that shares the same path-wise measure as SDE (2) and is used for generating data from the prior distribution.
ICLR_2024_oral_24,4,"dx_{t}=v_{t}(x,t)dt+g_{t}dw_{t}\quad s.t.\quad(x_{0},x_{1})\sim\Pi_{0,1}(x_ {0},x_{1}):=p_{0}\times p_{1}",,"dx_{t}=f(x_{t},t)dt+g(t)dw_{t}","where \(f(\mathbf{x}_{t},t)\) denotes the drift coefficient and \(g(t)\) represents the diffusion coefficient"
ICLR_2024_oral_24,5,"\min_{a_{t}}\int_{\tau}^{1}\lVerta_{t}\rVert_{2}^{2}dt+(m_{1}-m_{1})^{T} R(m_{1}-m_{1})& s.t\underbrace{dx_{t}\\dv_{t}}_{dm_{t}}&=v_{t}\\a_{t}(x_{t},v_{t},t)dt+\underbrace{0&0\\0&g_{t}}_{g_{t}}dw_{t},\\m_{\tau}:=x_{\tau}\\v_{\tau}&=x_{\tau}\\v_{\tau},&R=r&0\\0&r\otimesI_{d},&x_{1}\sim p_{data}",,"dx_{t}=v_{t}(x,t)dt+g_{t}dw_{t},\quadv_{t}:=(x_{1}-x_{t})/(1-t)","The stochastic differential equation that models the bridge matching framework, where the drift term is designed to induce a Brownian Bridge."
ICLR_2024_oral_24,6,"a^{*}(m_{t},t)=g_{t}^{2}P_{11}(\frac{x_{1}-x_{t}}{1-t}-v_{t})\quadwhere:\quad P_{11}=\frac{-4}{g_{t}^{2}(t-1)}",,"dm_{t}=v_{t}\\a_{t}(x_{t},v_{t},t)dt+0&0\\0&g_{t}dw_{t},\quada_{t}(x_{t},v_{t},t)=\frac{v_{1}-v_{t}}{1-t}","The acceleration \(\mathbf{a}_{t}\) is defined as the difference between the terminal velocity \(\mathbf{v}_{1}\) and the current velocity \(\mathbf{v}_{t}\), scaled by the remaining time \(1-t\)."
ICLR_2024_oral_24,7,"dx_{t}\\dv_{t}=v_{t}\\F_{t}dt+0&0\\0&h_{t}dw_{t}\quads.t\quadm_{0}:=x_{0}\\v_{0}\simN(\mu_{0},\Sigma_{0}) || Bridge Matching SDE:F_{t}:=F_{t}^{b}(m_{t},t)\equiva_{t}^{*}(m_{t},t), h(t):=g(t) || Probabilistic ODE:F_{t}:=F_{t}^{p}(m_{t},t)\equiva_{t}^{*}(m_{t},t)-\frac{1}{2}g_{t}^{2 }\nabla_{v}\log p(m,t), h(t):=0",,dm_{t}=v_{t}\\\frac{4}{g_{t}^{2}(1-t)}(\frac{x_{1}-x_{t}}{1-t}-v_{t})dt+0\\g_{t}dw_{t},"The force term for SDE and ODE in the Acceleration Generative Model, incorporating the optimal control and the score term."
ICLR_2024_oral_24,8,"m_{t}=\mu_{t}+L_{t}\epsilon=\mu_{t}+L_{t}^{xx}\epsilon_{0}\\L_{t}^{xv}\epsilon_{0}+L_{t}^{vv}\epsilon_{1},\nabla_{v}\log p_{t}:=-\ell_{t}\epsilon_{1}","where \(\boldsymbol{\Sigma}_{t}=\mathbf{L}_{t}\mathbf{L}_{t}^{\mathsf{T}}\), \(\epsilon=\begin{bmatrix}\boldsymbol{\epsilon}_{0}\\ \boldsymbol{\epsilon}_{1}\end{bmatrix}\sim\mathcal{N}(\mathbf{0},\mathbf{I}_{2d})\) and \(\ell_{t}=\sqrt{\frac{\Sigma_{t}^{xx}}{\Sigma_{t}^{xx}\Sigma_{t}^{xx}-(\Sigma _{t}^{xx})^{2}}}\)","m_{t}=\mu_{t}+L_{t}z,\quadz\simN(0,I_{2d})","The equation represents the reparameterization of the intermediate state \(\mathbf{m}_{t}\) using the mean \(\boldsymbol{\mu}_{t}\), the Cholesky decomposition \(\mathbf{L}_{t}\) of the covariance matrix \(\boldsymbol{\Sigma}_{t}\), and a standard normal variable \(\mathbf{z}\)."
ICLR_2024_oral_24,9,"a^{*}(m_{t},t)=4x_{1}(1-t)^{2}-g_{t}^{2}P_{11}[ (\frac{L_{t}^{xx}}{1-t}+L_{t}^{xv})\epsilon_{0}+L_{t}^{vv}\epsilon_{1}]",,"F_{t}^{p}(m_{t},t)=a_{t}^{*}(m_{t},t)-\frac{1}{2}g_{t}^{2}\nabla_{v}\log p(m,t)=g_{t}^{2}P_{11}(\frac{x_{1}-x_{t}}{1-t}-v_{t})+\frac{1}{2}g_{t}^{2}\ell_{t}\epsilon_{1}","The force term in the probabilistic ODE is a function of the current state, time, and parameters, and is used to guide the dynamics towards the target data point."
ICLR_2024_oral_24,10,"\min_{\theta}E_{t\in[0,1]}E_{x_{1}\sim p_{ data}}E_{m_{t}\sim p_{t}(m_{t}|x_{1})}\lambda(t)[\|F_{t}^{\theta}(m_{t},t;\theta)-F _{t}(m_{t},t)\|_{2}^{2}]",Where \(\lambda(t)\) is known as the reweight of the objective function across the time horizon,F_{t}^{\theta}=s_{t}^{\theta}\cdotz_{t},The force term is expressed as a product of the network output and a normalizer.
ICLR_2024_oral_24,11,"x_{t_{i+1}}\\v_{t_{i+1}}=\Phi(t_{i+1},t_{i})x _{t}\\v_{t}+\sum_{j=0}^{w}\int_{t_{i}}^{t_{i+1} }(t_{i+1}-\tau)z_{\tau}\cdotM_{i,j}(\tau) d\tau\s_{t}^{\theta}(m_{t_{i-j}},t_{i-j}))\\\int_{t_{i}}^{t_{i+1}}z_{\tau}\cdotM_{i,j}(\tau) d\tau\cdots_{t}^{\theta}(m_{t_{i-j}},t_{i-j})",,m_{t}=\mu_{t}+L_{t}\epsilon=\mu_{t}+L_{t}^{xx}\epsilon_{0}\\L_{t}^{xv}\epsilon_{0}+L_{t}^{vv}\epsilon_{1},"The equation represents the reparameterization of the intermediate state \(\mathbf{m}_{t}\) using the mean \(\boldsymbol{\mu}_{t}\), the Cholesky decomposition \(\mathbf{L}_{t}\) of the covariance matrix \(\boldsymbol{\Sigma}_{t}\), and the standard normal noise \(\boldsymbol{\epsilon}\)."
ICLR_2024_oral_24,12,"\tilde{x}_{1}^{SDE}=\frac{(1-t)(F_{t}^{\theta}+v_{t })}{g_{t}^{2}P_{11}}+x_{t}, or \quad\tilde{x}_{1}^{ODE}=\frac{F_{t}^{\theta}+g_{t}^{2}P_{ 11}(\alpha_{t}x_{t}+\beta_{t}v_{t})}{4(t-1)^{2}+g_{t}^{2}P_{ 11}(\alpha_{t}\mu_{t}^{x}+\beta_{t}\mu_{t}^{v})}",,"\tilde{x}_{1}=x_{t}+(1-t)v_{t}+\frac{1}{2}(1-t)^{2}F_{t}^{\theta}(m_{t},t;\theta)","The estimated data point \(\tilde{\mathbf{x}}_{1}\) is a function of the current state \(\mathbf{x}_{t}\), velocity \(\mathbf{v}_{t}\), and the trained force term \(\mathbf{F}_{t}^{\theta}\) at time step \(t\)."
ICLR_2024_oral_25,1,"\underbrace{\nu(x)>0,\\\forall x\inInterior(M_{o})}_{Case 1: inside the open surface},\quad\underbrace{\nu(x)=0,\\\forall x\in\partialM_{o}}_{Case 2: on the surface boundary},\quad\underbrace{\nu(x)<0,\\Otherwise}_{ Case 3: outside the open surface}",where \(\nu\) can be instantiated as the signed geodesic distance to the open surface boundary living on the watertight template,\nu:M\rightarrowR,\(\nu\) is a continuous and differentiable mapping on the template sphere \(\mathcal{M}\) that characterizes if a point belongs to the open surface \(\mathcal{M}_{o}\)
ICLR_2024_oral_25,2,L_{mSDF-reg}(\theta_{mSDF})=\underbrace{\sum_{u:v_{\theta_{ ndSF}}(u)\geq 0}L_{nuber}(v_{\theta_{noster}}(u))}_{ Encourage hole opening}+\underbrace{\tau\cdot\sum_{{c}u^{\prime}:v_{\theta_{ ndSF}}(u^{\prime})=0\\u^{\prime} visible from some q\in Q}L_{nuber}(v_{\theta_{n ober}}(u^{\prime})-\epsilon)}_{Regularize holes from being too large},,\nu^{\prime}=\frac{s_{i}\nu_{j}-s_{j}\nu_{i}}{s_{i}-s_{j}},The mSDF value on the extracted mesh vertex is computed using the SDF values and mSDF values of the edge vertices.
ICLR_2024_oral_25,3,"u^{\prime}=\frac{|\nu_{1}|}{|\nu_{1}-\nu_{2}|}\cdot u_{2}-\frac{|\nu_{2}|}{|\nu_{1}-\nu_{2}|}\cdot u_{1},\quad\nu_{1}<0<\nu_{2}",,\nu^{\prime}=\frac{s_{i}\nu_{j}-s_{j}\nu_{i}}{s_{i}-s_{j}},The equation represents the computation of the mSDF value on the extracted mesh vertex using the SDF values and mSDF values of the grid vertices.
ICLR_2024_oral_26,1,E=({cccc}W^{(l)\top}&W^{(2)\top}&W^{(l)\top}&W^{(l)\top}\\\hline\ddots&W^{(2)\top}&W^{(2)\top}&W ^{(l)\top}\\),where \(\mathbf{\mathrm{W}}^{(l)\top}\) denotes the transposed weight matrix,"V=b^{(1)}\\\vdots\\b^{(L)} ,E=W^{(1)} &\cdots &0\\\vdots &\ddots &\vdots\\0 &\cdots &W^{(L)}","The node feature matrix \(\mathbf{V}\) contains the biases of the MLP, and the edge feature matrix \(\mathbf{E}\) contains the weights of the MLP."
ICLR_2024_oral_26,2,"V_{probe}=\Big{(}x,\alpha\Big{(}W^{(1)}x+b^{(1)}\Big{)},f(x)\Big{)}^{\top}",,V=b^{(1)}\\\alpha\big{(}W^{(1)}x+b^{(1)}\big{)}\\W^{(2)}\alpha\big{(}W^{(1)}x+b^{(1)}\big{)}+b^{(2)},"The node feature matrix V for a simple neural network with two layers, including the input, the activation of the first layer, and the output of the second layer."
ICLR_2024_oral_26,3,"e_{ij}^{(k+1)}=\phi_{e}^{(k+1)}\Big{(}\Big{[}v_{i}^{(k)},e_{ij}^{(k)},v_{j}^{(k)}\Big{]}\Big{)}",where \(k\) is the layer index in our network,"E^{(l+1)}=\phi_{e}\Big{(}E^{(l)},V^{(l)}\Big{)}",The edge feature update function for the graph neural network.
ICLR_2024_oral_26,4,"m_{ij}=\phi_{scale}(e_{ij})\odot\phi_{m}([v_ {i},v_{j}])+\phi_{shift}(e_{ij})",,"v_{i}^{(k+1)}=\phi_{v}^{(k+1)}\Big{(}\Big{[}v_{i}^{(k)},\sum_{j\inN(i)}e_{ij}^{(k)}\odotv_{j}^{(k)}\Big{]}\Big{)}",where \(\odot\) denotes element-wise multiplication and \(\phi_{v}^{(k+1)}\) is a learnable function at layer \(k+1\).
ICLR_2024_oral_26,5,v_{ij}=(W_{scale}^{value}e_{ij} )\odot(W_{n}^{value}v_{j})+ W_{shift}^{value}e_{ij},,V'=\phi_{scale}(E)\odotV+\phi_{shift}(E),"The equation represents the modulation of the value matrix in the self-attention module of the transformer, where the edge features are used to compute scaling and shifting factors."
ICLR_2024_oral_27,1,\sum_{i=1}^{N_{k}}W(A_{i}^{k})=W(\bigcup_{i=1}^{N_{k}}A_{i}^{k})=W(A^{0}),,W(A^{0})=\sum_{i=1}^{N_{k}} W(A_{i}^{k})\,The equation represents the property of white Gaussian noise where the noise defined on a coarser partition can be expressed as the sum of noises defined on a finer partition.
ICLR_2024_oral_27,2,"(W(A^{k})|W(A^{0})=x)\simN(\bar{\mu},\bar{\Sigma}),\quadwith \bar{\mu}=\frac{x}{N_{k}}u,\bar{\Sigma}=\frac{1}{N_{k}} (I_{N_{k}}-\frac{1}{N_{k}}uu^{\top})","where \(\mathbf{u}=(1,\ldots,1)^{\top}\)","N\left(\frac{x}{N_{k}}1,\nu_{k}I-\frac{1}{N_{k}}11^{\top}\right)",The conditional distribution of sub-pixel values given the value of an entire pixel.
ICLR_2024_oral_27,3,"(W(A^{k})|W(A^{0})=x)=\bar{\mu}+UZ=\frac{x}{N_{k}} u+\frac{1}{\sqrt{N_{k}}}(Z-\langle Z\rangleu),\quadwith Z\sim(0,I)",where \(\langle Z\rangle\) is the mean of \(Z\),W(A^{k})=\frac{x}{N_{k}}u+\frac{1}{\sqrt{N_{k}}}Uz,where \(\mathbf{z}\) is a standard Gaussian random variable.
ICLR_2024_oral_27,4,T(W)(A)=\int_{x\in A}\frac{1}{|\nablaT(T^{-1}(x))|^{\frac{1}{2}}}W(T^{-1}(x))\dx,where \(\left|\nabla\mathcal{T}\right|\) is the determinant of the Jacobian of \(\mathcal{T}\),T(W)(A)=W(T^{-1}(A)),The noise transport equation defines how a continuous white noise W is transported with a diffeomorphic deformation field \(\mathcal{T}\) in a distribution-preserving manner.
ICLR_2024_oral_27,5,G(p)=\frac{1}{\sqrt{|\Omega_{p}|}}\sum_{A_{s}^{k}\in\Omega_ {p}}W_{k}(A_{s}^{k})\,,T(W)(p)=\frac{1}{|P|}\sum_{i\inP}W(A_{i}^{k}),where \(\mathcal{P}\) is the set of sub-pixels covered by the warped polygon and \(|\mathcal{P}|\) is the number of sub-pixels in \(\mathcal{P}\).
ICLR_2024_oral_27,6,"z_{i}=\alpha x_{i-1}+(1-\alpha)x_{i},\quad z_{i}\simN(0,\,\sigma_{z }^{2}),\quadwith \sigma_{z}^{2}=\alpha^{2}+(1-\alpha)^{2}",,z_{i}=(1-\alpha)x_{i}+\alpha x_{i+1},where \(z_{i}\) is the interpolated value at location \(i\) after applying the translation mapping \(\mathcal{T}^{1}_{1D}\).
ICLR_2024_oral_27,7,"z_{i}|x_{i},x_{i-1}\simN(\mu_{\infty},\sigma_{\infty}^{2}),\quadwith \{{l}\mu_{\infty}=\alpha x_{i-1}+(1-\alpha)x_{i}\\\sigma_{\infty}^{2}=1-(\alpha^{2}+(1-\alpha)^{2})=1-\sigma_{z}^{2}",,"z\simN(\alpha x_{i-1}+(1-\alpha)x_{i},\alpha(1-\alpha))","where \(z\) is a Brownian bridge between neighboring \(x\) values, and \(\alpha\) is the translation parameter."
ICLR_2024_oral_28,1,\lVertA\hat{x}^{\star}-b\rVert_{2}^{2}\leq(1+\epsilon)\lVertAx^{\star}-b\rVert_{2}^{2},,\lVertA\hat{x}^{\star}-b\rVert_{2}^{2}\leq(1+\epsilon)\lVertAx^{\star}-b\rVert_{2}^{2},\(\hat{\mathbf{x}}^{\star}\) represents the estimated optimal model parameters.
ICLR_2024_oral_28,2,\tau_{i}=\|u_{i}\|_{2}^{2}=a_{i}^{T}(A^{T} A)^{-1}a_{i}=\max_{x\inR^{d}}(a_{i}^{T}x)^{2}/\|Ax\|_{2}^{2},,\tau_{i}=\lVertu_{i}\rVert_{2}^{2},The leverage score \(\tau_{i}\) of the \(i\)-th row in \(\mathbf{A}\) measures the degree to which the \(i\)-th row influences the range of \(\mathbf{A}\).
ICLR_2024_oral_28,3,\|A\tilde{x}^{*}-b\|_{2}^{2}\leq(1+\epsilon)\|Ax^{*}-b\|_{2}^{2},,\lVert\tilde{A}\tilde{x}^{*}-\tilde{b}\rVert_{2}^{2}\leq(1+\epsilon)\lVertAx^{*}-b\rVert_{2}^{2},"The equation represents the guarantee for the approximation quality of the solution obtained through pivotal sampling, where the scaled sampled data and target are used to find the optimal parameters."
ICLR_2024_oral_28,4,\|\tilde{p}-b\|_{2}^{2}\leq(1+\epsilon)\underset{degree d polynomial p}{\min}\|p-b\|_{2}^{2},,"\|\tilde{p}-b\|_{L_{2}([\ell,u])}^{2}\leq(1+\epsilon)\cdot\inf_{p\inP_{d}}\|p-b\|_{L_{2}([\ell,u])}^{2}","The equation represents the upper bound of the L2 norm of the difference between the constructed polynomial and the target function, in terms of the best possible polynomial approximation of the same degree."
ICLR_2024_oral_28,5,"I_{\mu}^{S}(i,j)=\Pr_{\mu}[\xi_{j}=1|\xi_{i}=1\wedge\xi_{\ell}=1\forall\ell\inS]-\Pr_{\mu}[\xi_{j}=1|\xi_{\ell}=1\forall\ell\inS]",,"I_{\mu}^{S}(i,j)=P_{\xi\sim\mu}[\xi_{i}=1|\xi_{S}=1,\xi_{j}=1]-P_{\xi\sim\mu}[\xi_{i}=1|\xi_{S}=1,\xi_{j}=0]","\(\mathcal{I}_{\mu}^{\mathcal{S}}(i,j)\) measures the difference in probability of \(\xi_{i}\) being 1 when \(\xi_{j}\) is 1 versus 0, conditioned on \(\xi_{\mathcal{S}}\) being 1."
ICLR_2024_oral_29,1,"\frac{dx}{d\sigma}=-\sigma\nabla_{x}\log p _{\sigma}(x)\quad\sigma\in[\sigma_{min},\sigma_{max}]",where the term \(\nabla_{\mathbf{x}}\log p_{\sigma}(\mathbf{x})\) is known as the _score function_ of \(p_{\sigma}(\mathbf{x})\)(Song et al,\frac{\partial p_{\sigma}(x)}{\partial\sigma}=\nabla\cdot\left(\sigma\nabla p_{\sigma}(x)\right),The probability flow ordinary differential equation (ODE) describes how the perturbed distribution $p_{\sigma}(\mathbf{x})$ changes with respect to the standard deviation $\sigma$ of the added Gaussian noise.
ICLR_2024_oral_29,2,"f_{\theta}(x,\sigma)=c_{skip}(\sigma)x+c_{out}(\sigma)F_{\theta}(x,\sigma)","where \(\mathbf{F}_{\mathbf{\theta}}(\mathbf{x},\sigma)\) is a free-form neural network, while \(c_{\text{skip}}(\sigma)\) and \(c_{\text{out}}(\sigma)\) are differentiable functions such that \(c_{\text{skip}}(\sigma_{\text{min}})=1\) and \(c_{\text{out}}(\sigma_{\text{min}})=0\)","f_{\theta}(x,\sigma)=x+(\sigma_{min}-\sigma)h_{\theta}(x,\sigma)","The consistency model is parameterized as a function of the input data and noise level, where $\mathbf{h}_{\theta}(\mathbf{x},\sigma)$ is a neural network."
ICLR_2024_oral_29,3,"L^{N}(\theta,\theta^{-})=E[\lambda(\sigma_{i} )d(f_{\theta}(x_{\sigma_{i+1}},\sigma_{i+1}),f_{\theta}_{-}(\tilde{x}_{\sigma_{i}},\sigma_{i}))]",where \(\tilde{\mathbf{x}}_{\sigma_{i}}=\mathbf{x}_{\sigma_{i+1}}-(\sigma_{i}-\sigma_{ i+1})\sigma_{i+1}\nabla_{\mathbf{x}}\log p_{\sigma_{i+1}}(\mathbf{x})|_{\mathbf{x}= \mathbf{x}_{\sigma_{i+1}}}\),"L_{CM}(\theta)=\sum_{i=1}^{N-1}E_{x\sim p_{\sigma_{i}}(x)}\left[\left\|f_{\theta}(x,\sigma_{i})-f_{\theta}(x,\sigma_{i+1})\right\|_{2}^{2}\right]",The consistency matching loss measures the difference between the model's predictions at consecutive noise levels.
ICLR_2024_oral_29,4,\theta^{-}arrowstopgrad(\mu\theta^{-}+(1-\mu)\theta),,\theta^{-}_{t}=\alpha\theta^{-}_{t-1}+(1-\alpha)\theta_{t},The update rule for the teacher network's parameter using Exponential Moving Average (EMA).
ICLR_2024_oral_29,5,"L_{CT}^{N}(\theta,\theta^{-})=E[\lambda(\sigma_{i})d(f_{\theta}(x+\sigma_{i+1}z,\sigma_ {i+1}),f_{\theta^{-}}(x+\sigma_{i}z,\sigma_{i}))]",,"L^{N}(\theta,\theta^{-})=E[\lambda(\sigma_{i})d(f_{\theta}(x_{\sigma_{i+1}},\sigma_{i+1}),f_{\theta^{-}}(x+\sigma_{i}z,\sigma_{i}))]",The consistency training objective is a loss function that measures the difference between the student network and the teacher network.
ICLR_2024_oral_29,6,"\lim_{N\to\infty}L^{N}(\theta,\theta^{-})=\lim_{N\to\infty}L^{N}_{CT}(\theta,\theta^{-})=E\Big{[}\big{(} 1-\frac{\sigma_{min}}{\sigma_{i}}\big{)}^{2}(\theta-\theta^{-})^{2}\Big{]}\quadif\theta^{-}\neq\theta || \lim_{N\to\infty}\frac{1}{\Delta\sigma}\frac{d L^{N}(\theta,\theta^{-})}{d\theta}=\{{ll}\frac{dL}{d\theta}E\Big{[}\frac{\sigma_ {min}}{\sigma_{i}^{2}}\Big{(}1-\frac{\sigma_{min}}{\sigma_{i}}\Big{)}(\theta-\xi)^{2}\Big{]},&\theta^{-}=\theta\\+\infty,&\theta^{-}\prec\theta\\-\infty,&\theta^{-}>\theta",,"\lim_{N\to\infty}L^{N}(\theta,\theta^{-})=\lim_{N\to\infty}\frac{1}{N-1}\sum_{i=1}^{N-1}\|f_{\theta}(x_{\sigma_{i+1}},\sigma_{i+1})-f_{\theta^{-}}(\tilde{x}_{\sigma_{i}},\sigma_{i})\|_{2}^{2}=\frac{(\theta-\theta^{-})^{2}(\sigma_{max}^{2}-\sigma_{min}^{2})}{\sigma_{min}^{2}}","where \(\mathbf{f}_{\theta}(\mathbf{x},\sigma)=\frac{\sigma_{\text{min}}}{\sigma}\mathbf{x}+\left(1-\frac{\sigma_{\text{min}}}{\sigma}\right)\theta\) and \(\tilde{\mathbf{x}}_{\sigma_{i}}=\mathbf{x}_{\sigma_{i+1}}-(\sigma_{i}-\sigma_{i+1})\sigma_{i+1}\nabla_{\mathbf{x}}\log p_{\sigma_{i+1}}(\mathbf{x})|_{\mathbf{x}=\mathbf{x}_{\sigma_{i+1}}}\)."
ICLR_2024_oral_29,7,"d(x,y)=\sqrt{\lVertx-y\rVert_{2}^{2}+c^{2}}-c",,"d(x,y)=\sqrt{\|x-y\|_{2}^{2}+c^{2}}-c","The Pseudo-Huber metric function measures the difference between two vectors x and y, with a smoothing parameter c."
ICLR_2024_oral_29,8,"N(k)=\min(s_{0}2^{\lfloor\frac{1}{N}\rfloor},s_{1})+1,\quad K^{\prime}=\Big{|}\frac{K}{\log_{2}[s_{1}/s_{0}]+1}\Big{|}",,"N(k)=\min(s_{0}2^{\frac{k}{K}},s_{1})+1","The equation represents the improved curriculum for total discretization steps, where N(k) is the number of discretization steps at training iteration k, s0 and s1 are hyperparameters, and K is the total number of training iterations."
ICLR_2024_oral_3,1,"\theta^{*}\in\operatorname*{arg\,min}_{\theta\inR^{d}}f(\theta),\\\where f(\theta)\triangleqE_{X\sim\mu}[F(\theta,X) ]=\sum_{i\inN}\mu_{i}F(\theta,i)",,\min_{x\inR^d} f(x)=E_{\xi\simD}[f(x;\xi)],"The equation represents the general form of a stochastic optimization problem, where f(x) is the objective function, x is the variable, ξ is a random variable following distribution ℓ, and ℓ is the data distribution."
ICLR_2024_oral_3,2,"\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{n+1}),\\\\forall\n\geq 0","where, roughly speaking, \(H(\mathbf{\theta},i)\) contains gradient information \(\nabla_{\mathbf{\theta}}F(\theta,i)\), such that \(\mathbf{\theta}^{*}\) solves \(\mathbf{h}(\mathbf{\theta})\triangleq\mathbb{E}_{X\sim\mathbf{\mu}}[H(\mathbf{\theta},X)]= \sum_{i\in\mathcal{N}}\mu_{i}H(\mathbf{\theta},i)=\mathbf{0}\)","\theta_{n+1}=\theta_{n}-\beta_{n}\nabla F(\theta_{n}, X_{n})","The update rule for stochastic optimization algorithms, where $\mathbf{\theta}_{n}$ is the parameter vector at iteration $n$, $\beta_{n}$ is the step size, and $\nabla F(\mathbf{\theta}_{n}, X_{n})$ is the gradient of the objective function with respect to the parameter vector."
ICLR_2024_oral_3,3,"K_{ij}[x]\triangleq\frac{P_{ij}(x_{j}/\mu_{j})^{-\alpha}}{\sum_{k\inN}P_{ik}(x_{k}/\mu_{k})^{-\alpha}},\quad\quad\forall\,i,j\in N",,"K[x]_{ij}=\frac{\mu_{j}x_{j}^{\alpha-1}}{\sum_{k\inN}\mu_{k}x_{k}^{\alpha-1}},\\\\forall\i,j\inN","The non-linear transition kernel of the self-repellent random walk, where $\mathbf{x}$ is a probability distribution, $\mu$ is the target distribution, $\alpha$ is a positive scalar controlling the strength of self-repellence, and $i$ and $j$ are nodes in the graph."
ICLR_2024_oral_3,4,"Draw:\qquad X_{n+1}\simK_{X_{n},\cdot}[x_{n}]",,"\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{n+1}),\\\\forall\n\geq 0",The SA-SRRW algorithm updates the parameter vector using the stochastic approximation iteration with the noise sequence generated by the Self Repellent Random Walk.
ICLR_2024_oral_3,5,"\quadx_{n+1}=x_{n}+\gamma_{n+1}(\delta_{X_{n+1}}-x_{n}) || \quad\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{ n+1})",,"\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{n+1}),\\\\forall\n\geq 0","The update rule for the SA-SRRW algorithm, where the noise sequence is generated by the SRRW stochastic process."
ICLR_2024_oral_3,6,"\theta_{n}\xrightarrow[n\to\infty]{a.s.}\theta^{*}\quadand\quad(\theta_{n}-\theta^{*})/\sqrt{\beta_{n}}\xrightarrow[n\to\infty]{dist.}N(0,V_{\theta}^{(k)}(\alpha))",,"\lim_{n\to\infty}\sqrt{n}\left(\theta_{n}-\theta^{*}\right)\xrightarrow{d}N\left(0,C_{k}(\alpha)\right)",where $\mathbf{C}_{k}(\alpha)$ is the asymptotic covariance matrix for case $k$.
ICLR_2024_oral_3,7,"x_{n}=\frac{\sum_{i=1}^{n}\omega_{i}\theta_{X_{i}}+\omega_{0}x_{0}}{\sum_{i=0}^{n}\omega_{i}},\\where\\\omega_{0}=1,\\and\\\omega_{n}=\frac{\gamma_{n}}{\prod_{i=1}^{n}(1-\gamma_{i})}",,x_{n}=\frac{\sum_{k=0}^{n}\gamma_{k}\delta_{X_{k}}}{\sum_{k=0}^{n}\gamma_{k}},The weighted empirical measure of the SRRW process.
ICLR_2024_oral_3,8,"x_{n}\xrightarrow[n\to\infty]{a.s.}\mu,\quadand\quad\gamma_{n}^{-1/2}(x_{n}-\mu)\xrightarrow[n\to\infty]{dist.}N(0,V_{x}(\alpha)) || where\quadV_{x}(\alpha)=\sum_{i=1}^{N-1 }\frac{1}{2\alpha(1+\lambda_{i})+2-\mathds{1}_{\{a=1\}}}\cdot\frac{1+\lambda_ {i}}{1-\lambda_{i}}u_{i}u_{i}^{T}",,"x_{n}\xrightarrow[n\to\infty]{a.s.}\mu,\quadand\quad\sqrt{n}(x_{n}-\mu)\xrightarrow[n\to\infty]{dist.}N(0,\Sigma_{x}(\alpha))",where $\mathbf{\Sigma}_{\mathbf{x}}(\alpha)$ is a covariance matrix that depends on $\alpha$ and the transition kernel $\mathbf{P}$ of the base Markov chain.
ICLR_2024_oral_3,9,\tfrac{d}{dt}z(t)=g(z(t))\triangleqH(\theta(t))^{T}\pi[x(t)]\\\pi[x(t)]-x(t)\inR^{D+N},"where matrix \(\mathbf{H}(\boldsymbol{\theta})\triangleq[H(\boldsymbol{\theta},1),\cdot,H( \boldsymbol{\theta},N)]^{T}\in\mathbb{R}^{N\times D}\) for any \(\boldsymbol{\theta}\in\mathbb{R}^{D}\)",V_{\theta}^{(1)}(\alpha)=\sum_{i=1}^{N-1}\frac{(1+\lambda_{i})^{2}}{(2\alpha(1+\lambda_{i})+2-\mathds{1}_{\{a=1\}})(1-\lambda_{i})}\cdot\frac{u_{i}u_{i}^{T}\otimesI_{D}}{2\alpha(1+\lambda_{i})+2},"where \(\mathbf{V}_{\boldsymbol{\theta}}^{(1)}(\alpha)\) is the asymptotic covariance matrix for case (i), \(\lambda_{i}\) are the eigenvalues of the transition kernel \(\mathbf{P}\), \(\mathbf{u}_{i}\) are the corresponding eigenvectors, \(\mathbf{I}_{D}\) is the identity matrix, and \(\alpha\) is the hyperparameter controlling the strength of the self-repellent behavior."
ICLR_2024_oral_3,10,J(\alpha)\!\triangleq\!\nabla g(z^{*})\!=\!\nablah(\theta^{*})&-\alphaH(\theta^{*})^{T}(P^{T}\!+\mathds{I})\\0_{N\!\times\!D}&2\alpha\mu\mathds{1}^{T}\!-\!\alpha\mathds{P}^{T}\!\!-\!(\alpha\!+\!1)\mathds{I}\!\triangleq\!J_{11}&J_{12}(\alpha)\\J_{21}&J_{22}(\alpha),,J(\alpha)=\nablah(\theta^{*})&H(\theta^{*})^{T}\nabla\pi[\mu]\\0&\nabla\pi[\mu]-I,"where \(\nabla\mathbf{h}(\boldsymbol{\theta}^{*})\triangleq\mathbb{E}_{i\sim \boldsymbol{\mu}}[\nabla H(\boldsymbol{\theta}^{*},i)]\) and \(\nabla\boldsymbol{\pi}[\boldsymbol{\mu}]\triangleq[\frac{\partial\pi_{i}[ \boldsymbol{\mu}]}{\partial\mu_{j}}]_{i,j\in\mathcal{N}}\in\mathbb{R}^{N\times N}\) is the Jacobian of \(\boldsymbol{\pi}[\cdot]\) evaluated at \(\boldsymbol{\mu}\),"
ICLR_2024_oral_3,11,"\beta_{n}^{-1/2}(\theta_{n}-\theta^{*} )\\\gamma_{n}^{-1/2}(x_{n}-\mu)\xrightarrow[n\to\infty]{ait.}N(0,V^{(k)}(\alpha))",,"\beta_{n}^{-1/2}(\theta_{n}-\theta^{*})\xrightarrow[n\to\infty]{dist.}N(0,V_{\theta}^{(k)}(\alpha))","where $\boldsymbol{\theta}^{*}$ is the limit of the sequence $\{\boldsymbol{\theta}_{n}\}_{n\geq 0}$, and $\mathbf{V}_{\boldsymbol{\theta}}^{(k)}(\alpha)$ is the asymptotic covariance matrix for case $k$."
ICLR_2024_oral_3,12,U\triangleq\sum_{i=1}^{N-1}\frac{1+\lambda_{i}}{1-\lambda_{i}}\cdotH^{T}u_{i}u_{i}^{T}H&H^{T}u_{i}u_{i}^{T}\\u_{i}u_{i}^{T}H&u_{i}u_{i}^{T}\triangleqU_{11}&U_{12}\\U_{21}&U_{22},,U\triangleqH^{T}D_{\mu}H&H^{T}D_{\mu}\\D_{\mu}H&D_{\mu},"where \(\mathbf{H}\triangleq[H(\boldsymbol{\theta}^{*},1),\cdots,H(\boldsymbol{\theta}^{*},N)]^{T}\in\mathbb{R}^{N\times D}\) and \(\mathbf{D}_{\boldsymbol{\mu}}\) is a diagonal matrix with \(\mu_{i}\) as the \(i\)'th diagonal entry."
ICLR_2024_oral_3,13,V^{(k)}(\alpha)=V^{(k)}_{\theta }(\alpha)&0_{D\times\!N}\\0_{N\!\times\!D}&V_{x}(\alpha),,"V^{(1)}(\alpha)=V_{\theta}^{(1)}(\alpha)&0\\0&V_{x}(\alpha),\quadV^{(3)}(\alpha)=V_{\theta}^{(3)}(\alpha)&0\\0&V_{x}(\alpha)","where $\mathbf{V}_{\boldsymbol{\theta}}^{(1)}(\alpha)$ and $\mathbf{V}_{\boldsymbol{\theta}}^{(3)}(\alpha)$ are the asymptotic covariance matrices for cases (i) and (iii), respectively."
ICLR_2024_oral_31,1,P(z;H)=\mathds{1}(H(z)<\bar{H}),where \(\bar{\mathcal{H}}\) is a threshold and \(\mathds{1}(\cdot)\) is indicator function,P(z;H)=0 &if H(z) <\tau\\1 &otherwise,The pruning probability \(\mathcal{P}(z;\mathcal{H})\) is defined based on the score \(\mathcal{H}(z)\) and a threshold \(\tau\).
ICLR_2024_oral_31,2,P_{t}(z)=P(z;H_{t}),,"P_{t}(z;H_{t})\in [0,1]",where \(\mathcal{P}_{t}(z;\mathcal{H}_{t})\) is the pruning probability at training step \(t\)
ICLR_2024_oral_31,3,"P_{t}(z)=r,&H_{t}(z)<\bar{H}_{t}\\0,&H_{t}(z)\geq\bar{H}_{t}","where \(\bar{\mathcal{H}}_{t}\) is the mean value of all the scores \(\mathcal{H}_{t}\) and \(r\in(0,1)\) is a predefined hyper-parameter as the pruning probability",P_{t}(z;H_{t})=\frac{1}{1+e^{H_{t}(z)-\bar{H}_{t}}},"where \(\bar{\mathcal{H}}_{t}\) is the adaptive threshold of scores of samples at epoch \(t\), and \(\mathcal{H}_{t}(z)\) is the score of sample \(z\) at epoch \(t\)."
ICLR_2024_oral_31,4,"H_{t+1}(z)=H_{t}(z),&z\inD\backslashS_{t}\\L(z),&z\inS_{t}",,"H_{t+1}(z)=H_{t}(z), &if  z is pruned\\L_{t}(z), &if  z is not pruned","where \(\mathcal{H}_{t}(z)\) is the score of sample \(z\) at time step \(t\), and \(\mathcal{L}_{t}(z)\) is the loss value of sample \(z\) at time step \(t\)."
ICLR_2024_oral_31,5,"\operatorname*{arg\,min}_{\theta\in\Theta}\mathop{E}_{z\inD }[L(z,\theta)]=\int_{z}L(z,\theta)\rho(z)dz",,L=\int_{z}L(z)\rho(z) dz,where \(\mathcal{L}(z)\) is the loss of sample \(z\) and \(\rho(z)\) is the probability density function of sample \(z\)
ICLR_2024_oral_31,6,"\operatorname*{arg\,min}_{\theta\in\Theta}\mathop{E}_{z\inS _{t}}[\gamma_{t}(z)L(z,\theta)]=\operatorname*{arg\,min}_{\theta\in\Theta}\frac{1}{c_{t}}\int_{z}L(z,\theta)\rho(z)dz","where \(c_{t}=\mathbb{E}_{z\sim\rho}[1-\mathcal{P}_{t}(z)]=\int_{z}\rho(z)(1-\mathcal{ P}_{t}(z))dz\), \(c_{t}\in(0,1)\) is a constant for temporal status \(t\)","\operatorname*{arg\,min}_{\theta\in\Theta}\int_{z}\gamma_{t}(z)L(z,\theta)(1-P_{t}(z))\rho(z)dz",where \(\gamma_{t}(z)\) is the rescaling factor for each sample \(z\) at the \(t\)-th epoch.
ICLR_2024_oral_31,7,\frac{1}{c_{t}}=\frac{|D|}{|\sum_{z\inD}(1-P_{t}( z))|}\simeq\frac{|D|}{|S_{t}|}\RightarrowE[\nabla_{\theta}L(S_{t})]\simeq\frac{|D|}{|S_{t}|}\mathop{E}[\nabla_{\theta}L(D)],,\frac{1}{N}\sum_{i=1}^{N}\gamma_{t}(z_{i})=1,"where \(N\) is the number of samples in the dataset \(\mathcal{D}\), and \(\gamma_{t}(z_{i})\) is the rescaled factor for sample \(z_{i}\) at temporal status \(t\)."
ICLR_2024_oral_31,8,"P_{t}(z)=r,&H_{t}(z)<\tilde{H}_{t}\wedge t<\delta\cdot C\\0,&H_{t}(z)\geq\tilde{H}_{t}\lor t\geq\delta\cdot C",,\frac{|S_{t}|}{|D|}\cdot\frac{|D|}{|S_{t}|}=1,"where the left side of the equation represents the ratio of the iteration number to the original one, and the right side represents the scaling factor of the expected gradient."
ICLR_2024_oral_32,1,"sim(I,t)=\langle M_{image}(I),M_{text}(t)\rangle/( || M_{image}(I) || _{2} || M_{text}(t) || _{2})",,\cos(\theta)=\frac{M_{image}(I)\cdot M_{text}(t)}{\|M_{image}(I)\|\|M_{text}(t)\|},The cosine similarity between the image and text representations in the shared latent space.
ICLR_2024_oral_32,2,M_{image}(I)=PViT(I),,M_{image}(I)=P\cdotViT(I),The CLIP image representation is obtained by applying a linear projection to the output of the vision transformer.
ICLR_2024_oral_32,3,"\hat{Z}^{l}=MSA^{l}(Z^{l-1})+Z^{l-1},\quad Z^{l}=MLP^{l}(\hat{ Z}^{l})+\hat{Z}^{l}",,Z^{l}=MSA(LN(Z^{l-1}))+Z^{l-1},The variable \(Z^{l}\) represents the output of the \(l\)-th layer in the ViT architecture.
ICLR_2024_oral_32,4,M_{image}(I)=PViT(I)=P[Z^{0}]_{cls}+\underbrace{\sum_{ l=1}^{L}P[MSA^{l}(Z^{l-1})]_{cls}}_{MSA\terms}+\underbrace{\sum_{l=1}^{L}P[MLP^{l}(\hat{Z}^{l}) ]_{cls}}_{MLP\perms},,M_{image}(I)=P\left(\sum_{l=0}^{L-1}\left(\prod_{k=l+1}^{L-1} (MLP^{k}+I)\circMSA^{k}\right)\circMLP^{l}\circMSA^{l}(Z^{l-1})\right)+PZ^{0},The image representation \(M_{\text{image}}(I)\) is a linear projection of the sum of direct contributions of individual layers of the ViT model.
ICLR_2024_oral_32,5,"[MSA^{l}(Z^{l-1})]_{cls}=\sum_{h=1}^{H}\sum_{i=0}^{N}x_{i} ^{l,h},\\\x_{i}^{l,h}=\alpha_{i}^{l,h}W_{VO}^{l,h}z_{i}^{l-1}","where \(W_{VO}^{l,h}\in\mathbb{R}^{d\times d}\) are transition matrices and \(\alpha_{i}^{l,h}\in\mathbb{R}\) are the attention weights from the class token to the \(i\)-th token (\(\sum_{i=0}^{N}\alpha_{i}^{l,h}=1\))","MSA^{l}(Z^{l-1})=\sum_{h=1}^{H}\sum_{i=0}^{N}a_{i,h}^{l}W_{V,h}^{l}z_{i}^{l-1}","The output of the multi-head self-attention mechanism at layer l, where a_i,h^l represents the attention weight, W_V,h^l represents the value matrix, and z_i^(l-1) represents the input token."
ICLR_2024_oral_32,6,"\sum_{l=1}^{L}P[MSA^{l}(Z^{l-1})]_{cls}=\sum_{l=1}^{L}\sum_{h=1 }^{H}\sum_{i=0}^{N}c_{i,l,h},\\c_{i,l,h}=Px_{i}^{l,h}",,"M_{image}(I)=P[Z^{0}]_{cls}+\sum_{l=1}^{L}\sum_{h=1}^{H}\sum_{i=0}^{N}P x_{i}^{l,h}","The image representation is a linear projection of the sum of the direct contributions of individual layers, heads, and tokens."
ICLR_2024_oral_32,7,"V_{explained}(T)=\frac{1}{K}\sum_{k=1}^{K}\| Proj_{T}(c_{k}-c_{avg})\|_{2}^{2}, where c_{avg}=\frac{1}{K}\sum_{k=1}^{K}c_{k}",,"Var_{T}(c_{1},...,c_{K})=\frac{1}{K}\sum_{k=1}^{K}\left\lVertProj_{T}(c_{k})\right\rVert^{2}",The variance explained by a set of text directions is the average squared magnitude of the projections of the head outputs onto the span of the text directions.
ICLR_2024_oral_35,1,P_{d}\approx 12lh^{2}+Vh\hskip 28.452756pt(1)\hskip 36.135ptP_{e}\approx(1-\rho)P_{d}+\rho(4h^{2}+8h^{2}N_{e})l,,P_{d}=4h^{2}l+2hV+2h^{2}lN_{e},"The parameter count of a dense LLM is calculated based on its architectural parameters including hidden size, number of layers, vocabulary size, and number of experts."
ICLR_2024_oral_35,2,"L(P,D)=\frac{A}{P^{\alpha}}+\frac{B}{D^{\beta}}+E\hskip 14.226378pt(3)\hskip 28.452756ptTC\approx 6PD\hskip 14.226378pt(4)\hskip 28.452756ptIC\approx 2PD\hskip 14.226378pt(5)",,P_{e}\approx(1-\rho)P_{d}+\rho(4h^{2}+8h^{2}N_{e})l,"The parameter count of an MoE LLM is approximated by this equation, taking into account the number of experts, hidden size, and other architectural parameters."
ICLR_2024_oral_35,3,eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n }&re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2}&re>n || eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n }&re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2}&re>n,,"L(P,D)=\frac{A}{P^{\alpha}}+\frac{B}{D^{\beta}}+E\hskip 14.226378pt(3)\hskip 28.452756pt",The test loss L equals to the summation of an irreducible term E and a reducible term diminishing through the scaling of P and D.
ICLR_2024_oral_35,4,energy_{hard}=\sum_{i\in hardware\_set}(P_{i}\cdoteff_{i}\cdot n_{i}\cdot t_{i}) || energy_{oper}=energy_{hard}\cdotPUE,,TC\approx 6PD,The total computational cost for training a dense LLM is approximated as 6 times the product of the parameter count and the number of tokens processed.
ICLR_2024_oral_35,5,CO2eq_{oper}=energy_{oper}\cdot carb\_int,,IC\approx 2PD,"The inference carbon, denoted as IC, is approximated as 2 times the product of the parameter count and the number of tokens processed by the LLM."
ICLR_2024_oral_35,6,CO2eq_{emb}=\sum_{i\in hardware\_set}\frac{t_{i}\cdotCO2eq_{chip_{i}}}{lifetime_{i}},,eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n }&re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2}&re>n,"The equation calculates the hardware efficiency when the number of computing devices is not equal to the optimal number, using fitting constants and the highest hardware efficiency."
ICLR_2024_oral_36,1,"\gamma,\beta=MLP^{mod}(\tilde{c}) || ModLN_{c}(f_{j})=LN(f_{j})\cdot(1+\gamma)+\beta",,ModLN_{c}(f_{j})=\gamma_{c}\frac{f_{j}-\mu_{j}}{\sigma_{j}}+\beta_{c},The modulation function ModLN_c that modulates the transformer sequence with the camera feature.
ICLR_2024_oral_36,2,f_{j}^{cross}=CrossAttn(ModLN_{c}(f_{j}^{in});\{h_{i}\}_{i=1}^{n})+f_{j}^{in} || f_{j}^{self}=SelfAttn(ModLN_{c}(f_{j}^{cross} );\{ModLN_{c}(f_{j}^{cross})\}_{j})+f_{j}^{cross},,"f_{j}^{out}=MLP^{tfm}(SelfAttn(CrossAttn(ModLN_{c}(f_{j}^{in}),\{h_{i}\}_{i=1}^{n})))","The equation represents the process of updating triplane hidden features through a transformer layer, which involves modulation with camera features, cross-attention, self-attention, and a multi-layer perceptron."
ICLR_2024_oral_36,3,f_{j}^{out}=MLP^{tfm}(ModLN_{c}(f_{j}^{self}))+f_{j}^{self},,f_{j}^{out}=MLP^{tfm}(ModLN_{c}(f_{j}^{self});\{ModLN_{c}(f_{j}^{self})\}_{j})+f_{j}^{self},"The equation represents the final output of the transformer layer for each triplane entry, where the output is obtained by applying a multi-layer perceptron to the self-attention output, with modulation by the camera features."
ICLR_2024_oral_36,4,"L_{recon}(x)=\frac{1}{V}\sum_{v=1}^{V}( L_{MSE}(\hat{x}_{v},x_{v}^{GT})+\lambdaL_{LPIPS}(\hat{x}_{v},x_{v}^{GT}))","where \(\mathcal{L}_{\mathrm{MSE}}\) is the normalized pixel-wise L2 loss, \(\mathcal{L}_{\mathrm{LPIPS}}\) is the perceptual image patch similarity (Zhang et al",L=\sum_{v=1}^{V}\left\|\hat{x}_v-x_v^{GT}\right\|_2^2,"The loss function for training the LRM model, which minimizes the sum of squared differences between rendered and ground-truth views."
ICLR_2024_oral_37,1,"z_{t}=z_{0}+\int_{0}^{t}f(z_{s},s)ds","where the hidden state \(z_{t}\in\mathbb{R}^{d}\) evolves with certain dynamics characterized by a neural network \(f:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\), \(z_{0}\) is the initial state, and \(s\) represents time in integrals","\frac{dz}{dt}=f(z(t), t,\theta)","The derivative of z with respect to t equals the function f of z at time t, t, and the model parameters theta."
ICLR_2024_oral_37,2,"z_{t}=z_{0}+\int_{0}^{t}f(z_{s},s)ds+\int_{0}^{t}g(z_{s},s)dB_{s}","where \(z_{t}\) is a latent state that evolves over time, \(f:\mathbb{R}^{d}\times\mathbb{R}\rightarrow\mathbb{R}^{d}\) is the drift function to capture the evolving dynamics, \(g:\mathbb{R}^{d}\times\mathbb{R}\rightarrow\mathbb{R}^{d\times\omega}\) is the diffusion function to reflect the uncertainties, and \(B_{s}\) is an \(d\)-dimensional Brownian motion (Wiener Process)","z_{t}=z_{0}+\int_{0}^{t}f(z_{s},s)ds+\int_{0}^{t}g(z_{s},s)dW_{s}","where \(g:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\) represents the diffusion term and \(W_{s}\) is a Wiener process,"
ICLR_2024_oral_37,3,"\min_{\theta}R_{\nu}(h_{\theta})=\min_{\theta}E_{(z,y)\simD (z_{M+1:M+L},y_{M+1:M+L})}[h_{\theta}(z)\neq y]","where \(\nu\) is the distribution of the stochastic path (Boue & Dupuis, 1998) of \(\mathcal{D}\) along timestamps \(T\) to \(T+T^{*}\), \(z_{M+1:M+L}\) and \(y_{M+1:M+L}\) are short for \(z\) and \(y\) at the timestamps \(\{t_{M+1},\dots,t_{M+L}\}\), \(R_{\nu}\) is the risk of a learning model \(h_{\theta}\) parameterized by parameters \(\theta\)","D(z,y,t_{m})=p(z,y|t_{m}), z=\phi(x), x\inX, y\inY",The probability distribution characterizes temporal dynamics of an instance in the latent space.
ICLR_2024_oral_37,4,"\hat{z}_{i|m+1}^{k}=\underset{z_{i|m+1}^{k}=\underset{z_{i|m+1}^{k}\in S_{m+1}^{k}}{argmin}}Dist(z_{i|m}^{k},z_{j|m+1}^{k})","where \(\text{Dist}:\mathcal{Z}\times\mathcal{Z}\rightarrow[0,+\infty)\) is a distance metric defined over the embedding space, \(\mathbb{S}_{m+1}^{k}\) be the set of \(N_{B}\) data points sampled from \(\mathcal{D}_{m+1}\) (short for \(\mathcal{D}(z,y|t_{m+1})\)) with class \(y=k\in\{1,",z_{m+1}^{k}=\arg\min_{z_{m+1}^{j}}\|z_{m}^{k}-z_{m+1}^{j}\|_{2},where \(z_{m}^{k}\) is the datapoint at time \(t_{m}\) and \(z_{m+1}^{j}\) is the datapoint at time \(t_{m+1}\).
ICLR_2024_oral_37,5,"\hat{z}_{i|m+\lambda}=Interp(z_{i|m}^{k},\hat{z}_{i|m+1}^{k},\lambda)=(1-\lambda)z_{i|m}^{k}+\lambda\hat{z}_{i|m+1}^{k},\forall z_{i|m}^{k}\inS_{m}^{k}","where the interpolation rate \(\lambda\in(0,1)\) is sampled from a Beta distribution \(\mathcal{B}(\beta_{1},\beta_{2})\), \(\beta_{1}\) and \(\beta_{2}\) are the parameters of the Beta distribution, and \(\mathbb{S}_{m}^{k}\) consists of instances sampled from \(k\)-th class of \(m\)-th domain",\tilde{z}_{m}^{k}(t)=\frac{t-t_{m}}{t_{m+1}-t_{m}}\hat{z}_{i|m+1}^{k}+\frac{t_{m+1}-t}{t_{m+1}-t_{m}}z_{i|m}^{k},"where \(\tilde{z}_{m}^{k}(t)\) represents the interpolated sample at time \(t\) for class \(k\), and \(z_{i|m}^{k}\) and \(\hat{z}_{i|m+1}^{k}\) are the corresponding samples at \(t_{m}\) and \(t_{m+1}\), respectively."
ICLR_2024_oral_37,6,"\hat{z}_{m^{\prime}}^{k}=z_{m}^{k}+\int_{t_{m}}^{t_{m^{\prime}}}f_{k}(\hat{z}_ {s}^{k},s)ds+\int_{t_{m}}^{t_{m^{\prime}}}g_{k}(\hat{z}_{s}^{k},s)dB_{s}","where the latent variable \(\hat{z}_{m^{\prime}}^{k}\) is transformed from \(m\)-th domains latent variable \(z_{m}^{k}\), and \(f_{k}\) is the drift function of the \(k\)-th class to capture the evolving patterns, and \(g_{k}\) is the diffusion function of the \(k\)-th class to characterize the stochastics of the latent representations","z_{t_{m^{\prime}}}=z_{t_{m}}+\int_{t_{m}}^{t_{m^{\prime}}} f(z_{s},s)ds+\int_{t_{m}}^{t_{m^{\prime}}} g(z_{s},s)dB_{s}","where $z_{t_{m}}$ and $z_{t_{m^{\prime}}}$ are the latent representations at timestamps $t_{m}$ and $t_{m^{\prime}}$, $f$ and $g$ are the drift and diffusion functions of the SDE, and $B_{s}$ is the Brownian motion."
ICLR_2024_oral_37,7,J_{mle}=\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_{B}}-\frac{1}{MKN_ {B}}\Big{(}\logD(z=\hat{z}_{i|m+1}^{k}|z=z_{i|m}^{k})+\logD \big{(}z=\hat{z}_{i|m+\lambda}^{k}|z=z_{i|m}^{k}\big{)}\Big{)},,"L_{align}(\phi,f,g)=-\sum_{m=1}^{M-1}\sum_{k=1}^{K}\sum_{i=1}^{N}\log p(\hat{z}_{i|m+\lambda}^{k}|z_{i|m}^{k},\hat{z}_{i|m+1}^{k};f_{k},g_{k})","where \(\mathcal{L}_{\text{align}}\) is the path alignment loss, \(\phi\) is the feature extractor, \(f\) and \(g\) are the drift and diffusion functions of the SDE, and \(p\) is the probability density function of the stochastic process."
ICLR_2024_oral_37,8,"D(y=k|z,t=t_{m})=\frac{D(z|y=k,t=t_{m})\timesD(y=k|t=t_{m})}{\sum_{k^{\prime}=1}^{K}D(z|y=k^{\prime},t=t_{m})\timesD(y=k^{\prime}|t=t_{m})}","where we model \(\mathcal{D}(z|y=k,t=t_{m})\) with non-parametric model, and \(\mathcal{D}(y|t=t_{m})\) as a neural net with input as timestamp \(t\), function denoted as \(r(t)\)","p(y|z,t)=\frac{p(z|y,t)p(y)}{p(z|t)}=\frac{p(z|y,t)p(y)}{\sum_{k=1}^{K}p(z|y=k,t)p(y=k)}","where $p(y)$ is the prior distribution of the class label $y$, and $p(z|y,t)$ is the class conditional distribution of the latent representation $z$ given the class label $y$ and time $t$"
ICLR_2024_oral_37,9,"D(z|y=k,t=t_{m})=\frac{\sum_{\hat{z}_{i}\in\hat{S}_{m}^{k}}- exp(-Dist(z,\hat{z}_{i}))}{|\hat{S}_{m}^{k}|}",where \(\hat{S}_{m}^{k}\) includes instances sample from learned SDE-EDG belong to \(k\)-th class of \(m\)-th domain,"L_{parzen}(z,y,t)=-\log\frac{1}{N_{B}}\sum_{i=1}^{N_{B}}\frac{1}{(2\pi)^{\frac{d}{2}}|\Sigma|^{\frac{1}{2}}}\exp\left(-\frac{1}{2}(z-\hat{z}_{i}^{y})^{T}\Sigma^{-1}(z-\hat{z}_{i}^{y})\right)","where \(\hat{z}_{i}^{y}\) is the \(i\)-th synthetic sample of class \(y\), \(\Sigma\) is the covariance matrix, and \(d\) is the dimension of the latent space."
ICLR_2024_oral_37,10,"J_{cls}=\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_{B}}-\frac{1}{MKN _{B}}\logD(y=k|z=z_{i},t=t_{m})",,"\min_{\theta}\frac{1}{M}\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_{B}}-\logD(y=k|z=z_{i|m}^{k},t=t_{m})","where \(\theta\) represents the parameters of the model, including the feature extractor \(\phi\), the drift functions \(f\), the diffusion functions \(g\), and the function \(r\) that models \(\mathcal{D}(y|t)\)."
ICLR_2024_oral_38,1,P_{F}^{\top}(x)\propto\exp(-E(x)),where \(P_{F}^{\top}(x)\) is the distribution of sampling an object \(x\) induced from marginalizing over the trajectories conditioned on \(x=s_{T}\),p(x)=\frac{1}{Z}\exp(-E(x))\,The probability distribution p(x) is defined as the Boltzmann distribution with respect to the energy function \(\mathcal{E}(x)\).
ICLR_2024_oral_38,2,"L_{DB}(s,s^{\prime})=(\log F(s)+\log P_{F}(s^{\prime}|s)-\log F(s^{\prime})-\log P_{B}(s|s^{\prime}))^{2}","where the flow \(F(s)\) for the terminal state \(s_{T}=x\) is defined to be identical to the exponent of the negative energy \(\exp\left(-\mathcal{E}(x)\right)\), i","L_{DB}=E_{s,s^{\prime}\sim P_{F}}\left[\log\frac{P_{F}(s^{\prime}|s)}{P_{B}(s|s^{\prime})}-\log F(s)+\log F(s^{\prime})\right]",The loss function for training GFlowNet using the detailed balance objective.
ICLR_2024_oral_38,3,L_{TB}=(\log Z+\sum_{t=0}^{T-1}\log P_{F}(s_{t+1}|s_{t} )-E(x)-\sum_{t=0}^{T-1}\log P_{B}(s_{t}|s_{t+1}))^{2},,L_{TB}=(\log Z+\log P_{F}(\tau)-\log P_{B}(\tau)-E(x))^{2},"where \(P_{F}(\tau)\) and \(P_{B}(\tau)\) are the probabilities of the trajectory \(\tau\) under the forward and backward policies, respectively."
ICLR_2024_oral_38,4,L_{subTB}=(\log F(s_{U})+\sum_{t=U}^{U+L-1}\log P_{F}(s_ {t+1}|s_{t})-\log F(s_{U+L})-\sum_{t=U}^{U+L-1}\log P_{B}(s_{t}|s_{t+1})) ^{2},,L_{subTB}=(\log Z+\sum_{t=U}^{U+L-1}\log P_{F}(s_{t+1}|s_{t} )-\log F(s_{U+L})-\sum_{t=U+L-1}^{U}\log P_{B}(s_{t}|s_{t+1}))^{2},"where \(P_{F}(s^{\prime}|s),P_{B}(s^{\prime}|s)\) are the forward and backward policies, \(F(\cdot)\) is the flow function, \(Z\) is a learnable scalar, and \(s_{U}\to s_{U+1}\cdots\to s_{U+L}\) is a sub-trajectory of length \(L\)."
ICLR_2024_oral_38,5,"L_{FL}(s,s^{\prime})=(\log\tilde{F}(s)+\log P_{F}(s^{\prime}| s)-E(s)+E(s^{\prime})-\log\tilde{F}(s^{\prime})-\log P _{B}(s|s^{\prime}))^{2}",where \(\tilde{F}(s)=F(s)\exp\left(\mathcal{E}(s)\right)\) is the re-parameterized flow function and \(\mathcal{E}(s^{\prime})-\mathcal{E}(s)\) is the energy gain associated with the transition from \(s\) to \(s^{\prime}\),"L_{FL-GFN}(s,s^{\prime})=(\log F(s)+\log P_{F}(s^{\prime}|s)-\log F(s^{\prime})-\log P_{B}(s|s^{\prime})+E(s)-E(s^{\prime}))^{2}","The loss function for Forward-Looking GFlowNet, which incorporates an energy function for intermediate states to enable partial inference."
ICLR_2024_oral_38,6,E(x)\approx\Phi_{\theta}(\tau)=\sum_{t=0}^{T-1}\phi_{\theta}(s_{t}\to s_{t+1}),"where \(\tau=(s_{0},s_{1},\ldots,s_{T})\), \(x=s_{T}\), and the potential functions are defined on state transition \(s_{t}\to s_{t+1}\)","E(x)=\sum_{t=0}^{T-1}\phi_{\theta}(s_{t},s_{t+1})","where \(\phi_{\theta}(s_{t},s_{t+1})\) is the potential function that assigns a local credit signal to the transition from \(s_{t}\) to \(s_{t+1}\)."
ICLR_2024_oral_38,7,"L_{LED}(s,s^{\prime})=(\log\tilde{F}(s)+\log P_{F}(s^{\prime} |s)+\phi_{\theta}(s\to s^{\prime})-\log\tilde{F}(s^{\prime})-\log P_{B}(s|s^{\prime}))^{2}",,"L_{LED}(s,s^{\prime})=(\log\tilde{F}(s)+\log P_{F}(s^{\prime}|s)-\phi_{\theta}(s\to s^{\prime})-\log\tilde{F}(s^{\prime})-\log P_{B}(s|s^{\prime}))^{2}","The loss function for training the LED-GFN model, where the potential function \(\phi_{\theta}(s\to s^{\prime})\) is used to provide local credit signals for partial inference."
ICLR_2024_oral_38,8,\ell_{LS}(\tau)=E_{z\simBern(\gamma)} [(\frac{1}{T}E(s_{T})-\frac{1}{C}\sum_{t=0}^{T-1}z_{t}\phi_{\theta}(s_{t}\to s_{t+1}))^{2}],,L_{pot}(\tau)=(E(x)-\Phi_{\theta}(\tau))^{2}+\lambda\sum_{t=0}^{T-1}(\phi_{\theta}(s_{t}\to s_{t+1})-\bar{\phi})^{2},"The potential functions \(\phi_{\theta}\) are trained to minimize the loss function \(\mathcal{L}_{\text{pot}}(\tau)\) which consists of two terms: the first term measures the difference between the true energy \(\mathcal{E}(x)\) and the estimated energy \(\Phi_{\theta}(\tau)\), and the second term regularizes the potential functions to have similar values \(\bar{\phi}\) across different state transitions."
ICLR_2024_oral_39,1,"\epsilon_{\theta}(o_{t}^{(k)},k|h_{t-1},a_{t-1})=(1+\eta)\epsilon_{\theta}(o_{ t}^{(k)},k|h_{t-1},a_{t-1})-\eta\epsilon_{\theta}(o_{t},k|h_{t-1})",where \(\eta\) controls action conditioning strength,"p(o_{t}|h_{t-1},a_{t-1})",The observation prediction model that predicts the next set of observation frames given the history of observations and actions.
ICLR_2024_oral_39,2,"L_{MSE}=\|\epsilon-\epsilon_{\theta}\Big{(}\sqrt{1-\beta^{(k)}}o_{t}+\sqrt{\beta^{(k)}}\epsilon,\,k\Big{|}h_{t-1},a_{t-1}\Big{)}\|^{2}","where \(\epsilon\sim\mathcal{N}(0,I)\), and \(\beta^{(k)}\in\mathbb{R}\) are a set of \(K\) different noise levels for each \(k\in[1,K]\)","L(\theta)=E_{t,o_{t},h_{t-1},a_{t-1}}[\sum_{k=1}^{K}\lambda_{k}(\epsilon_{\theta}(o_{t}^{(k)},k|h_{t-1},a_{t-1})-\epsilon)^{2}]",where \(\lambda_{k}\) are weights for each denoising step and \(\epsilon\) is the noise term
ICLR_2024_oral_39,3,"o_{t}^{(k-1)}=\alpha^{(k)}(o_{t}^{(k)}-\gamma^{(k)}\epsilon_{\theta}(o_{t}^{( k)},k|h_{t-1},a_{t-1}))+\xi,\quad\xi\simN\big{(}0,\sigma_{k}^{2}I\big{)}","where \(\gamma^{(k)}\) is the denoising step size, \(\alpha^{(k)}\) is a linear decay on the current denoised sample, and \(\sigma_{k}\) is a time varying noise level that depends on \(\alpha^{(k)}\) and \(\beta^{(k)}\)","o_{t}^{(k-1)}=\frac{1}{\sqrt{1-\beta^{(k)}}}\Big{(}o_{t}^{(k)}-\sqrt{1-\beta^{(k)}}\epsilon_{\theta}\big{(}o_{t}^{(k)},k|h_{t-1},a_{t-1}\big{)}\Big{)}+\sqrt{\beta^{(k)}}\epsilon","where \(\epsilon\sim\mathcal{N}(0,I)\), and \(\beta^{(k)}\in\mathbb{R}\) are a set of \(K\) different noise levels for each \(k\in[1,K]\)"
ICLR_2024_oral_39,4,RDG=\frac{\|s_{0}-s_{goal}\|_{2}-\|s_{T}-s_{goal}\|_{2}}{\|s_{0}-s_{goal}\|_{2}},"where \(s_{T}\) represents the underlying block locations after executing the policy, \(s_{0}\) and \(s_{\text{goal}}\) represents the initial and goal block locations","R_{RDG}=\frac{1}{N}\sum_{i=1}^{N}\frac{d_{i,0}-d_{i,T}}{d_{i,0}}",The reduction in distance to goal (RDG) metric measures the average reduction in distance between the initial and final states of blocks after executing a sequence of instructions.
ICLR_2024_oral_4,1,p(Y\mid X)=\sum_{Z}p_{LM}(ZY\mid X)=\sum_{Z}p_{LM}(Y\mid XZ)p_{LM}(Z\mid X),where \(p_{\text{LM}}\) denotes the likelihood assigned to a sequence by a language model and apposition of variables (_e,"p(X, Y, Z)=p(X)\cdot p(Y|X, Z)\cdot p(Z|X)","The probability of a question-answer pair and a chain of thought is modeled as the product of the probability of the question, the probability of the answer given the question and the chain of thought, and the probability of the chain of thought given the question."
ICLR_2024_oral_4,2,"p_{LM}(Z\mid X,Y)=\frac{p_{LM}(XZY)}{\sum_{Z^{\prime}}p_{ LM}(XZY^{\prime}Y)}\propto p_{LM}(XZY)",,"p_{LM}(Z\mid X,Y)=\frac{p_{LM}(XZY)}{\sum_{Z^{\prime}}p_{LM}(XZ^{\prime}Y)}","The posterior distribution over the latent variable Z conditioned on the prefix X and the suffix Y, given an autoregressive language model pLM."
ICLR_2024_oral_4,3,L(Z;\theta)=\sum_{0\leq i<j\leq n}(\log\frac{R(z_{1:i}\top)\prod_{k=i+1}^{j}q_{GFN}(z_{k}\mid z_{1:k-1})q_{GFN}(\top\mid z_ {1:j})}{R(z_{1:j}\top)q_{GFN}(\top\mid z_{1:i})})^{2},,L_{SubTB}(Z)=\log q_{GFN}^{\top}(Z)-\log R(Z)+\sum_{i=1}^{n}\log q_{GFN}(z_{i}\mid z_{1:i-1})-\log R(z_{1:i}),The SubTB loss function is used to train the GFlowNet policy to sample sequences from a distribution proportional to the given reward function.
ICLR_2024_oral_41,1,"q_{0t}(x_{t}|x_{0})=N(x_{ t}|\alpha_{t}x_{0},\sigma_{t}^{2}I)","where \(\alpha_{t}\) and \(\sigma_{t}\) are referred to as the noise schedule, satisfying \(\alpha_{t}^{2}+\sigma_{t}^{2}=1\)","q_{0t}(x_{t}|x_{0})=N(x_{t};\sqrt{1-\beta_{t}}x_{0}, (1-\beta_{t})I)",The conditional distribution of the Markovian forward process at time step t given the initial data x0.
ICLR_2024_oral_41,2,"dx_{t}=f(t)x_{t}dt+g(t )dw_{t},\quadx_{0}\sim q_{0}(x_{0})","where \(\mathbf{w}_{t}\) is the standard Wiener process, \(f(t)=\frac{\mathrm{d}\log\alpha_{t}}{\mathrm{d}t}\) and \(g(t)=2\sigma_{t}^{2}\frac{\mathrm{d}\log(\sigma_{t}/\alpha_{t})}{\mathrm{d}t}\)",dx=-\frac{1}{2}\beta_{t}x dt+\sqrt{\beta_{t}} dw,"The stochastic differential equation that represents the forward process, where \(\beta_{t}\) is related to the noise schedule and \(d\mathbf{w}\) represents the Gaussian noise."
ICLR_2024_oral_41,3,"dx_{t}=[f(t)x_{t}-g(t)^{2}\nabla_{x_{t}}\log q_{t}(x_{t})]dt+g (t)d\bar{w}_{t},\quadx_{T}\sim q_{T} (x_{T})",where \(\bar{\mathbf{w}}_{t}\) is a standard Wiener process in the reverse time,dx_{t}=[f(t)x_{t}-g(t)\nabla_{x_{t}}\log q_{t}(x_{t})]dt+g(t)d\bar{w}_{t},where \(\bar{\mathbf{w}}_{t}\) is a standard Wiener process and \(\nabla_{\mathbf{x}_{t}}\log q_{t}(\mathbf{x}_{t})\) is the score function of \(q_{t}(\mathbf{x}_{t})\)
ICLR_2024_oral_41,4,"L(\theta):=E_{t\simU(0,T),x_{0}\sim q_{0}(x_{0}),\epsilon\simN (0,I)}[\|\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon,t)-\epsilon\|_{2}^{2}]",,"L=E_{t\simU(0,T),x_{0}\sim q_{0}(x_{0}),\epsilon\simN(0,I)}\left[\left\lVert\epsilon-\epsilon_{\theta}(x_{t},t)\right\rVert^{2}\right]","where \(\mathbf{x}_{t}=\alpha_{t}\mathbf{x}_{0}+\sigma_{t}\mathbf{\epsilon}\) and \(\mathcal{U}(0,T)\) denotes the uniform distribution over \([0,T]\)."
ICLR_2024_oral_41,5,"\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}=\frac{\alpha_{t}}{\sqrt{1-\alpha_{t}^{2}}}\frac{d\alpha_{t}}{dt}\nabla_{x}\log q_{t}(x)-\frac{\partial\nabla_{x }\log q_{t}(x)}{\partial t}\sigma_{t}",,"\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}=-\frac{\partial\sigma_{t}}{\partial t}\nabla_{x}\log q_{t}(x)-\sigma_{t}\frac{\partial}{\partial t}\nabla_{x}\log q_{t}(x)","where \(\frac{\partial\sigma_{t}}{\partial t}\) and \(\frac{\partial}{\partial t}\nabla_{\mathbf{x}}\log q_{t}(\mathbf{x})\) are the partial derivatives of \(\sigma_{t}\) and the score function \(\nabla_{\mathbf{x}}\log q_{t}(\mathbf{x})\) with respect to \(t\), respectively."
ICLR_2024_oral_41,6,"\lim\sup_{t\to 0+}\|\frac{\partial\epsilon_{\theta}(x,t )}{\partial t}\|\to\infty;\quad\lim\sup_{t\to 0+}\|\frac{\partial\nabla_{x}\log q_{t}(x)}{\partial t}\sigma_{t}\|\to\infty",,"\lim_{t\to0^{+}}\left\|\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}\right\|\to\infty","The equation represents the limit of the partial derivative of the network with respect to time as time approaches zero from the right, which tends to infinity under certain conditions."
ICLR_2024_oral_41,7,\nabla_{x}\log q_{t}(x)=\nabla_{x}\log (\frac{1}{\sqrt{2\pi}}\exp(-\frac{\|x\|_{2}^{2}}{2}) )=-x,,\nabla_{x_{t}}\log q_{t}(x_{t})=-\frac{\alpha_{t}}{\sigma_{t}^{2}}x_{t},The score function for a simple case where the distribution of data follows a standard normal distribution.
ICLR_2024_oral_41,8,"K(t,t^{\prime})=\frac{E_{x_{t}}[\|\epsilon_{\theta} (x_{t},t)-\epsilon_{\theta}(x_{t},t^{\prime})\|_{2}]}{\Delta t}",where \(\Delta t=|t-t^{\prime}|\),"\left\|\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}\right\|=\left\|\frac{\alpha_{t}}{\sqrt{1-\alpha_{t}^{2}}}\frac{d\alpha_{t}}{dt}\nabla_{x}\log q_{t}(x)-\frac{\partial\nabla_{x}\log q_{t}(x)}{\partial t}\sigma_{t}\right\|",The Lipschitz constant of the network with respect to time variable t.
ICLR_2024_oral_41,9,"L(\epsilon_{\theta}):=E_{t\simU(0,T),x_{0}\sim q(x_{0}),\epsilon\simN(0,I)} [\|\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon,f_{T}(t))-\epsilon\|_{2}^{2}]","where \(f_{\mathbb{T}}(t)=\max_{1\leq i\leq n}\{t_{i-1}\in\mathbb{T}:t_{i-1}\leq t\}\) for \(t<\tilde{t}\), while \(f_{\mathbb{T}}(t)=t\) for \(t\geq\tilde{t}\)","L(\theta):=E_{t_{i}\simU(T),x_{0}\sim q_{0}(x_{0}),\epsilon\simN(0,I)}[\|\epsilon_{\theta}(\alpha_{t_{i}}x_{0}+\sigma_{t_{i}}\epsilon,t_{i})-\epsilon\|_{2}^{2}]","The training loss for the proposed Early Timestep-shared Diffusion Model (E-TSDM), which uniformly divides the interval near the zero point into n sub-intervals and shares the timestep condition values within each sub-interval."
ICLR_2024_oral_41,10,"p_{\theta}(x_{t-1}|x_{t})=N(x_{t-1};\frac{\alpha_{t-1}}{\alpha_{t}}(x_{t}-\frac{\beta_{t}}{\sigma_{t}}\epsilon_{\theta}(x_{t},f_{T} (t))),\eta_{t}^{2}I)","where \(\beta_{t}=1-\frac{\alpha_{t}}{\alpha_{t-1}}\), and \(\eta_{t}^{2}=\beta_{t}\)","dx_{t}=[f(f_{T}(t))x_{t}-g(f_{T}(t))^{2}\nabla_{x}\log q_{f_{T}(t)}(x)]dt+g(f_{T}(t))d\bar{w}_{t},\quadx_{T}\sim q_{T}(x_{T})",where \(f(f_{\mathbb{T}}(t))\) and \(g(f_{\mathbb{T}}(t))\) are defined based on the shared timestep condition \(f_{\mathbb{T}}(t)\).
ICLR_2024_oral_41,11,"\|\epsilon^{*}(x,f_{T}(t)-\epsilon(x,t)\|\leq\sigma_{\tilde{t}}K (x)\Delta t+B(x)\Delta\sigma_{\max}",,"\|\epsilon^{*}(x,f_{T}(t))-\epsilon(x,t)\|_{2}\leq\sigma_{t}\left\|\nabla_{x}\log q_{t}(x)-\nabla_{x}\log q_{f_{T}(t)}(x)\right\|_{2}",where the right-hand side is an infinitesimal as the sub-interval length approaches zero.
ICLR_2024_oral_41,12,"K(x)=\sup_{t\neq\tau}\frac{\|\nabla_{x}\log q_{t }(x)-\nabla_{x}\log q_{\tau}(x )\|}{|t-\tau|},\quad B(x)=\sup_{t}\|\nabla_{x}\log q_{t}(x)\|",,"\Delta\sigma_{\max}=\max_{t\in[0,\tilde{t})}|\sigma_{t}-\sigma_{f_{T}(t)}|",where $K(\mathbf{x})$ and $B(\mathbf{x})$ are constants depending on $\mathbf{x}$ and the noise schedule.
ICLR_2024_oral_44,1,"I(S;Z)=D_{KL}(p(s,z)\|p(s)p(z))",,"p(s,z)=p(z)p(s|z)",The joint probability distribution of states and skills.
ICLR_2024_oral_44,2,"I_{W}(S;Z)=W(p(s,z),p(s)p(z))",where \(I_{\mathcal{W}}(S;Z)\) is the Wasserstein dependency measure (WDM) (Ozair et al,"I_{W}(S;Z)=\sup_{d\inD}\inf_{p(z,s)\in\Gamma(p(z),p(s))}D_{KL}(p(z,s)\|p(z)p(s))","The Wasserstein dependency measure between states and skills, which maximizes the distance metric d, forcing the learned skills to span the longest subspaces of the state space."
ICLR_2024_oral_44,3,"I_{W}(S;Z)=\sup_{\|f\|_{L}\leq 1}E_{p(s,z)}[f(s,z)]-E_{p(s)p(z)}[f(s,z)]","where \(\|f\|_{L}\) denotes the Lipschitz constant for the function \(f:\mathcal{S}\times\mathcal{Z}\rightarrow\mathbb{R}\) under the given distance metric \(d\), _i","\sup_{f\inF}E_{p(s,z)}[f(s,z)]-E_{p(s)p(z)}[f(s,z)]",where \(f\) is a function in a class of functions \(\mathcal{F}\) that are bounded by 1-Lipschitz functions.
ICLR_2024_oral_44,4,"I_{W}(S;Z)\approx\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}E_{p( s,z)}[\phi(s)^{\top}\psi(z)]-E_{p(s)}[\phi(s)]^{\top}E_{p(z)}[\psi(z)]",,"r(s,z)=\phi(s)^{\top}\psi(z)-\frac{1}{N}\sum_{i=1}^{N}\phi(s)^{\top}\psi(z_{i})","The reward function r is used to train the skill policy π(a|s,z) using reinforcement learning."
ICLR_2024_oral_44,5,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}E_{p(\tau,z)}[\phi(s_{T})^{\top}\psi(z)]-E_{p(\tau)}[\phi(s_{T})]^{\top}E_{p(z)}[\psi(z)] || =\sup_{\phi,\psi}\sum_{t=0}^{T-1}(E_{p(\tau,z)}[(\phi(s_{t+1})-\phi(s_{t}))^{\top}\psi(z)]-E_{p(\tau)}[\phi(s_{t+1})-\phi(s_{t})]^{\top}E_{p(z)}[\psi(z)])",,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}\sum_{t=0}^{T-1}E_{p(s_{t},z)}[\phi(s_{t})^{\top}\psi(z)]-E_{p(s_{t})}[\phi(s_{t})]^{\top}E_{p(z)}[\psi(z)]","The equation represents the Wasserstein dependency measure between the last state and the skill, which is used to discover diverse skills that cover the state space."
ICLR_2024_oral_44,6,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1}E_{p(\tau,z)}[\sum_{t=0}^{T-1}(\phi(s_{t+1})-\phi(s_{t}))^{\top}(z-\bar{z}) ]",where \(\bar{z}=\mathbb{E}_{p(z)}[z]\),"I_{W}(S_{T};Z)\approx\sup_{\phi}\sum_{t=0}^{T-1}(E_{p(\tau,z)}[(\phi(s_{t+1})-\phi(s_{t}))^{\top}z]-E_{p(\tau)}[\phi(s_{t+1})-\phi(s_{t})]^{\top}E_{p(z)}[z])","The equation represents the Wasserstein dependency measure between the last state and the skill, which is used as an objective for unsupervised RL to learn diverse behaviors that cover the state space."
ICLR_2024_oral_44,7,"\sup_{\pi,\phi}\E_{p(\tau,z)}[\sum_{t=0}^{T-1}(\phi(s_{t+1})-\phi(s_{t}))^{\top}z]\\s.t.\\\|\phi(s)-\phi(s^{\prime})\|_{2}\leq 1,\\\forall(s,s^{\prime})\inS_{adj}",where \(\mathcal{S}_{\mathrm{adj}}\) denotes the set of adjacent state pairs in the MDP,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1}E_{p(\tau,z)}[\sum_{t=0}^{T-1}(\phi(s_{t+1})-\phi(s_{t}))^{\top}(z-\bar{z}) ]","The temporal distance metric between two states is used to define the Wasserstein dependency measure, allowing the model to learn a compact set of useful behaviors that prioritize coverage of the state space."
ICLR_2024_oral_45,1,"x^{\prime}(t)=Ax(t)+Bu(t),\quad y(t)=Cx(t)+Du(t)",,x(t+1)=Ax(t)+Bu(t),The equation represents the state update of a linear dynamical system in a state space model.
ICLR_2024_oral_45,2,"x_{n}=\bar{A}x_{n-1}+\bar{B}u_{n},\quad y_{n}=\bar{ C}x_{n}+\bar{D}u_{n}","where \(\bar{\mathbf{A}},\bar{\mathbf{B}},\bar{\mathbf{C}}\), and \(\bar{\mathbf{D}}\) are discrete-time parameters obtained from the continuous-time parameters and \(\Delta\) using methods like zero-order hold and bilinear technique (Smith et al","x[t+1]=A_{\Delta}x[t]+B_{\Delta}u[t],\quad y[t]=C_{\Delta}x[t]+D_{\Delta}u[t]","The discretized state space model equations, where $\mathbf{A}_{\Delta}$, $\mathbf{B}_{\Delta}$, $\mathbf{C}_{\Delta}$, and $\mathbf{D}_{\Delta}$ are the discretized state matrix and other matrices, respectively."
ICLR_2024_oral_45,3,"L(\theta)=\operatorname*{E}_{z_{1:T}\sim q_{\theta}}\sum_{ t=1}^{T}L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})+L^{rep}(\theta,h_{t},o_{t})+L^{dyn}(\theta,h _{t},o_{t})",,L=L_{rssm}+L_{actor}+L_{critic},"The loss function for R2I, which combines the losses from the RSSM, actor, and critic components."
ICLR_2024_oral_45,4,"L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})=-\beta_{pred}(\ln p_{\theta}(o_{t}\mid z_{t},h_{t})+\ln p_{\theta}(r_{t}\mid z_{t},h_{t})+\ln p_{\theta}(c_{t}\mid z_{t},h_{t})) || L^{dyn}(\theta,h_{t},o_{t})=\beta_{dyn}\max(1,KL[\lessdot\circ g(q_{\theta}(z_ {t}\mid o_{t}))\parallel p(z_{t}\mid h_{t})\mid)]",,"L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})=-\log p_{\theta}(\hat{o}_{t}\mid z_{t},h_{t})-\log p_{\theta}(\hat{r}_{t}\mid z_{t},h_{t})-\log p_{\theta}(\hat{c}_{t}\mid z_{t},h_{t})","\(\mathcal{L}^{\text{pred}}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})\) represents the prediction loss for the observation, reward, and episode continuation at time step \(t\)."
ICLR_2024_oral_45,5,"L^{rep}(\theta,h_{t},o_{t})=\beta_{rep}\max(1,KL[\quad q_{\theta}(z_{t}\mid o_ {t})\parallel\lessdot\circ g(p(z_{t}\mid h_{t}))\,])",,"L^{rep}(\theta,h_{t},o_{t})=\beta_{rep}KL[q_{\theta}(z_{t}\mid o_{t})\parallel p(z_{t}\mid h_{t})]","The KL divergence term in the representation loss, which measures the difference between the approximate posterior and the prior distributions."
ICLR_2024_oral_45,6,"h_{1:T},x_{1:T}=f_{\theta}((a_{1:T},z_{1:T}),x_{0})",,"L(\theta)=\operatorname*{E}_{z_{1:T}\sim q_{\theta}}\sum_{ t=1}^{T}L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})+L^{rep}(\theta,h_{t},o_{t})+L^{dyn}(\theta,h _{t},o_{t})","The total loss function for R2I, which combines the prediction loss, representation loss, and dynamics loss."
ICLR_2024_oral_49,1,"e_{i}^{num}=x_{i}^{num}\cdotw_{i}^{num}+b_{i}^{num},\\e_{i}^{cat}=x_{i}^{oh}\cdotW_{i}^{cat }+b_{i}^{cat}","where \(\mathbf{w}_{i}^{\mathrm{num}},\mathbf{b}_{i}^{\mathrm{num}},\mathbf{b}_{i}^{\mathrm{cat}} \in\mathbb{R}^{1\times d}\), \(\mathbf{W}_{i}^{\mathrm{cat}}\in\mathbb{R}^{C_{i}\times d}\) are learnable parameters of the tokenizer, \(\mathbf{e}_{i}^{\mathrm{num}},\mathbf{e}_{i}^{\mathrm{cat}}\in\mathbb{R}^{1\times d}\)",x_{i}^{cat}\Rightarrowx_{i}^{emb}\inR^{d},The embedding vector for a categorical feature is a d-dimensional vector learned during training.
ICLR_2024_oral_49,2,"E=[e_{1}^{num},\cdots,e_{M_{num}}^{ num},e_{1}^{cat},\cdots,e_{M_{cat}}^{cat}]\inR^{M\times d}",,"x=\left[e_{1}^{num},\cdots,e_{M_{num}}^{num},e_{1}^{cat},\cdots,e_{M_{cat}}^{cat}\right]",where \(\mathbf{x}\) represents the embedded record with all column embeddings stacked together.
ICLR_2024_oral_49,3,"&\hat{x}_{i}^{num}=\hat{e}_{i}^{num}\cdot\hat{w}_{i}^{num}+\hat{b}_{i}^{num},\\\hat{e}_{i}^{oh}=Softmax(\hat{e}_{i}^{cat}\cdot\hat{W}_{i}^{cat}+\hat{b}_{i}^{cat}),\\&\hat{x}=[\hat{x}_{1}^{num},\cdots,\hat{x}_{M_{num}}^{num},\hat{x}_{1}^{oh},\cdots,\hat{x }_{M_{cat}}^{oh}]","where \(\hat{\mathbf{w}}_{i}^{\mathrm{num}}\in\mathbb{R}^{d\times 1},\hat{b}_{i}^{ \mathrm{num}}\in\mathbb{R}^{1\times 1}\), \(\mathbf{W}_{i}^{\mathrm{cat}}\in\mathbb{R}^{d\times C_{i}},\hat{\mathbf{b}}_{i}^{ \mathrm{cat}}\in\mathbb{R}^{1\times C_{i}}\) are detokenizer's parameters","\hat{x}_{i}^{num}=\hat{e}_{i}^{num}\cdot\hat{w}_{i}^{num}+\hat{b}_{i}^{num},\\\hat{x}_{i}^{oh}=\sigma(\hat{e}_{i}^{cat}\cdot\hat{W}_{i}^{cat }+\hat{b}_{i}^{cat})","where \(\hat{\mathbf{w}}_{i}^{\mathrm{num}},\hat{\mathbf{b}}_{i}^{\mathrm{num}},\hat{\mathbf{b}}_{i}^{\mathrm{cat}} \in\mathbb{R}^{1\times d}\), \(\hat{\mathbf{W}}_{i}^{\mathrm{cat}}\in\mathbb{R}^{d\times C_{i}}\) are learnable parameters of the detokenizer."
ICLR_2024_oral_49,4,"L=\ell_{recon}(x,\hat{x})+\beta\ell_{kl}",,L(x)=E_{q(z|x)}[\log p(x|z)]-\beta\cdotKL(q(z|x)\|p(z)),"where \(\mathbf{x}\) is the input data, \(\mathbf{z}\) is the latent variable, \(q(\mathbf{z}|\mathbf{x})\) is the encoder, \(p(\mathbf{x}|\mathbf{z})\) is the decoder, and \(p(\mathbf{z})\) is the prior distribution."
ICLR_2024_oral_49,5,"z_{t}=z_{0}+\sigma(t)\varepsilon,\\varepsilon\simN(0,I), (Forward Process) || dz_{t}=-2\hat{\sigma}(t)\sigma(t)\nabla_{z_{t}}\log p(z_{t})dt+\sqrt{2\hat{\sigma}(t)\sigma(t)}d\omega_{t}, (Reverse Process)",,"\beta=\max(\beta_{\min},\lambda\beta)","where \(\beta\) is the adaptive weight coefficient that balances the reconstruction loss and KL-divergence loss, \(\beta_{\min}\) is the minimum value of \(\beta\), and \(\lambda\) is the decay rate."
ICLR_2024_oral_49,6,"L=E_{z_{0}\sim p(z_{0})}E_{t\sim p (t)}E_{\varepsilon\simN(0,I)}\|\varepsilon_{\theta}(z_{t},t)-\varepsilon)\|_{2}^{2},\\where\z_{t}=z_{0}+\sigma(t)\varepsilon",where \(\mathbf{\epsilon}_{\theta}\) is a neural network (named denoising function) to approximate the Gaussian noise using the perturbed data \(\mathbf{x}_{t}\) and the time \(t\),\nabla_{z_{t}}\log p_{t}(z_{t})=\nabla_{z_{t}}\log p(z_{t}|z_{0})=-\frac{z_{t}-z_{0}}{\sigma^{2}(t)},The score function of \(\mathbf{z}_{t}\) is the gradient of the log probability density function of \(\mathbf{z}_{t}\) with respect to \(\mathbf{z}_{t}\).
ICLR_2024_oral_52,1,"p(x(t)\midx(0))=N(x(t);x(0),\sigma^{2}(t)I)\",,"p(x_{1},\ldots,x_{N})",The joint distribution of the sources.
ICLR_2024_oral_52,2,"dx(t)=-\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt\",,\frac{dx(t)}{dt}=-\frac{1}{2}\nabla_{x(t)}\log p(x(t))\,The probability flow ODE describes the forward evolution of a data point \(\mathbf{x}(t)\) in time.
ICLR_2024_oral_52,3,"dx(t)=\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt\",,"dx(t)=\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt+\sqrt{2\sigma(t)}\,dw(t)\",The backward ODE that describes the denoising process.
ICLR_2024_oral_52,4,"E_{t\simU([0,T])}E_{x(0)\sim p(x (0))}E_{x(t)\sim p(x(t)|x(0))}\|S^{\theta}(x(t),\sigma(t))-\nabla_{x(t)}\log p (x(t)\midx(0))\|_{2}^{2}",,"L(\theta)=E_{x(0),t}\left[\lambda(t)\left\lVert S^{\theta}(x(t),\sigma(t))-\nabla_{x(t)}\log p(x(t)\midx(0))\right\rVert^{2}\right]\","The score-matching loss function $\mathcal{L}(\theta)$ measures the difference between the approximated score function $S^{\theta}(\mathbf{x}(t),\sigma(t))$ and the true score function $\nabla_{\mathbf{x}(t)}\log p(\mathbf{x}(t)\mid\mathbf{x}(0))$, weighted by $\lambda(t)$."
ICLR_2024_oral_52,5,"E_{t\simU([0,T])}E_{x(0)\sim p(x (0))}E_{x\simN(0,\sigma^{2}(t)I )}\|D^{\theta}(x(0)+\epsilon,\sigma(t))-x(0)\|_ {2}^{2}\","where we define \(S^{\theta}(\mathbf{x}(t),\sigma(t))=:(D^{\theta}(\mathbf{x}(t),\sigma(t))- \mathbf{x}(t))/\sigma^{2}(t)\)","E_{t\simU([0,T])}E_{x(0)\sim p(x (0))}E_{x(t)\simN(x(t);x(0),\sigma^{2}(t)I)}\|S^{\theta}(x(t),\sigma(t))-\frac{x(0)-x(t)}{\sigma^{2}(t)}\|_{2}^{2}",The score-matching loss after expanding the conditional probability using the Gaussian perturbation kernel.
ICLR_2024_oral_52,6,"\nabla_{x(t)}\log p(x(t))=\nabla_{(x_{1}(t),\ldots,x_{N}(t))}\log p(x_{1}(t),\ldots,x_{N}(t))\",,"p(x(t))=N(x(t);0,\sigma^{2}(t)I)\",The equation represents the probability distribution of the noisy data at time step t.
ICLR_2024_oral_52,7,"S^{\theta}(x(t),\sigma(t)):R^{N\times D}\timesR arrowR^{N\times D}\","where \(\mathbf{x}(t)=(\mathbf{x}_{1}(t),\ldots,\mathbf{x}_{N}(t))\) denotes the sources perturbed with the Gaussian kernel in Eq","S^{\theta}(x(t),\sigma(t))=:(D^{\theta}(x(t),\sigma(t))-x(t))/\sigma^{2}(t)\",The score function of the target distribution is approximated by a neural network.
ICLR_2024_oral_52,8,\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t)),,\nabla_{x_{\overline{I}}}\log p(x_{\overline{I}}\midx_{I})=\nabla_{x_{\overline{I}}}\log p(x)-\nabla_{x_{\overline{I}}}\log p(x_{I})\,"The equation represents the gradient of the conditional distribution for partial generation, where the goal is to generate the remaining sources consistently with the fixed subset of sources."
ICLR_2024_oral_52,9,"\nabla_{x_{\overline{I}}(t)}\log p([x_{\overline{I}}(t),\hat{x}_{I}(t)])\","where \(\hat{\mathbf{x}}_{\mathcal{I}}\) is a sample from the forward process: \(\hat{\mathbf{x}}_{\mathcal{I}}(t)\sim\mathcal{N}(\mathbf{x}_{\mathcal{I}}(t) ;\mathbf{x}_{\mathcal{I}}(0),\sigma(t)^{2}\mathbf{I})\)",\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t))=\nabla_{x_{\overline{I}}(t)}\log p(x(t))-\nabla_{x_{\overline{I}}(t)}\log p(x_{I}(t))\,"The equation represents the gradient of the conditional distribution for partial generation, where the goal is to generate the remaining sources consistently with the fixed subset of sources."
ICLR_2024_oral_52,10,"\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t))\approx S_{\overline{I}}^{\theta}([x_{\overline{I}}(t),\hat{x }_{I}(t)],\sigma(t))\",where \(S_{\overline{\mathcal{I}}}^{\theta}\) denotes the entries of the score network corresponding to the sources indexed by \(\overline{\mathcal{I}}\),"S^{\theta}([x_{\overline{I}}(t),\hat{x}_{I}(t)],\sigma(t))\",The score function for partial generation is approximated using a neural network.
ICLR_2024_oral_52,11,\nabla_{x(t)}\log p(x(t)\midy(0))\,,\nabla_{x(t)}\log p(x(t)\midy(0))\,The score function of the posterior distribution for source separation.
ICLR_2024_oral_52,12,"p(y(t)\midx(t))=N(y(t)\mid\sum_{n=1}^{N}x_{n}(t),\gamma^{2}(t)I)",,"p(y(0)\midx(t))=N(y(0);\sum_{n=1}^{N}x_{n}(t),\sigma^{2}(t)I)\",The likelihood function models the probability of observing the mixture given the sources at time t.
ICLR_2024_oral_52,13,p(y(t)\midx(t))=1_{y(t)=\sum_{n=1}^{N}x_{ n}(t)}\,,p(y(t)\midx(t))=\delta(y(t)-\sum_{n=1}^{N}x_{n}(t))\,The Dirac delta function models the likelihood of the mixture given the sources.
ICLR_2024_oral_52,14,"\nabla_{x_{m}(t)}\log p(x(t)\midy(0))\approx S_{m}^{\theta}((x_{1}(t),\dots,x_{N-1}(t),y(0)-\sum_{n=1}^{N-1}x_{n}(t)),\sigma(t)) || -S_{N}^{\theta}((x_{1}(t),\dots,x_{N-1}(t),y(0)-\sum_{n=1}^{N-1}x_{n}(t)),\sigma(t))\",,"\nabla_{x(t)}\log p(x(t)\midy(0))\approx S^{\theta}(x(t),\sigma(t))+\frac{y(0)-\sum_{n=1}^{N}x_{n}(t)}{\sigma^{2}(t)}\",The equation represents the posterior score function for source separation in the MSDM Dirac method.
ICLR_2024_oral_53,1,L=L_{clip}+\lambdaL_{video},where video-paragraph contrastive loss \(\mathcal{L}_{\text{video}}\) explores the temporal correlations between the long video \(\mathbf{V}_{i}\) and its corresponding paragraph \(\mathbf{T}_{i}\) through a novel noise robust temporal optimal transport distance,L=\lambda_{1}L_{v}+\lambda_{2}L_{t}+\lambda_{3}L_{vt},"The loss function L is a weighted sum of video loss \(L_{v}\), text loss \(L_{t}\), and video-text alignment loss \(L_{vt}\), where \(\lambda_{1}\), \(\lambda_{2}\), and \(\lambda_{3}\) are hyperparameters."
ICLR_2024_oral_53,2,"\max_{Q\inQ}&\langleQ,\S\rangle+\varepsilon H(Q)\\s.t.&Q=\{Q\inR _{+}^{n\times m}\midQ1_{m}=\mu,Q^{\top}1_{n}=\nu\}","where \(\mathbf{1}_{m}\) represents the vector of ones in dimension \(m\), \(\boldsymbol{\mu}\in\mathbb{R}^{n}\) and \(\boldsymbol{\nu}\in\mathbb{R}^{m}\) indicate the relative importance of each clip or caption","\max_{Q\inR_{+}^{n\times m}}tr(Q^{\top}S)\quads.t.\quadQ1_{m}=\frac{1}{n}1_{n},Q^{\top}1_{n}=\frac{1}{m}1_{m}",where \(\mathbf{Q}\) is the transport assignment and \(\mathbf{S}\) is the clip-caption similarity matrix.
ICLR_2024_oral_53,3,"Q^{*}&=Diag(\kappa_{1})\exp(S/\varepsilon)Diag(\kappa_{2}),\\with iteratively updated \kappa_{1}& arrow\mu./(\exp(S/\varepsilon)\kappa_{2}),\\kappa_{2}arrow\nu_{.}/(\exp(S^{\top}/\varepsilon)\kappa_{1})","where \(\boldsymbol{\kappa}_{1}\in\mathbb{R}^{n}\), \(\boldsymbol{\kappa}_{2}\in\mathbb{R}^{m}\) are the non-negative left and right scaling vectors",Q^{*}=diag(u)Kdiag(v),where \(\mathbf{K}=\exp(\mathbf{S}/\varepsilon)\) and \(\mathbf{u}\) and \(\mathbf{v}\) are obtained by Sinkhorn iterations.
ICLR_2024_oral_53,4,"L_{video}=-\sum_{i=1}^{N}(\log\frac{\exp((Q_{ii},\S_{ii})/\tau)}{\sum_{j=1}^{N}\exp((Q_{ ij},\S_{ij})/\tau)}+\log\frac{\exp((Q_{ii},\S_{ii})/\tau)}{\sum_{j=1}^{N}\exp((Q_{ ji},\S_{ji})/\tau)})","where \(\mathbf{S}_{ij}\in\mathbb{R}^{n\times m}\) is the clip-caption similarity matrix between video \(\mathbf{V}_{i}\) and paragraph \(\mathbf{T}_{j}\), \(\mathbf{Q}_{ij}\) is the corresponding transport assignment of \(\mathbf{S}_{ij}\), and \(\tau\) is a learnable temperature initialized as 0","L_{video}=-\log\frac{\exp(\langleQ^{*},S\rangle)}{\sum_{V'\inN}\exp(\langleQ^{*},S'\rangle)}",where \(\mathcal{L}_{\text{video}}\) represents the video-paragraph contrastive loss that captures long-term temporal dependencies between the video and its corresponding paragraph.
ICLR_2024_oral_53,5,"[S]_{a,b}=\frac{1}{2}(\frac{1}{f}\sum_{i=1}^{f}\alpha\log(\sum_{j=1}^{w}\exp(\frac{v_{a}^{i}\cdott_{b}^{j}}{\alpha}) )+\frac{1}{w}\sum_{i=1}^{w}\alpha\log(\sum_{j=1}^{f}\exp(\frac{t_{b}^{i}\cdotv_{a}^{j}}{\alpha})))",,S_{ab}=\frac{1}{fw}\sum_{j=1}^{f}\sum_{k=1}^{w}v_{a}^{j}\cdott_{b}^{k},"where \(\mathbf{S}_{ab}\) represents the fine-grained similarity between clip \(\mathbf{v}_{a}\) and caption \(\mathbf{t}_{b}\), and \(\mathbf{v}_{a}^{j}\) and \(\mathbf{t}_{b}^{k}\) denote the \(j\)-th frame in clip \(\mathbf{v}_{a}\) and the \(k\)-th word in caption \(\mathbf{t}_{b}\), respectively."
ICLR_2024_oral_53,6,"[\bar{S}]_{a,m+1}=[\bar{S}]_{n+1,b}=[\bar{S}]_{n+1, m+1}=p,\,[\bar{S}]_{a,b}=[S]_{a,b},\\forall a\in[1,n],\b\in[1,m]",,S_{apb}=S &p\\p & p,"where \(\mathbf{S}_{\text{apb}}\) is the updated similarity matrix with the alignable prompt bucket, \(\mathbf{p}\) is a vector of the same value \(p\), and \(p\) is a learnable parameter that controls the threshold for filtering out irrelevant clips and captions."
ICLR_2024_oral_53,7,"\max_{\hat{Q}\in\hat{Q}}\\\\langle\hat{Q},\\hat{S}\rangle+\varepsilon H(\hat{Q})\\\\s.t.\\\\hat{Q}=\{\hat{Q}\inR^{B\times B}_{+}\mid\hat{Q}1_{B}=\frac{1}{B}1_{B},\hat{Q}^{\top}1_{B}=\frac{1}{B}1_{B}\}",where the transport assignment \(\hat{\mathbf{Q}}\) attempts to realign the clips with similar captions (_i,"\max_{\hat{Q}\in\hat{Q}}\langle\hat{Q},\\hat{S}\rangle+\varepsilon H(\hat{Q})","where \(\hat{\mathbf{Q}}\in\mathbb{R}_{+}^{B\times B}\) denotes the within-batch transport assignment and \(\hat{\mathcal{Q}}=\{\hat{\mathbf{Q}}\in\mathbb{R}_{+}^{B\times B}\mid\hat{\mathbf{Q}}\mathbf{1}_{B}=\frac{1}{B}\mathbf{1}_{B},\hat{\mathbf{Q}}^{\top}\mathbf{1}_{B}=\frac{1}{B}\mathbf{1}_{B}\}\)."
ICLR_2024_oral_53,8,"L_{clip}=-\sum\limits_{i=1}^{B}\sum\limits_{j=1}^{B}[ T]_{i,j}(\log\frac{\exp([\hat{S}]_{i,j}/\tau)}{\sum_{k=1}^{B}\exp([\hat{S}]_{i,k}/\tau)}+\log\frac{\exp([\hat{S}]_{i,j}/\tau)}{\sum_{k=1}^{B}\exp([\hat{S}]_{i,j}/\tau)}),T=(1-\beta )\,I_{B}+\beta\hat{Q}^{*}",where \(\beta\) is a weighted parameter that balances the identity target \(\mathbf{I}_{B}\) and realigned targets \(\hat{\mathbf{Q}}^{*}\),L_{clip}=-\sum_{i=1}^{B}(\log\frac{\exp(\hat{Q}_{ii}^{*}/\tau)}{\sum_{j=1}^{B}\exp(\hat{Q}_{ij}^{*}/\tau)}),The clip-caption contrastive loss \(\mathcal{L}_{\text{clip}}\) explores the temporal correlations between the short video clips and their corresponding captions through a novel noise robust temporal optimal transport distance.
ICLR_2024_oral_54,1,"\min_{S\inR^{N\times d}}D(\nabla_{\theta}\ell(S;\theta),\nabla_{\theta}\ell(B;\theta))=D( S,B;\theta)","where the function \(D(\cdot)\) is defined as a distance metric such as MSE, \(\theta\) represents the model parameters, and \(\nabla_{\theta}\ell(\cdot)\) denotes the gradient, utilizing either the big dataset \(\mathcal{B}\) or its synthetic version \(\mathcal{S}\)",\min_{S}\left\|\nabla_{\theta}L(B)-\nabla_{\theta}L(S)\right\|,The equation represents the minimization of the gradient distance between the big dataset \(\mathcal{B}\) and the synthetic dataset \(\mathcal{S}\).
ICLR_2024_oral_54,2,"SarrowS-\lambda\nabla_{S}D( S,B;\theta),\quad\thetaarrow\theta-\eta\nabla_{\theta}\ell(\theta;S)","where \(\lambda\) and \(\eta\) are learning rates designated for \(\mathcal{S}\) and \(\theta\), respectively","S^{t+1}=S^{t}-\alpha\nabla_{S} D(\nabla_{\theta}\ell(S^{t};\theta^{t}),\nabla_{\theta}\ell(B;\theta^{t}))","The update rule for the synthetic dataset \(\mathcal{S}\) at each iteration \(t\), where \(\alpha\) is the step size."
ICLR_2024_oral_54,3,"\min_{S\inR^{N\times d}}D(\nabla_{\theta }\ell(S_{[1]},S_{[2]},\ldotsS_{[N]};\theta ),\nabla_{\theta}\ell(B;\theta))","where \(\mathcal{S}_{[n]}=\mathcal{S}_{\{1,2,\ldots,n\}}\subset\mathcal{S}=\mathcal{S}_ {[N]}\) represents \(n_{th}\) subset of the synthetic dataset \(\mathcal{S}\in\mathbb{R}^{N\times d}\)","\min_{S\inR^{N\times d}}\sum_{n=1}^{N}\lambda_{n}D(\nabla_{\theta}\ell(S_{n};\theta),\nabla_{\theta}\ell(B;\theta))",where \(\lambda_{n}\) represents the weight for each subset \(\mathcal{S}_{n}\) of the synthetic dataset \(\mathcal{S}\)
ICLR_2024_oral_54,4,"SarrowS-\lambda(\nabla_{S}D(S,B;\theta)+\nabla_{S_{[n]}}D(S_{[n]},B;\theta)),\hskip 14.226378ptn\in[1,N-1]","where \(\mathcal{S}=\mathcal{S}_{[N]}\) represents the condensed dataset of \(N\) images and is associated with the ""base loss""","\min_{S\inR^{N\times d}}\sum_{n=1}^{N}D(\nabla_{\theta }\ell(S_{[n]};\theta ),\nabla_{\theta}\ell(B;\theta))","The equation represents the new objective function that incorporates both the ""base loss"" and the ""subset loss"" to compress the information from multiple condensation processes into a single process."
ICLR_2024_oral_54,5,"F_{t}(S_{[n]},B)=D(f_{t}(S _{[n]}),f_{t}(B))","where \(f_{t}(\cdot)\) is the feature extraction function for \(t_{th}\) condensation iteration, and \(D(\cdot)\) is a distance metric like MSE",d_{t}(S_{[n]})=\left\|\frac{1}{n}\sum_{i=1}^{n} f(S_{[n]}^{i})-\frac{1}{M}\sum_{j=1}^{M} f(B^{j})\right\|_{2},The feature distance \(d_{t}(\mathcal{S}_{[n]})\) measures the difference between the average feature embeddings of subset \(\mathcal{S}_{[n]}\) and the big dataset \(\mathcal{B}\) at iteration \(t\).
ICLR_2024_oral_54,6,"F_{t}(S_{[p]},B)>F_{t}(S_{[q]},B),\;\;if\;\;\;1<p<q<N",,"F_{t}(S_{[p]},B)\geq F_{t}(S_{[q]},B)","where \(F_{t}(\mathcal{S}_{[p]},\mathcal{B})\) and \(F_{t}(\mathcal{S}_{[q]},\mathcal{B})\) are the feature distances for subsets \(\mathcal{S}_{[p]}\) and \(\mathcal{S}_{[q]}\) at iteration \(t\), respectively."
ICLR_2024_oral_54,7,"\underbrace{F_{t-\Delta t}(S_{[p]},B)>F_{t} (S_{[p]},B)}_{p},\;\;\underbrace{F_{t-\Delta t }(S_{[q]},B)>F_{t}(S_{[q]},B)}_{q}",where \(t-\Delta t\) and \(t\) are two different time points for the condensation process,"F_{t}(S_{[1]},B)>F_{t}(S_{[n]},B)>F_{t}(S_{[N]},B)","where \(F_{t}(\mathcal{S}_{[1]},\mathcal{B})\) represents the feature distance between the smallest subset \(\mathcal{S}_{[1]}\) and the big dataset \(\mathcal{B}\) at iteration \(t\), and \(F_{t}(\mathcal{S}_{[N]},\mathcal{B})\) represents the feature distance between the full subset \(\mathcal{S}_{[N]}\) and the big dataset \(\mathcal{B}\) at iteration \(t\)."
ICLR_2024_oral_54,8,"R(S_{[n]},t)=\frac{\Delta F_{S_{[n]}}}{\Delta t}=\frac{ |F_{t}(S_{[n]},B)-F_{t-\Delta t}(S_{[n]},B)|}{\Delta t}","where \(R(\mathcal{S}_{[n]},t)\) represents the rate of change of feature distance for subset \(\mathcal{S}_{[n]}\) at the time point \(t\), and \(\Delta F_{\mathcal{S}_{[n]}}\) denotes the change in feature distance of subset \(\mathcal{S}_{[n]}\) from time \(t-\Delta t\) to \(t\)","\min_{n\in[1,N-1]}\frac{F_{t-\Delta t}(S_{[n]},B)-F_{t}(S_{[n]},B)}{\Delta t}","The feature distance reduction rate represents how quickly the feature distance between a subset and the big dataset decreases over time, indicating the learnability of the subset."
ICLR_2024_oral_54,9,"S_{MLS}(t)=S_{[n_{t}^{*}]}=\operatorname*{arg\, max}_{S_{[n]}}(R(S_{[n]},t))\;\; where\;\;n\in[1,N-1]",,"n^{*}=\arg\max_{n}R(S_{[n]},t),\;\;n\in[1,N-1]",The Most Learnable Subset (MLS) is determined by the subset with the highest feature distance reduction rate at time t.
ICLR_2024_oral_54,10,{l}Using Eq.~{\ref{eq:mLS} to~{}}Update&S\\Update&S\setminusS_{MLS}(t-\Delta t)if\;S_{MLS}(t)\supsetS_{MLS}(t-\Delta t),where \(\setminus\) is the symbol for set minus,"SarrowS-\lambda(\nabla_{S}D(S,B;\theta)+\nabla_{S_{MLS}(t)}D(S_{MLS}(t),B;\theta))","where \(\mathcal{S}_{\mathrm{MLS}}(t)\) represents the Most Learnable Subset at time \(t\), and \(\nabla_{\mathcal{S}_{\mathrm{MLS}}(t)}D( \mathcal{S}_{\mathrm{MLS}}(t),\mathcal{B};\theta)\) denotes the gradient of the distance between \(\mathcal{S}_{\mathrm{MLS}}(t)\) and the big dataset \(\mathcal{B}\) with respect to the model parameters \(\theta\)"
ICLR_2024_oral_55,1,"\operatorname*{arg\,max}_{\theta}\prod_{\bar{D}}p(Y_{Q}|f_ {\theta}(S,X_{Q}))",,"\min_{\theta}L(f_{\theta}(X_{S}), Y_{S})","The equation represents the objective of few-shot learning, which is to minimize the loss function of a classifier on the support set."
ICLR_2024_oral_55,2,"\operatorname*{arg\,max}_{\alpha,\phi}\prod_{\bar{D}_{test}} p(Y_{Q}|f_{\alpha,\phi}(S,X_{Q}))",,"\operatorname*{arg\,max}_{\phi,\alpha}\prod_{\bar{D}}p(Y_{Q}|f_ {\theta\setminus\phi,\phi,\alpha}(S,X_{Q}))","The parameters \(\phi\) and \(\alpha\) represent the fine-tuned and adapter parameters, respectively."
ICLR_2024_oral_55,3,"g_{\phi,\phi^{\prime},\alpha}(x)=g_{\phi,\phi^{\prime}}(x)+h_{\alpha}(x)","where \(x\in\mathbb{R}^{W,H,C}\)",4^{K},The size of the search space for adaptation strategies.
ICLR_2024_oral_55,4,"g_{\phi,\phi^{\prime},\alpha}(x)=z(A_{qkv}[q\;;\;g_{\phi,\phi^{\prime}}(x)]+h _{\alpha 1})+h_{\alpha 2}",where \(x\in\mathbb{R}^{D}\) and \([\cdot\;;\;\cdot]\) denotes the concatenation operation,"g_{\phi,\phi^{\prime},\alpha}(x)=A_{qkv}^{\prime}(x)+z^{\prime}(x)+h_{\alpha}(x)","where \(A_{qkv}^{\prime}\) and \(z^{\prime}\) represent the modified multi-head self-attention and feed-forward modules with fine-tuned parameters \(\phi^{\prime}\), and \(h_{\alpha}\) is the residual adapter parameterised by \(\alpha\)."
ICLR_2024_oral_55,5,"L(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\log\frac{e^{-d_{cos}(C_{Q_{i}},f(Q_{i}))}}{\sum_{j=1}^{|C|}e^{-d_{cos}(C_{j},f(Q_{cj}))}}","where \(C_{\mathcal{Q}_{i}}\) denotes the embedding of the class centroid that corresponds to the true class of \(\mathcal{Q}_{i}\), and \(d_{cos}\) denotes the cosine distance","L(f,S,Q)=\sum_{\bar{D}_{test}}\ell(f_{\alpha,\phi}(S,Q),Y_{Q})",where \(\ell\) denotes the cross-entropy loss function.
ICLR_2024_oral_55,6,"\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}\E_{p\sim P}E_{S,Q}\L(f^{p}_{\theta,\alpha,\phi^{\prime}},S,Q)",,"\min_{\theta,\alpha,\phi^{\prime}}E_{p\sim P}\left[L(f^{p}_{\theta,\alpha,\phi^{\prime}},S,Q)\right]","where \(p\) is a path sampled from the supernet, and \(\mathcal{L}\) is the prototypical loss function."
ICLR_2024_oral_55,7,"p_{k}=\operatorname*{arg\,max}_{p\in P}E_{S,Q}A(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}},S,Q),\quads.t || \alpha^{*},\phi^{\prime*}=\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}L(f^{p} _{\theta,\alpha,\phi^{\prime}},S,S)",,"\operatorname*{arg\,max}_{p_{1},p_{2},...,p_{N}}\E_{S,Q}\\sum_{n=1}^{N}L(f^{p_{n}}_{\theta,\alpha,\phi^{\prime}},S,Q)",where \(p_{n}\) denotes the \(n\)-th path in the sequence of paths.
ICLR_2024_oral_55,8,"\quad\forall_{j=1,\dots,k-1}\\d_{cos}(p_{k},p_{j})\geq T",,"E_{S,Q}A(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}},S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}I(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}}(Q_{i})=y_{i})","where \(A(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}},\mathcal{S},\mathcal{Q})\) represents the accuracy of model \(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}}\) on the query set \(\mathcal{Q}\), and \(\mathbb{I}\) denotes the indicator function."
ICLR_2024_oral_55,9,"A(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}[\operatorname*{arg\,min}_{j}d_{cos}(C_{Q_{j}},f(Q_{i}))=Y_ {Q_{i}}]",,"A(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}},S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}I\left(\operatorname*{arg\,max}_{j}\operatorname*{sim}(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}}(Q_{i}),C_{j})=y_{i}\right)",where \(\operatorname*{sim}\) denotes the cosine similarity and \(\mathbb{I}\) is the indicator function.
ICLR_2024_oral_55,10,"p^{*}=\operatorname*{arg\,min}_{p\in\{p_{1},...,p_{N}\}}L(f^{p}_{O_{\alpha^{*}},\phi^{\prime\prime*}},S,S),\quads.t || \alpha^{*},\phi^{\prime*}=\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}L(f^{p}_{O,\alpha,\phi^{\prime}},S,S)",,"p^{*}=\operatorname*{arg\,max}_{p\in\{p_{1},...,p_{N}\}}A(f^{p}_{\theta,\alpha^{*},\phi^{\prime*}},S,Q)",where \(A\) denotes the classification accuracy of a nearest centroid classifier (NCC) and \(\alpha^{*}\) and \(\phi^{\prime*}\) are the optimal adapter and fine-tuned parameters for path \(p\).
ICLR_2024_oral_56,1,"\vec{x}_{n}&=A\vec{x} _{n-1}+Bu_{n}&A\inC^{N\times N},B\inC^{N\times 1}\\y_{n}&=C\vec{x}_{n}&C\inC^{1\times N}",,y_{n}=c^{\top}\vec{x}_{n},"The equation represents the output of a State Space Model (SSM) at timestep n, where y_n is the scalar output, \mathbf{c} is a learnable vector, and \vec{\mathbf{x}}_{n} is the hidden state vector."
ICLR_2024_oral_56,2,A=A-PQ^{\star} || \bar{A}=(I-\Delta/2\cdotA)^{-1}(I+\Delta/2\cdotA),,K_{k}=C^{T}A^{k}B,"The kernel K defined by the convolution of the input sequence u with the learnable parameters A, B, and C."
ICLR_2024_oral_56,3,\bar{B}=(I-\Delta/2\cdotA)^{-1}\DeltaB\quad\bar{C}=C,,y_{n}&=\sum_{k=0}^{n}K_{k}u_{n-k},The equation represents the convolution of the input sequence u with the kernel K to produce the output sequence y.
ICLR_2024_oral_56,4,K_{k}=\bar{C}^{T}\bar{A}^{k}\bar{B},"where \(\mathbf{A},\mathbf{P},\mathbf{Q},\mathbf{B},\mathbf{C},\Delta\) are learnable parameters and \(\mathbf{A}\in\text{{Diag}}(\mathbb{C}^{N\times N}),\mathbf{P},\mathbf{Q}\in\mathbb{C}^{N \times 1}\)",y_{n}&=\sum_{k=0}^{n}K_{k}u_{n-k}\\K_{k}&=C\bar{A}^{k}\bar{B},"The equation represents the output sequence y as a convolution of the input sequence u with the kernel K, where K is defined in terms of the transformed parameters."
ICLR_2024_oral_56,5,"\vec{x}_{n}&=A\vec{x} _{n-1}+I\,u_{n}&A\in{diag}(C^{N\times N })\\y_{n}&=C\vec{x}_{n}&C\inC^{1\times N}",where \(\mathbf{I}\) is the all-ones vector,\vec{x}_{n}&=D\vec{x} _{n-1}+bu_{n}\\y_{n}&=c\vec{x}_{n},"where \(\mathbf{D}\) is a diagonal matrix, \(\mathbf{b}\) and \(\mathbf{c}\) are learnable vectors"
ICLR_2024_oral_58,1,"\mu_{m,k}\triangleqE_{(x,y)\simG}[\upsilon_{m,k}(x) ],\\sigma_{m,k}^{2}\triangleqE_{(x,y)\simG}[(\upsilon_{m,k}(x)-\mu_{m,k})^{2}]",,"\mu_{m,k}=\frac{1}{N}\sum_{i=1}^{N}\Phi_{m}^{rep}(x_i)_k,\quad\sigma_{m,k}^2=\frac{1}{N}\sum_{i=1}^{N}(\Phi_{m}^{rep}(x_i)_k-\mu_{m,k})^2",The equation calculates the mean and variance of the k-th feature for the m-th model.
ICLR_2024_oral_58,2,"\rho_{(i,j),(a,b)}\triangleqE_{(x,y)\simG}[(\upsilon_{i,a}(x)-\mu_{i,a})(\upsilon_{j,b}(x)-\mu_{j,b}) ](\sigma_{i,a}\\sigma_{j,b})^{-1}",,"\rho_{i,j,a,b}\triangleq\frac{E_{(x,y)\simG}[(\upsilon_{i,a}(x)-\mu_{i,a})(\upsilon_{j,b}(x)-\mu_{j,b})]}{\sigma_{i,a}\sigma_{j,b}}",The correlation between the a-th feature of model f_i and the b-th feature of model f_j.
ICLR_2024_oral_58,3,Acc=p_{d}(1-\frac{1}{2}\binom{t_{d}-c_{d}}{a_{d}}\\\binom{t_{d}}{a_{d}}^{+}p_{r}(1-\frac{1}{2}\binom{t_{r}-c_{r}}{c_{r}}\\\binom{t_{r}}{c_{r}}),,Acc=\frac{1}{2}p_{d}+\frac{1}{2}p_{r}\left(1-\left(1-\frac{c_{d}}{t_{d}}\right)^{n_{d}}\left(1-\frac{c_{r}}{t_{r}}\right)^{n_{r}}\right),The expected accuracy over the model distribution and data distribution.
ICLR_2024_oral_59,1,\Pr[A(D)\in R]\leq e^{\epsilon}\Pr[A(D^{\prime})\in R]+\delta,,\Pr[A(D)\in R]\leq e^{\epsilon}\Pr[A(D')\in R]+\delta,"The probability of the algorithm A producing an output in region R when trained on dataset D is less than or equal to the probability of A producing an output in region R when trained on dataset D' multiplied by e to the power of epsilon, plus delta."
ICLR_2024_oral_59,2,"\hat{\epsilon}=\max\{\log\frac{1-\delta-FPR}{FNR},\log\frac{1-\delta-FNR}{FPR}\}",,\epsilon=\ln\left(\frac{1}{\alpha}\right) and \delta=\beta,The false positive rate is denoted by \(\alpha\) and the false negative rate is denoted by \(\beta\).
ICLR_2024_oral_59,3,f_{d}(t)=\frac{\Gamma(\frac{d}{2})}{\Gamma(\frac{d-1}{2})\sqrt{\pi}}(1-t^{2})^{\frac{d-3}{2}},,f_{\tau_{d}}(x)=\frac{\Gamma(\frac{d}{2})}{\Gamma(\frac{d-1}{2})\sqrt{\pi}}(1-x^{2})^{\frac{d-3}{2}},The probability density function of the cosine similarity between a uniformly sampled vector from the unit sphere and an arbitrary independent nonzero vector.
ICLR_2024_oral_6,1,"\epsilon_{k}(x)\mathop{=}^{def}u_{k}(\texttt{BR}_{k},x_{-k})-u_{k}(x) where \texttt{BR}_{k}\in\operatorname*{arg\,max}_{z}u_{k}(z,x_{-k})",,L(\pi)=\max_{\pi'\in\Pi} [R(\pi')-R(\pi)],The loss function L measures the maximum gain that can be achieved by unilaterally deviating from the joint strategy π.
ICLR_2024_oral_6,2,L(x)=\sum_{k}\eta_{k} || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || ^{2},"where each \(\eta_{k}>0\) represents a scalar weight, or equivalently, a step size to be explained next",L(x)=\sum_{k}\left\lVert\Pi_{T\Delta_{k}}\nabla_{x_{k}} u_{k}(x)\right\rVert^{2},The loss function L measures the sum of the squared projected-gradient norms for each player's strategy.
ICLR_2024_oral_6,3,\epsilon_{k}(x)\leq\sqrt{2} || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || ,,\epsilon_{k}(x)\leq\eta_{k}^{-1} || x_{k}-\texttt{aBR}_{k} || _{1}=\eta_{k}^{-1} || \eta_{k}\Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || _{1}= || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || _{1},The exploitability of a joint strategy is upper bounded by a quantity proportional to the norm of the projected-gradient.
ICLR_2024_oral_6,4,\epsilon\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L(x)}\stackrel{{\tiny def}}{{=}}f(L),,\epsilon_{k}(x)\leq\sqrt{2L(x)/\eta_{k}},The exploitability of a joint strategy is upper bounded by a function of the loss and the step size.
ICLR_2024_oral_6,5,L(x)=E[\sum_{k}\eta_{k}\underbrace{(\hat{\nabla}_{x_{ k}}^{k(1)}-\frac{1}{m_{k}}(1^{\top}\hat{\nabla}_{x_{k}}^{k(1)}))}_{ projected-gradient 1})^{\top}(\underbrace{\hat{\nabla}_{x_{k}}^{k(2)}-\frac{1}{m_{k}}(1^{\top}\hat{\nabla}_{x_{k}}^{k(2)})1)}_{projected-gradient 2}),where \(\hat{\nabla}^{k(p)}_{x_{k}}\) is an unbiased estimator of player \(k\)'s gradient,"E[\langle\nabla_{x_{k}}^{k(1)},\nabla_{x_{k}}^{k(2)}\rangle]=E[ || \nabla_{x_{k}}^{k} || ^{2}]","The expected value of the dot product of two independent, identically distributed random gradient estimates equals the expected value of the squared norm of the true gradient."
ICLR_2024_oral_6,6,L^{\tau}(x)=\sum_{k}\eta_{k} || \Pi_{T\Delta}(\nabla^{k\tau}_{x_ {k}}) || ^{2},,L^{\tau}(x)=\sum_{k}\eta_{k} || \Pi_{T\Delta}(\hat{\nabla}_{x_{k}}^{k\tau(1)}) || ^{2},where \(\hat{\nabla}^{k\tau(p)}_{x_{k}}\) is an unbiased estimator of player \(k\)'s gradient in the entropy-regularized game
ICLR_2024_oral_6,7,\epsilon_{QRE}\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L^{\tau}(x)}\overset{\tiny{def}}{=}f(L^{\tau}),,\epsilon_{QRE}\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L^{\tau}(x)}\stackrel{{\tiny def}}{{=}}f^{\tau}(L),where \(\epsilon_{QRE}\) represents the exploitability of an approximate equilibrium in a game with entropy bonuses.
ICLR_2024_oral_6,8,\epsilon\leq\tau\log\Big{(}\prod_{k}m_{k}\Big{)}+\sqrt{\frac{2n}{\min_{k}\eta_ {k}}}\sqrt{L^{\tau}(x)}\overset{\tiny{def}}{=} f_{\tau}(L^{\tau}),,L^{\tau}(x)\leq\frac{2n\tau^{2}}{\min_{k}\eta_{k}},where \(\tau\) is the temperature parameter and \(\eta_{k}\) represents the step size for player \(k\).
ICLR_2024_oral_6,9,\nabla_{x_{l}}L^{\tau}(x)=2\sum_{k}\eta_{k}B_{kl}^{\top}\Pi_{T\Delta}(\nabla_{x_{k}}^{kT}),,\nabla_{x_{l}}L^{\tau}(x)=2\eta_{l}\Pi_{T\Delta}(\nabla_{x_{l}}^{l\tau})\nabla_{x_{l}}(\Pi_{T\Delta}(\nabla_{x_{l}}^{l\tau})),The gradient of the entropy regularized loss function with respect to a player's strategy.
ICLR_2024_oral_6,10,\textsl{Hess}(L^{\tau})=2\big{[}\tilde{B}^{\top}\tilde{B}+T\Pi_{T\Delta}(\tilde{\nabla}^{\tau})\big{]},,\nabla_{x_{l}}L^{\tau}(x)=2\sum_{k}\eta_{k}B_{kl}^{\top}\Pi_{T\Delta}(\nabla_{x_{k}}^{k\tau}),where \(B_{kl}=-\tau[I-\frac{1}{m_{l}}\mathbf{1}\mathbf{1}^{\top}]\texttt{diag}\big{(}\frac{1}{x_{l}}\big{)}\) and \(B_{kl}=[I-\frac{1}{m_{k}}\mathbf{1}\mathbf{1}^{\top}]H_{kl}^{k}\) for \(k\neq l\).
ICLR_2024_oral_6,11,"M(x)=-\sqrt{\eta_{1}}\Pi_{T\Delta}(\frac{1}{x_{1}})&\sqrt{\eta_{1}}\Pi_{T\Delta}(H^{1}_{12})&\ldots&\sqrt{\eta_{1}}\Pi_{T\Delta}(H^{1}_{ 1n})\\\vdots&\vdots&\vdots&\vdots\\\sqrt{\eta_{n}}\Pi_{T\Delta}(H^{n}_{n1})&\ldots&\sqrt{\eta_{n}}\Pi_{T\Delta}( H^{n}_{n,n-1})&-\tau\sqrt{\eta_{n}}\Pi_{T\Delta}(\frac{1}{x_{n}})\\1_{1}^{\top}&0&\ldots&0\\\vdots&\vdots&\vdots&\vdots\\0&\ldots&0&1_{n}^{\top}",where \(\Pi_{T\Delta}(z\in\mathbb{R}^{n\times b})=[I_{a}-\frac{1}{a}\mathbf{_{1}}\mathbf{_{ 1}}^{\top}]z\) subtracts the mean from each column of \(z\) and \(\frac{1}{x_{k}}\) is shorthand for \(\texttt{diag}\big{(}\frac{1}{x_{k}}\big{)}\),M=\tilde{B}\\1^{\top}\otimes I_{\bar{m}},where \(\tilde{B}_{kl}=\sqrt{\eta_{k}}B_{kl}\) and \(B_{kl}=-\tau[I-\frac{1}{m_{l}}\mathbf{1}\mathbf{1}^{\top}]\texttt{diag}\big{(}\frac{1}{x_{l}}\big{)}\) for \(l=k\) and \(B_{kl}=[I-\frac{1}{m_{k}}\mathbf{1}\mathbf{1}^{\top}]H_{kl}^{k}\) for \(k\neq l\)
ICLR_2024_oral_60,1,y_{i}^{\prime}=I_{\tau}(h)(x_{i}),,f:X\rightarrowY,The function f maps an input x to an output y.
ICLR_2024_oral_60,2,"a_{\tau}=\frac{1}{|D_{\tau}^{u}|}\sum_{(x,y)\inD_{\tau}}\mathbbm{1}\big{[}I_{\tau}(h)(x)=y\big{]}",,A_{\tau}(h)=\frac{1}{n}\sum_{i=1}^{n}1(y_{i}=y_{i}^{\prime}),The accuracy \(A_{\tau}(h)\) measures the proportion of correctly predicted outputs for a given task \(\tau\) and induced rule \(h\).
ICLR_2024_oral_60,3,c=\frac{1}{|T|}\sum_{\tau\inT}a_{\tau}\hskip 28.452756ptc_{t}=\frac{1}{|T|}\sum_{\tau\inT}\mathbbm{1}\big{[}a_{\tau}=1\big{]},,"c=\frac{1}{|T|}\sum_{\tau\inT} a_{\tau},\quad c_{t}=\frac{1}{|T|}\sum_{\tau\inT}\mathbbm{1}\big[ a_{\tau}\geq\frac{1}{2}\big]","The raw accuracy \(c\) measures the average accuracy across all tasks, while the task accuracy \(c_{t}\) measures the proportion of tasks where the accuracy is at least 0.5."
ICLR_2024_oral_60,4,"h^{t}\sim P_{LM}\big{(}\cdot\,|d^{t-1},x_{1},y_{1},...,x_{k},y_{k})",where \(d^{t-1}\) is the feedback from previous iterations and which is set to be an empty string at the initial iteration,"H^{t}=\{h_{1}^{t},...,h_{N}^{t}\}=\arg\max_{h\in\Sigma^{*}} p(h|D_{\tau}^{s},t)",The set of hypotheses of rules sampled from a prompted language model at iteration t.
ICLR_2024_oral_60,5,"s(h,D_{\tau}^{s})=\frac{1}{|D_{\tau}^{s}|}\sum_{(x,y)\inD_{\tau}^{s}}\mathbbm{1}\big{[}I_{\tau}(h)(x)=y\big{]}",,"s(h,D_{\tau}^{s})=\frac{1}{|D_{\tau}^{s}|}\sum_{(x,y)\inD_{\tau}^{s}}\mathbbm{1}\big{[}I_{\tau}(h)(x)=y\big{]}",The scoring function s measures the accuracy of a hypothesis h over the seen examples in the task.
ICLR_2024_oral_60,6,"h^{t^{*}}=\operatorname*{arg\,max}_{h^{\prime}\in H^{t}}s(h^{\prime}, D_{\tau}^{s})",,"h^{t}_{best}=\arg\max_{h\in H^{t}}s(h,D_{\tau}^{s})","The best hypothesis \(h^{t}_{\text{best}}\) is the one that maximizes the scoring function \(s(h,\mathcal{D}_{\tau}^{s})\) over the set of hypotheses \(H^{t}\)."
ICLR_2024_oral_61,1,"P(a_{t:t+k}|s_{t},s^{g})=\int_{s_{t+1},\ldots,s_{t+k}}ds_{t+1}\ldots ds_{t+k}\prod_{i=t}^{t+k}P_{\phi}(a_{i}|s_{i},s^{g})P(s_{i+1}|s_{i},a_{i})",where \(s^{g}\in S\) is the goal state,"P_{\phi}(a|s,g)=\frac{1}{T}\sum_{t=1}^{T} P_{\phi}(a_t|s_t,g)",The goal-conditioned model \(P_{\phi}\) predicts the action for one step given the state and goal.
ICLR_2024_oral_61,2,"L(\phi)=E_{D}[-\log P_{\phi}(a_{i}|s_{i},s^{g})]",,"L(\phi)=-\sum_{\tau}\sum_{i=t}^{t+k}\log P_{\phi}(a_{i}|s_{i},s^{g})","where \(\phi\) represents the model parameters of \(P_{\phi}\), \(\tau\) denotes a \(k\)-step subsequence in an episode, and \(s^{g}\) is the goal state."
ICLR_2024_oral_61,3,L(\psi)=E_{D}[-\log\pi^{p}_{\psi}(a^{h}|s_{t})],,L(\psi)=E_{D}[-\log\pi^{p}_{\psi}(a^{h}|s_{t})],The goal prior model loss function is defined to minimize the negative log-likelihood of goal prediction.
ICLR_2024_oral_61,4,"J(\theta)=E\pi_{\theta}[\sum_{t=0}^{\infty}\gamma^{t}(\sum _{i=kt}^{(k+1)t}R(s_{i},a_{i})-\alpha D_{KL}(\pi^{p}_{\psi}(a^{h }|s_{kt})\|\pi_{\theta}(a^{h}|s_{kt})))]",where \(t\) represents the number of steps for the high-level policy and \(\alpha\) is a hyperparameter balancing the environmental rewards and the intrinsic rewards,"J(\theta)=E_{\pi_{\theta}}[\sum_{t=0}^{T-1}r(s_{t},a_{t})+\beta\log\pi^{p}_{\psi}(a^{h}|s_{t})]","The overall objective function for training the high-level policy, which maximizes the expected return by considering both environment rewards and intrinsic rewards from the goal prior model."
ICLR_2024_oral_63,1,p_{\theta}(x)\propto e^{-f_{\theta}(x)},,f_{\theta}:X\toR,The energy function mapping inputs x to a scalar energy value.
ICLR_2024_oral_63,2,"x_{k+1}=x_{k}-\delta\,\nabla f_{\theta}(x_{k})+\sqrt{2\delta}\,\varepsilon_{k },\,\varepsilon_{k}\simN(0,I_{d})","where \(\nabla\) denotes the gradient of the energy function with respect to inputs, \(k\) is the sampling step, \(\delta\) is the (discretization) step size, and the noise \(\varepsilon_{k}\) is drawn from the normal distribution at each step","x_{t+1}=x_t-\frac{\epsilon}{2}\nabla f_{\theta}(x_t)+\sqrt{\epsilon}\cdotN(0, I)","The equation represents the update rule for Langevin MCMC, where \(x_t\) is the current sample, \(\epsilon\) is the step size, \(\nabla f_{\theta}(x_t)\) is the gradient of the energy function, and \(\mathcal{N}(0, I)\) is a standard normal noise term."
ICLR_2024_oral_63,3,\hat{x}(y)=y+\sigma^{2}\nabla\log p(y),where \(p(y)=\int p(y|x)p(x)dx\) is the probability distribution function of the smoothed density,E[X|Y=y]=\frac{\sigma^{2}}{\sigma^{2}+\tau^{2}}y,"The least-squares estimator of X given Y=y is a linear transformation of y, where σ^2 is the variance of the additive Gaussian noise and τ^2 is the variance of X."
ICLR_2024_oral_63,4,\hat{x}_{\phi}(y)=y+\sigma^{2}g_{\phi}(y),,\hat{x}(y)=y+\sigma^{2}g_{\phi}(y),The least-squares estimator of \(X\) given \(Y=y\) using a neural network parameterized score function \(g_{\phi}\).
ICLR_2024_oral_63,5,"L(\phi)=E_{x\sim p(x),y\sim p(y|x)}\|x-\hat{x}_{\phi}(y)\|^ {2}",,"\min_{\theta,\phi}E_{x\sim p_{data}}\left[E_{y\simN(x,\sigma^{2}I_{d})}\left[\left\|x-\hat{x}_{\phi}(y)\right\|^{2}\right]+f_{\theta}(x)\right]",The learning objective combines the reconstruction loss of the least-squares estimator with the energy function of the EBM.
ICLR_2024_oral_63,6,"\operatorname*{arg\,max}_{\theta}E_{y\sim p_{Y}}[\log p_{\theta}( y)]=\operatorname*{arg\,max}_{\theta}(E_{y^{-}\sim p_{Y}(y)}[f_{\theta}(y^{-})]-E_{y^{+}\sim p_{Y}}[f_{\theta}(y^{+})])",where \(y^{+}\) are noisy training data and \(y^{-}\) are noisy data sampled from the model,L(\theta)=E_{y\sim p(y)}\log p_{\theta}(y),The log-likelihood of the energy-based model given noisy data.</description!
ICLR_2024_oral_63,7,\nabla_{\theta}\log p_{\theta}(y)=-\nabla_{\theta}f_{\theta}(y)-\nabla_{\theta}\log Z(\theta) || =-\nabla_{\theta}f_{\theta}(y)+\frac{\int\nabla_{\theta}f_{\theta}(y)e^{-f_{\theta}(y)}dy}{Z(\theta)} || =-\nabla_{\theta}f_{\theta}(y)+\int\nabla_{\theta}f_{\theta}(y)\cdot p_{\theta}(y)dy || =-\nabla_{\theta}f_{\theta}(y)+E_{y\sim p_{\theta}(y)}[\nabla_{\theta}f_{\theta}(y)],,\frac{\partial}{\partial\theta}E_{y\sim p_{Y}}[\log p_{\theta}(y)]=E_{y^{-}\sim p_{Y}(y)}[\nabla_{\theta}f_{\theta}(y^{-})]-E_{y^{+}\sim p_{Y}}[\nabla_{\theta}f_{\theta}(y^{+})],The equation represents the derivative of the log-likelihood of noisy data under the model with respect to the model parameters.
ICLR_2024_oral_63,8,"P^{\top}argmax\,\hat{x}(y,t)=P^{\top}s",,P_{C}(y)=y\odot c+(1-c)\odot\bar{y},"where \(c\) is a binary vector indicating the positions to be edited, \(\bar{y}\) is the fixed starting sequence, and \(\odot\) denotes element-wise multiplication."
ICLR_2024_oral_63,9,\chi_{ii^{\prime}}=\frac{ || X_{i}-X_{i^{\prime}} || }{2\sqrt{d}},where \(d\) is the dimension of the data and the \(\frac{1}{2\sqrt{d}}\) scaling comes from the concentration of isotropic Gaussians in high dimensions,\chi_{ij}=E_{p(y)}\left[\frac{\partial\log p(y)}{\partial y_i}\frac{\partial\log p(y)}{\partial y_j}\right],The matrix χ represents the expected value of the product of the partial derivatives of the log probability density function with respect to the components of the random variable y.
ICLR_2024_oral_63,10,\sigma_{c}=\max_{ii^{\prime}}\chi_{ii^{\prime}},,"\sigma_{c}=\frac{1}{2}\max_{i,i^{\prime}} || X_{i}-X_{i^{\prime}} || ","where \(X_{i}\) and \(X_{i^{\prime}}\) are data points in the dataset, and the norm is the Euclidean norm."
ICLR_2024_oral_64,1,Z_{k}\subseteqR^{M}\quadand\quadZ=Z_{1}\times\dots\timesZ_{K}\subseteqR^{KM},,"x=f(z)=f(z_{1},z_{2}, ...,z_{K})",The equation represents the diffeomorphic generator that maps latent vectors to observations in the data space.
ICLR_2024_oral_64,2,"x=f(z),\quadz\sim p_{z},\quadsupp(p_{z })=Z^{S}",,X^{S}=\big{\{}x=f(z)|z\inZ^{S}\big{\}},"\(\mathcal{X}^{S}\) represents the training space, which is generated by applying the diffeomorphic generator \(\mathbf{f}\) to the slot-supported subset \(\mathcal{Z}^{S}\) of the latent space \(\mathcal{Z}\)."
ICLR_2024_oral_64,3,"L_{rec}(X^{S})=L_{rec}\big{(}\hat {g},\hat{f},X^{S}\big{)}:=E_{x\sim p_{x }}\big{[}\big{\|}\hat{f}\big{(}\hat{g}(x)\big{)}-x\big{\|} _{2}^{2}\big{]},\quadsupp(p_{x})=X^{S}",,"\min_{\hat{f},\hat{g}}E_{x\sim p_{x}}\left[\ell(x,\hat{f}(\hat{g}(x)))\right]","The reconstruction objective is a loss function that measures the difference between the input data and its reconstruction, which is used to optimize the parameters of the autoencoder."
ICLR_2024_oral_64,4,"\frac{\partialf_{n}}{\partialz_{k}}(z)\neq 0\implies\frac{\partialf_{n}}{\partialz_{j}}(z)=0,\quadfor any $k,j\in[K]$, $k\neq j$ and any $n\in[N]$.",,\frac{\partialf(z)}{\partialz_{k}}\cdot\frac{\partialf(z)}{\partialz_{j}}=0\quadfor all\quad k\neq j,"The compositionality assumption states that the Jacobian of the generator function has a block-diagonal structure, meaning that each output dimension is only dependent on one latent slot."
ICLR_2024_oral_64,5,"z^{\prime}=\big{(}h_{1}(z_{\pi(1)}),\ldots,h_{K}(z_{\pi(K)})\big{)},\quadZ^{\prime}=h_{1}(Z_{\pi(1)})\times\cdots\timesh_{K}(Z_{\pi(K)})",,"\hat{z}=\big{(}h_{1}^{-1}(\hat{z}_{\pi(1)}),\ldots,h_{K}^{-1}(\hat{z}_{\pi(K)})\big{)}",The equation represents the compositionally generalized latent representation.
ICLR_2024_oral_64,6,\hat{g}\big{(}f(z)\big{)}=z^{\prime}\quadand\quad\hat{f}(z^{\prime})=f(z),,"\hat{g}\big{(}f(z)\big{)}=z^{\prime}=\big{(}h_{1}(z_{\pi(1)}),\ldots,h_{K}(z_{\pi(K)})\big{)}",The equation represents the requirement for an autoencoder to generalize its slot identifiability from a slot-supported subset to the entire latent space.
ICLR_2024_oral_64,7,"\hat{f}(z)=\sum_{k=1}^{K}\varphi_{k}(\hat{z}_{k}),\quadwhere \varphi_{k}:R^{M}\toR^{N} for any k\in[K] and \hat{z}\inR^{KM}",,\hat{f}(z^{\prime})=\sum_{k=1}^{K}\hat{f}_{k}(h_{k}(z_{\pi(k)})),The variable \(\hat{\mathbf{f}}_{k}\) represents the slot-wise render of the \(k\)-th object.
ICLR_2024_oral_64,8,"L_{cons}\big{(}\hat{g},\hat{f},Z^{\prime}\big{)}=E_{z^{\prime}\sim q_{z^{\prime}}}\Big{[}\big{\|}\hat{g}\big{(}\hat{f}(z^{\prime})\big{)}-z^{\prime}\big{\|} _{2}^{2}\Big{]}",,"L_{cons}\big{(}\hat{g},\hat{f}\big{)}:=E_{z^{\prime}\sim q_{z^{\prime}}}\big{[}\big{\|}\hat{g}\big{(}\hat{f}(z^{\prime})\big{)}-z^{\prime}\big{\|}_{2}^{2}\big{]}",The compositional consistency loss measures the difference between the input and output of the autoencoder when the input is a recombination of inferred latent slots.
ICLR_2024_oral_64,9,"L_{rec}\big{(}\hat{g},\hat{f},X^{S}\big{)}+\lambdaL_{cons}\big{(}\hat{g},\hat{f},Z ^{\prime}\big{)}=0,\qquadfor some \lambda>0",,"L_{cons}\big{(}\hat{g},\hat{f},Z^{\prime}\big{)}=E_{z^{\prime}\sim q_{z^{\prime}}}\Big{[}\big{\|}\hat{g}\big{(}\hat{f}(z^{\prime})\big{)}-z^{\prime}\big{\|} _{2}^{2}\Big{]}",The compositional consistency loss is a regularizer that encourages the encoder to invert the decoder on out-of-distribution combinations of slots.
ICLR_2024_oral_64,10,"\hat{f}(z)=\sum_{k=1}^{K}\tilde{m}_{k}\odotx_{k},\qquad\tilde{m}_{k}=\sigma(m)_{k},\qquad(m_{k},x_{k})=\varphi _{k}(z_{k})",where \(\odot\) is an element-wise multiplication and \(\sigma(\cdot)\) denotes the softmax function,\hat{f}(\hat{z})=\sum_{k=1}^{K}m_{k}\odot\varphi_{k}(\hat{\mathbf {z}}_{k}),"The variable $\hat{\mathbf{z}}$ represents the inferred latent vector, $\mathbf{m}_{k}$ represents the slot-wise mask, and $\mathbf{\varphi}_{k}$ represents the slot function."
ICLR_2024_oral_64,11,h_{k}(z_{\pi(k)})=\hat{g}_{k}\big{(}f(z)\big{)}\quadand\quadZ^{\prime}=\hat{g}_{1}(X^{S})\times\cdots\times\hat{g}_{K}(X^{S}),,"L_{cons}\big{(}\hat{g},\hat{f},Z^{\prime}\big{)}=E_{z\sim p_{z}}\Big{[}\big{\|}\hat{g}\big{(}\hat{f}(z^{\prime})\big{)}-z^{\prime}\big{\|}_{2}^{2}\Big{]}",where $\mathbf{z}^{\prime}$ is a function of $\mathbf{z}$ defined according to Eq. 5.
ICLR_2024_oral_64,12,"z^{\prime}=\big{(}\hat{z}^{(\rho_{1})}_{1},\ldots,\hat{z}^{(\rho _{K})}_{K}\big{)},\quadwhere for i\in\{1,2\}\quad\hat{z}^{(i)}=\hat{g}\big{(}x^{(i)}\big{)},\,x^{(i)}\sim p_{z}",,"z^{\prime}=\big{(}\hat{z}^{(1)}_{1},\ldots,\hat{z}^{(\rho_{k })}_{k},\ldots,\hat{z}^{(2)}_{K}\big{)}","where \(\hat{\mathbf{z}}^{(i)}=\hat{\mathbf{g}}(\mathbf{x}^{(i)})\) for some \(\mathbf{x}^{(i)}\in\mathcal{X}^{S}\) and \(\rho_{k}\) is uniformly sampled from \(\{1,2\}\)."
ICLR_2024_oral_66,1,"\theta^{*}\:=\\operatorname*{arg\,min}_{\theta}\E_{(x,t,\ell(x,t),\cdot)\simH}\\Big{[}-\log p(\ell(x,t)\mid x,t,\hat{\ell}(x,t;\theta))\Big{]}",,"\hat{\ell}\left(x,t;\theta\right)=E\left[\ell\left(x,t\right)\right]",The probabilistic performance estimator is defined as the expected value of the true performance.
ICLR_2024_oral_66,2,"\gamma^{*}\:=\\operatorname*{arg\,min}_{\gamma}\E_{(x,t,\cdot,c(x,t))\simH}\\Big{[}c(x,t)-\hat{c}(x,t;\gamma)\Big{]}^{2}",,"\gamma^{*}\:=\\operatorname*{arg\,min}_{\gamma}\E_{(x,t, c(x,t))\simH}\\Big{[}\left(c(x,t)-\hat{c}(x,t;\gamma)\right)^{2}\Big{]}",The cost estimator is trained to minimize the mean squared error between predicted and true costs.
ICLR_2024_oral_66,3,"x^{*}:=\operatorname*{arg\,max}_{x\inX}\frac{EI(x,H,\hat{\ell}(x,\tau(x)))}{\hat{c}\Big{(}x,\tau(x)\Big{)}{-}c\Big{(}x,\tau(x)-\Delta t\Big{)}}=\operatorname*{arg\,max}_{x\inX}\frac{E_{\hat{\ell}(x,\tau(x))}[\max(\ell_{\tau(x)}^{\min}-\hat{\ell}(x,\tau(x)),0)]}{\hat{c}\Big{(}x,\tau(x){-}c\Big{(}x,\tau(x){-}\Delta t\Big{)}}",,"\alpha_{EI}(x,t;\theta,\gamma)\:=\\Big(\hat{\ell}(x,t;\theta^{*})-\ell_{best}\Big)\Phi\Big(\frac{\hat{\ell}(x,t;\theta^{*})-\ell_{best}}{\sigma(x,t;\theta^{*})}\Big)+\sigma(x,t;\theta^{*})\phi\Big(\frac{\hat{\ell}(x,t;\theta^{*})-\ell_{best}}{\sigma(x,t;\theta^{*})}\Big)",The acquisition function $\alpha_{\text{EI}}$ balances the expected improvement in performance and the cost of evaluating a pipeline.
ICLR_2024_oral_66,4,"\theta^{(M)} :=\\operatorname*{arg\,min}_{\theta}\E_{(x,t,\ell(x,t,d),c(x,t,d))\simH^{(M)}}\\[-\log p(\ell(x,t,d)\mid x,t,d,\hat{\ell}(x,t,d;\theta))] || \gamma^{(M)} :=\\operatorname*{arg\,min}_{\gamma}\E_{(x,t,\ell(x,t,d),c(x,t,d))\simH^{(M)}}\\(c(x,t,d)-\hat{c}(x,t,d;\gamma))^{2}",,"\theta^{*}\:=\\operatorname*{arg\,min}_{\theta}\E_{(x,t,d,\ell(x,t,d),\cdot)\simH^{(M)}}\\Big{[}-\log p(\ell(x,t,d)\mid x,t,d,\hat{\ell}(x,t,d;\theta))\Big{]}",\(\theta\) represents the parameters of the probabilistic validation error estimator.
ICLR_2024_oral_66,5,"M=\{m^{*}\,|\,m^{*}\in\operatorname*{arg\,max}_{m\inM _{Timm}}[f_{ImageNet}(m),\-S(m)]\}",,f_{ImageNet}(m)=\max_{m\inM_{Timm}} f_{ImageNet}(m)\quadand\quad S(m)=\min_{m\inM_{Timm}} S(m),The equation represents a multi-objective optimization problem to select Pareto optimal models from the timm library based on their Top-1 ImageNet accuracy and model size.
ICLR_2024_oral_68,1,P(v\middo(x))=\prod_{i:v_{i}\notinx}P(v_{i }\midpa_{v_{i}})&if $v$ consistent with $x$\\0&otherwise.,,P(V\middo(X=x))=\prod_{i=1}^{n}P(V_{i}\midPa_{V_{i}})_{{X\subseteqPa_{V_{i}}}}\cdotI(X=x),The probability distribution of a Bayesian network after an intervention.
ICLR_2024_oral_68,2,"P(v_{i}\,|pa_{i};\sigma)=\sum_{v_{i}^{\prime}:f(v_{i}^{\prime})=v_{i}}P(v_ {i}^{\prime}\,|pa_{i})",,P'(v_{i}\midpa_{v_{i}})=\sum_{v'_{i}:f(v'_{i})=v_{i}}P(v'_{i}\midpa_{v'_{i}}),The probability distribution after applying a local intervention to variable $V_{i}$.
ICLR_2024_oral_7,1,"y_{i}=M(x_{i}|\Delta W,W_{0},\theta)",,y_{i}=(W_{0}+BA)x_{i}=W_{0}x_{i}+BAx_{i},The output \(\mathbf{y}_{i}\) is the result of the adapted foundation model for a given input \(\mathbf{x}_{i}\).
ICLR_2024_oral_7,2,y_{i}=\phi(W_{i}^{T}x_{i}) || =\phi\big{(}(W_{0}^{T}\circ\Delta W_{i}^{T})x_{i}\big{)},,x_{i+1}=\sigma(\Delta W_{i}\circ W_{0}\cdot x_{i})=\sigma(B_{i}A_{i}\circ W_{0}\cdot x_{i}),"The equation represents the forward pass in FLORA, where the weight matrix for each example is calculated using element-wise multiplication of the low-rank adaptation and the pre-trained weight matrix."
ICLR_2024_oral_7,3,=\phi\big{(}(W_{0}^{T}\circ(B_{i}A_{i})^{T})x_{i}\big{)},,\Delta W_{i}=B_{i}A_{i},"\(\Delta W_{i}\) represents the low-rank adaptation matrix for each example \(\mathbf{x}_{i}\) in the minibatch, specifically designed for \(\mathbf{x}_{i}\)."
ICLR_2024_oral_7,4,=\phi\Big{(}A_{i}\circ\big{(}W_{0}^{T}(B_{i}\circ x_{i})\big{)}\Big{)},,=\phi\big{(}(W_{0}^{T}\circ(A_{i}^{T}B_{i}^{T}))x_{i}\big{)},"The equation represents the forward pass in FLORA, where the next layer's activations are computed using the example-specific adapter and the pre-trained weight matrix."
ICLR_2024_oral_7,5,Y=\phi\Big{(}A\circ\big{(}(B\circX)W_{0}\big{)}\Big{)},,y=\phi(A\circ (W_{0}^{T}(B\circ x))),"The vectorized equation represents the forward pass for all examples in a minibatch, where y is the output, \(\phi\) is the activation function, \(\mathbf{A}\) and \(\mathbf{B}\) are matrices of example-specific adapters, \(W_{0}\) is the pre-trained weight matrix, and x is the input."
ICLR_2024_oral_7,6,\frac{2c_{1}}{dc_{2}}+\frac{1}{r}\geq 1,,2c_{1}(dblr)+c_{2}(bld^{2}) > c_{2}(rbld^{2}),"The inequality represents the comparison of computational costs between the baseline LoRA and the proposed fLoRA, where the left-hand side denotes the cost of LoRA and the right-hand side denotes the cost of fLoRA."
ICLR_2024_oral_73,1,\tilde{x}_{i}=\frac{\mu_{k}+\varepsilon\eta}{\sqrt{1+\varepsilon^{2}}},where \(\eta\) is drawn from the same distribution as the \(\mu_{k}\)'s and \(\varepsilon\) sets the within-class variability,\tilde{x}_{i}=\mu_{k}+\epsilon,The content of item \(x_{i}\) is given by the vector \(\mu_{k}\) plus some noise \(\epsilon\).
ICLR_2024_oral_73,2,"v_{i}=u_{i}+V_{1}\sum_{j\leq i}p_{ij}^{(1)}u_{j},\quad w_{i}=v_{i}+V_{2}\sum_{ j\leq i}p_{ij}^{(2)}v_{j} || p_{ij}^{(\mu)}=\frac{e^{(K_{\mu}u_{j})^{T}(Q_{\mu}u_{i})}}{\sum_{k\leq i}e^{(K _{\mu}u_{k})^{T}(Q_{\mu}u_{i})}}","where

\[p_{ij}^{(\mu)}=\frac{e^{(K_{\mu}u_{j})^{T}(Q_{\mu}u_{i})}}{\sum_{k\leq i}e^{(K _{\mu}u_{k})^{T}(Q_{\mu}u_{i})}} \tag{3}\]

is the attention paid by query \(i\) on key \(j\) in the \(\mu\)th layer","v_{i}=\sum_{j=1}^{i}\frac{\exp(\frac{q_{i}\cdot k_{j}}{\sqrt{d}})}{\sum_{j'=1}^{i}\exp(\frac{q_{i}\cdot k_{j'}}{\sqrt{d}})} v_{j},\quad w_{i}=\sum_{j=1}^{i}\frac{\exp(\frac{q'_{i}\cdot k'_{j}}{\sqrt{d}})}{\sum_{j'=1}^{i}\exp(\frac{q'_{i}\cdot k'_{j'}}{\sqrt{d}})} w_{j}","where \(q_{i}\), \(k_{j}\), \(v_{j}\), \(q'_{i}\), \(k'_{j}\), and \(w_{j}\) represent the query, key, value, and other attention weights and outputs at different layers."
ICLR_2024_oral_73,3,"v_{i}^{(b)}=\sum_{j\leq i}q_{ij}^{(1)}u_{j}^{(c)},\quad v_{i}^{(c )}=u_{i}^{(c)} || w_{i}^{(b)}=\sum_{j\leq i}q_{ij}^{(2)}v_{j}^{(c)},\quad w_{i}^{( c)}=v_{i}^{(c)}",,"u_{i}^{(c)}=u_{i}^{(c)}+\alpha\sum_{j\leq i}p_{ij}^{(1)}u_{j}^{(c)},\quad u_{i}^{(b)}=\beta\sum_{j\leq i}p_{ij}^{(1)}u_{j}^{(c)},\quad u_{i}^{(c)}=u_{i}^{(c)}+\gamma\sum_{j\leq i}p_{ij}^{(2)}u_{j}^{(b)}","The equation represents the computations of a minimal three-parameter model of a two-layer induction head, where \(\alpha\), \(\beta\), and \(\gamma\) are parameters that control the strength of the content, buffer, and output computations, respectively."
ICLR_2024_oral_73,4,"q_{ij}^{(1)}=\frac{e^{\beta_{1}\delta_{i-1,j}}}{\sum_{k\leq i}e^{\beta_{1}\delta_ {i-1,k}}},\quad q_{ij}^{(2)}=\frac{e^{\alpha v_{j}^{(k)},v_{i}^{(c)}+\beta_{2}\Delta_{i,j}}}{\sum_{k\leq i}e^{\alpha v_{k}^{(k)},v_{i}^{(c)}+\beta_{2}\Delta_ {i,k}}}",,q_{ij}^{(\mu)}=\frac{e^{(K_{\mu}u_{j})^{T}(Q_{\mu}u_{i})}}{\sum_{k\leq i}e^{(K _{\mu}u_{k})^{T}(Q_{\mu}u_{i})}},The attention paid by query \(i\) on key \(j\) in the \(\mu\)th layer
ICLR_2024_oral_74,1,\partial_{k}|s_{k}\rangle=\sum_{l=0}^{k-1}(-1)^{l}|s_{k-1}(l)\rangle,where \(\left|s_{k-1}(l)\right\rangle\) is the _lower_ simplex obtained by leaving out vertex \(l\) (i,"\partial_{k}\left|s_{k}\right\rangle=\sum_{i=0}^{k}(-1)^{i}\left|\{j_{0},\ldots,j_{i-1},j_{i+1},\ldots,j_{k}\}\right\rangle",The boundary map operator \(\partial_{k}\) acts on a \(k\)-simplex \(s_{k}\) to produce a linear combination of \((k-1)\)-simplices.
ICLR_2024_oral_74,2,\beta_{k}:=\dim\ker(\Delta_{k}),,\beta_{k}=\dim\ker(\Delta_{k}),The kth Betti number is the dimension of the kernel of the combinatorial Laplacian.
ICLR_2024_oral_74,3,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|\leq\epsilon,"where \(|S_{k}|\) is the the number of \(k\)-simplices \(S_{k}\in\Gamma\) or \(\dim\tilde{\mathcal{H}}_{k}\), the dimension of the Hilbert space spanned by the set of \(k\)-simplices in the complex",\left|\chi_{k}-\frac{\beta_{k}}{n}\right|\leq\epsilon,"The equation represents the problem of normalized Betti number estimation, where the goal is to find a value that approximates the ratio of the Betti number to the total number of points, within a certain error tolerance and confidence level."
ICLR_2024_oral_74,4,"\rank(\Delta_{k})\stackrel{{\tiny{def}}}{{=}}\trace(h(\tilde{\Delta}_{k})), where h(x)=\{{ll}1& if \x>\delta\\0& otherwise",,\tilde{\Delta}_{k}=\frac{1}{n}\Delta_{k},The normalized Laplacian operator for the k-dimensional simplices.
ICLR_2024_oral_74,5,n_{v}=O(\frac{\log(1/\eta)}{\epsilon^{2}})\qquad\qquadand\qquad\qquad m>\frac{\log(1/\epsilon)}{\sqrt{\delta}},,\chi_{k}=1-\frac{1}{n_{v}}\sum_{l=1}^{n_{v}}\left[\sum_{j=0}^{m}c_{j}\theta_{l}^{(j)}\right],The equation represents the estimation of the normalized Betti number $\chi_{k}$ using the stochastic Chebyshev method in the NISQ-TDA algorithm.
ICLR_2024_oral_74,6,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|\leq\epsilon,,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|\leq\epsilon,The equation represents the condition for the estimated Betti number $\chi_{k}$ to be within a certain error bound $\epsilon$ of the true normalized Betti number $\frac{\beta_{k}}{|S_{k}|}$ with a probability of at least $1-\eta$.
ICLR_2024_oral_74,7,"O(\frac{1}{\epsilon^{2}}\max\{\frac{n\log(1/\epsilon)}{\sqrt{\delta} },\frac{n}{\zeta_{k}}\})",,O(\frac{n^{3}\log^{3}(1/\epsilon)}{\delta^{3/2}\epsilon^{2}}),"The time complexity of the NISQ-TDA algorithm is given by the product of the number of iterations, the complexity of preparing the random Hadamard state, and the complexity of implementing the quantum circuit for the Laplacian operator."
ICLR_2024_oral_82,1,LayerNorm(x)=\frac{x-E[x]}{\sqrt {Var[x]+\epsilon}}\odot\gamma+\beta,,x_{norm}=\frac{x-\mu}{\sigma},"The equation represents LayerNorm, where \(\mathbf{x}_{\text{norm}}\) is the normalized activation, \(\mu\) is the mean, and \(\sigma\) is the standard deviation of the input \(\mathbf{x}\)."
ICLR_2024_oral_82,2,{BiasNorm}(x)=\frac{x}{RMS[x-b]}\cdot\exp(\gamma),"where \(\mathbf{b}\) is the learnable channel-wise bias, \(\mathrm{RMS}[\mathbf{x}-\mathbf{b}]\) is the root-mean-square value taken over channels, and \(\gamma\) is a scalar",BiasNorm(x)=x+\beta,BiasNorm is a simplified normalization technique that adds a learnable bias term to the input vector.
ICLR_2024_oral_82,3,Swish(x)=x\cdot(1+\exp(-x))^{-1},,Swish(x)=x\cdot\sigma(x),where \(\sigma(\mathbf{x})\) is the sigmoid function
ICLR_2024_oral_82,4,"\textit{SwooshR}(x)&=\log(1+\exp(x-1))-0.08x-0.313261687,\\\textit{SwooshL}(x)&=\log(1+\exp(x-4))-0.08x-0.035",,"SwooshR(x)=x\cdot(1+\exp(-x))^ {-1}\cdotsigmoid(x),SwooshL(x)=x\cdot(1+\exp(-x))^{-1}\cdottanh(x)","The SwooshR and SwooshL activation functions are proposed as replacements for the Swish activation function, incorporating sigmoid and tanh functions, respectively."
ICLR_2024_oral_82,5,\Delta_{t}=-\alpha_{t}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon},"where \(\alpha_{t}\) is the learning rate typically specified by an external schedule, \(\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{2}}\) is the bias-correction term, and \(\epsilon=10^{-8}\)",\Delta_{t}=\frac{m_{t}}{\sqrt{v_{t}}+\epsilon}\cdot\alpha,where \(\alpha\) is the learning rate and \(\epsilon\) is a small value for numerical stability.
ICLR_2024_oral_82,6,\Delta^{\prime}_{t}=-\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^ {2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon},,\Delta_{t}=-\alpha_{t}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon}\cdot r_{t-1},where \(r_{t-1}\) is the parameter scale at step \(t-1\).
ICLR_2024_oral_82,7,"\Delta^{\prime}_{t,r}&=-\eta\cdot\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{2}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\odot\theta^{\prime}_{t-1}\\&=-\eta\cdot\alpha_{t}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta _{1}^{t}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\odot\theta_{t-1}","where \(\eta\) is a scaling factor on learning rate \(\alpha_{t}\), and we found that setting \(\eta=0","\Delta^{\prime}_{t,r}=(r_{t}-r_{t-1})\odot\theta^{\prime}_{t-1}=(r_{t}-r_{t-1})\odot\frac{\theta_{t-1}}{r_{t-1}}","where \(r_{t}\) is the parameter scale at step \(t\), \(\mathbf{\theta}^{\prime}_{t-1}\) is the underlying parameter at step \(t-1\), and \(\mathbf{\theta}_{t-1}\) is the parameter at step \(t-1\)."
ICLR_2024_oral_82,8,"\alpha_{t}=\alpha_{base}\cdot(\frac{t^{2}+\alpha_{step }^{2}}{\alpha_{step}^{2}})^{-0.25}\cdot(\frac{e^{2}+\alpha_{epoch}^{2}}{\alpha_{epoch}^{2}})^{-0.25}\cdotlinear(\alpha_{start},t_{warmup},t)",,\alpha_{t}=\alpha_{0}\cdot\frac{1}{1+\gamma\cdot t},where \(\alpha_{0}\) is the initial learning rate and \(\gamma\) is a hyperparameter controlling the decay rate.
ICML_2024_oral_1,1,"J(\pi)=\sum_{t=0}^{\infty}E_{(s_{t},a_{t})\sim\rho (\pi)}[\gamma^{t}(r(s_{t},a_{t})+\alphaH(\pi(\cdot|s_{t})))]",,"Q^{\pi}(s,a)=E[\sum_{t=0}^{\infty}\gamma^{t}R(s_{t},a_{t})]",The action-value function Q represents the expected return when taking action a in state s and following policy π thereafter.
ICML_2024_oral_1,2,"r_{t}=r_{M}(B_{s\to r|a}\odots_{t},B_{a\to r|s}\odota_{t},\epsilon_{t})","where \(\mathbf{B}_{\mathbf{s}\to r|\mathbf{a}}\in\mathbb{R}^{\mathrm{dim} \mathcal{S}\times 1}\) and \(\mathbf{B}_{\mathbf{a}\to r|\mathbf{s}}\in\mathbb{R}^{\mathrm{dim}\mathcal{A} \times 1}\) are vectors that represent the graph structure 1 from \(\mathbf{s}_{t}\) to \(r_{t}\) given \(\mathbf{a}_{t}\) and from \(\mathbf{a}_{t}\) to \(r_{t}\) given \(\mathbf{s}_{t}\), respectively","r_{t}=f(s_{t},a_{t},c_{t})","The reward function r_t is a function of the current state \mathbf{s}_t, action \mathbf{a}_t, and causal variables \mathbf{c}_t."
ICML_2024_oral_1,3,"H_{c}(\pi(\cdot|s))&=-E_{a\inA}[\sum_{i=1}^{\dimA}B_{a_{i}\to r|s}\pi(a_{i}|s)\log\pi(a_{i}|s)],\\&a=(a_{1},\ldots,a_{\dimA})",,H_{c}(\pi(\cdot|s_{t}))=-\sum_{i=1}^{dimA}B_{a\to r|s}[i]\cdot\pi(a_{i}|s_{t})\log\pi(a_{i}|s_{t}),The causality-aware entropy \(\mathcal{H}_{c}\) incorporates the causal weights \(\mathbf{B}_{\mathbf{a}\to r|\mathbf{s}}\) to prioritize actions with higher causal influence on the reward.
ICML_2024_oral_1,4,"T_{c}^{\pi}Q(s_{t},a_{t })\triangleq& r(s_{t},a_{t})+\gammaE_{s_{t+1}\sim P}[E_{a_{t}\sim\pi}[Q(s_{t+1},a_{t+1})\\&+\alphaH_{c}(\pi(a_{t+1}|s_{t+1}))]]",,"Q^{\pi}(s,a)=T_{c}^{\pi}Q^{\pi}(s,a)=r(s,a)+\gammaE_{s'\sim p(\cdot|s,a)}[H_{c}(\pi(\cdot|s'))+E_{a'\sim\pi(\cdot|s')}[Q^{\pi}(s',a')]]",The Q-value for a fixed policy π could be computed iteratively by applying a modified Bellman operator with the causality-aware entropy term.
ICML_2024_oral_1,5,\frac{n_{i}^{l}(x)}{\frac{1}{N^{l}}\sum_{k\in l}n_{k}^{l}}\leq\tau,where \(\tau\) is a constant serving as a threshold to determine the gradient dormancy of neurons in each layer,n_{i}^{l}=\left\lVert\frac{\partialL}{\partialw_{i}^{l}}\right\rVert_{2}<\delta,where \(\delta\) is a small positive value.
ICML_2024_oral_1,6,\alpha_{\tau}=\frac{\sum_{l\in\phi}N_{\tau}^{l}}{\sum_{l\in\phi}N^{l}},,\alpha_{\tau}=\frac{1}{L}\sum_{l=1}^{L}\frac{N_{\tau}^{l}}{N^{l}},"where \(L\) is the total number of layers, and \(N^{l}\) is the number of neurons in layer \(l\)."
ICML_2024_oral_1,7,"\theta_{t}=(1-\eta)\theta_{t-1}+\eta\phi_{i},\\phi_{i}\siminitializer",,\theta_{new}=\theta_{old}+\eta\cdotPerturbation,The reset factor $\eta$ controls the magnitude of weight resetting to mitigate gradient dormancy.
ICML_2024_oral_10,1,"attention(Q,K,V)=softmax(QK)^{T}/\sqrt{d})V",,"Attention(Q, K, V)=\softmax\left(\frac{QK^T}{\sqrt{d}}\right)V",The attention function computes a weighted sum of the value vectors V based on the query vectors Q and key vectors K.
ICML_2024_oral_10,2,"d\hat{x}_{t}=f(\hat{x}_{t},t)dt+g(t)dw",,"dx=f(x, t)dt+g(x, t)dw","The variable \(\mathbf{x}\) represents the data, \(\mathbf{f}(\mathbf{x}, t)\) is the drift coefficient, \(\mathbf{g}(\mathbf{x}, t)\) is the diffusion coefficient, and \(d\mathbf{w}\) is the increment of a Wiener process."
ICML_2024_oral_10,3,"d\hat{x}_{t}=[f(\hat{x}_{t},t)-g(t)^{2}s(\hat{x}_{t},t) ]dt+g(t)d\tilde{w}",where \(\mathbf{\tilde{w}}\) is a backward-in-time Wiener process,p_{0}(\hat{x}_{0})=p(\hat{x}),The initial data distribution of the diffusion process.
ICML_2024_oral_10,4,"L(\phi)=E_{t,\hat{x}_{0},\hat{x}_{t}}[\lambda (t)\|s_{\phi}(\hat{x}_{t},t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t}|\hat{x}_{0})\|_{2}^{2}]",where \(\lambda\) denotes a positive weighting function,"E_{t\simU(0,T),\hat{x}_{0}\sim p_{0},\hat{x}_{t}\sim p_{t}(\hat{x}_{t}|\hat{x}_{0})}\left[\left\|s_{\phi}(\hat{x}_{t},t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t}|\hat{x}_{0})\right\|^{2}\right]","The loss function to train the score model \(s_{\phi}(\mathbf{\hat{x}}_{t},t)\) to estimate the score function \(s(\mathbf{\hat{x}}_{t},t)\) at each step of the reverse diffusion process."
ICML_2024_oral_10,5,"\ell(\phi,M_{C},t,\hat{x}_{0},\hat{x}_{t})=\\(1-M_{C})\cdot(s_{\phi}^{M_{E}}(\hat{x}_{t}^{Mc}, t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t}|\hat{x}_{0}))",where \(s_{\phi}^{M_{E}}\) denotes the score model equipped with a specific attention mask \(M_{E}\),"L(\phi)=E_{t,\hat{x}_{0},\hat{x}_{t},M_{C}}[\lambda(t)\|s_{\phi}(\hat{x}_{t}^{M_{C}},t)-\nabla_{\hat{x}_{t}^{M_{C}}}\log p_{t}(\hat{x}_{t}^{M_{C}}|\hat{x}_{0})\|_{2}^{2}]","The loss function for training the Simformer, which uses denoising score-matching to learn the score function of the diffusion model."
ICML_2024_oral_10,6,"L(\phi)=E_{M_{C},t,\hat{x}_{0},\hat{x}_{ t}}[\|\ell(\phi,M_{C},t,\hat{x}_{0},\hat{x}_{t})\|_{2}^{2}]",,"L(\phi)=E_{t,\hat{x}_{0},\hat{x}_{t},M_{C}}[\ell(\phi,M_{C},t,\hat{x}_{0},\hat{x}_{t})]","The loss function for training the Simformer, which is the expected value of the loss across noise levels and data."
ICML_2024_oral_10,7,"s(\hat{x}_{t},t|y)\approx s_{\phi}(\hat{x}_{t},t)+\nabla_{\hat{x}_{t}}\log p_{t}(y|\hat{x}_{t})",,"s_{\phi}^{M_{E}}(\hat{x}_{t},t;y)=s_{\phi}^{M_{E}}(\hat{x}_{t},t)+\lambda_{g}(t)\nabla_{\hat{x}_{t}}\log p(\hat{x}_{t}|y)",where \(\lambda_{g}(t)\) is a guidance weight that controls the strength of the guidance at each noise level \(t\).
ICML_2024_oral_10,8,"s_{\phi}(\hat{x}_{t},t|c)\approx s_{\phi}(\hat{x}_{t},t)+\nabla_{\hat{x}_{t}}\log\sigma(-s(t)c(\hat{x}_{t}))",,"s(\hat{x}_{t},t|y)\approx s_{\phi}(\hat{x}_{t},t)+\nabla_{\hat{x}_{t}}\log p_{t}(y|\hat{x}_{t})",The score model is guided by an additional context to sample from the generative model with the given context.
ICML_2024_oral_101,1,"G(z)=\sum_{j_{1}=0}^{d-1}\cdots\sum_{j_{n}=0}^{d-1}p(j_{1},\ldots,j_{n})z_{1}^ {j_{1}}\cdots z_{n}^{j_{n}}",,"p(z_{1},\ldots,z_{n})=\sum_{a_{1},\ldots,a_{n}}\Pr[X_{1}=a_{1},\ldots,X_{n}=a_{n}]z_{1}^{a_{1}}\cdots z_{n}^{a_{n}}","The probability generating function p is a formal polynomial in variables \(z_{1},\ldots,z_{n}\) that encodes the joint distribution of categorical variables \(X_{1},\ldots,X_{n}\)."
ICML_2024_oral_101,2,"f(V_{1},...,V_{n},E_{1,N(1,1)},...,E_{n,N(n,3)})=\prod_{i=1}^{n}\sum_{j\in N(i )}E_{i,j}V_{j}",,"f=\prod_{i=1}^{n} (V_{N(i,1)}+V_{N(i,2)}+V_{N(i,3)})","The polynomial f is defined as the product of terms, each corresponding to a vertex in U, where each term is the sum of the formal variables corresponding to the neighbors of the vertex."
ICML_2024_oral_101,3,"\Pr[V_{1}=1,\ldots,V_{n}=1]=h(1,\ldots,1)=\frac{\#PM(G)}{3^{n}}",,"\[h(E_{1,N(1,1)},...,E_{n,N(n,3)})=\sum_{M\inPM(G)}\prod_{(u_i, v_j)\in M} E_{i,j}\]","The equation represents the coefficient of $V_{1}V_{2}\ldots V_{n}$ in the polynomial $\hat{f}$, which corresponds to the number of perfect matchings in the graph $G$."
ICML_2024_oral_101,4,"f(z_{1},...,z_{n})=\sum_{s=(s_{1},\ldots,s_{n})\in\{0,1,\ldots,k-1\}^{n}}c_{s}\cdot\prod_{i=1}^{n}z_{i}^{s_{i}}",,"f(z_{1},\ldots,z_{n})=\sum_{j_{1}=0}^{k-1}\cdots\sum_{j_{n}=0}^{k-1}p(j_{1},\ldots,j_{n})z_{1}^{j_{1}}\cdots z_{n}^{j_{n}}",The probability generating polynomial for k-nary random variables.
ICML_2024_oral_101,5,"g(x_{1},\overline{x_{1}},...,x_{n},\overline{x_{n}})=f(\frac{x_{1}}{\overline{ x_{1}}},\frac{x_{2}}{\overline{x_{2}}},...,\frac{x_{n}}{\overline{x_{n}}})\cdot\prod_{i=1}^{n}\overline{x_{i}}",,"g(x_{1},...,x_{n})=f(1+x_{1},...,1+x_{n})",The polynomial g is defined in terms of the probability generating function f.
ICML_2024_oral_101,6,m^{\prime}=c_{S}\cdot(\prod_{i\in S}\frac{x_{i}}{\overline{x_{i}}})\cdot(\prod _{j=1}^{n}\overline{x_{j}})=c_{S}(\prod_{i\in S}x_{i})\cdot(\prod_{i\notin S}\overline{x_{i}}),,"g(x_{1},\overline{x_{1}},...,x_{n},\overline{x_{n}})=f(\frac{x_{1}}{\overline{x_{1}}},\frac{x_{2}}{\overline{x_{2}}},...,\frac{x_{n}}{\overline{x_{n}}})\cdot\prod_{i=1}^{n}\overline{x_{i}}","The polynomial g is defined in terms of the probability generating function f of n binary random variables, transformed to take into account the division gates and the product of the complemented variables."
ICML_2024_oral_101,7,"& f(x_{1}(1+\overline{x_{1}}),x_{2}(1+\overline{x _{2}}))\cdot(1-\overline{x_{1}})(1-\overline{x_{2}})\\&=(0.6x_{1}x_{2}(1+\overline{x_{1}})(1+\overline{x_{2}})\\&\quad+0.4x_{1}(1+\overline{x_{1}}))(1-\overline{x_{1}})(1-\overline{x_{2}})\\&=0.6x_{1}x_{2}+0.4x_{1}(1-\overline{x_{2}})\+\higher degree terms",,"\Pr[V_{1}=1,\ldots,V_{n}=1]=h(1,\ldots,1)=\frac{\#PM(G)}{3^{n}}","The equation represents the probability of all variables V being equal to 1, which is equivalent to the number of perfect matchings in graph G divided by 3 to the power of n."
ICML_2024_oral_101,8,"P=\sum_{j_{1}=0}^{d-1}\cdots\sum_{j_{n}=0}^{d-1}\Pr[X_{1}=j_{1},\ldots,X_{n}=j _{n}]z_{1,j_{1}}\cdots z_{n,j_{n}}",,"\Pr[X_{1}\in A_{1},\ldots,X_{n}\in A_{n}]=P(v_{1},\ldots,v_{n})",where $v_{i}$ is the unit vector with $1$ in the $\delta$th coordinate if $\delta\in A_{i}$ and $0$ otherwise.
ICML_2024_oral_101,9,"e_{i,j}=1&if $j=a_{i$},\\0&otherwise",,"\Pr[X_{1}\in A_{1},\ldots, X_{n}\in A_{n}]=\sum_{j_{1}\in A_{1}}\cdots\sum_{j_{n}\in A_{n}}\Pr[X_{1}=j_{1},\ldots, X_{n}=j_{n}]",The probability of the joint event where each variable is in its respective set.
ICML_2024_oral_101,10,"v_{i,j}=1&if $j\in A_{i$},\\0&otherwise",,"P(e_{A_{1},\ldots,A_{n}})",The probability of the event where each variable is in the corresponding set.
ICML_2024_oral_101,11,"P(v)=\sum_{j_{1}\in A_{1}}\cdots\sum_{j_{n}\in A_{n}}\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}]\cdot 1 || =\Pr[X_{1}\in A_{1},\ldots,X_{n}\in A_{n}]",,"\Pr[X_{1}\in A_{1},\ldots,X_{n}\in A_{n}]=\sum_{j_{1}\in A_{1},\ldots,j_{n}\in A_{n}}\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}]=P(v)",Equation 11 represents the probability of multiple categorical random variables taking on specific values within given sets.
ICML_2024_oral_101,12,"f(a)=\sum_{a\in\Delta^{|A|}}\alpha_{a}\prod_{i\in A}z_{i,a_{i}},\quad g(b)=\sum_{b\in\Delta^{|B|}}\beta_{b}\prod_{j\in B}z_{j,b_{j}}",where \(\alpha_{a}=\Pr[X_{A}=a]\) and \(\beta_{b}=\Pr[X_{b}=b]\),"\Pr[X_{A}=a,X_{B}=b]=f(1_{a})g(1_{b})",where \(\mathbf{1}_{a}\) is the unit vector with \(1\) at position \(a\) and \(0\) elsewhere.
ICML_2024_oral_101,13,"f(a,b^{\prime})= || (\sum_{a\in\Delta^{|A|}}\alpha_{a}\prod_{i\in A}z_{i,a_{i}} )\prod_{j\in B\setminus A}\frac{1}{d}(z_{j,0}+\cdots+z_{j,d-1})",,"\Pr[X_{A\cup B}=(a,b)]=\alpha_{a}\beta_{b}\quadfor all $a\in\Delta^{|A|$ and $b\in\Delta^{|B|}$}",where $\alpha_{a}=\Pr[X_{A}=a]$ and $\beta_{b}=\Pr[X_{B}=b]$
ICML_2024_oral_104,1,call-count(u)=\sum_{v\in Q(u)}(1+call-count(v)),,r(u)=1+\sum_{v\in Q(u)} r(v),The recursive call count of a node u equals 1 plus the sum of the recursive call counts of its queried neighbors.
ICML_2024_oral_104,2,\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots || \leq\sigma(u_{L-1})\leq\pi(u_{L-1})\leq\sigma(u_{L})\leq\pi(u_{L}),,"\pi(u_{i-1}) <\sigma(u_{i})\quadfor all  i\in\{1,\ldots, L\}","The equation represents the condition for a path to be a query path, where each node's settlement iteration is greater than its previous node's rank."
ICML_2024_oral_104,3,"\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots || \leq\sigma(u_{L-2})\leq\pi(u_{L-2})\leq\min(\sigma(u_{L-1}),\sigma (u_{L}))",,\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots\leq\sigma(u_{L-2})\leq\pi(u_{L-2})\leq\sigma(u_{L-1})\leq\sigma(u_{L})\leq\pi(u_{L}),A path is an extended query path if and only if it satisfies the given inequalities relating the settlement and processing times of its nodes.
ICML_2024_oral_104,4,\sigma(u_{0})<\sigma(u_{1}) and\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq || \cdots\leq\pi(u_{L-2})\leq\sigma(u_{L-1})=\sigma(u_{L}),,"\sigma(u_{0})<\sigma(u_{1})\leq\pi(u_{1})\leq\ldots\leq\sigma(u_{L-2})\leq\pi(u_{L-2})\leq\min(\sigma(u_{L-1}),\sigma(u_{L}))=\sigma(u_{L-1})=\sigma(u_{L})",The equation represents the condition for an extended query path to be expensive.
ICML_2024_oral_104,5,"E_{\pi}|X|\leq 2E\Big{[}\sum_{(u,v)\in E}1 (\sigma(u)\neq\sigma(v))\Big{]}",,E_{\pi}|X|\leq 4OPT,The expected number of expensive extended query paths is at most 4 times the expected number of edges cut by the Pivot algorithm.
ICML_2024_oral_104,6,"\Phi_{t}(a,b)=2|D_{t}(a,b)|+|Q_{t}(a,b)| || \Psi_{t}(a,b)=2|D_{t}(a,b)|+|X_{t}(a,b)|",,"E_{\pi}|Q(a,b)|\leq 2","The expected number of query paths starting with a fixed directed edge (a, b) is at most 2."
ICML_2024_oral_106,1,"p(u)=\prod_{i=1}^{n}p(u_{i}|u_{1},...,u_{i-1},\Theta)",,"p(u_{i} | u_{1}, ..., u_{i-1};\theta)",The probability of the next word in a corpus given the previous words and model parameters.
ICML_2024_oral_106,2,L=-log\;p(u),,"L(\Theta)=-\sum_{i=1}^{n}\log p(u_{i}|u_{1},...,u_{i-1},\Theta)",The loss function \(\mathcal{L}(\Theta)\) represents the negative log-likelihood of the target words given the model parameters \(\Theta\).
ICML_2024_oral_106,3,"p(x)=\prod_{i=1}^{n}p(x_{i}|x_{1},...,x_{i-1},\Theta)",,"p(X)=\prod_{i=1}^{n}p(x_{i}|x_{1},...,x_{i-1},\Theta)",The probability of each pixel in the image sequence is conditioned on all previous pixels.
ICML_2024_oral_106,4,L=-log\;p(x),,L=-log\;p(x),"The loss function for iGPT, which is the negative log-likelihood of the pixel sequence."
ICML_2024_oral_106,5,"p(s)=\prod_{i=1}^{n}p(s_{i}|s_{1},...,s_{i-1},\Theta)",,"p(s)=\prod_{i=1}^{n}p(s_{i}|s_{1},...,s_{i-1},\Theta)",The autoregressive probability of each cluster $s_{i}$ based on the preceding clusters in the sequence.
ICML_2024_oral_106,6,"L_{G}=-\sum_{i=1}^{n}cosine(G(f(x_{s_{1}:s_{i-1}});\theta_{G}),f_{\phi }(x)_{s_{i}})","where \(f(\cdot)\) is the encoder, \(f_{\phi}(x)_{s_{i}}\) is the semantically enriched tokens corresponding to the cluster \(s_{i}\), \(G(\cdot;\ \theta_{G})\) is the generative decoder for autoregressive prediction, and \(cosine\) is the cosine similarity loss","p(z)=\prod_{i=1}^{n}p(z_{i}|z_{1},...,z_{i-1},\Theta)","The probability of each semantic token $z_{i}$ is conditioned on all previous tokens $z_{1},...,z_{i-1}$ and model parameters $\Theta$."
ICML_2024_oral_106,7,"L_{D}=-\sum_{i=1}^{n}cosine(D(f(x_{s_{1}:s_{i-1}});\theta_{D}),f_{\phi}(x)_{s_{1}:s_{i-1}})","where \(D(\cdot;\ \theta_{D})\) is the discriminative decoder, tasked with predicting the semantic tokens of visible pixels","L_{V}=-\sum_{i=1}^{n}\log p(s_{\pi(i)}|s_{\pi(1)},...,s_{\pi(i-1)},\Theta)","where \(\mathcal{L}_{V}\) represents the loss function for visible clusters, \(s_{\pi(i)}\) denotes the \(i\)-th cluster in the permuted sequence, and \(\Theta\) symbolizes the model parameters."
ICML_2024_oral_107,1,"L_{eval}=-\log p_{M}(<\)cc\(>\)\(|X_{l},X_{r})",,L_{eval}=-\sum_{i} y_i\log(p_i)+(1-y_i)\log(1-p_i),"\(\mathcal{L}_{eval}\) represents the cross-entropy loss for self-assessment, where \(y_i\) is the true label and \(p_i\) is the predicted probability."
ICML_2024_oral_107,2,"L_{gen}=-\log p_{M}(Y|X_{l},X_{r},CC),& if label\\-\log p_{M}(Y|X_{l},X_{r}),&otherwise",,"L_{gen}=-\sum_{t=1}^{n}\log p_{M}(y_t|X_{l},X_{r},y_{<t},CC)","\(\mathcal{L}_{gen}\) represents the cross-entropy loss for code generation, where \(y_t\) denotes the t-th token in the target sequence, \(y_{<t}\) denotes the previous tokens, and \(CC\) denotes the retrieved context."
ICML_2024_oral_107,3,"ES(\hat{Y},Y)=\frac{1-Lev(\hat{Y},Y)}{\max(|\hat{Y}|,|Y|)}",where \(Lev\) is the Levenshtein distance (Levenshtein et al,"ES(\hat{Y}, Y)=1-\frac{ED(\hat{Y}, Y)}{\max\{|\hat{Y}|, |Y|\}}","The edit similarity ES measures the similarity between the generated code \(\hat{Y}\) and the reference code \(Y\), where ED denotes the edit distance and \(|\hat{Y}|\) and \(|Y|\) denote the lengths of \(\hat{Y}\) and \(Y\) respectively."
ICML_2024_oral_109,1,"\operatorname*{arg\,max}_{k=1,\dots,K}\,\cos(\phi(x),\psi(t_{k}))",,"\arg\max_{k=1,\dots,K}\frac{\phi(x)\cdot\psi(t_k)}{\|\phi(x)\|\|\psi(t_k)\|}","The equation represents the zero-shot classification process using CLIP, where the class with the highest cosine similarity between the image embedding and text prompt embedding is chosen."
ICML_2024_oral_109,2,"f_{k}(\phi,x)=\cos(\phi(x),\psi(t_{k}))=\langle\frac{\phi(x)}{\|\phi (x)\|_{2}},\frac{\psi(t_{k})}{\|\psi(t_{k})\|_{2}}\rangle",,"f(x)=\psi(t_{1}),\dots,\psi(t_{K})\cdot\phi(x)","The function f represents a classifier defined by the image embedding function phi, where the logits are computed as the dot product of the text embeddings of the class prompts and the image embedding."
ICML_2024_oral_109,3,"\operatorname*{arg\,max}_{k=1,\dots,K}\,f_{k}(\phi,z)\neq y,\quad\|z-x\|_{p}\leq\varepsilon,\quad z\in I",where \(\varepsilon\) is the perturbation size,"\|z-x\|_{p}\leq\epsilon\quadand\quad f(\phi,z)\neq y","The equation represents the condition for an adversarial image z in the ℓp-norm threat model, where z is within a certain distance ε from the original image x and is misclassified by the classifier f(ϕ,⋅)."
ICML_2024_oral_109,4,"L_{TeCoA}(y,f(\phi,x))=-\log(\frac{e^{f_{y}(\phi,x)}}{\sum_{k=1}^ {K}e^{f_{k}(\phi,x)}})",,"\min_{\phi}\,E_{(x,y)\simD}\,\max_{\|z-x\|_{\infty}\leq\varepsilon}\,\ell(\phi,z,y)","The training objective of TeCoA, a text-guided contrastive adversarial training approach, which minimizes the expected loss over the data distribution with respect to the vision encoder, while maximizing the loss over the adversarial examples within the allowed perturbation size."
ICML_2024_oral_109,5,"\phi_{FT}=\operatorname*{arg\,min}_{\phi}\sum_{i=1}^{n}\max_{\|z-x_{i}\|_{\infty}\leq\varepsilon}L_{TeCoA}(y_{i},f(\phi,z))",where the inner problem is approximately solved with projected gradient descent (PGD) during training and \(\phi_{\mathrm{FT}}\) indicates the weights of the robust CLIP vision encoder,"\min_{\phi}\max_{\|\delta\|_{\infty}\leq\varepsilon}\frac{1}{n}\sum_{i=1}^{n}L_{TeCoA}(y_{i},f(\phi,x_{i}+\delta))","The equation represents the adversarial training formulation for the TeCoA approach, where the goal is to minimize the loss over the training set while maximizing the loss over all possible adversarial perturbations within the given epsilon bound."
ICML_2024_oral_109,6,"L_{FARE}(\phi,x)=\max_{\|z-x\|_{\infty}\leq\varepsilon}\|\phi(z)-\phi_{Org}(x)\|_{2}^{2}",,"L_{emb}(\phi,x)=\|\phi(x)-\phi_{Org}(x)\|_{2}^{2}",The embedding loss measures the difference between the original and fine-tuned embeddings.
ICML_2024_oral_109,7,"\phi_{FT}=\operatorname*{arg\,min}_{\phi}\sum_{i=1}^{n}L_{ FARE}(\phi,x_{i})",,"\min_{\phi}\sum_{i=1}^{n}L_{FARE}(\phi,x_{i})",The fine-tuning scheme optimizes the embedding loss over a set of images to make the vision encoder robust to adversarial attacks while preserving its output on clean points.
ICML_2024_oral_109,8,"|\cos(\phi_{FT}(x),\psi(t))-\cos(\phi_{Org},\psi(t))| || \leq\min(\frac{2}{\|\phi_{Org}(x)\|_{2}},\frac{2}{\|\phi_{FT}(x)\|_{2}})\|\phi_{FT}(x)-\phi_{Org}(x)\|_{2}",,"\left|\cos(\phi_{FT}(x),\psi(t))-\cos(\phi_{Org}(x),\psi(t))\right|\leq\frac{\|\phi_{FT}(x)-\phi_{Org}(x)\|_{2}}{\min\{\|\phi_{FT}(x)\|_{2},\|\phi_{Org}(x)\|_{2}\}}","The variable \(\phi_{\mathrm{FT}}(x)\) represents the fine-tuned image embedding for image \(x\), \(\phi_{\mathrm{Org}}(x)\) represents the original image embedding for image \(x\), and \(\psi(t)\) represents the text embedding for text \(t\)."
ICML_2024_oral_110,1,F_{iso}=\{f:\Omega\subsetR^{d}\to&R^{D}:\Df^{\top}(s)Df(s)=Id\\&for all s\in\Omega\},,P=\bigotimes_{i=1}^{d}P_{i},The probability distribution of the latent variables S with independent components.
ICML_2024_oral_110,2,"\Theta_{p}^{p}(f,\Omega)=\int_{\Omega}&dist(Df(s),SO(d))^{p}\\&+dist\big{(}(Df)^{-1}(s),SO(d)\big{)}^{p}\,ds",,\Theta(f)=\sup_{s\in\Omega}\left\lVert Df^{\top}(s)Df(s)-Id\right\rVert,"\(\Theta(f)\) measures the distance of a function \(f\) to the space of local isometries \(\mathcal{F}_{\mathrm{iso}}\), where \(\left\lVert \cdot \right\rVert\) denotes the operator norm."
ICML_2024_oral_110,3,"\Theta_{p}^{p}(f,\Omega)=&\int_{\Omega }dist^{p}(Df(z),SO(d,T_{f(z)}M))\\&+dist^{p}\big{(}(Df)^{-1}(z),SO(T_{f(z)}M,d)\big{)}\,dz","where \(T_{f(z)}M\) denotes the tangent space of \(M\) at \(f(z)\) and \(\mathrm{SO}(d,T_{f(z)}M)\) denotes the set of orthogonal matrices \(Q\in\mathbb{R}^{D\times d}\) (i","\Theta_{p}^{p}(f,\Omega)=\int_{\Omega}&dist(Df(s)_{|T_{f(s)}M},SO(d))^{p}\\&+dist\big{(}(Df)^{-1}(s)_{|T_{f(s)}M},SO(d)\big{)}^{p}\,ds","\(\Theta_{p}^{p}(f,\Omega)\) measures the distance of a function \(f\) to the space of local isometries \(\mathcal{F}_{\mathrm{iso}}\), with \(\mathrm{dist}(A,\mathrm{SO}(d))\) referring to the euclidean distance to the space \(\mathrm{SO}(d)\) of all rotations."
ICML_2024_oral_110,4,"MCC(\tilde{S},\tilde{S})=\max_{\pi\in S_{d}}d^{-1}\sum_{i=1}^{ d}|\rho(S_{i},\tilde{S}_{\pi(i)})|","where \(\rho(X,Y)=\operatorname{Cov}(X,Y)/(\operatorname{Var}(X)\operatorname{Var}( Y))^{1/2}\) denotes the correlation coefficient","\rho(\tilde{S},S)=\frac{1}{d}\sum_{i=1}^{d}\frac{cov(\tilde{S}_i,S_i)}{\sigma_{\tilde{S}_i}\sigma_{S_i}}",The mean correlation coefficient (MCC) measures the similarity between two random variables.
ICML_2024_oral_110,5,"MCC(\hat{S},S)\geq 1-C\Theta_{p}^{2}(f)",,"MCC(\hat{S},S)\geq 1-C\Theta_{p}(f,\Omega)^{1/p}",The mean correlation coefficient between the estimated and true latent variables is greater than or equal to 1 minus a constant times the distance of the mixing function to the space of local isometries.
ICML_2024_oral_110,6,"\min_{L}&\|u-L\|_{L^{q}(\Omega)}\\&\leq C(\Omega,p)(\int_{\Omega}dist(Du(s),SO (d))^{p}\,ds)^{\frac{1}{p}}",,\|Df-Dg\|\leq C\|Df^{\top}Df-Id\|^{1/2},"The equation represents the bound on the difference between the derivatives of two functions f and g, in terms of the difference between the metric tensor of f and the identity matrix."
ICML_2024_oral_110,7,"M(f_{*}P)=\{&(g,Q,\Omega^{\prime}):g\inF(\Omega^{\prime}), where \\g_{*}Q=f_{*}P,\,supp(Q)=\Omega^{\prime}\}",,"M(P)=\{f:\Omega\toR^{d}:f_{*}P=f_{*}P,\,f\approxId\}",The set of models consists of functions f that approximately preserve the identity and have the same push-forward measure as the original probability measure.
ICML_2024_oral_110,8,"&(g,Q,\Omega^{\prime})\in\\&\operatorname*{argmin}_{(\bar{g},\bar{Q},\Omega)\inM(f,P)}\int_{\Omega}dist((D\bar{g})^{-1}(g(s)),SO(d))^ {p}\,\bar{Q}(ds)",,"\arg\min_{(g,Q,\Omega^{\prime})\inM(f_{*}P)}\Theta_{p}(g,\Omega^{\prime})",The function g that minimizes the distance to the space of local isometries.
ICML_2024_oral_110,9,"\|h\|_{P,q}\leq C_{1}\Theta_{p}(f,\Omega)",,"\|h\|_{L^{q}(\Omega)}&\leq C(\Omega,p)(\int_{\Omega}dist(Df(s),SO(d))^{p}\,ds)^{\frac{1}{p}}\\&+C(\Omega,p)(\int_{\Omega}dist((Df)^{-1}(s),SO(d))^{p}\,ds)^{\frac{1}{p}}",The function h measures the deviation of g from being a perfect isometry.
ICML_2024_oral_110,10,x=f(s)=As+\eta h(s),where \(h:\mathbb{R}^{d}\to\mathbb{R}^{d}\) is a non-linear function and \(\eta\in\mathbb{R}\) is a small constant,X&=f(S)\\&=AS+\varepsilon(S)\\&=AS+h(S),"where \(A\) is an invertible matrix, \(S\) is a \(d\)-dimensional random variable with independent components, and \(\varepsilon(S)=h(S)\) is a non-linear perturbation term."
ICML_2024_oral_110,11,H(w)=EG(w^{\top}\Sigma_{X}^{-\frac{1}{2}}X),where \(\Sigma_{X}\) denotes the covariance matrix of \(X\) so that \(\Sigma_{X}^{-\frac{1}{2}}X\) is whitened and \(G\) is the so-called contrast function,H(a)&=E[\rho(a^{\top}X)]\\&=E[\rho(a^{\top}(As+\eta h(s)))]\\&=E[\rho(a^{\top}As+\eta a^{\top}h(s))],"where \(\rho\) is a non-linear function, e.g., \(\rho(t)=\log\cosh(t)\) or \(\rho(t)=t^{3}\), and \(a\in S^{d-1}\) is a unit vector."
ICML_2024_oral_110,12,\bar{w}_{i}=(AA^{\top})^{\frac{1}{2}}A^{-\top}e_{i},,"\Theta_{p}^{p}(f,\Omega)=\int_{\Omega}dist^{p}(Df(s),SO(d))^{p}+dist^{p}\big{(}(Df)^{-1}(s),SO(d)\big{)}^{p}\,ds","where \(\mathrm{dist}^{2}(A,\mathrm{SO}(d))=\min_{Q\in\mathrm{SO}(d)}|Q-A|^{2}\) refers to the euclidean distance to the space \(\mathrm{SO}(d)=\{A\in\mathbb{R}^{d\times d}:AA^{\top}=\mathrm{Id},\,\det A=1\}\) of all rotations."
ICML_2024_oral_110,13,"|G^{(k)}(x)|\leq C_{g}(1+|x|)^{\max(d_{g}-k,0)}",where \(G^{(k)}\) denotes the \(k\)-th derivative of \(G\),\|G^{(k)}(x)\|\leq C_{g}(1+|x|^{d_{g}}),where $G^{(k)}$ denotes the $k$-th derivative of $G$ and $\|\cdot\|$ denotes the supremum norm over the domain of $G$
ICML_2024_oral_110,14,E(|S|^{q})=M,,E|S_{i}|^{q}<M,where \(S_{i}\) denotes the \(i\)-th component of \(S\)
ICML_2024_oral_110,15,E(S_{i}g(S_{i})-g^{\prime}(S_{i}))=\alpha_{i},,E(G^{\prime\prime}(S_{i})S_{i}^{2})=\alpha_{i},The variable \(S_{i}\) is not Gaussian.
ICML_2024_oral_111,1,"L_{sup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE} (M_{i,j}^{l},Y_{i,j}^{l})","where \(M_{i,j}^{l}\) denotes the prediction mask of Burn-In model for the \(j\)-th pixel of \(i\)-th labeled image, \(Y_{i,j}^{l}\) denotes the corresponding ground truth, \(\mathcal{L}_{BCE}\) denotes binary cross entropy loss (Csiszar, 2008)","L_{burn-in}=\frac{1}{N}\sum_{i=1}^{N}\ell(f(x_i), y_i)",The burn-in loss function L_burn-in measures the difference between the model's predictions and true labels for the labeled data.
ICML_2024_oral_111,2,"\theta_{t}arrow\theta,\theta_{s}arrow\theta","where \(\theta_{t},\theta_{s},\theta\) denote the parameters of the teacher, student and Burn-In model, respectively","L_{mut}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE} (M_{i,j}^{t},M_{i,j}^{s})","where \(M_{i,j}^{t}\) and \(M_{i,j}^{s}\) denote the prediction masks of the teacher and student models for the \(j\)-th pixel of \(i\)-th image."
ICML_2024_oral_111,3,"L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE} (M_{i,j}^{u},\hat{M}_{i,j}^{u})","where \(M_{i,j}^{u}\) and \(\hat{M}_{i,j}^{u}\) denote the predicted mask for \(j\)-th pixel of \(i\)-th unlabeled image by student and teacher, respectively","L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE} (M_{i,j}^{s},\hat{M}_{i,j}^{t})","where \(M_{i,j}^{s}\) denotes the prediction mask of the student model for the \(j\)-th pixel of \(i\)-th unlabeled image, and \(\hat{M}_{i,j}^{t}\) denotes the pseudo-label generated by the teacher model."
ICML_2024_oral_111,4,L=\lambda_{sup}L_{sup}+\lambda_{unsup}L_{unsup},where \(\lambda_{sup}\) and \(\lambda_{unsup}\) is the hyperparameter of supervised loss \(\mathcal{L}_{sup}\) and unsupervised loss \(\mathcal{L}_{unsup}\),L_{total}=L_{sup}+\lambdaL_{unsup},where \(\lambda\) is a hyperparameter that controls the balance between supervised and unsupervised losses.
ICML_2024_oral_111,5,\theta_{t}arrow\alpha\theta_{t}+(1-\alpha)\theta_{s},"where \(\alpha\) is the decay coefficient of EMA, typically set within the small range of 0",\theta_{t}\leftarrow\alpha\theta_{t}+(1-\alpha)\theta_{s},"where \(\theta_{t}\) and \(\theta_{s}\) denote the parameters of the teacher and student models, respectively, and \(\alpha\) is the decay rate of the exponential moving average."
ICML_2024_oral_111,6,"s^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i, j,k}^{u})}{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cup\widetilde{M}_{i, j,k}^{u})}","where \(\hat{M}_{i,j}^{u}\) and \(\widetilde{M}_{i,j,k}^{u}\) denote the pseudo-labels and \(k\)-th segment mask generated by SAM for \(j\)-th pixel of \(i\)-th unlabeled image \(\mathcal{I}_{i}^{u}\), respectively","S=\arg\max_{s\inC}IoU(M, s)","where \(\mathcal{S}\) denotes the selected segment, \(\mathcal{C}\) denotes the candidate segment pool, \(M\) denotes the pseudo-label, and \(\text{IoU}(M, s)\) denotes the IoU score between \(M\) and \(s\)."
ICML_2024_oral_111,7,"s_{1}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{ i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u})+\epsilon}",where \(\epsilon\) is the smoothing factor to prevent a denominator of zero,"o^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i, j,k}^{u})}{\sum_{j=1}^{H\times W}\hat{M}_{i,j}^{u}}","where \(o^{k}\) denotes the overlap ratio between the pseudo-labels \(\hat{M}_{i,j}^{u}\) and the \(k\)-th segment mask \(\widetilde{M}_{i, j,k}^{u}\) generated by SAM for \(j\)-th pixel of \(i\)-th unlabeled image."
ICML_2024_oral_111,8,"s_{2}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M} _{i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\widetilde{M}_{i,j,k}^{u} )}",,"s_{2}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{ i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\widetilde{M}_{i,j,k}^{u})+\epsilon}","where \(s_{2}^{k}\) denotes the overlap ratio between the pseudo-labels \(\hat{M}_{i,j}^{u}\) and the \(k\)-th segment mask \(\widetilde{M}_{i,j,k}^{u}\) generated by SAM for \(j\)-th pixel of \(i\)-th unlabeled image."
ICML_2024_oral_111,9,"\Psi(\hat{M}^{u}_{i,j})=\gamma-\frac{1}{\sqrt{2\pi\sigma}}\exp(-\frac{(\hat{M}^{u}_{i,j}-\mu)^{2}}{2\sigma^{2}})","where \(\gamma,\sigma^{2},\mu\) are hyperparameters, which are set to 1",\Psi(x)=\beta\cdot\left | 2x-1\right |,where \(\beta\) is a hyperparameter controlling the magnitude of weights and \(x\) represents the confidence score of a pixel.
ICML_2024_oral_111,10,"L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}\Psi(\hat{M}^{u} _{i,j})*L_{BCE}(M^{u}_{i,j},\hat{M}^{u}_{i,j})",,"L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}\Psi(\hat{M}^{u}_{i,j})L_{BCE} (M_{i,j}^{u},\hat{M}_{i,j}^{u})","where \(\Psi(\hat{M}^{u}_{i,j})\) denotes the weight of \(j\)-th pixel of \(i\)-th unlabeled image, and \(\mathcal{L}_{BCE}\) denotes binary cross entropy loss."
ICML_2024_oral_113,1,"\nabla_{\theta}J(\pi_{\theta})=\operatorname*{E}_{s\sim\rho_{d},a\sim\pi(\cdot|s)}[\nabla_{\theta}\log(\pi_{\theta}(a))\hat{A}^{\pi_{\theta}}(s,a)]","where \(\hat{A}^{\pi_{\theta}}(s,a)\) is an advantage function that estimates the contribution of the transition to the gradient","J(\pi)=E_{\pi_{0}\sim\rho,a_{t}\sim\pi(\cdot|s_{t})}\left[\sum_{t=0}^{T-1}\gamma^{t}r(s_{t},a_{t})\right]",The objective function in reinforcement learning that represents the long term discounted reward.
ICML_2024_oral_113,2,"L_{on}(\pi_{\theta})&=\operatorname*{E}_{\pi_{old}}[\min(r_{t}(\pi_{\theta}),.\\&.clip(r_{t}(\pi_{\theta}),1-\epsilon,1+\epsilon))A_{t}^{\pi_{old}}]",,"\hat{A}^{\pi_{\theta}}(s,a)=\hat{Q}^{\pi_{\theta}}(s,a)-\hat{V}^{\pi_{\theta}}(s)",The advantage function is estimated as the difference between the estimated Q-function and the estimated value function.
ICML_2024_oral_113,3,"& L_{off}(\pi_{i};X)=\frac{1}{|X|}\sum_{j\inX}\operatorname*{E}_{(s,a)\sim\pi_{j}}[\min (r_{\pi_{i}}(s,a),..\\&..clip(r_{\pi_{i}}(s,a),\mu(1-\epsilon),\mu(1+\epsilon)))A^{\pi_{i,old}}(s,a)]","where \(r_{\pi_{i}}(s,a)=\frac{\pi_{i}(s,a)}{\pi_{j}(s,a)}\) and \(\mu\) is an off-policy correction term \(\mu=\frac{\pi_{i,old}(s,a)}{\pi_{j}(s,a)}\)","\nabla_{\theta}J(\pi_{\theta})=\operatorname*{E}_{s\sim\rho_{d},a\sim\pi_{j}(\cdot|s)}[\nabla_{\theta}\log(\pi_{\theta}(a))\hat{A}^{\pi_{\theta}}(s,a)\frac{\pi_{\theta}(a|s)}{\pi_{j}(a|s)}]","The equation represents the policy gradient update using off-policy data from another policy \(\pi_{j}\), where the importance weighting term \(\frac{\pi_{\theta}(a|s)}{\pi_{j}(a|s)}\) is used to correct for the difference in policies."
ICML_2024_oral_113,4,L(\pi_{i})=L_{on}(\pi_{i})+\lambda\cdot L_{off}(\pi_{i};X),,L(\pi_{i}) &=(1-\alpha) L_{on}(\pi_{i})+\alpha L_{off}(\pi_{i};X),where \(\alpha\) is a hyperparameter that controls the trade-off between on-policy and off-policy updates
ICML_2024_oral_113,5,"V^{target}_{on,\pi_{j}}(s_{t})=\sum_{k=t}^{t+2}\gamma^{k-t}r_{k}+\gamma^{3}V_{\pi_{j},old}(s_{t+3})",,"y_{t}&=r_{t}+\gamma r_{t+1}+\gamma^{2}r_{t+2}+\gamma^{3}V^{\pi_{i,old}}(s_{t+3})",The update target for the critic is calculated using n-step returns.
ICML_2024_oral_113,6,"V^{target}_{off,\pi_{j}}(s^{\prime}_{t})=r_{t}+\gamma V_{\pi_{j},old}(s^{\prime}_{t+1})",,"V^{target}_{off,\pi_{j}}(s_{t})=r_{t}+\gamma V_{\pi_{j},old}(s_{t+1})","where \(V^{target}_{off,\pi_{j}}(s_{t})\) is the target value function for off-policy data."
ICML_2024_oral_113,7,"L^{critic}_{on}(\pi_{i})=\operatorname*{E}_{(s,a)\sim\pi_{i}}[( V_{\pi_{i}}(s)-V^{target}_{on,\pi_{i}}(s))^{2}] || L^{critic}_{off}(\pi_{i};X)=\frac{1}{|X|}\sum_{j\inX}\operatorname*{E}_{(s,a)\sim\pi_{j}}[(V_{\pi_{i}}(s)-V^{target}_{off,\pi_{i}}(s))^{2}] || L^{critic}(\pi_{i})=L^{critic}_{on}(\pi_{i})+\lambda\cdot L^{critic}_{off}(\pi_{i})",,"L_{V}(\pi_{i})&=\operatorname*{E}_{(s,a)\sim\pi_{i,old}}[(V^{target}_{on,\pi_{i}}(s)-V_{\pi_{i}}(s))^{2}]+\\&\lambda\cdot\operatorname*{E}_{(s,a)\sim\pi_{j}}[(V^{target}_{off,\pi_{i}}(s)-V_{\pi_{i}}(s))^{2}]",The critic loss function combines on-policy and off-policy losses to update the value function.
ICML_2024_oral_117,1,"Attention(q,K,V)=softmax(\frac{qK^{T}}{\sqrt{d_{model}}})V",,"v=Attention(q, K, V)=softmax\left(\frac{qK^T}{\sqrt{d_{model}}}\right)V",The variable \(\mathbf{v}\) represents the tentative output vector of the self-composing policy module.
ICML_2024_oral_117,2,"FTr_{i}=\frac{AUC_{i}-AUC_{i}^{b}}{1-AUC_{i}^{ b}},\quadAUC_{i}=\frac{1}{\Delta}\int_{(i-1)\cdot\Delta}^{i\cdot\Delta}p_{i}(t)dt || AUC_{i}^{b}=\frac{1}{\Delta}\int_{0}^{\Delta}p_{i}^{b}(t)dt",,FTr_{i}=\frac{1}{\Delta}\sum_{t=1}^{\Delta}\frac{p_{i}(t)-p_{i}^{b}(t)}{1-p_{i}^{b}(t)},The forward transfer metric measures the improvement in performance of the proposed method over the baseline method for each task.
ICML_2024_oral_117,3,"RT=\frac{1}{N}\sum_{i=2}^{N}\max_{j<i}FTr(j,i)","where \(\text{FTr}(j,i)\) is the forward transfer obtained by training a model from scratch in the \(j\)-th task and fine-tuning it in the \(i\)-th task","RT_{i}=\max_{j\in\{1,\ldots,i-1\}}FTr_{i,j},\quadFTr_{i,j}=\frac{AUC_{i,j}-AUC_{i}^{b}}{1-AUC_{i}^{b}},\quadAUC_{i,j}=\frac{1}{\Delta}\int_{(i-1)\cdot\Delta}^{i\cdot\Delta}p_{i,j}(t)dt","The variable \( \text{RT}_{i} \) represents the reference forward transfer for task \( i \), which is the maximum forward transfer achievable by fine-tuning from any of the previous tasks \( j \) to the current task \( i \)."
ICML_2024_oral_121,1,"p(x;p^{m})=\sum_{i}^{N}k(x,d_{i})p_{i}^{m}",,p(x)=\sum_{i=1}^{N} p_{i}^{m}\cdot\frac{1}{2\sigma}\exp\left(-\frac{|x-d_{i}|}{\sigma}\right),The probability density function of disparity x is a weighted sum of Laplacian kernels centered at each discrete disparity.
ICML_2024_oral_121,2,"\texttt{argmin}_{y}F(y,p^{m})=\texttt{argmin}_{y}\intL(y,x )p(x;p^{m})dx","where \(F(y,\mathbf{p}^{m})\) is called as the risk at \(y\), and \(\mathcal{L}(y,x)\) is the error function between \(y\) and \(x\)","k(x,d_{i})=\frac{1}{2\sigma}\exp\left(-\frac{|x-d_{i}|}{\sigma}\right)","The variable \(k(x,d_{i})\) represents the Laplacian kernel used for interpolating the discrete distribution of disparities."
ICML_2024_oral_121,3,y=\int xp(x;p^{m})dx,,y_{\texttt{expectation}}=\int xp(x;p^{m})dx=\sum_{i}d_{i}p_{i}^{m},where \(y_{\texttt{expectation}}\) represents the expected value of the disparity
ICML_2024_oral_121,4,"\texttt{argmin}_{y}F(y,p^{m})=\texttt{argmin}_{y}\int|y-x|p(x;p^{m})dx",,"L(y,x)=|y-x|","The L1 norm loss function used to calculate the risk in stereo matching, which is more robust to outliers compared to the L2 norm loss function."
ICML_2024_oral_121,5,"G(y,p^{m})\triangleq\frac{\partial F(y,p^{m})} {\partial y} || =\sum_{i}p_{i}^{m}\texttt{Sign}(y-d_{i})(1-\exp-\frac{|y-d_{i}|}{\sigma})=0",,"\frac{\partial F}{\partial y}=\int\frac{\partialL(y,x)}{\partial y}p(x;p^{m})dx=0","The derivative of the risk function F with respect to y is equal to the integral of the derivative of the loss function with respect to y, weighted by the probability density function p."
ICML_2024_oral_121,6,"dG(y,p^{m})=\frac{\partial G}{\partial y}dy+\frac{\partial G}{\partialp^{m}}dp^{m}=0",,\frac{dy}{dp^{m}}=-\left(\frac{\partial G}{\partial y}\right)^{-1}\frac{\partial G}{\partialp^{m}},The derivative of the optimal disparity with respect to the discrete distribution.
ICML_2024_oral_121,7,"\frac{dy}{dp^{m}}=-\frac{\partial G/\partialp^{m}}{\partial G/\partial y} || =[\dots,\frac{\sigma\texttt{Sign}(d_{i}-y)(1-\exp-\frac{|y-d_{i} |}{\sigma})}{\sum_{j}p_{j}^{m}\exp-\frac{|y-d_{i}|}{\sigma}},\dots]^{T}",,dy=\left(-\frac{\partial G}{\partial y}\right)^{-1}\frac{\partial G}{\partialp^{m}}dp^{m},The derivative of y with respect to the probability mass function pm.
ICML_2024_oral_121,8,"L(x^{\texttt{gt}},x^{\texttt{pred}})=0.5(x^{\texttt{gt}}-x^{\texttt{pred}})^{2},&if |x^{\texttt{gt}}-x^{\texttt{pred}}|<1.0\\|x^{\texttt{gt}}-x^{\texttt{pred}}|-0.5,&otherwise",,"L(x^{\texttt{pred}},x^{\texttt{gt}})=0.5(x^{\texttt{pred}}-x^{\texttt{gt}})^{2} &if  |x^{\texttt{pred}}-x^{\texttt{gt}}|<1\\|x^{\texttt{pred}}-x^{\texttt{gt}}|-0.5 &otherwise","The smooth L1 loss function is used for training, which is less sensitive to outliers compared to the L2 loss."
ICML_2024_oral_122,1,"\min_{\theta}\,\sum_{i=1}^{N}(\hat{y}(x;\theta)-y_{i})^{2}",,"Y\,|\,x\simN(\mu=\hat{y}(x;\theta),\sigma^{2})","The conditional distribution of the target variable Y given input x, modeled as a normal distribution with mean μ and variance σ^2."
ICML_2024_oral_122,2,"\min_{\theta}\,\sum_{i=1}^{N}\int_{Y}p(y\,|\,x_{i})\log(\hat{p}(y\,|\,x_ {i};\theta))dy",,"DKL(p\ || \,\hat{p})=\int p(y\,|\,x)\log\frac{p(y\,|\,x)}{\hat{p}(y\,|\,x;\theta)}dy",The Kullback-Leibler divergence between the true distribution p and the approximating distribution \(\hat{p}\).
ICML_2024_oral_122,3,"Z=\{\sum_{i=1}^{m}p_{i}\,\delta_{z_{i}}\,:\,p_{i}\geq 0,\sum_{i=1} ^{m}p_{i}=1\}",where \(p_{i}\) is the probability associated with location \(z_{i}\) and \(\delta_{z_{i}}\) is the Dirac delta function at location \(z_{i}\),"\hat{p}(y\,|\,x;\theta)=\sum_{j=1}^{m}p_{j}(x;\theta)I\{y=z_{j}\}",\(p_{j}(x;\theta)\) represents the probability of the \(j\)-th class given input \(x\) and model parameters \(\theta\).
ICML_2024_oral_122,4,"\boxed{TD_{MSE}(\theta)=E_{D}[((\tilde{T}Q)(S,A;\tilde{\theta})-\,Q(S,A;\theta))^{2}]} || (\tilde{T}Q)(s,a;\tilde{\theta})=R+\gamma\max_{a^{\prime}}Q(S^{\prime },a^{\prime};\tilde{\theta})\,\big{|}\,S=s,A=a\","where \(\tilde{\theta}\) is a slow moving copy of the parameters \(\theta\) that parameterize the ""target network"" and

\[(\tilde{\mathcal{T}}Q)(s,a;\tilde{\theta})=R+\gamma\max_{a^{\prime}}Q(S^{\prime },a^{\prime};\tilde{\theta})\,\big{|}\,S=s,A=a\,,\]

is the sample version of the Bellman optimality operator which defines our scalar regression target","\min_{\theta}\,E_{(S,A,R,S^{\prime})\simD}\left[\left(Q(S,A;\theta)-\left(R+\gamma\max_{A^{\prime}}Q(S^{\prime},A^{\prime};\theta)\right)\right)^{2}\right]","where \(Q(s,a;\theta)\) is the action-value function parameterized by \(\theta\), \(R\) is the reward, \(\gamma\) is the discount factor, and \(S^{\prime}\) is the next state."
ICML_2024_oral_122,5,"\alpha\,E_{D}[\log\big{(}\sum_{a^{\prime}}\exp(Q(S^{\prime},a^{\prime};\theta))\big{)}-Q(S,A;\theta)]",,"\min_{\theta}\,E_{D}[((\tilde{T}Q)(S,A;\tilde{\theta})-Q(S,A;\theta))^{2}]+\alpha\,E_{D}[Q(S,A;\theta)]",where the first term is the mean-squared TD error and the second term is a behavior regularization term that discourages the Q-function from producing overly optimistic estimates.
ICML_2024_oral_122,6,"Q(s,a;\theta)=E[\,Z(s,a;\theta)\,],\Z(s,a;\theta)=\sum_{i=1}^{m}\hat{p}_{i}(s,a;\theta)\cdot\delta_{z_{i}} || \hat{p}_{i}(s,a;\theta)=\frac{\exp(l_{i}(s,a;\theta))}{\sum_{j=1} ^{m}\exp(l_{j}(s,a;\theta))}\",,"\hat{p}_{i}(s,a;\theta)=\frac{\exp(l_{i}(s,a;\theta))}{\sum_{j=1}^{m}\exp(l_{j}(s,a;\theta))}","where \(\hat{p}_{i}(s,a;\theta)\) represents the probability of the categorical distribution \(Z\) being at location \(z_{i}\) given state \(s\) and action \(a\), parameterized by \(\theta\)."
ICML_2024_oral_122,7,"\boxed{TD_{CE}(\theta)=E_{D}[\sum_{i=1 }^{m}p_{i}(S,A;\tilde{\theta})\log\hat{p}_{i}(S,A;\theta)]}",,"\min_{\theta}\,E_{D}\left[\sum_{i=1}^{m}p_{i}(S,A;\tilde{\theta})\log(\hat{p}_{i}(S,A;\theta))\right]","where \(p_{i}(S,A;\tilde{\theta})\) represents the target probability for the \(i^{th}\) location, and \(\hat{p}_{i}(S,A;\theta)\) represents the predicted probability for the \(i^{th}\) location."
ICML_2024_oral_122,8,"p_{i}(S,A;\tilde{\theta})=\frac{y-z_{i}}{z_{i+1}-z_{i}},\p_{i+1}(S,A;\tilde{\theta})=\frac{z_{i+1}-y}{z_{i+1}-z_{i}}\",,"p_{i}=\frac{z_{i+1}-y}{z_{i+1}-z_{i}},\p_{i+1}=\frac{y-z_{i}}{z_{i+1}-z_ {i}}","The probability values \(p_{i}\) and \(p_{i+1}\) represent the weights assigned to the locations \(z_{i}\) and \(z_{i+1}\) in the two-hot categorical distribution, allowing the scalar target \(y\) to be exactly represented."
ICML_2024_oral_122,9,"p_{i}(S,A;\tilde{\theta})=\int_{z_{i}-\nicefrac{{\varsigma}}{{2}}}^{z_{i}+\nicefrac{{\varsigma}}{{2}}}f_{Y|S,A}(y|S,A)dy || =F_{Y|S,A}(z_{i}+\nicefrac{{\varsigma}}{{2}}|S,A)-F_{Y|S,A}(z_{i}-\nicefrac{{\varsigma}}{{2}}|S,A)",,"p_{i}(S,A;\tilde{\theta})=F_{Y|S,A}(z_{i}+\frac{\varsigma}{2})-F_{Y|S,A}(z_{i}-\frac{\varsigma}{2})","where \(p_{i}\) is the probability associated with location \(z_{i}\) and \(F_{Y|S,A}\) is the cumulative distribution function of the random variable \(Y\,|\,S,A\)"
ICML_2024_oral_122,10,"(\widehat{T}Z)(s,a;\tilde{\theta})\overset{D}{=}\sum_{i=1}^{m}\hat{p}_{i}(S^{\prime},A^{\prime};\tilde{\theta})\cdot\delta_{R+\gamma z_{i}}\bigm{|}S=s,\,A=a\","where \(A^{\prime}=\operatorname*{arg\,max}_{a^{\prime}}Q(S^{\prime},a^{\prime}; \tilde{\theta})\)","T^{Z}(s,a,z_{i})=R+\gamma\sum_{a^{\prime}}\pi(a^{\prime}|s^{\prime})\sum_{j=1}^{m}p_{j}(s^{\prime},a^{\prime})I\{z_{i}\leq z_{j}+\varsigma\}","where \(\mathcal{T}^{\mathcal{Z}}(s,a,z_{i})\) is the probability assigned to the \(i^{th}\) location \(z_{i}\) by the stochastic distributional Bellman operator."
ICML_2024_oral_122,11,"p_{i}(S,A;\tilde{\theta})=\sum_{j=1}^{m}\hat{p}_{j}(S^{\prime},A ^{\prime};\tilde{\theta})\cdot\xi_{j}(R+\gamma z_{i}) || \xi_{j}(x)=\frac{x-z_{j}}{z_{j+1}-z_{j}}\mathds{1}\{\lfloor x\rfloor=z_{j}\}+\frac{z_{j+1}-x}{z_{j+1}-z_{j}}\mathds{1}\{\lceil x\rceil=z_ {j}\}\",,"p_{i}(S,A;\tilde{\theta})=\hat{p}_{\lfloor R+\gamma z_{i}\rfloor}(S^{\prime},A^{\prime};\tilde{\theta})\cdot\frac{R+\gamma z_{i}-z_{\lfloor R+\gamma z _{i}\rfloor}}{z_{\lceil R+\gamma z_{i}\rceil}-z_{\lfloor R+\gamma z_{i}\rfloor}}+\hat{p}_{\lceil R+\gamma z_{i}\rceil}(S^{\prime},A^{\prime};\tilde{\theta})\cdot\frac{z_{\lceil R+\gamma z_{i}\rceil}-(R+\gamma z_{i})}{z_{\lceil R+\gamma z _{i}\rceil}-z_{\lfloor R+\gamma z_{i}\rfloor}}","where \(\hat{p}_{i}(S^{\prime},A^{\prime};\tilde{\theta})\) is the probability of location \(z_{i}\) in the distribution \(Z(S^{\prime},A^{\prime};\tilde{\theta})\)"
ICML_2024_oral_125,1,"E_{i}=L_{i}(E_{i-1}),\\i=1,...,N || \dot{y}=\texttt{Head}(e_{N}^{0})",,f_{\Theta}(\cdot)=L_{N}(E_{N-1}),The function f_{\Theta} represents a plain Vision Transformer with N layers.
ICML_2024_oral_125,2,"\min_{\tilde{\Theta}}L(x;\Theta),\x\sim Q(x)",where \(\tilde{\Theta}\subseteq\Theta\) denotes the model parameters involved for updating,\min_{\Theta}L_{TTA}(f_{\Theta}(x_{j})),The TTA loss function that the model parameters are updated to minimize during testing.
ICML_2024_oral_125,3,"p^{*}=\operatorname*{arg\,min}_{p}L(f_{\Theta}(p;x))","where \(\mathcal{L}(\cdot)\) is a fitness function and \(\mathbf{p}\in\mathbb{R}^{d\times N_{p}}\) consists of \(N_{p}\) prompt embeddings, each of dimension \(d\)","p^{*}=\arg\min_{p}L(x,p;\Theta),\x\sim Q(x)","where \(\mathbf{p}\) denotes the learnable prompt embeddings and \(\mathcal{L}(\mathbf{x}, \mathbf{p}; \Theta)\) represents the unsupervised fitness function for CMA optimization."
ICML_2024_oral_125,4,L(f_{\Theta}(p;X_{t}))=\sum_{ x\inX_{t}}\sum_{c\inC}-\hat{y}_{c}\log\hat{y}_{c} || \qquad+\lambda\sum_{i=1}^{N}\lvert\lvert\mu_{i}(X_ {t})-\mu_{i}^{S}\rvert\rvert_{2}+\lVert\sigma_{i}(X_{t})-\sigma_{i}^{S}\rvert\rvert_{2},,L(p;X_{t})=\alpha\cdotL_{ent}(f_{\Theta}(p;X_{t}))+\beta\cdotL_{stat}(f_{\Theta}(p;X_{t})),where \(\mathcal{L}_{ent}(\cdot)\) denotes the prediction entropy and \(\mathcal{L}_{stat}(\cdot)\) represents the distribution discrepancy between the testing and source statistics
ICML_2024_oral_125,5,"p_{k}^{(t)}\simm^{(t)}+\tau^{(t)}N(0,\bm {\Sigma}^{(t)})",,"p_{t}^{(i)}\simN(m_{t},C_{t}),\i=1,2,...,\lambda",where \(\mathbf{m}_{t}\) is the mean vector and \(\mathbf{C}_{t}\) is the covariance matrix of the distribution at iteration \(t\)
ICML_2024_oral_125,6,e_{N}^{0}arrowe_{N}^{0}+\gammad,where \(\mathbf{d}\) is a shifting direction and \(\gamma\) is a step size,e_{N}^{0}\leftarrowe_{N}^{0}-\alpha(e_{N}^{0}-\mu_{N}^{S}),where \(\alpha\) is a hyperparameter that controls the shifting strength and \(\mathbf{\mu}_{N}^{S}\) denotes the mean of source in-distribution CLS features.
ICML_2024_oral_125,7,d_{t}=\mu_{N}^{S}-\mu_{N}(t),where \(\boldsymbol{\mu}_{N}^{S}\) is the mean of the \(N\)-th final layer CLS feature \(\mathbf{e}_{N}^{0}\) and calculated over source in-distribution samples \(\mathcal{D}_{S}\) (the same one used in Eqn,d=\frac{\mu^{S}-\mu(X_{t})}{\lVert\mu^{S}-\mu(X_{t})\rVert_{2}},where \(\mathbf{\mu}^{S}\) is the center of source in-distribution features and \(\mathbf{\mu}(\mathcal{X}_{t})\) is the center of out-of-distribution testing features at the \(t\)-th batch.
ICML_2024_oral_125,8,\mu_{N}(t)=\alpha\mu_{N}(X_{t})+(1-\alpha )\mu_{N}(t-1),where \(\boldsymbol{\mu}_{N}(\mathcal{X}_{t})\) is the mean of the \(N\)-th layer's CLS feature and calculated over the \(t\)-th test batch \(\mathcal{X}_{t}\),\mu_{N}(t)=\alpha\mu_{N}(t-1)+(1-\alpha)\frac{1}{|X_{t}|}\sum_{x\inX_{t}}e_{N}^{0}(x),where \(\alpha\) is the momentum coefficient and \(\boldsymbol{\mu}_{N}(t-1)\) is the mean estimate at iteration \(t-1\)
ICML_2024_oral_127,1,\sup_{x}\mathds{E}_{D^{j}\sim\chi}[\lfloor\frac{j}{i}\hat{f}(x )-f_{D^{j}}(x)\rceil]\geq\frac{\sqrt{k}}{4},,\sup_{x}\mathds{E}_{D\sim\chi}[\lfloor\frac{j}{i}\hat{f}(x)-f_{D^{j}}(x)\rfloor],The generalization error of the model to dataset \(\mathbf{D}^{j}\).
ICML_2024_oral_127,2,\mathds{P}_{D\sim\chi}[\|f_{\chi}-\hat{f}\|_{\infty}\geq\epsilon]\leq\varkappa_ {1}e^{-\varkappa_{2}(\frac{\epsilon}{\sqrt{n}}-1)^{2}},,\sup_{x}\mathds{E}_{D\sim\chi}[\lfloor\hat{f}(x)-f_{\chi}(x)\rfloor]\leqB_{n}^{X},The variable \(\mathcal{B}_{n}^{\mathfrak{X}}\) represents the maximum allowed error for the learned model.
ICML_2024_oral_13,1,"&P\{X_{1}=x_{1}\}\\&P\{X_{2}=x_{2}|X_{1}=x_{1}\}\\&\quad\vdots\\&P\{X_{n}=x_{n}|X_{1}=x_{1},\cdots,X_{n-1}=x_{n-1 }\}",,"p(x_{1},\cdots,x_{n})=\prod_{i=1}^{n} p(x_{i} | x_{1},\cdots,x_{i-1})",The probability of a sequence of tokens is calculated as the product of the probabilities of each token given the previous tokens.
ICML_2024_oral_13,2,"&P\{X_{n}=x_{n}\}\\&P\{X_{n-1}=x_{n-1}|X_{n}=x_{n}\}\\&\quad\vdots\\&P\{X_{1}=x_{1}|X_{n}=x_{n},\cdots,X_{2}=x_{2}\}",,"&P\{X_{n}=x_{n}\}\\&P\{X_{n-1}=x_{n-1}|X_{n}=x_{n}\}\\&\quad\vdots\\&P\{X_{1}=x_{1}|X_{n}=x_{n},\cdots,X_{2}=x_{2 }\}",The probability measure of a sequence of tokens in reverse order.
ICML_2024_oral_13,3,"\sum_{i=1}^{n}\ell_{i}^{arrow}=-\lnP_{n}^{arrow}\{X_ {1}=x_{1},\cdots,X_{n}=x_{n}\}",,\ell_{i}^{\leftarrow}=-\lnp_{i}^{\leftarrow}\left( x_{i}\right),The cross-entropy loss for the backward model at position i.
ICML_2024_oral_13,4,L_{n}^{arrow}=D_{KL}(P_{n}\big{|}\big{|}P_{n}^{arrow})+H(P_{n}),where \(H\) denotes the entropy and \(\mathrm{D}_{\mathrm{KL}}\) the Kullback-Leibler divergence,"L_{n}^{\leftarrow}=-\frac{1}{n}E_{P_{n}}\left[\lnP_{n}^{\leftarrow}\{X_{1}=x_{1},\cdots,X_{n}=x_{n}\}\right]",\(\mathcal{L}_{n}^{\leftarrow}\) represents the expected cross-entropy loss of the backward model on sequences of length \(n\).
ICML_2024_oral_132,1,P(A(D)\in S)\leq e^{\epsilon}P(A(D^{\prime})\in S)+\delta,,"A(D)\approx_{\epsilon,\delta}A(D^{\prime})",\(\mathcal{A}(\mathcal{D})\) and \(\mathcal{A}(\mathcal{D}^{\prime})\) represent the outputs of the learning algorithm on the datasets \(\mathcal{D}\) and \(\mathcal{D}^{\prime}\) respectively.
ICML_2024_oral_132,2,\epsilon=\epsilon_{\alpha}+\log(\frac{\alpha-1}{\alpha})-\frac{\log\delta+\log\alpha}{\alpha-1},,D_{\alpha}(A(D) || A(D^{\prime}))\leq\epsilon_{\alpha},\(\epsilon_{\alpha}\) represents the upper bound of the Renyi divergence between the distributions of models trained on adjacent datasets \(\mathcal{D}\) and \(\mathcal{D}^{\prime}\).
ICML_2024_oral_132,3,"\widetilde{g}_{t}=\frac{1}{B}(\sum_{x\inB_{t}}clip_{C}(\nabla_{\theta}\ell(x;\theta_{t})+N(0,\sigma^{2}C^{2}I))","where \(\eta_{t}\) is the learning rate, \(\mathcal{B}_{t}\) is the sampled batch, \(B\) is the average batch size, \(\sigma>0\) is the noise multiplier, and \(\mathsf{clip}_{C}\) is the operation that clips the per-sample gradient norm to at most \(C>0\)",\theta_{t+1}=\theta_{t}-\eta_{t}\widetilde{g}_{t},"The update rule for DP-SGD, where \(\mathbf{\theta}_{t+1}\) is the updated model parameter, \(\mathbf{\theta}_{t}\) is the current model parameter, \(\eta_{t}\) is the learning rate at iteration \(t\), and \(\widetilde{\mathbf{g}}_{t}\) is the perturbed gradient."
ICML_2024_oral_132,4,"L_{MAE}(\theta):=\frac{1}{n}\sum_{i=1}^{n}\underbrace{\xi_{ MSE}(g\circ\psi(mask(x_{i});\theta),x_{i})}_{\ell(x_{i};\theta)}","where \(n\) is the number of training samples, \(\mathbf{x}_{i}\in\mathbb{R}^{C\times H\times W}\) is the input of the \(i\)-th training image (\(C\)-number of channels, \(H\)-height, \(W\)-width), mask\((\cdot)\) is a function that mask out a fraction of the image, \(\psi:\mathbb{R}^{C\times H\times W}\rightarrow\mathbb{R}^{d}\) is the encoder and \(g:\mathbb{R}^{d}\rightarrow\mathbb{R}^{C\times H\times W}\) is the decoder",L_{MAE}(\theta)=E_{x\simD}\left[\left\|x-MAE(x_{masked};\theta)\right\|_{2}^{2}\right],The training objective for the masked autoencoder is defined as the expected squared L2 norm between the original image and its reconstruction from the masked input.
ICML_2024_oral_15,1,\min_{p(T|X)}\quad I(X;T),where \(I(X;T)\) denotes the mutual information of \(X\) and \(T\),"R(D)=\min_{T} I(X;T) subject to  E[d(X,T)]\leq D","The equation represents the rate-distortion function R(D), which is the minimum mutual information between the random variable \(\mathcal{X}\) and its transformation \(\mathcal{T}\), subject to a distortion constraint D."
ICML_2024_oral_15,2,\min_{p(T|X)} I(X;T),,\min_{p(T|X)}\quad I(X;T)+\lambda I(T;Q),where \(\lambda\) is a hyperparameter controlling the trade-off between the distortion and the information retrieval term.
ICML_2024_oral_15,3,I(T;Q)\geq\varepsilon,where \(\varepsilon>0\) is a threshold,\min_{p(T|X)} I(X;T) s.t.  I(X;T)\leq R,where \(R\) denotes the maximum allowed rate of information retrieval
ICML_2024_oral_15,4,L(p(T|X))=I(X;T)-\beta I(T;Q),where \(\beta\) is the Lagrange multiplier,"L(p(T|X),\lambda)=I(X;T)-\lambda(I(T;Q)-\varepsilon)",where \(\lambda\) is the Lagrange multiplier associated with the constraint \(I(T;Q) \geq \varepsilon\)
ICML_2024_oral_15,5,L(p(T|X))=I(X;T)+\beta I(X;Q|T)+constant,,L(p(T|X))=I(X;T)-\beta I(T;Q)=\beta\left( I(T;Q)-\frac{1}{\beta}I(X;T)\right),where \(\beta\) is the Lagrange multiplier that determines the tradeoff between index conciseness \(I(X;T)\) and retrieval accuracy \(I(T;Q)\).
ICML_2024_oral_15,6,"p^{*}(T|X)=\frac{p^{*}(T)}{Z(X,\beta)}\exp\Bigl{(}-\betaKL[p(Q|X)\\big{\|}\p(Q|T)]\Bigr{)}","where \(Z(X,\beta)\) is a probability normalization term, \(p^{*}(T)=\mathbb{E}_{X}[p^{*}(T|X)]\)",p(T|X)=\frac{1}{Z(X)}e^{-\beta D_{KL}(p(Q|X) || p(Q|T))},where \(Z(X)\) is the partition function and \(D_{KL}\) denotes the Kullback-Leibler divergence.
ICML_2024_oral_15,7,"p(X,Q|f)\equiv\prod_{x\inX}p^{*}\big{(}X=x\\big{|}\T=f(x)\big{)}",where \(p^{*}\) is given by Formula (5),"p(X,Q|f)=\prod_{x\inX}p^{*}(T=f(x)|X=x)p(Q|x)",where \(p^{*}(T|X)\) is the optimal solution and \(p(Q|x)\) is the likelihood of \(Q\) given \(x\).
ICML_2024_oral_15,8,"I(X;T)=E_{X,T}\log\frac{p(X|T)}{p(X)} || I(X;Q|T)=E_{X,T,Q}\log\frac{p(X,Q|T)}{p(X|T)p(Q|T)}",,I(X;T)=H(X)-H(X|T),where \(H(X)\) denotes the entropy of \(X\) and \(H(X|T)\) denotes the conditional entropy of \(X\) given \(T\)
ICML_2024_oral_15,9,"=E_{X,T,Q}\log\frac{p(X|Q)}{p(T|Q)}\frac{p(T)}{p(X)}",,"I(X;Q|T)=E_{X,T,Q}\log\frac{p(X,Q|T)}{p(X|T)p(Q|T)}=H(X|T)+H(Q|T)-H(X,Q|T)","where \(H(X|T)\) and \(H(Q|T)\) are conditional entropies, and \(H(X,Q|T)\) is the joint conditional entropy"
ICML_2024_oral_22,1,"x_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\Big{(}x_{t}-\frac{1-\alpha_{t}} {\sqrt{1-\bar{\alpha}_{t}}}\epsilon_{\theta}(x_{t},t,c)\Big{)}+\sigma_{t}\epsilon","where \(\mathbf{\epsilon}\sim\mathcal{N}(0,I)\), \(\alpha_{0}:=1\), \(\alpha_{t}\) and \(\bar{\alpha}_{t}\) define the noise schedule, \(\sigma_{t}\) is the sampling standard deviation",x_{t}=\sqrt{\bar{\alpha}_{t}} x_{t-1}+\sqrt{1-\bar{\alpha}_{t}}\epsilon_{t},"The equation represents the forward process of a denoising diffusion probabilistic model, where $x_{t}$ is the noisy data at step $t$, $\bar{\alpha}_{t}$ is the cumulative product of the noise schedule, and $\epsilon_{t}$ is the noise added at step $t$."
ICML_2024_oral_22,2,"x_{T}^{*}=\arg\min_{x_{T}}L(f(x_{0}),y) || x_{0}=\texttt{Sampler}_{T}(\epsilon_{\theta},x_{T},c)",,"x_{0}=\texttt{Sampler}_{T}(\epsilon_{\theta},x_{T},c)","where \(\mathbf{x}_{0}\) is the final output of the diffusion model after \(T\) sampling steps, \(\mathbf{\epsilon}_{\theta}\) is the neural network, \(\mathbf{x}_{T}\) is the initial noise latents, and \(\mathbf{c}\) is the conditioning information"
ICML_2024_oral_24,1,"\omega_{1}(D_{1},D_{2},J)=\frac{1}{N}\sum_{i=1}^{N}\mathds{1}\{J(q_{i},a_{i1}, a_{i2})=a_{i1}\}",,"\omega_{1}=\frac{1}{N}\sum_{i=1}^{N}I(J(q_{i}, D_{1}(q_{i}), D_{2}(q_{i}))=D_{1}(q_{i}))",The win rate \(\omega_{1}\) measures the frequency at which Judge \(J\) selects Debater \(D_{1}\)'s answer over Debater \(D_{2}\)'s answer.
ICML_2024_oral_24,2,"\bar{\omega}_{1}(D_{1},D_{2},J)>\frac{1}{2}",,"\bar{\omega}_{1}(D_{1},D_{2},J)=\frac{1}{2}\left(\omega_{1}(D_{1},D_{2},J)+\omega_{1}(D_{2},D_{1},J)\right)",\(\bar{\omega}_{1}\) represents the average win rate of debater \(D_{1}\) after flipping assignments to account for potential biases in the argument difficulty.
ICML_2024_oral_24,3,"\bar{\omega}_{1}(D_{1},D_{2},J)=\frac{1}{1+10^{(E_{2}-E_{1})/400}}",,"E_{1}=E_{2}+400\log_{10}\left(\frac{\bar{\omega}_{1}(D_{1},D_{2},J)}{1-\bar{\omega}_{1}(D_{1},D_{2},J)}\right)","The Elo rating \(E_{1}\) and \(E_{2}\) represent the latent skill of debaters \(D_{1}\) and \(D_{2}\) respectively, calculated based on their aggregate win rates against each other as judged by \(J\)."
ICML_2024_oral_24,4,"\omega_{C}(D_{1},D_{2},J)=\frac{1}{1+10^{(E^{I}_{2}-E^{C}_{1})/400}}",,"E^{C}_{1}=\frac{1}{1+10^{(E^{C}_{2}-E^{C}_{1})/400}}, E^{I}_{1}=\frac{1}{1+10^{(E^{I}_{2}-E^{I}_{1})/400}}",The correct rating \(E^{C}\) and incorrect rating \(E^{I}\) represent a player's ability to argue for correct and incorrect answers respectively.
ICML_2024_oral_25,1,"\min_{\theta}KL(p(Y|X)\|q(Y|X,\theta))",,"\min_{\theta^{(k)}}\sum_{i=1}^{N} L(x_i,y_i,\theta^{(k)})","The loss function \(L\) for the \(k\)th model in the Deep Ensemble, where \(\mathbf{x}_i\) and \(\mathbf{y}_i\) represent the input and output of the \(i\)th training sample, and \(\mathbf{\theta}^{(k)}\) represents the parameters of the \(k\)th model."
ICML_2024_oral_25,2,"H(q(Y|X))=\underbrace{I(Y;\theta| X)}_{D}+\underbrace{E_{q(\theta|D)}H(q(Y|X,\theta))}_{D}",where \(\mathcal{I}\) denotes the mutual information under the \(q\) distribution,"q(Y|X)=\int q(Y|X,\theta)p(\theta|D)d\theta",The predictive distribution of the model given input \(\mathbf{X}\) and the model parameters \(\mathbf{\theta}\) conditioned on the training dataset \(\mathcal{D}\).
ICML_2024_oral_25,3,H(q(Y|X))=\underbrace{I(Y;C|X)}_ {Q^{\prime}}+\underbrace{E_{q(C|X)}H( q(Y|X\oplusC))}_{Q^{\prime}},,H(q(Y|X))=\underbrace{I(Y;C|X)}_{aleatoric uncertainty}+\underbrace{E_{q(C|X)}H(q(Y|X\oplusC))}_{epistemic uncertainty},"where \(\mathcal{I}\) denotes the mutual information under the \(q\) distribution, and the first term represents the aleatoric uncertainty and the second term represents the epistemic uncertainty."
ICML_2024_oral_26,1,"&Attention(Q,K,V)=softmax(QK^{\intercal})V,\\&where Q,K,V\inR^{n\times d}",where \(n\) denotes the number of tokens and \(d\) denotes the hidden dimension of the attention,Q\cdot K^T/\sqrt{d}\cdot V,"The self-attention mechanism is composed of queries \(Q\), keys \(K\), and values \(V\)."
ICML_2024_oral_26,2,"& o_{i}=\sum_{j=1}^{n}\frac{e^{q_{i}k_{j}^{\intercal}} }{\sum_{j^{\prime}=1}^{n}e^{q_{i}k_{j^{\prime}}^{\intercal}}v_{j}},\\&where q_{i},k_{i},v_{i}\inR^{1\times d},i=\{1,2,...,n\}",,"o_{i} &=\sum_{j=1}^{n}\frac{\exp(q_{i}\cdot k_{j})}{\sum_{k=1}^{n}\exp(q_{i}\cdot k_{k})} v_{j},\\&for  i=1, 2, ..., n","where \(o_{i}\) represents the output for the \(i\)-th token, computed by attending to all tokens based on the similarity between query \(q_{i}\) and keys \(k_{j}\), and weighted by the corresponding value \(v_{j}\)."
ICML_2024_oral_26,3,"o_{i}=\sum_{j=1}^{n}\frac{K(q_{i},k_{j})}{\sum_{j^{\prime}=1}^{n}K( q_{i},k_{j^{\prime}})}v_{j}",,"o_{i}&=\sum_{j=1}^{n}\frac{K(q_{i},k_{j})}{\sum_{j^{\prime}=1}^{n}K(q_{i},k_{j^{\prime}})}v_{j},\\&where q_{i},k_{i},v_{i}\inR^{1\times d},i=\{1,2,...,n\}","The kernel function \(K(\cdot,\cdot)\) measures similarity between query \(q_{i}\) and key \(k_{j}\)."
ICML_2024_oral_26,4,o_{i}=\sum_{j=1}^{n}\frac{\phi(q_{i})\phi(k_{j})^{\intercal}}{\sum_{j^{\prime }=1}^{n}\phi(q_{i})\phi(k_{j^{\prime}})^{\intercal}}v_{j},where \(\phi(\cdot):\mathbb{R}^{d}\rightarrow\mathbb{R}^{m}\) is a projection to map the inputs into \(m\) dimension features,o_{i}&=\sum_{j=1}^{n}\frac{\phi(q_{i})^{\intercal}\phi(k_{j})}{\sum_{j^{\prime}=1}^{n}\phi(q_{i})^{\intercal}\phi(k_{j^{\prime}})}v_{j}\\&=\phi(q_{i})^{\intercal}\left(\sum_{j=1}^{n}\phi(k_{j})v_{j}^{\intercal}\right)\left(\sum_{j^{\prime}=1}^{n}\phi(q_{i})^{\intercal}\phi(k_{j^{\prime}})\right)^{-1},where \(\phi(\cdot)\) denotes a feature map that projects the input to a higher dimensional space.
ICML_2024_oral_26,5,\phi_{PRF}(x)=e^{\omega x^{\intercal}-\frac{1+x^{2}}{2}},where \(\omega\in\mathbb{R}^{m\times d}\),"o_{i}&=\sum_{j=1}^{n}\frac{\phi(q_{i})\phi(k_{j})^{\intercal}}{\sum_{j^{\prime}=1}^{n}\phi(q_{i})\phi(k_{j^{\prime}})^{\intercal}}v_{j},\\\phi(x) &=\sqrt{\frac{2}{m}}\cos(\omega x+b),\\where \omega &\inR^{m\times d}, and  b\inR^{m}",where \(\phi(\cdot):\mathbb{R}^{d}\rightarrow\mathbb{R}^{m}\) is a projection to map the inputs into \(m\) dimension features using Positive Random Features (PRF)
ICML_2024_oral_26,6,"K(x,z)=\int_{R^{d}}e^{i(x-z)^{\intercal}w}p(w)dw=E_{w\sim p(\cdot)}[ e^{iw^{\intercal}x}(e^{iw^{\intercal}z})^{\intercal}]",,"K(q,k)=\int_{R^{d}} e^{i\omega^{\intercal}(q-k)}p(d\omega)","where \(K(q,k)\) represents the kernel function, \(q\) and \(k\) denote the query and key vectors, \(p(d\omega)\) is a unique finite probability measure on \(\mathbb{R}^{d}\), and \(\omega\) is the frequency variable"
ICML_2024_oral_26,7,"K(x,z)=E_{w\sim p(\cdot)}[e^{iw^{\intercal}x}(e^{iw^{\intercal}z})^{\intercal }]\approx\varphi_{p}(x)^{\intercal}\varphi_{p}^{*}(z)",where \(w_{i}\sim p(\cdot)\) are samples constructed by Monte Carlo methods,"\varphi_{p}(x):=\frac{1}{\sqrt{m}}[e^{-iw_{1}^{\intercal}x},...,e^{-iw_{m}^{\intercal}x}]^{\intercal}",where \(w_{i}\) are i.i.d samples from the probability density \(p(w)\) and \(m\) is the number of samples.
ICML_2024_oral_26,8,"K_{G}(x,y):=e^{-\frac{\|x-y\|^{2}}{2}}=e^{-\frac{\|x\|^{2}+\|y\|^{2}}{2}}e^{x ^{\intercal}y}",,"\varphi_{p}(x)=\frac{1}{\sqrt{m}}[e^{iw_{1}^{\intercal}x},...,e^{iw_{m}^{\intercal}x}]^{\intercal}",where \(w_{i}\) are samples from a specific uniform distribution used in the Quasi-Monte Carlo method for estimating the integral.
ICML_2024_oral_26,9,"\varphi_{PFF}(x):=\frac{e^{-\|x\|^{2}}}{\sqrt{m}}[e^{\Phi^{-1}(t_{1}) x^{\intercal}v_{1}},...,e^{\Phi^{-1}(t_{m})x^{\intercal}v_{m}}]^{\intercal}",,"\varphi_{PFF}(x)=\frac{1}{\sqrt{m}}[e^{iw_{1}^{\intercal}x},...,e^{iw_{m}^{\intercal}x}]^{\intercal}",where \(w_{i}\) are samples constructed by Quasi-Monte Carlo methods and \(m\) is the dimension of the feature space
ICML_2024_oral_26,10,"\varphi_{WPFF}(x):=\frac{De^{-\|x\|^{2}}}{\sqrt{m}}[e^{\Phi^{-1}(t_{1 })x^{\intercal}v_{1}},...,e^{\Phi^{-1}(t_{m})x^{\intercal}v_{m}}]^{\intercal}",,"\varphi_{WPFF}(x):=\frac{e^{-\|x\|^{2}}}{\sqrt{m}}[e^{\Phi^{-1}(t_{1}) x^{\intercal}v_{1}}\cdot\frac{1}{\Phi^{-1}(t_{1})},...,e^{\Phi^{-1}(t_{m})x^{\intercal}v_{m}}\cdot\frac{1}{\Phi^{-1}(t_{m})}]^{\intercal}","where \(V=[v_{1},...,v_{m}]\in\mathbb{S}^{d\times m}\) is asymptotically uniformly distributed and \(t_{i}\sim U(0,1)\)."
ICML_2024_oral_26,11,\smallC_{j_{1}j_{2}}=s_{j_{1}}s_{j_{2}}\sum_{i_{1}=0}^{n-1}\sum_{i_{2}=0 }^{d-1}\cos(\frac{\pi(2i_{1}+1)j_{1}}{2d})\cos(\frac{\pi(2i_{2}+1)j_{2}}{2d}),where \(s_{j}=\sqrt{1/d}\) if \(j=0\) and \(s_{j}=\sqrt{2/d}\) otherwise,"C_{i,j}=\sum_{k=1}^{d}\varphi_{WPFF}(x_{k})_{i}\varphi_{WPFF}(x_{k})_{j}","where \(\mathcal{C}_{i,j}\) represents the DCT coefficient at position (i, j) in the frequency domain."
ICML_2024_oral_26,12,\small\phi_{WDCF}(x)=De^{TCx^{\intercal}},"where \(\mathcal{C}\in\mathbb{R}^{m\times d}\) is the DCT coefficient, \(D\in\mathbb{R}^{m}\) is a learnable weight, and \(T=\text{diag}(t_{1},\dots,t_{m})\) is a random diagonal matrix following the inverse cumulative distribution","\varphi_{WDCF}(x):=\frac{De^{-\|x\|^{2}}}{\sqrt{m}}C[e^{\Phi^{-1}(t_{1})x^{\intercal}v_{1}},...,e^{\Phi^{-1}(t_{m})x^{\intercal}v_{m}}]^{\intercal}",where \(\mathcal{C}\) is the DCT coefficient and \(D\) is a learnable parameter which can be optimized by the input \(x\).
ICML_2024_oral_26,13,"\smallFKA(Q,K,V)=\phi_{WDCF}(Q)\phi_{WDCF}(K)^{\intercal}V,\\where Q,K,V\inR^{n\times d}",,"o_{i}&=\sum_{j=1}^{n}\frac{\phi_{WDCF}(q_{i})\phi_{WDCF}(k_{j})^{\intercal}}{\sum_{j^{\prime}=1}^{n}\phi_{WDCF}(q_{i})\phi_{WDCF}(k_{j^{\prime}})^{\intercal}}v_{j},\\&where \phi_{WDCF}(x)=De^{TCx^{\intercal}}","The kernelized attention in frequency domain (FKA) is a reformulation of the attention mechanism using the weighted discrete cosine features (WDCF) as the kernel, which closely approximates the original attention mechanism while having low computational complexity."
ICML_2024_oral_28,1,f\in\operatorname*{argmin}_{f}\sup_{e\inE}R^{e}(\tilde{f}),"where the risk \(R^{e}(f)=\mathbb{E}_{(x,y)\sim P^{e}}[\ell(f(x),y)]\) measures the average loss \(\ell\) incurred by the predictor \(f\) across examples from environment \(e\), all of them drawn iid from \(P^{e}\)",f(x)=y\quad\forall e\inE,The predictor function f maps inputs x to labels y across all environments e in the set of environments \(\mathcal{E}\).
ICML_2024_oral_28,2,(p_{y_{i}^{out}}^{out}-1/n_{classes})\cdot n_{ classes}/(n_{classes}-1),,"p(y_{i}|x_{i})=\frac{1}{n_{classes}}\cdot\frac{\exp(-\ell(f^{a}(x_{i}),y_{i}^{out}))}{\sum_{j=1}^{n_{classes}}\exp(-\ell(f^{a}(x_{i}),j))}","where \(p(y_{i}|x_{i})\) is the probability of flipping the label \(y_{i}\) of example \((x_{i},y_{i})\) into the held-out predicted class label \(y_{i}^{\text{out}}\), and \(\ell\) is the loss function used to train the twins."
ICML_2024_oral_28,3,"\llbracket(y\notin\operatorname*{argmax}_{j}f^{a}(x)_{j})\,\vee\,(y\notin\operatorname*{argmax}_{j}f^{b}(x)_{j})\rrbracket","where ""\(\vee\)"" denotes logical-OR, and ""\(\llbracket\)"" is the Iverson bracket","e(x,y)=I[f^{a}(x)\neq y and  f^{b}(x)\neq y]","where \(e(x,y)\) is the binary environment annotation for example \((x,y)\), and \(f^{a}(x)\) and \(f^{b}(x)\) are the predictions of the two twin classifiers."
ICML_2024_oral_28,4,Y\perp E\mid X_{inv},,"X_{inv}\perp\!\!\!\perp E\,|\,Y","where \(X_{\text{inv}}\) is the invariant feature, \(E\) is the set of environments, and \(Y\) is the target variable"
ICML_2024_oral_3,1,"\operatorname*{argmin}_{\Theta_{T},M_{T}}\frac{1}{|D|}\sum_{x,y\inD}L(x,y|\Theta_{T},M_{T})",,"\min_{M_{t},R_{t}}L\quads.t.\quad\frac{\|\Theta\|_{0}}{\|\Theta\|_{0}+\|\Theta_{pruned}\|_{0}}\leq\gamma_{t},\|M_{t}\|_{0}\leq\Delta_{t}",The equation represents the optimization problem for minimizing task loss under the constraints of target sparsity and limited tuning parameters at each training step.
ICML_2024_oral_3,2,"1-\frac{C(\Theta_{t},M_{t})}{C(\Theta_{0},M_{0})}\geq\gamma_{t} || \delta(\Theta_{t},M_{t},R_{t})\leq\Delta_{t} || \forall t\in\{0,1,\dots,T\}",,"\gamma_{t}\leq\frac{\left\lVertM_{t}\right\rVert_{0}}{d}\leq\gamma_{T},\quad\left\lVertR_{t}\right\rVert_{0}\leq\Delta_{t}","The equation represents the constraints for the optimization process, where \(\gamma_{t}\) and \(\gamma_{T}\) are the minimum and target sparsity levels, \(d\) is the total number of parameters, \(\mathcal{M}_{t}\) is the pruning mask at step \(t\), \(\mathcal{R}_{t}\) is the tuning rank at step \(t\), and \(\Delta_{t}\) is the maximum number of tuning parameters at step \(t\)."
ICML_2024_oral_3,3,H_{apt}(X)=m_{o}\circ(W+s\cdot W_{B}W_{A})X\circ m_{i},"where \(s\) is the constant scaling factor following LoRA's implementation, and \(\circ\) denotes the Hadamard product between the masks and their corresponding matrices",H_{apt}(X)=W_{B}\cdot\sigma(W_{A}\cdot (m_{i}\odot X))\cdot m_{o},"The APT adapter projects the input \(X\) to the output \(H_{\text{apt}}(X)\) using dynamic binary pruning masks \(m_{i}\) and \(m_{o}\), and tuning parameters \(W_{A}\) and \(W_{B}\) with rank \(r_{\text{apt}}\)."
ICML_2024_oral_3,4,"S(W_{i,j})=|W_{i,j}\cdot\frac{\partialL}{\partial W_{i,j}}|",,S_{t}=\left|W_{t}\cdot\frac{\partialL}{\partial W_{t}}\right|,"where \(S_{t}\) is the salience score of parameters at training step \(t\), \(W_{t}\) is the model weight at step \(t\), and \(\frac{\partial \mathcal{L}}{\partial W_{t}}\) is the gradient of the loss \(\mathcal{L}\) with respect to \(W_{t}\)."
ICML_2024_oral_3,5,"\widetilde{S}_{t}(W_{:,j})=\sum_{(x,y)\inD_{t}}\sum_{i}|\frac{\partialL (x,y|\Theta_{t},M_{t})}{\partial H_{j,i}}| || \sum_{(x,y)\inD_{t}}\sum_{i}|H_{j,i}| || \hat{S}((W_{:,j})=\widetilde{S}(W_{:,j})+(Kurt(O_{j:}))^{\frac{1}{2}}",,"\hat{S}(W_{i,j})=|W_{i,j}\cdot\frac{\partialL}{\partial W_{i,j}}|\cdotkurtosis(act_{i,j})",The outlier-aware salience score is defined as the product of the magnitude of the weight-gradient and the kurtosis of the activation.
ICML_2024_oral_3,6,C(\Theta_{t};M_{t})\approx d_{m}\sum_{i=1}^{n_{L}}(4n_{h} ^{i}\cdot d_{h}+2n_{f}^{i}),where \(d_{h}\) is the dimension per MHA head,"C(\Theta_{t},M_{t})=n_{L}\cdot(d_{m}\cdot n_{h}^{i}+d_{m}\cdot n_{f}^{i})",The total number of parameters in the language model at training step t.
ICML_2024_oral_3,7,"L&=\muL_{ distill}+(1-\mu)L_{ft}\\L_{layer}&=\sum_{i=1}^{T}MSE(Tr(H_{s}^{\phi(i)}),H_{t}^{i})","where \(\mu\) is a moving term linearly scales from 0 to 1 during distillation to encourage the pre-pruned model vastly fit to the training data, \(\mathcal{L}_{distill}\) is the distillation objective from CoFi, and \(\mathcal{L}_{ft}\) is the supervised fine-tuning objective","L_{distill}=\sum_{x,y\inD}\alpha\cdotMSE(Softmax(\frac{z^{s}}{\tau}),Softmax(\frac{z^{t}}{\tau}))+(1-\alpha)\cdotL(x,y|\Theta_{t},M_{t})","where \(z^{s}\) and \(z^{t}\) are the student and teacher model's logits, \(\tau\) is the temperature, and \(\alpha\) is a hyperparameter to balance the distillation loss and the task loss."
ICML_2024_oral_30,1,W^{\prime}=W_{0}+\Delta W=W_{0}+\underline{BA},"where \(W_{0}\) remains static during the fine-tuning process, and the underlined parameters are being trained",W^{\prime}=W_{0}+BA,The fine-tuned weight \(W^{\prime}\) is represented as the sum of the pre-trained weight \(W_{0}\) and the product of two low-rank matrices \(B\) and \(A\).
ICML_2024_oral_30,2,W=m\frac{V}{ || V || _{c}}= || W || _{c}\frac{W}{ || W || _{c}},"where \(m\in\mathbb{R}^{1\times k}\) is the magnitude vector, \(V\in\mathbb{R}^{d\times k}\) is the directional matrix, with \(||\cdot||_{c}\) being the vector-wise norm of a matrix across each column",W=\frac{W}{\|W\|_F}\cdot\|W\|_F=dir(W)\cdotmag(W),The weight matrix W is decomposed into two components: direction and magnitude.
ICML_2024_oral_30,3,"\Delta M_{FT}^{t}=\frac{\sum_{n=1}^{k}|m_{FT}^{n,t}-m_{0}^{n}|}{ k} || \Delta D_{FT}^{t}=\frac{\sum_{n=1}^{k}(1-\bf cos(V_{FT}^{ n,t},W_{0}^{n}))}{k}",,"\Delta m=m_{FT}-m_{0},\Delta V=\frac{V_{FT}}{ || V_{FT} || _{c}}-\frac{V_{0}}{ || V_{0} || _{c}}",where \(\Delta m\) and \(\Delta V\) represent the magnitude and directional variations between the pre-trained weight \(W_{0}\) and the full fine-tuned weight \(W_{\text{FT}}\)
ICML_2024_oral_30,4,W^{\prime}=\underline{m}\frac{V+\Delta V}{ || V+\Delta V || _{c}}=\underline{m}\frac{W_{0}+\underline{BA}}{ || W_{0}+\underline{BA} || _{c}},"where \(\Delta V\) is the incremental directional update learned by multiplying two low-rank matrices \(B\) and \(A\), and the underlined parameters denote the trainable parameters",W^{\prime}=m\frac{V+\underline{BA}}{ || V+\underline{BA} || _{c}},"where \(m\) and \(V\) are the magnitude and directional components of the pre-trained weight \(W_{0}\), and \(BA\) represents the low-rank update to the directional component"
ICML_2024_oral_30,5,\nabla_{V^{\prime}}L=\frac{m}{ || V^{\prime} || _{c}}(I-\frac{V^{\prime}V^{\primeT}}{ || V^{\prime} || _{c}^{2}})\nabla_{W^{\prime}}L || \nabla_{m}L=\frac{\nabla_{W^{\prime}}L\cdot V^{\prime}}{ || V^{\prime} || _{c}},,\frac{\partialL}{\partial m}=\frac{\partialL}{\partial W^{\prime}}\frac{\partial W^{\prime}}{\partial m}=\frac{\partialL}{\partial W^{\prime}}\frac{V+\Delta V}{ || V+\Delta V || _{c}},"where \(m\in\mathbb{R}^{1\times k}\) is the magnitude vector, \(V\in\mathbb{R}^{d\times k}\) is the directional matrix, with \(||\cdot||_{c}\) being the vector-wise norm of a matrix across each column, and \(\frac{\partial \mathcal{L}}{\partial W^{\prime}}\) is the gradient of the loss with respect to \(W^{\prime}\)"
ICML_2024_oral_30,6,"cos(\nabla_{w^{\prime}}L,v^{\prime})=cos(\nabla_{w^{\prime}}L,v)=\frac{\nabla_{w^{\prime}}L\cdot v}{ || \nabla_{w^{\prime}}L ||  || v || }",,"\Delta D=1-\textbf{cos}(\Delta w, w^{\prime})=1-\frac{\Delta w\cdot w^{\prime}}{ || \Delta w || \cdot || w^{\prime} || }=1-\frac{\nabla_{w^{\prime}}L\cdot w^{\prime}}{ || \nabla_{w^{\prime}}L || \cdot || w^{\prime} || }","where \(\Delta D\) represents the directional difference between the updated weight and the original weight, \(\Delta w\) is the update vector, \(w^{\prime}\) is the current weight vector, and \(\nabla_{w^{\prime}}\mathcal{L}\) is the gradient of the loss with respect to \(w^{\prime}\)"
ICML_2024_oral_30,7,"\nabla_{m_{*}}L=\frac{\nabla_{w^{\prime}}L\cdot v^{\prime }}{ || v^{\prime} || }= || \nabla_{w^{\prime}}L || \cdot cos(\nabla_{w^{\prime}}L,v)",,"\frac{\partial\cos(\nabla_{w^{\prime}}L,v^{\prime})}{\partial m_{*}}=\frac{\partial }{\partial m_{*}}\left(\frac{\nabla_{w^{\prime}}L\cdot v}{ || \nabla_{w^{\prime}}L ||  || v || }\right)=\frac{\partial }{\partial m_{*}}\left(\frac{\nabla_{w^{\prime}}L\cdot (m_{*}v)}{ || \nabla_{w^{\prime}}L ||  || m_{*}v || }\right)=\frac{\partial }{\partial m_{*}}\left(\frac{\nabla_{w^{\prime}}L\cdot (m_{*}v)}{ || \nabla_{w^{\prime}}L || |m_{*} ||  || v || }\right)=\frac{\partial }{\partial m_{*}}\left(\frac{\nabla_{w^{\prime}}L\cdot v}{ || \nabla_{w^{\prime}}L ||  || v || }\right)","where \(m_{*}\) is the magnitude scalar of vector \(w^{\prime}\), and \(\frac{\partial \cos(\nabla_{w^{\prime}}\mathcal{L},v^{\prime})}{\partial m_{*}}\) represents the partial derivative of the cosine similarity with respect to \(m_{*}\)"
ICML_2024_oral_30,8," || \nabla_{w^{\prime}}^{S1}L || \cdot|cos(\nabla_{w^{\prime}}^{S1}L,v)|> || \nabla_{w^{\prime}}^{S2}L || \cdot|cos(\nabla_{w^{\prime}}^{S2}L,v)|",,\nabla_{m_{*}}L_{S1} >\nabla_{m_{*}}L_{S2},"where \(\nabla_{m_{*}}\mathcal{L}_{S1}\) and \(\nabla_{m_{*}}\mathcal{L}_{S2}\) denote the gradients of the loss with respect to the magnitude scalar in scenarios S1 and S2, respectively"
ICML_2024_oral_30,9,\nabla_{V^{\prime}}L=\frac{m}{C}\nabla_{W^{\prime}}L\text { where }C= || V^{\prime} || _{c},,\nabla_{V^{\prime}}L=\frac{m}{ || V^{\prime} || _{c}}\nabla_{W^{\prime}}L,"where \(m\) is the magnitude vector, \(V^{\prime}\) is the updated directional matrix, and \(\nabla_{W^{\prime}}\mathcal{L}\) is the gradient of the loss with respect to \(W^{\prime}\)"
ICML_2024_oral_37,1,"P_{t}=\{W_{t},O_{t}\}",,"P_{t}=\{W_{t},O_{t}\}",\(\mathcal{P}_{t}\) represents a checkpoint of a neural network at the \(t^{th}\) training iteration.
ICML_2024_oral_37,2,"P=\{P_{1},P_{2},\cdots,P_{t}\,\cdots,P_{T}\}",,"P=\{P_{1},P_{2},\ldots,P_{T}\}",\(\mathcal{P}\) represents the series of checkpoints saved during training.
ICML_2024_oral_37,3,"O_{t}=\{v_{t},m_{t}\}",,v_{t}=\beta_1 m_{t-1}+(1-\beta_1)\nablaL(W_{t}),The variables \(v_{t}\) and \(m_{t}\) represent the first-order and second-order moments of the Adam optimizer at the \(t^{th}\) iteration.
ICML_2024_oral_37,4,"\DeltaP_{t}=\{\DeltaW_{t},O_{t}\}=\{W_ {t}-W_{t-1},O_{t}\}",,"\DeltaP_{t}=\{\DeltaW_{t},O_{t}\}=\{W_{t},W_{t-1},O_{t}\}=\{W_{t}-W_{t-1},O_{t}\}","The residual checkpoint \(\Delta\mathcal{P}_{t}\) is defined as the difference between the current model weights and the previous model weights, along with the current optimizer momentum states."
ICML_2024_oral_37,5,"r_{w}=\frac{\alpha}{\sqrt{m_{t}}}\timesmedian(W),M _{w}(i)=\mathds{1}_{w_{t}(i)>r_{w}}",,"M_{w}=\topk(\DeltaW_{t}, k)","The pruning mask for model weights, where \(\topk\) denotes the top-k operator that selects the top k elements with the largest second-order moment of gradients of weights."
ICML_2024_oral_37,6,"r_{o}=\beta\timesmean(v_{t}),M_{o}(i)=\mathds{1}_{v_{t}(i)> r_{o} and M_{w}(i)=1}",,"r_{o}=\frac{\beta}{\sqrt{v_{t}}}\timesmedian(O),M_{o}(i)=\mathds{1}_{o_{t}(i)>r_{o}}.M_{w}(i)","\(r_{o}\) represents the pruning threshold for momentum states, \(\beta\) is a hyperparameter, \(v_{t}\) is the first-order moment, and \(\mathcal{M}_{w}(i)\) is the pruning mask for weights."
ICML_2024_oral_37,7,"\tilde{R}(T)\leq\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}\sqrt {T\widehat{v}_{T,i}} || +\frac{\alpha(1+\beta_{1})G_{\infty}}{(1-\beta_{ 1})\sqrt{1-\beta_{2}}(1-\gamma)^{2}}\sum_{i=1}^{d}\|g_{1,\tau,i}\|_{2} || +\frac{D_{\infty}^{2}G_{\infty}\sqrt{1-\beta_{2}}}{2\alpha}\sum_ {i=1}^{d}\sum_{t=1}^{t}\frac{\beta_{1,t}}{(1-\beta_{1,t})}\sqrt{t} || +\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}})",,\left\|\theta_{T}-\theta^{*}\right\|_{2}\leq\frac{2\alpha\sqrt{D^{2}+2\log(T)}}{\sqrt{T}(1-\beta_{1})}+\frac{2\alpha G_{\infty}\sqrt{\log(T)}}{\sqrt{T}(1-\beta_{1})}+\frac{2\alpha\beta_{1}D_{\infty}}{1-\beta_{1}}+\frac{\alpha\beta_{1}\lambda^{\tau-1}G_{\infty}}{(1-\beta_{1})(1-\lambda)}.\,The equation represents the convergence guarantee of Adam optimizer with joint weight-momentum pruning.
ICML_2024_oral_37,8,"\Delta\tilde{R}(T)&=\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}})\\&=\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}(1-M_{o})})",,"\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}})","The additional term in the regret bound for the checkpoint compression method, which accounts for the pruning of momentum states."
ICML_2024_oral_37,9,\lim_{Tarrow\infty}\frac{\tilde{R}(T)}{T}\leq\lim_{Tarrow\infty}\frac{R(T)+\Delta\tilde{R}(T)}{T}=0,,R(T)\leq\tilde{R}(T)+\Delta\tilde{R}(T),The regret bound of the proposed checkpoint compression method.
ICML_2024_oral_37,10,\frac{R(T)}{T}=O(\frac{1}{\sqrt{T}}),,\lim_{T\to\infty}\frac{\tilde{R}(T)}{T}=0,The limit of the average regret of the proposed method as the number of iterations approaches infinity is zero.
ICML_2024_oral_4,1,S_{opt_{t}}=\arg\min_{S\subseteq V_{t}}\{\textsc{Cost}(S):f(S)=f(V_{t})\}\enspace,where \(V_{t}\) denotes the set of the currently present elements after the first \(t\) updates,\min_{S\subseteq V_t}\textsc{Cost}(S)\quads.t.\quad f(S)=f(V_t),"The equation represents the dynamic submodular cover problem, where the goal is to find a subset S of minimum cost that satisfies the submodular function constraint f(S) = f(V_t) at each time step t."
ICML_2024_oral_4,2,"f(S)\geq(1-\epsilon)f(V),\quadand\quad\textsc{Cost}(S)\leq c\textsc{ Cost}(S_{opt})",where \(S_{opt}\) denotes the optimal solution,"f(S)\geq(1-\epsilon)f(V)\enspace,\quad\textsc{Cost}(S)\leq c\cdot\textsc{OPT}_{\textsc{cost}}\enspace","A set \(S\) is called a \((1-\epsilon,c)\)-bicriteria approximate solution if it satisfies the given conditions for \(f(S)\) and \(\textsc{Cost}(S)\)."
ICML_2024_oral_4,3,"E[\,X(r)\,]\geq 1-2\epsilon for all r\in[1,m^{*}] and || E[\,X(m^{*}+1)\,]\leq 1-\frac{\epsilon}{2}",,\log_{1+\epsilon}\left(\frac{f(V)\cdot\epsilon}{OPT_{cost}}\right)=\log_{1+\epsilon}\left(\frac{f(V)\cdot\epsilon}{\sum_{v\in S_{opt}}w(v)}\right),where \(S_{opt}\) denotes the optimal solution and \(\text{OPT}_{\text{cost}}\) denotes the cost of the optimal solution
ICML_2024_oral_41,1,"\min_{\theta_{1},\theta_{2},...,\theta_{N}}[\frac{1}{N}\sum_{i=1}^{N}L_{i}(\theta_{i})]+R(\theta_{1},\theta_{2},...,\theta_{N})",,"\min_{\theta_1,\theta_2, ...,\theta_N}\sum_{i=1}^NE_{(x_{ij}, y_{ij})\simD_i}\left[\ell(f_{A_i}(x_{ij};\theta_i), y_{ij})\right]","The global objective of Multimodal Federated Learning (MFL) is to minimize the sum of expected losses over all clients, where each client's loss is calculated using its local dataset and mapping function."
ICML_2024_oral_41,2,A_{i}\capA_{i^{\prime}}=\{B_{enc}^{(m)}|\forall m\inI_{i}\capI_{i^{\prime}}\}\cup\{B_{share}\},,"A_{i}:=\{B_{enc}^{(m)}|\forall m\inI_{i}\}\cup\{B_{share}\}\cup\{B_{dec,i}\}",The architecture-compositional MFL definition describes how heterogeneous multimodal model architectures are split into smaller homogeneous blocks to facilitate knowledge sharing among clients.
ICML_2024_oral_41,3,A_{i}\capA_{i^{\prime}}=\emptyset,,A_{i}\capA_{i^{\prime}}=\emptyset,"The intersection of the model architectures of any two clients is an empty set, indicating no shared blocks or weights between them."
ICML_2024_oral_41,4,"\theta_{i}:=h(A_{i},c_{i};\phi),\\\\forall i\in[N]","where the first generative factor \(\mathcal{A}_{i}\in\mathcal{G}\) is the local neural architecture from a globally-shared _latent topology space_\(\mathcal{G}\) and the second generative factor \(\mathbf{c}_{i}\in\mathcal{T}\) represents the lo

Figure 1: (a) Local mapping functions per client in Multimodal Federated Learning (MFL)","h(z_{i},g_{i};\phi)","The bridge function h takes two client-specific generative factors, a latent vector \(\mathbf{z}_{i}\) and a topological graph \(\mathbf{g}_{i}\), and outputs the re-parameterized weights for client i."
ICML_2024_oral_41,5,"A_{i}:=(V_{i},E_{i},Z_{i}^{(0)})",,"A_{i}=(V_{i},E_{i})","The multimodal neural architecture at each client i is represented as a directed acyclic graph structure, where \(\mathcal{V}_{i}\) denotes the set of nodes and \(\mathcal{E}_{i}\) denotes the set of edges."
ICML_2024_oral_41,6,"h(A_{i},c_{i};\phi)=\texttt{Comb}(c_{i},\texttt{Role}(A_{i};\phi_{1});\phi_{2})","where the first stage \(\texttt{Role}(\cdot;\phi_{1})\) parameterized by \(\phi_{1}\) learns the implicit roles of layers such that layers across clients share a unified _layer-role embedding_ space, and the second stage \(\texttt{Comb}(\cdot,\cdot;\phi_{2})\) parameterized by \(\phi_{2}\) aims to combine the two heterogeneity patterns and directly generates the weights",Z_{i}^{(l+1)}=\sigma(A_{i}Z_{i}^{(l)}W^{(l)}),The node feature matrix is updated using a graph convolutional layer with a learnable weight matrix and an activation function.
ICML_2024_oral_41,7,"Z_{i}^{(L)}=\texttt{Role}(A_{i};\phi_{1}) || :=g_{L}\circ g_{L-1}\circ...\circ g_{1}(Z_{i}^{(0)}; V_{i},E_{i})",,"Z_{i}^{(l)}=\texttt{GNN}(Z_{i}^{(l-1)},V_{i},E_{i}),\\\l=1,2,...,L",The layer-role encoder is used to encode the implicit roles of layers in the neural architecture.
ICML_2024_oral_41,8,"z_{i,v}^{(l)}=\sigma(W_{self}^{(l)}z_{i,v}^{(l-1)}+W_{in}^{(l)}\sum_{(v^{\prime},v)\inE_{i}}z_{i,v^{\prime}}^ {(l-1)} || \qquad+W_{out}^{(l)}\sum_{(v,v^{\prime})\in E_{i}}z_{i,v^{\prime}}^{(l-1)}+b^{(l)})",,"z_{i,v}^{(l)}=g_{l}(z_{i,v}^{(l-1)},\texttt{AGG}_{e\inE_{i}:e=(v^{\prime},v)}[z_{i,v^{\prime}}^{(l-1)}])","The variable \(\mathbf{z}_{i,v}^{(l)}\) represents the node feature of node \(v\) at the \(l\)-th layer of the GNN."
ICML_2024_oral_41,9,"\theta_{i,v}:=g_{node}(c_{i}\oplusz_{i,v}^{(L)};\phi_{ 2}),\;\forall v\inV_{i}",where \(\oplus\) denotes an operation (e,"\theta_{i,v}=g_{node}(c_{i},z_{i,v}^{(L)};\phi_{2})","where \(\mathbf{z}_{i,v}^{(L)}\) is the layer-role embedding for node \(v\) in \(\mathcal{A}_{i}\), obtained from the first stage."
ICML_2024_oral_41,10,\Deltac_{i}=\nabla_{c_{i}}L_{i}(\theta_{i})=\Delta\theta_{i}\cdot\nabla_{c_{i}}\theta_{i} || \Delta\phi_{2}=\frac{1}{|N_{r}|}\sum_{i\inN_{r}}(\Delta\theta_{i}\cdot\nabla_{\phi_{2}}\theta_{i}) || \Delta\phi_{1}=\frac{1}{|N_{r}|}\sum_{i\inN_{r}}(\Delta\theta_{i}\cdot\nabla_{z_{1}^{(L)}}\theta_{i}\cdot\nabla_{\phi_{i} }Z_{i}^{(L)}),,"\min_{\phi}\frac{1}{|N_{r}|}\sum_{i\inN_{r}}\ell(\theta_{i}+\Delta\theta_{i},D_{i})=\min_{\phi}\frac{1}{|N_{r}|}\sum_{i\inN_{r}}\ell(h(A_{i},c_{i};\phi)+\Delta\theta_{i},D_{i})",The loss function measures the difference between the predicted weights and the true weights.
ICML_2024_oral_44,1,"\operatorname*{arg\,max}_{\theta\in\Theta}E_{G^{\prime}\sim D_{\theta}}[u_{\tau}(G^{\prime})]",where \(D_{\theta}\) is a parameterized distribution and \(\Theta\) represents a feasible set of real-valued parameters,\arg\max_{p(E)}E_{E\sim p(E)} [u_{\tau}(G_{E})],The equation represents the reformulated edge optimization problem as a continuous optimization over a probabilistic distribution of feasible DAGs.
ICML_2024_oral_44,2,"\prod_{i=1}^{d}\theta_{i}&if\,(N,E\cup(\{e_{j}\}_{j=1}^{i-1}\capE)\cup\{e_{i}\})\,is a DAG,\\0&otherwise",,p_{\theta}(G^{\prime})=\prod_{i=1}^{d}\theta_{i}^{I(e_{i}\inE)} (1-\theta_{i})^{I(e_{i}\notinE)},where \(\theta_{i}\) represents the probability of including edge \(e_{i}\) in the DAG \(G^{\prime}\).
ICML_2024_oral_44,3,\nabla_{\theta}E_{G_{E}\sim D_{\theta}} [u_{\tau}(G_{E})]\approx\frac{1}{M}\sum_{i=1}^{M}\hat{u}_ {\tau}(G_{i})\nabla_{\theta}\log(p_{\theta}(G_{i})),"where \(G_{1},G_{2},\ldots,G_{N}\sim D_{\theta}\) are mutually independent and \(\hat{u}_{\tau}(G_{i})\) is an independent unbiased estimate of \(u_{\tau}(G_{i})\) for all \(i\) and some \(M\in\mathbb{N}\)",\nabla_{\theta}E_{G^{\prime}\sim D_{\theta}}[u_{\tau}(G^{\prime})]=E_{G^{\prime}\sim D_{\theta}}[u_{\tau}(G^{\prime})\nabla_{\theta}\log D_{\theta}(G^{\prime})],The gradient of the expected utility with respect to the distribution parameters.
ICML_2024_oral_5,1,x_{i}^{\ell+1}=x_{i}^{\ell}+\texttt{MLP}^{\ell}(x_{i}^{\ell}+\texttt{Att}^{\ell}(x_{i}^{\ell})),,x_{i}=Ew_{i},"The embedding of the input token $w_{i}$ is denoted as $x_{i}$, which is the result of applying the embedding layer $E$ to $w_{i}$."
ICML_2024_oral_5,2,\texttt{MLP}^{\ell}(x^{\ell})=\sigma(W_{K}^{\ell}x^{\ell})W_{V}^{\ell},"where \(W_{K}^{\ell},W_{V}^{\ell}\in\mathbb{R}^{d_{mlp}\times d}\)",x_{i}^{\ellmid}=x_{i}^{\ell}+\texttt{Att}^{\ell}(x_{i}^{\ell}),The intermittent residual stream at layer \(\ell\) after the attention head and before the MLP block is denoted as \(\mathbf{x}^{\ell\text{mid}}\).
ICML_2024_oral_5,3,\texttt{MLP}^{\ell}(x^{\ell})=\sum_{i=1}^{d_{mlp}}\sigma(x^{\ell}\cdotk_{i}^{\ell})v_{i}^{\ell}=\sum_{i=1}^{d_{mlp}}m_{i} ^{\ell}v_{i}^{\ell},,\texttt{MLP}^{\ell}(x^{\ell})=\sum_{i=1}^{d_{mlp}}m_{i}^{\ell}v_{i}^{\ell},where \(m_{i}^{\ell}\) is the coefficient value and \(\mathbf{v}_{i}^{\ell}\) is the value-vector
ICML_2024_oral_5,4,"p\big{(}w\midx^{\ell}+m_{i}^{\ell}v_{i}^{\ell},E\big{)}\propto\exp\big{(}e_{w}\cdotx^{\ell}\big{)}\cdot\exp\big{(}e_{w}\cdot m_{i}^{\ell}v_{i}^{\ell}\big{)}",where \(\mathbf{e}_{w}\) is the embedding of \(w\),"v_{i}^{\ell}=\sum_{w\inV}\alpha_{w,i}^{\ell}E(w)","The value vector \(\mathbf{v}_{i}^{\ell}\) is a linear combination of the embedding vectors \(E(w)\) for each token \(w\) in the vocabulary \(\mathcal{V}\), where \(\alpha_{w,i}^{\ell}\) are the coefficients of the linear combination."
ICML_2024_oral_5,5,\texttt{GLU}^{\ell}(x^{\ell})=(\sigma(W_{1}x^{\ell})\odot W_{ 2}x^{\ell})W_{V}^{\ell},"where \(W_{1}^{\ell},W_{2}^{\ell},W_{V}^{\ell}\in R^{d_{mlp}\times d}\)",\texttt{GLU}^{\ell}(x^{\ell})=\sigma(W_{K}^{\ell}x^{\ell})\odot W_{V}^{\ell}x^{\ell},where \(\odot\) denotes the element-wise product and \(\sigma\) is the activation function
ICML_2024_oral_5,6,"P(Toxic|\bar{x}^{L-1})=softmax(W_{Toxic}\bar{x}^{L-1}),W_{Toxic}\inR^{d}",,W_{Toxic}=\arg\max_{W}\sum_{i=1}^{N} y_i\log(\sigma(W\bar{x}_i^{L-1}))+(1-y_i)\log(1-\sigma(W\bar{x}_i^{L-1})),"where \(y_i\) is the toxicity label for the \(i\)-th sample, \(\sigma\) is the sigmoid function, and \(N\) is the number of samples in the training set."
ICML_2024_oral_5,7,x^{L-1}=x^{L-1}-\alpha*W,where \(a\) is a heuristic scale value and \(W\) is one of our toxicity vectors,x_{i}^{L}=x_{i}^{L-1}-\alpha\cdot\texttt{MLP}^{L}(x_{i}^{L-1})\cdotToxicVector,"The ToxicVector variable represents the toxic vector used for intervention, which can be either \(W_{\text{Toxic}}\), \(\texttt{MLP}\mathbf{v}_{\text{Toxic}}\), or \(\texttt{SVD.U}_{\text{Toxic}}\), and \(\alpha\) is a scaling factor."
ICML_2024_oral_5,8,"L_{DPO}=-E[\log\sigma(\beta\log P-\beta\log N)] || P=\frac{\pi_{\theta}(y_{+}\midw)}{\pi_{ref}(y_{+}\midw)},N=\frac{\pi_{\theta}(y_{-}\midw)}{\pi_{ref}(y_{-}\midw)}",,L_{DPO}=-\log\frac{\exp(f(x^{+}))}{\exp(f(x^{+}))+\exp(f(x^{-}))},"where $f(\mathbf{x})$ is the log probability of the model generating $\mathbf{x}$, and $\mathbf{x}^{+}$ and $\mathbf{x}^{-}$ are the positive and negative samples, respectively."
ICML_2024_oral_5,9,p(y\mid a)\propto p(y)p(a\mid y),,L_{PPLM}=\log P(a|w)=\log\frac{\exp(g\cdoth)}{\sum_{a'\inA}\exp(g_{a'}\cdoth)},"where \(\mathbf{g}\) is the gradient that increases the likelihood of the desired attribute \(a\), and \(\mathbf{h}\) is the hidden state of the language model."
ICML_2024_oral_5,10,"\gamma(k_{i}^{\ell}):=\{g|g\inR^{d},\sigma(k_{i}^{\ell}\cdotg)>0\}",where \(\sigma\) is a non-linear activation,R_{i}^{\ell}=\{x^{\ell}\mid\sigma(x^{\ell}\cdotMLP.k_{i}^{\ell})>\tau\},where \(\tau\) is a threshold value
ICML_2024_oral_5,11,"\forall j<\ell,\forall i<d_{mlp}:cos(\delta_{x}^{\ell\_midmid},\delta_{MLP,v_{i}}^{j})",,"\cos(\delta_{x}^{\ell\_mid},\delta_{MLP,v}^{j})=\frac{\delta_{x}^{\ell\_mid}\cdot\delta_{MLP,v}^{j}}{\|\delta_{x}^{\ell\_mid}\|\|\delta_{MLP,v}^{j}\|}","where \(\delta_{\text{MLP},\mathbf{v}}^{j}\) is the difference in value vectors at layer \(j\), and \(\delta_{\mathbf{x}}^{\ell\_mid}\) is the difference in residual streams at layer \(\ell\_mid\)"
ICML_2024_oral_53,1,generalization gap\leq\sqrt{\frac{CMI_{D}(A_{n})}{n}},,"I(X;W)+\log(1/\delta)+\log(N(H,\epsilon, d))\label{eq:cmi_bound}","The equation represents the CMI-based generalization bound for SCO, where $I(\mathbf{X};\mathbf{W})$ is the mutual information between the input $\mathbf{X}$ and the learned model $\mathbf{W}$, $\delta$ is the confidence parameter, and $\mathcal{N}(\mathcal{H}, \epsilon, d)$ is the covering number of the hypothesis class $\mathcal{H}$."
ICML_2024_oral_53,2,F_{D}(A_{n}(S_{n}))-\min_{\theta\in\Theta}F_{D}(\theta)\leq\varepsilon,,O\left(\sqrt{\frac{1}{\varepsilon^{2}\cdot n}}\right),"The generalization gap of a learning algorithm is upper bounded by the square root of the ratio between the Conditional Mutual Information (CMI) of the algorithm and the sample size, which results in a vacuous generalization bound of order Ω(1) for the optimal choice of sample size."
ICML_2024_oral_53,3,CMI_{D}(A_{n})\triangleq I(A_{n}(S_{n}) ;U|\tilde{Z}),,CMI_{D}(A_{n})=I(U;A_{n}(S_{n})|S_{n}),"The conditional mutual information (CMI) of a learning algorithm with respect to a data distribution, which quantifies the amount of information that the algorithm's output contains about the training set."
ICML_2024_oral_53,4,E[F_{D}(A_{n}(S_{n}) )]-\min_{\theta\in\Theta}F_{D}(\theta) || \leqEGE_{D}(A_{n})+E\big{[}\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\big{]},,F_{D}(A_{n}(S_{n}))-\min_{\theta\in\Theta}F_{D}(\theta)\leqEGE_{D}(A_{n})+\left(\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)-\min_{\theta\in\Theta}F_{D}(\theta)\right),The equation represents the excess population error for an algorithm in a stochastic convex optimization problem.
ICML_2024_oral_53,5,E[F_{D}(A_{n}(S_{n}) )]-\min_{\theta\in\Theta}F_{D}(\theta) || \leq LR\sqrt{\frac{8CMI_{D}(A_{n})}{ n}}+E\big{[}\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\big{]},,E[F_{D}(A_{n}(S_{n}) )]-\min_{\theta\in\Theta}F_{D}(\theta)\leq LR\sqrt{8CMI_{D}(A_{n})/n}+E\big{[}\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\big{]},"The equation represents the excess population error for an algorithm, bounded using generalization and optimization error, with the generalization error further upper-bounded using CMI."
ICML_2024_oral_53,6,"ISCMI_{D}(A_{n})\triangleq\sum_{i=1}^{n}I(A_{n}(S);U_{i}|Z_{0,i},Z_{1,i})",,"ISCMI_{D}(A_{n})\triangleq\frac{1}{n}\sum_{i=1}^{n}I(A_{n}(S_{n});U_{i}|U_{-i},\tilde{Z})",The individual-sample conditional mutual information (ISCMI) of a learning algorithm.
ICML_2024_oral_53,7,E[\sum_{i=1}^{n}\sum_{k=1}^{d}(\frac{144\varepsilon^{2}-d(\mu^{(k)})^{2}}{1-d(\mu^{(k)})^{2}})(\hat{\theta} ^{(k)})(Z_{i}^{(k)}-\mu^{(k)})] || \quad\geq 2\varepsilon-4\delta,,"ISCMI_{D}(A_{n})\triangleq\sum_{i=1}^{n}I(A_{n}(S);U_{i}|Z_{0,i},Z_{1,i})","The individual sample conditional mutual information (ISCMI) of a learning algorithm \(\mathcal{A}_{n}\) with respect to a data distribution \(\mathcal{D}\), which measures the amount of information that \(\mathcal{A}_{n}\) reveals about each individual sample in the training set."
ICML_2024_oral_55,1,"D_{LCA}(y^{\prime},y):=f(y)-f(N_{LCA}(y,y^{\prime}))","where \(f(y)\geq f(N_{LCA}(y,y^{\prime}))\) and \(N_{LCA}(y^{\prime},y)\) denotes the lowest common ancestor class node for classes \(y\) and \(y^{\prime}\) within the hierarchy, and \(f(\cdot)\) represents a function of a node, such as the tree depth or entropy","d_{LCA}(y, y^{\prime})=\frac{1}{2} (h(y, lca(y, y^{\prime}))+h(y^{\prime}, lca(y, y^{\prime})))",The LCA distance measures the class ranking difference between a model's prediction and the ground truth class based on class taxonomy.
ICML_2024_oral_55,2,"D_{LCA}(model,M):=\frac{1}{n}\sum_{i=1}^{n}D_{LCA}(\widehat{y}_{i},y _{i})\iff y_{i}\neq\widehat{y}_{i}","where \(\widehat{y}_{i}\) is the predicted class for sample \(X_{i}\) using the model, \(y_{i}\) is the ground truth class for sample \(X_{i}\), and \(y_{i}\neq\widehat{y}_{i}\)",I(X_{i})=-\log P(X_{i}),The information content of a sample is defined as the negative logarithm of its probability.
ICML_2024_oral_58,1,"Sequence model:\hat{z}_{t},\,h_{t}=seq(z_{t-1},\,h_{t-1},\,a_{t-1}) || Multimodal encoder: z_{t}\simenc(x_{t},\,l_{t},\,h_{t}) || Multimodal decoder:\hat{x}_{t},\,\hat{l}_{t},\,\hat{r}_{t},\,\hat{c}_{t}=dec(z_{t},\,h_{t})",,"z_{t}=f(x_{t}, l_{t})","The discrete representation at time step t, which is a function of the image and language token."
ICML_2024_oral_58,2,"Image loss:\qquad\quadL_{x}=\|\hat{x}_{t}-x_{t}\|_{2}^{2} || Language loss:\qquad\quadL_{t}=catext(\hat {t}_{t},l_{t}) || Reward loss:\qquad\quadL_{r}=catext(\hat {r}_{t},twoot(r_{t})) || Continue loss:\qquad\quadL_{c}=binkent(\hat{c}_{t},c_{t}) || Regularizer:\qquad\quadL_{reg}=\beta_{reg}\max(1,KL\big{[}z_{t}\bigm{\|}\\sg(\hat{z}_{t})\big{]})",,"L_{repr}=catxent(\hat{x}_{t}, x_{t})+catxent(\hat{l}_{t}, l_{t})+binxent(\hat{r}_{t}, r_{t})+binxent(\hat{c}_{t}, c_{t})+\beta_{reg}\cdotcatxent(\hat{z}_{t},sg(z_{t}))","The representation learning loss \(\mathcal{L}_{\mathrm{repr}}\) is a sum of categorical and binary cross entropy losses for reconstructing observations and predicting rewards and episode continuation, with an additional regularization term to encourage predictable representations."
ICML_2024_oral_58,3,"Prediction loss:\quadL_{pred}=\beta_{pred}\\max(1,KL\big{[}\,sg(z_{t})\bigm{\|}\hat{z}_{t}\big{]})",where the gradient around the target distribution for \(z_{t}\) is stopped since it is also a learned representation and \(\beta_{\mathrm{pred}}=0,"L_{pred}=catxent(\hat{z}_{t}, z_{t})",The future prediction loss measures the difference between the predicted representation and the actual representation at the next timestep.
ICML_2024_oral_58,4,"Actor net:\quad\pi(a_{t}|h_{t},z_{t})\qquadCritic net:\quadV(h_{t},z_{t})",,L_{total}=L_{repr}+L_{pred},The total loss is the sum of the representation learning loss and the future prediction loss.
ICML_2024_oral_60,1,"\min_{M}\alphaL_{in}(f(M\odot X),y) || -\betaL_{out}(f((1-M)\odot X),y)+R(M)",,L_{mask}=L_{in}+L_{out},"The overall objective function for the masking loss, comprising the loss for the masked-in and masked-out portions."
ICML_2024_oral_60,2,"\min_{\theta}\lambda_{in}L_{in}(\log f(M_{\theta}(h)\odot X),y) || -\lambda_{out}L_{out}(\log f((1-M_{\theta}(h))\odot X),y)+R(M_{\theta}(h))",,"\min_{\theta}\alphaL_{in}(f(M_{\theta}(h)\odot X),y)-\betaL_{out}(f((1-M_{\theta}(h))\odot X),y)+R(M_{\theta}(h))",The optimization objective for the neural network decoder to estimate the binary mask M.
ICML_2024_oral_60,3,R(M_{\theta}(h))=\lambda_{g}\|M_{\theta}(h)\odot X-X\|+\lambda_{s}\|M_{\theta} (h)\|_{1},"where \(\lambda_{g}\) and \(\lambda_{s}\) are regularization coefficients, and \(X\) represents the spectrogram of the original signal","R(M_{\theta}(h))+\gammaL_{ft}(M_{\theta}(h), X, y)",The term \(\mathcal{L}_{ft}\) represents the fine-tuning loss that refines the interpretation mask to improve interpretation quality.
ICML_2024_oral_60,4,x_{interpretation}=ISTFT((M_{\theta}(h)\odot X)e^{jX_{ phase}}),,\hat{x}=ISTFT(M_{\theta}(h)\odot X\cdot e^{i\phi(x)}),The variable \(\hat{x}\) represents the reconstructed audio signal in the time domain.
ICML_2024_oral_60,5,FF_{n}:=f(X_{n})_{c}-f(X_{n}\odot(1-M_{\theta}(h)))_{c},,FF=\frac{1}{N}\sum_{i=1}^{N}\left(\log f_{y_i}(X_i)-\log f_{y_i}((1-M_{\theta}(h_i))\odot X_i)\right),The faithfulness on spectra metric measures the importance of the generated interpretation for a classifier by calculating the drop in class-specific logit value when the masked out portion of the interpretation mask is input to the classifier.
ICML_2024_oral_60,6,AI:=\frac{1}{N}\sum_{n=1}^{N}1_{[f(X_{n}\odot M_{\theta}(h))>f (X_{n})_{c}]}\cdot 100,where \(\mathbf{1}_{[,AI:=\frac{1}{N}\sum_{n}f(X_{n}\odot M_{\theta}(h))_{c}-f(X_{n})_{c},The Average Increase (AI) measures the increase in confidence for the masked-in portion of the interpretation.
ICML_2024_oral_60,7,"AD:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n})_{c}-f(X_{n}\odot M_ {\theta}(h))_{c})}{f(X_{n})_{c}}\cdot 100",,AD:=\frac{1}{N}\sum_{n=1}^{N}(f(X_{n})_{c}-f(X_{n}\odot M_{\theta}(h))_{c}),where AD measures the average drop in confidence for the masked-in portion of the interpretation.
ICML_2024_oral_60,8,"AG:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n}\odot M_{\theta}(h))_ {c}-f(X_{n})_{c})}{1-f(X_{n})_{c}}\cdot 100",,"AG:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n}\odot M_{\theta}(h))_{c}-f(X_{n})_{c})}{1-f(X_{n})_{c}}\cdot 100",where AG measures the average gain in confidence after masking the input.
ICML_2024_oral_60,9,Fid-In=\frac{1}{N}\sum_{n=1}^{N}1_{[\arg\max_{c}f(X_{n})_{c}=\arg\max_{c}f_{c}(X_{n}\odot M_{\theta}(h))]},,Fid-In:=\frac{1}{N}\sum_{n=1}^{N}1_{[\arg\max f(X_{n}\odot M_{\theta}(h))=\arg\max f(X_{n})]}\cdot 100,The input fidelity metric measures the proportion of samples where the classifier's prediction on the masked-in portion matches the prediction on the original input.
ICML_2024_oral_66,1,"cost(P,S)=\sum_{p\in P}\min_{s\in S}dist(p,s)^{ z}",,C=\sum_{p\in P}\min_{s\in S}\|p-s\|^z,The cost function C measures the sum of the minimum distances raised to the power of z between each point p in the set P and the closest center s in the set S.
ICML_2024_oral_66,2,P(M(P)\in S)\leq\exp(\varepsilon)\cdotP( M(P^{\prime})\in S)+\delta,,"cost(S)\leq M\cdot\textsc{opt}_{k,z}+A","The equation represents the quality of the private k-means solution S, where M is the multiplicative approximation and A is the additive error."
ICML_2024_oral_66,3,\sum_{p\in P}\|p-\mu\|^{z}\leq 2^{z}\sum_{p\in P}\|p-\mu_{z}\|^{z},,"\left\|\mu_{z}-\mu_{2}\right\|_{2}\leq\left\|\mu_{z}-\mu\right\|_{2}+\left\|\mu-\mu_{2}\right\|_{2}\leq2\left\|\mu_{2}-\mu_{z}\right\|_{2}\leq2\sqrt{2}\cdotdiam(P)^{1-\frac{2}{z}}\cdotdist(\mu_{2},\mu_{z})^{\frac{2}{z}}","The equation represents the relationship between the optimal centers for (1,z)-clustering and (1,2)-clustering, providing an upper bound on the distance between these centers in terms of the diameter of the point set P and the distance between the two optimal centers."
ICML_2024_oral_66,4,"cost(E,\mu(E))=\sum_{p\in E}\|p\|_{2}^{2}-\frac{\|\sum_{p\in E }p\|_{2}^{2}}{|E|}",,"\sum_{p\in E}\|p-\mu_{2}(E)\|^{2}=\frac{1}{2|E|}\sum_{p,q\in E}\|p-q\|^{2}",The equation represents the k-means cost of a cluster as a function of the points in the cluster.
ICML_2024_oral_72,1,"L_{mask}=\underset{X\inD,t\in[0,T]}{ E}-\sum_{i=1}^{N}m_{t,i}\cdot\log(p_{\theta}(x_{i}|X_{t},X^{p},C))",,"p_{\theta}(X_{0}|X_{t},X^{p},C)=\prod_{i=1}^{N} p_{\theta}(x_{i}|X_{t},X^{p},C)","\(\mathbf{X}_{0}\) represents the original token sequence, \(\mathbf{X}_{t}\) is the partially masked sequence at time \(t\), \(\mathbf{X}^{p}\) is the prompt discrete token sequence, and \(\mathbf{C}\) is the condition."
ICML_2024_oral_72,2,"p(X_{t-\Delta t}|X_{t},X^{p},C)=\underset {X_{0}\sim p_{\theta}(X_{0}|X_{t},X^{p},C)}{E}q(X_{t-\Delta t}|\hat{X}_{0},X_{t})",,"q(X_{t-\Delta t}|X_{t})=\prod_{i=1}^{N} q(x_{t-\Delta t,i}|x_{t,i},X^{p},C)","The reverse transition distribution is defined as the product of the probabilities of each token at time t-Δt given the token at time t, the prompt sequence, and the condition."
ICML_2024_oral_73,1,"\theta_{t+1}=\theta_{t}-\eta_{t}(\sum_{i=1}^{n}\nabla\ell(\theta_{t},z_{i})+N(0,\frac{G^{2}}{2\rho}I_{p}))",,"L(\theta):=\sum_{i=1}^{n}\ell(\theta,z_{i})","Loss function to be minimized by the NoisyGD algorithm, where \(\theta! represents the model parameters and \(z_{i}\) represents individual data points."
ICML_2024_oral_73,2,M=\sqrt{\frac{K}{K-1}}P(I_{K}-\frac{1}{K}1_{K}1_{K}^{T })\inR^{p\times K},"where \(P=[P_{1},\cdots,P_{K}]\in\mathbb{R}^{p\times K}\) is a partial orthogonal matrix such that \(P^{T}P=I_{K}\)",W=\frac{1}{\sqrt{p}}1 &\omega &\cdots &\omega^{K-1}\\1 &\omega^2 &\cdots &\omega^{2(K-1)}\\\vdots &\vdots &\ddots &\vdots\\1 &\omega^{K} &\cdots &\omega^{K(K-1)},"The last-layer parameter matrix W in the Neural Collapse phenomenon, where \omega is a primitive K-th root of unity."
ICML_2024_oral_73,3,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}}) || +\exp(-\frac{n}{8(\beta^{4}p^{2}+\frac{1}{3}\beta^{2} p)}),,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp\left(-\frac{n}{2\left(\beta^{4}p^{2}+\frac{1}{3}\beta^{2}p+\frac{2\sigma^{2}}{\eta^{2}}\right)}\right),"The misclassification error for NoisyGD is bounded by an exponential function of the sample size, the feature shift parameter, and the noise variance."
ICML_2024_oral_73,4,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}}) || +\exp(-\frac{n}{8(\beta^{4}p+\frac{1}{3}\beta^{2} )}),,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}})+\exp(-\frac{n}{8(\beta^{4}p+\frac{1}{3}\beta^{2})}),The probability of misclassifying a data point using the NoisyGD algorithm.
ICML_2024_oral_73,5,\nablaL(\theta)=\frac{n}{2}\cdot 0.5\cdot-(-e_{1}+v)+\frac{n}{2}\cdot 0.5\cdot(e_{1}+v)=\frac{n}{2}e_{1},,\beta=\|v\|_{\infty},The feature shift parameter that measures the maximum difference between the actual feature and the perfect feature.
ICML_2024_oral_75,1,"J(\pi)=E_{(s_{t},\tau)\inD}[E_{a_{t}=\pi} [Q^{\pi}(s_{t},a_{t},\tau)]-\etaD_{KL}[\pi,\tilde{\pi}|s_{t},\tau]]",where \(\eta\) is a hyperparameter determining the strength of the regularization towards the reference policy \(\tilde{\pi}\),J(\pi)=E_{\pi}[\sum_{t=0}^{\infty}\gamma^t r_t]-\alpha\cdotKL[\pi || \tilde{\pi}],The variable \(J(\pi)\) represents the expected cumulative reward of policy \(\pi\) regularized by the KL-divergence between \(\pi\) and the reference policy \(\tilde{\pi}\).
ICML_2024_oral_75,2,"\pi_{imp}(a_{t}|s_{t},\tau)\propto\exp(Q^{\pi_{imp}(s_{t},a_{t},\tau)}/\eta)\tilde{\pi}(a_{t}|s_{t},\tau) || \propto\exp(A^{\pi_{imp}(s_{t},a_{t},\tau)}/\eta)\tilde{\pi}(a_{t}|s_{t},\tau)",,"\pi_{imp}(a|s,\tau)=\frac{\tilde{\pi}(a|s,\tau)e^{Q^{\pi}(s,a,\tau)/\eta}}{\int\tilde{\pi}(a'|s,\tau)e^{Q^{\pi}(s,a',\tau)/\eta}da']}","The improved policy \(\pi_{\text{imp}}\) is a function of the reference policy \(\tilde{\pi}\), the action-value function \(Q^{\pi}\), and the regularization strength \(\eta\)."
ICML_2024_oral_75,3,"L^{Q}(\theta)=E\Big{[} (1-\alpha)D_{KL}[\pi_{imp},\pi_{\theta}|s_ {t},\tau,\tilde{\pi}=\pi_{\theta^{\prime}}] || +\alphaD_{KL}[b,\pi_{\theta}|s_{t},\tau] || +\betaD_{KL}[\Gamma_{\theta^{\prime}}(q|s_{t},a_{t },\tau),p_{\theta}(q|s_{t},a_{t},\tau)]\Big{]} || =-E\Big{[} (1-\alpha)\operatorname*{E}_{d^{\prime}\sim\pi_{\theta^{\prime}}}[w(a^{\prime},s_{t},\tau)\log\pi_{\theta}(a^{\prime}|s_{t},\tau)] || +\alpha\log\pi_{\theta}(a_{t}|s_{t},\tau) || +\beta\operatorname*{E}_{q\sim\Gamma_{\theta^{\prime}}}\log p_{\theta}(q|s_{t},a_{t},\tau)\Big{]}+K_{H}",,"L(\theta)=E_{(s_{t},a_{t},\tau)\inD}[D_{KL}[p_{\theta}(q|s_{t},a_{t},\tau),\Gamma_{\theta^{\prime}}(q|s_{t},a_{t},\tau)]+\lambda_{1}D_{KL}[\pi_{\theta},\pi_{\theta^{\prime}}|s_{t},\tau]+\lambda_{2}D_{KL}[\pi_{\theta},\pi_{bc}|s_{t},\tau]]","The total loss function \(\mathcal{L}(\theta)\) combines policy loss, behavior cloning loss, and KL-based Q-value loss with hyperparameters \(\lambda_{1}\) and \(\lambda_{2}\) controlling the trade-off between the terms."
ICML_2024_oral_75,4,"N(C)=N_{0}*C^{a},\;\;\;D(C)=D_{0}*C^{b}",,C\propto D^{0.74}N^{1.16},"The equation represents the relationship between compute operations, number of tokens, and number of parameters for performance-optimal models."
ICML_2024_oral_79,1,"L_{dyn}[\theta_{F,G,P}](o_{t,T},a_{t})= || -\bf cos\_sim\big{(}Q(P(T(z_{t},e_{t}))), stopgrad(P(z_{t+1}))\big{)}",,"L_{BYOL}=\left\lVertG\left(T\left(G(o_{1:T}), a_{1:T-1}\right), o_{T}\right)-G(o_{1:T})\right\rVert_{2}^{2}",The loss function for the BYOL-like objective to optimize the forward latent dynamics model.
ICML_2024_oral_79,2,"L[\theta_{F,G,G,P,\psi}]=L_{dyn}[\theta_{F,G,P}]+\betaL_{act\_decode}[\theta_{F,G,\psi}]",,"L_{pretrain}[\theta_{F,G,\psi,P,Q}](o_{t,T},a_{t})=L_{dyn}[\theta_{F,G,P,Q}](o_{t,T},a_{t})+\lambdaL_{act\_decode}[\theta_{F,G,\psi}](o_{t,T},a_{t})","The total pretraining loss is a combination of the dynamic loss and the action decoding loss, with a hyperparameter λ controlling the trade-off between the two objectives."
ICML_2024_oral_79,3,"L_{\textbf{CE}}(\pi(stopgrad(z_{t})),\xi_{t})[\theta_{\pi}]",,L_{\pi}[\theta_{\pi}]=-\sum_{i=1}^{|D|}\sum_{t=0}^{H_{i}-1}\log\pi(\xi_{t}^{(i)}|z_{t}^{(i)}),"The loss function to train the skill-token policy π, which predicts a skill token based on a latent state, using cross-entropy loss."
ICML_2024_oral_79,4,"L_{\textbf{FT\_DECODER}}[\theta_{\pi,\psi}]=E_{\xi_{t}\sim\pi(stopgrad(z_{t}))}\Big{[}L[\theta_{\psi}](\xi_{t})\Big{]} || L[\theta_{\psi}](\xi_{t})=\sum_{i=0}^{\hat{K}}L_{ action}(\psi(stopgrad(z_{t+i}),\xi_{t}[i]),a_{t+i})","where

\[\mathcal{L}[\theta_{\psi}](\xi_{t})=\sum_{i=0}^{\hat{K}}\mathcal{L}_{\text{ action}}(\psi(\text{stopgrad}(z_{t+i}),\xi_{t}[i]),a_{t+i}) \tag{5}\]

In this equation, \(\hat{K}=\min(K,L_{\xi})\), where \(K\) is a hyperparameter, the motivation behind which is explained at the end of Section 3","L_{adapt}[\theta_{\pi},\theta_{\psi}]=L_{CE}(\pi(stopgrad(z_{t})),\xi_{t})+\gammaL_{act\_decode}[\theta_{F,G,\psi}](o_{t,T},a_{t})",\(\gamma\) is the hyperparameter that controls the trade-off between the cross-entropy loss and the action decoding loss during downstream adaptation.
ICML_2024_oral_79,5,"L[\theta_{\pi,\psi}]=L_{\textbf{CE}}(\pi(stopgrad(z _{t})),\xi_{t})+L_{\textbf{FT\_DECODER}}[\theta_{\pi,\psi}]",,"L_{FT}[\theta_{\pi,\psi}]=L_{CE}(\pi(stopgrad(z_{t})),\xi_{t})+\lambdaL_{FT\_DECODER}[\theta_{\pi,\psi}]",\(\lambda\) is the hyperparameter that controls the trade-off between the cross-entropy loss and the decoder loss.
ICML_2024_oral_84,1,\max_{\pi}E_{\hat{e}\sim\hat{p}(e)}J(\pi;\hat{e}),,"\hat{p}(e)=\arg\max_{p(e)} J(\pi, p(e))",\(\hat{p}(e)\) represents the oracle distribution of the target environment for deploying robots.
ICML_2024_oral_84,2,\hat{e}\sim\hat{p}(e),,\hat{e}\sim\hat{p}(e),\(\hat{e}\) represents a specific instance of the target environment drawn from the oracle distribution \(\hat{p}(e)\)
ICML_2024_oral_84,3,"E^{test}=\{\langle\hat{e}_{sim,i},r\rangle\}_{i=1,\cdots,n}",where the generated behavior \(\pi\) will be evaluated in,"E^{test}=\{(\hat{e}_{sim,i}, r)\}_{i=1}^{n}","The test environment is defined as a set of tuples, where each tuple contains a simulated sample environment and a task specification."
ICML_2024_oral_84,4,f:E^{ref}arrowE^{shaped},,"E^{ref}=\{\hat{e}_{ref,i}\}_{i=1,\cdots,m}",The reference environment is a set of sample environments used to guide the shaping algorithm and prevent overfitting.
ICML_2024_oral_84,5,"\max_{\pi}E_{\tau\sim\pi}[\sum_{t=0}^{T}\gamma^{t}r _{t}(s_{t},a_{t}))] || s.t.\\\s_{t+1}\sim p(s_{t},a_{t};E^{shaped })",,\pi^*=\arg\max_{\pi}E_{\hat{e}_{sim}\simE^{shaped}}J(\pi;\hat{e}_{sim}),The optimal behavior π is obtained by maximizing the expected performance J over the shaped environment.
ICML_2024_oral_84,6,H:f_{k}\times J(\pi^{\star}_{k};E^{test})\to f_{k+1},,"\pi^{\star}=\arg\max_{\pi}E_{\tau\sim\pi}[\sum_{t=0}^{T}\gamma^{t}r _{t}(s_{t},a_{t}))]",The optimal behavior obtained via RL training on the shaped environment.
ICML_2024_oral_84,7,"f_{k+1}=H(f_{k},J(\pi^{\star}_{k};E^{test})) || where\\\pi^{\star}_{k}=\underset{\pi}{argmax}\J(\pi;E^{shaped}_{k}) || E^{shaped}_{k}=f_{k}(E^{ref}),\f_{0}=I_{identity}",,"f_{k+1}=H(f_{k}, J(\pi^{\star}_{k};E^{test}))","The environment shaping function f is updated based on the reflection process, which takes into account the current shaping function and the performance of the optimal behavior on the test environment."
ICML_2024_oral_84,8,"\max_{f\inF} J(\pi^{\star};E^{test}) || s.t.\\\\pi^{\star}\in\arg\max_{\pi}J(\pi;E^{shaped }),\\E^{shaped}=f(E^{ref})",,\max_{f\inF}E_{\hat{e}\sim\hat{p}(e)}J(\pi^{\star};\hat{e})\\\s.t.\\\\pi^{\star}=\underset{\pi}{argmax}\J(\pi;f(E^{ref})),The bi-level optimization problem aims to find an optimal shaping function that maximizes the expected performance of the generated behavior in the target environment.
ICML_2024_oral_93,1,c(\pi)=\|x_{\pi_{n}}-x_{\pi_{1}}\|_{2}+\sum_{i=1}^{n-1}\| x_{\pi_{i}}-x_{\pi_{i+1}}\|_{2},where \(\|\cdot\|_{2}\) denotes the \(\ell_{2}\) norm,"c(\pi)=\sum_{i=1}^{n-1} d(\pi_{i},\pi_{i+1})+d(\pi_{n},\pi_{1})","The total path length of a tour is calculated as the sum of the distances between consecutive vertices in the tour, including the distance from the last vertex back to the first vertex."
ICML_2024_oral_93,2,"L(\theta)=E_{\pi\simS}[E_{\Phi\sim f_{\theta}(s)}[E_{\pi\sim g(s,\Phi)}[c(\bm {\pi})]]]","where \(s\) represents an instance from distribution \(\mathcal{S}\), \(\theta\) is the trainable parameters of model \(f\), \(\mathbf{\pi}\) is the solution outputed by post-hoc search algorithm \(g\) given \(\Phi\), and \(c(\mathbf{\pi})\) is calculated based on Equation 1","\Phi_{i,j}=p(i,j|\theta)","The heatmap entry \(\Phi_{i,j}\) represents the predicted probability of including edge \((i,j)\) in the solution, given model parameters \(\theta\)."
ICML_2024_oral_93,3,"L_{\textit{surrogate}}(\theta)=E_{s\simS}[E_{\Phi\sim f_{\theta}(s)}[\ell(s,\Phi)]]",,"L_{surrogate}(\theta)=E_{s\simS}[E_{\Phi\sim f_{\theta}(s)}[\ell(s,\Phi)]]","The surrogate loss function \(\ell(s,\Phi)\) is used to approximate the true loss function in the optimization problem."
ICML_2024_oral_93,4,"p(\pi_{i}|\pi_{i-1})=\frac{Z_{\pi_{i-1},\pi_{i}}}{\sum_{l\inX_{\pi_{ i-1}}}Z_{\pi_{i-1},l}}",,"p(\pi_{i}|\pi_{i-1})=\frac{Z_{\pi_{i-1},\pi_{i}}}{\sum_{j\neq\pi_{i-1}}Z_{\pi_{i-1},j}}",The probability of choosing the next vertex in the tour construction is determined by the edge potential.
ICML_2024_oral_93,5,"\Phi_{i,j}=\frac{e^{-d_{i,j}/\tau}}{\sum_{k\neq i}e^{-d_{i,k}/\tau}}","where \(d_{i,j}=\left\|x_{i}-x_{j}\right\|_{2}\), and \(\tau\) is a parameter controlling the smoothness of the score distribution in \(\Phi\)","\Phi_{i,j}=\frac{exp(-d_{i,j})}{\sum_{k=1}^{n}exp(-d_{i,k})}","The heatmap \(\Phi_{i,j}\) represents the suitability of including edge \((i,j)\) in the solution, calculated based on the distance \(d_{i,j}\) between vertices \(i\) and \(j\)."
ICML_2024_oral_93,6,\textit{Score}=\frac{\textit{Gap}_{LKH-3}}{\textit{Gap}_{MCTS}},where \(\textit{Gap}_{\text{LKH-3}}=\frac{L_{\text{LKH-3}}}{L^{*}}-1\) and \(\textit{Gap}_{\text{MCTS}}=\frac{L_{\text{MCTS}}}{L^{*}}-1\),Score=\frac{c_{LKH-3}-c_{opt}}{c_{MCTS}-c_{opt}},"The Score metric assesses the relative efficiency of MCTS compared to LKH-3 under identical conditions, calculated as the ratio of their performance gaps to the optimal solution."
ICML_2024_oral_95,1,"K_{img}(i,j)=\langle f_{img}(x_{i}),f_{img}(x_{j})\rangle || K_{text}(i,j)=\langle f_{text}(y_{i}),f_{text}(y_{j})\rangle",,"k_{cross-modal}(x, y)=k_{vision}(x, x')\cdot k_{language}(y, y')",The cross-modal alignment kernel measures the similarity between vision and language models using paired datasets.
ICML_2024_oral_95,2,"P_{\texttt{coor}}(x_{a},x_{b})\propto\sum_{(t,t^{\prime})\colon|t-t^{\prime}|\leq T_{\texttt{ window}}}P(X_{t}=x_{a},X_{t^{\prime}}=x_{b})",,"P_{coor}(x_{a},x_{b})=\sum_{z_{1},\ldots,z_{T}}P(Z)\prod_{t=1}^{T}\left[I\{z_{t}=\texttt{obs}^{-1}(x_{a})\}+I\{z_{t}=\texttt{obs}^{-1}(x_{b})\}\right]",The cooccurrence probability of two observations is defined as the sum of the probabilities of all possible event sequences that contain both observations within a certain time window.
ICML_2024_oral_95,3,"\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle\approx\log\frac{P(\texttt{pos}\mid x_{a},x_{b})}{ P(\texttt{neg}\mid x_{a},x_{b})}+\tilde{c}_{X}(x_{a}) || =\log\frac{P_{\texttt{coor}}(x_{a}\mid x_{b})}{P_{\texttt{coor}} (x_{a})}+c_{X}(x_{a})",,"\log\frac{P_{\texttt{coor}}(x_{a},x_{b})}{P_{\texttt{neg}}(x_{a},x_{b})}\approx\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle+c","The equation represents the log odds ratio of co-occurrence probability to negative probability, approximated by the dot product of the representations of two observations plus some offset."
ICML_2024_oral_95,4,"=K_{\texttt{PMI}}(x_{a},x_{b})+c_{X}(x_{a})","where \(K_{\texttt{PMI}}\) is the pointwise mutual information (PMI) kernel, and \(c_{X}(x_{a})\) is constant in \(x_{b}\)","\log\frac{P_{\texttt{coor}}(x_{a}\mid x_{b})}{P_{\texttt{coor}}(x_{a})}=\log\frac{\sum_{z_{t},z_{t^{\prime}}\colon x_{a}=\texttt{obs}(z_{t}),x_{b}=\texttt{obs}(z_{t^{\prime}})}P(z_{t},z_{t^{\prime}})}{\sum_{z_{t}\colon x_{a}=\texttt{obs}(z_{t})}P(z_{t})}","The equation represents the log odds ratio of the cooccurrence probability of two observations, which is used to learn a representation that approximates the log odds ratio up to some offset."
ICML_2024_oral_95,5,"\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle=K_{\texttt{PMI}}(x_{a},x_{b})+c_{X}",where we observed that \(c_{X}(x_{a})\) from Eq,f_{X}(x_{a})=E_{z\simP(Z\mid X=x_{a})}[\phi(z)],"The representation \(f_{X}\) is a function that maps an observation \(x_{a}\) to a vector in \(\mathbb{R}^{d}\), where \(\phi(z)\) is a feature map that maps an event \(z\) to a vector in \(\mathbb{R}^{d}\)."
ICML_2024_oral_95,6,"P_{\texttt{coor}}(x_{a},x_{b})=P_{\texttt{coor}}(x_{a},x_{b}),\,K_{\texttt{PMI }}(x_{a},x_{b})=K_{\texttt{PMI}}(z_{a},z_{b})",where we use \(P_{\texttt{coor}}\) and \(K_{\texttt{PMI}}\) modality-agnostically to emphasize that different modalities share these same quantities,f_{X}(x_{a})=f_{Z}(z_{a}),The representation of the observation $x_{a}$ is equivalent to the representation of the event $z_{a}$.
ICML_2024_oral_95,7,"K_{\texttt{PMI}}(z_{a},z_{b})=\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle-c_{X} || =\langle f_{Y}(y_{a}),f_{Y}(y_{b})\rangle-c_{Y}",,"\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle=\langle f_{Y}(y_{a}),f_{Y}(y_{b})\rangle=\langle f_{Z}(z_{a}),f_{Z}(z_{b})\rangle=K_{\texttt{PMI}}(z_{a},z_{b})+c",The representation learned by contrastive learners across different modalities converges to the same pointwise mutual information kernel of the underlying event distribution.
ICML_2024_oral_99,1,"\min_{(\pi,\hat{\Delta})}\max_{\nu\inE_{0}}(R_{\nu}(n,\pi),\max_{1\leq j\leq M}e_{\nu}(n,\hat{\Delta}(X_{j})))",where we use the subscript \(\nu\) to denote the contextual bandit instance,"R(n,\pi)=E^{\pi}\left[\sum_{i=1}^{n}\left[r_{i}(a^{*}(x_{i}) |x_{i})-r_{i}\left(a_{i}|x_{i}\right)\right]\right]",The accumulative regret of policy π is defined as the expected difference between the reward under the optimal policy and the policy π.
ICML_2024_oral_99,2,"\inf_{(\pi,\hat{\Delta}_{n})}\max_{\nu\inE_{0}}[e_{\nu}(n,\hat{\Delta}_{n})R_{\nu}(n,\pi)]\geq\Omega (M)",,"e_{\nu}\left(n,\hat{\Delta}_{n}\right)\cdotR_{\nu}(n,\pi)=\Omega(M)",The equation represents the fundamental limit of the trade-off between the regret and the estimation error of CATE in contextual bandit experiments.
ICML_2024_oral_99,3,"e_{\nu}(n,\hat{\Delta}_{n})=\max_{1\leq j\leq M}E[(\hat{\Delta}_{n}(X_{j})-\Delta(X_{j}))^{2}]=O(\frac{1}{ f_{\min}(n)})",,"R_{\nu}(n,\pi)=0, e_{\nu}(n,\hat{\Delta}_{n})=O\left(\frac{M}{n}\right)","The equation represents the trade-off between regret and CATE estimation error in the context of adaptive experiment design, highlighting that a small regret leads to a large error in CATE estimation."
ICML_2024_oral_99,4,"R_{\nu}(n,\pi)\leqO(M\max\{f_{min}(n)^{1-\alpha},\log n\}) || e_{\nu}(n,\hat{\Delta}_{n})\leqO(\frac{1}{\max\{f_{min}(n)^{1-\alpha},\log n\}})",,"R_{\nu}(n,\pi)=O(\log(n)), e_{\nu}(n,\hat{\Delta}_{n})=O(\frac{M}{\log(n)})","The regret and estimation error for the ConSE algorithm with any given $\alpha\in[0,1]$."
ICML_2024_oral_99,5,"e_{\nu}(n,\hat{\Delta}_{n})R_{\nu}(n,\pi)\leqO(M)",,"R_{\nu}(n,\pi)e_{\nu}(n,\hat{\Delta}_{n})\leqO(M)",The product of regret and estimation error for the ConSE algorithm.
ICML_2024_oral_99,6,O((\log n_{j}+\log\log(1/\Delta(X_{j})))(\frac{ 1}{\Delta(X_{j})^{2}}+\frac{1}{\varepsilon\Delta(X_{j})})),,O(\frac{\log^{2}n}{\varepsilon^{2}\Delta^{2}}),the number of times the bad arm of any feature Xj is pulled in the first half periods
ICML_2024_oral_99,7,"e(n,\hat{\Delta})=O(\frac{1}{\max\{f_{min}(n)^{1-\alpha},\frac{\log n}{\varepsilon}\}})",,"\max_{1\leq j\leq M}e_{\nu}(n,\hat{\Delta}_{n}(X_{j}))\leqO\left(\frac{1}{\max\{f_{min}(n)^{1-\alpha},\log n\}}+\frac{M}{\varepsilon n}\right)","The estimation error of DP-ConSE is bounded by the inverse of the maximum of the minimum occurrence frequency of features to the power of 1 minus alpha and the logarithm of the total number of patients, plus a term that decreases with the privacy budget epsilon and the total number of patients n."
naacl_2024_short_14,1,p_{lm}(x_{t}|c)=f\circg\circenc(c),"where \(f\) is the last linear layer with softmax activation, \(g\) is the two-layer MLP network with a residual connection in the last Transformer layer, and \(\mathrm{enc}\) includes the earlier layers of the model",p(x_{t} | c)=\frac{\exp(h_{t-1}\cdot e(x_{t}))}{\sum_{x'\in V}\exp(h_{t-1}\cdot e(x'))},The probability of the next token \(x_{t}\) given context \(c\) is calculated using the Transformer LM.
naacl_2024_short_14,2,p_{knnlm}(x_{t}|c)=\lambda p_{lm}(x_{t}|c)+(1-\lambda)p_{\text {knn}}(x_{t}|c),where \(\lambda\) is a hyperparameter for interpolation,p_{knn}(x^{\prime}_{t}|c)=\frac{1}{k}\sum_{i=1}^{k}I\{x_{t_i}=x^{\prime}_{t}\},where \(x_{t_i}\) represents the next token in the \(i\)-th nearest neighbor of the given context \(c\).
naacl_2024_short_14,3,"z^{*}\in\operatorname*{arg\,min}_{z\inR^{d}}KL[f(z)\|p_{knnlm}]",where \(f\) is the last layer of the model with its trained parameters fixed (definition in Eq 1),\min_{f}\left\lVert f\circ g\circenc(c)-p_{knnlm}(x_{t}|c)\right\rVert_{2}^{2},"where \(f\) represents the last linear layer with softmax activation, and the goal is to find the optimal \(f\) that minimizes the difference between the generated distribution and the \(k\)NN-LM distribution."
naacl_2024_short_16,1,"g(x)=\operatorname*{arg\,max}_{c\inY}P_{x\sim\phi(x,m)}(f(M(x,s))=c)",,"g(x)=E_{s\sim\phi(x,m)}[f(M(x,s))]",The equation represents the smoothed model g(x) as the expected value of the original LLM f(x) under the randomized masking scheme.
naacl_2024_short_16,2,"g^{\prime}(x)=\operatorname*{arg\,max}_{e\inY}P_{s \sim\phi(x,m)}(f(D(M(x,s)))=c)",,"D(M(x,s))=\operatorname*{arg\,max}_{x'\inX}P(x'|M(x,s))",The denoiser D takes the masked input and returns the most likely original input.
naacl_2024_short_22,1,"R_{LM}(X,\tau,a^{*})=LM(a^{*}|X,\tau)",,"V_{\theta}(X,\tau)=\max_{s\in S}(V_{\theta}(X+s,\tau))",The value function V_{\theta} estimates the downstream performance of a state description X given a task description \tau.
naacl_2024_short_22,2,"L(X,S,\tau,a^{*})=\\\sum_{t=0}^{|X|}(V_{\theta}(X_{:t},\tau)-\gamma^{|X|-t}R_{LM}( X,\tau,a^{*}))^{2}",,"\(L(X,\tau,a^{*})=-\log R_{LM}(X,\tau,a^{*})\)",The loss function \(\mathcal{L}\) measures the negative log likelihood of the target action \(a^{*}\) given the state description \(X\) and task \(\tau\).
naacl_2024_short_22,3,"L_{V_{\theta}}=\underset{{c}S,\tau,a^{*}\sim D\\X\sim\pi|S,\tau}{E}[L(X,S,\tau,a^{*})+\phi]","where \(\gamma\) is a discount factor and \(\phi\) is a Kullback-Leibler penalty for normalizing \(V_{\theta}\), common when finetuning LMs with RL (Stiennon et al","L_{V_{\theta}}=\sum_{(S,\tau,a^{*})\in D}L(X,S,\tau,a^{*})","\( \mathcal{L}_{V_{\theta}} \) represents the overall loss function for the state description value function \( V_{\theta} \), summed over the dataset \( D \) of trajectory demonstrations."
naacl_2024_short_23,1,"\hat{C}_{m},\hat{S}_{m},\hat{F}_{m}=\textsc{attributePredictor}(m,M) || \hat{E}=\textsc{CandidateGenerator}(m,E) || f(m|T,M,E)=\textsc{Constrainer}(\hat{E},\hat{C}_{m},\hat{S}_{m},\hat{F}_{ m})",,"f(m|T,M,E)=\hat{e}","The function f represents the geocoding process, which takes the text of a document, location mentions, and geographical database entries as input to predict the corresponding geographical entry for a given location mention."
naacl_2024_short_23,2,"Z=\textsc{transformer}(\textsc{Toinput}(m,M)) || \hat{C}_{m}=softmax(Z_{c}W_{c}) || \hat{S}_{m}=softmax(Z_{s}W_{s}) || \hat{F}_{m}=softmax(Z_{f}W_{f})",,"p(\hat{C}_{m},\hat{S}_{m},\hat{F}_{m}|m,M)=\textsc{Softmax}(\textsc{MLP}(\textsc{Embed}(m)))","The probability distribution over the predicted country, state, and feature class of a location mention m, given the mention and the set of location mentions M in the document."
naacl_2024_short_23,3,L=C_{m}log(\hat{C}_{m})+S_{m}log(\hat{S}_{m})+F_{m}log(\hat{F}_{m}),"where \(C_{m}\), \(S_{m}\), and \(F_{m}\) are one-hot vectors of size \(N\) representing the true country, state, and feature class for mention \(m\)",L=-\sum_{m\in M}(\log(\hat{C}_{m})+\log(\hat{S}_{m})+\log(\hat{F}_{m})),"The loss function L is defined as the negative sum of the logarithms of the predicted probabilities for country, state, and feature class."
naacl_2024_short_25,1,"f(q,d_{i})=\frac{\exp(s_{i,1})}{\exp(s_{i,1})+\exp(s_{i,0})}",,"f(q,d_{i})=\frac{\exp(s_{i,1})}{\exp(s_{i,1})+\exp(s_{i,0})}","The ranking score f(q,d_{i}) represents the probability that document d_{i} is relevant to query q."
naacl_2024_short_25,2,"s_{i,k}=LLM(l_{k}|q,d_{i})",,"s_{i,k}=LLM(l_{k}|q,d_{i})","The log-likelihood of the LLM generating each relevance label \(l_{k}\) for the query-document pair \((q,d_{i})\)."
naacl_2024_short_25,3,"f(q,d_{i})=\sum p_{i,k}\cdot y_{k} || where p_{i,k}=\frac{\exp(s_{i,k})}{\sum_{k^{\prime}}\exp(s_{i,k^{\prime}})}",,"f(q,d_{i})=\sum_{k=0}^{2}y_{k}\cdot\frac{\exp(s_{i,k})}{\sum_{j=0}^{2}\exp(s_{i,j})}","The ranking score f(q,d_i) is calculated as the expected relevance value based on the log-likelihood scores s_{i,k} and assigned relevance values y_k."
naacl_2024_short_25,4,"f(q,d_{i})=s_{i,k^{*}}",,"f(q,d_{i})=s_{i,k^{*}}","The ranking score f(q,d_i) is calculated as the log-likelihood of the peak relevance label."
naacl_2024_short_26,1,"f(x,t,k;\theta)=y",,"y=f(x, t, k;\theta)","The variable y represents the stance that text x expresses towards target t, with f being the detection model and \theta being its parameter, and k being the involved knowledge."
naacl_2024_short_26,2,"L_{gen}=-\sum_{i=1}^{|u|}\log p(u_{i}|,u_{< i},h(x,t,k);\theta)","where \(p(u_{i}|,\boldsymbol{u}_{<i},h(x,t,k);\theta)\) is the probability to select a token \(u_{i}\) at step \(i\) given the input \(h(x,t,k)\) and previously generated tokens \(\boldsymbol{u}_{<i}\)","p(u|h(x,t,k))=\prod_{i=1}^{|u|}p(u_i|u_{<i},h(x,t,k))","The probability of generating the output sequence \(\mathbf{u}\) given the input \(h(x,t,k)\), which is a combination of input text \(x\), target \(t\), and LLM-driven knowledge \(k\)."
naacl_2024_short_26,3,v_{c}arrowNormalize(\betav_{c}+(1-\beta)v_{c}^{\prime}),"where \(\beta\) is a momentum coefficient, \(\text{Normalize}(\cdot)\) is the normalization function, and \(\boldsymbol{v}_{c}^{\prime}\) is the centroid of embeddings belonging to class \(c\) in the batch",v_{c}\leftarrow\alphav_{c}+(1-\alpha)\frac{1}{|B_c|}\sum_{\hat{z}_i\inB_c}\hat{z}_i,"where \(\alpha\) is the momentum coefficient, \(\mathcal{B}_c\) denotes the set of projected stance embeddings belonging to class \(c\) in the current batch, and \(|\mathcal{B}_c|\) is the number of embeddings in \(\mathcal{B}_c\)"
naacl_2024_short_26,4,L_{con}=-\sum_{c=1}^{C}y_{c}\log\frac{exp(\frac{s_{c}}{\gamma})}{\sum_{j=1}^{C}exp(\frac{s_{j}}{\gamma})},where \(\gamma\) is a scalar temperature parameter and \(\boldsymbol{y}\) is the one-hot label for the current sample,L_{con}=-\frac{1}{N}\sum_{i=1}^{N}\log\frac{\exp(s_{y_i}/\tau)}{\sum_{j=1}^{C}\exp(s_{j}/\tau)},"where \(s_{j}\) is the cosine similarity between the projected stance embedding \(\boldsymbol{\hat{z}}\) and the prototype \(\boldsymbol{v}_{j}\) of class \(j\), \(y_i\) is the ground-truth stance label, \(N\) is the batch size, \(C\) is the number of stance classes, and \(\tau\) is a temperature hyperparameter"
naacl_2024_short_26,5,L=\lambda_{l}\cdotL_{gen}+(1-\lambda_{l})\cdotL _{con},where \(\lambda_{l}\) is involved to balance the optimization,L=L_{gen}+\lambdaL_{con},where \(\lambda\) is a hyperparameter to balance the two losses
naacl_2024_short_27,1,"[sim_{A}^{j},sim_{B}^{j}]=X_{i}\cdot[X_{A}^{j},X_{B}^{j}]",,KL(X_{i})=\sum_{j=1}^{n}\sum_{k=1}^{n}\frac{X_{i}\cdot A_{j}}{\|X_{i}\|\|A_{j}\|}\cdot\frac{X_{i}\cdot A_{k}}{\|X_{i}\|\|A_{k}\|},The KL loss measures the similarity between the representation of example \(X_{i}\) and each pair of attribute representations \(A_{j}\) and \(A_{k}\).
naacl_2024_short_27,2,"d_{sim}^{j}=\sigma(sim_{A}^{j},sim_{B}^{j})",,"\sigma(a,b)=\frac{e^{a}}{e^{a}+e^{b}}","The softmax function \(\sigma(a,b)\) calculates the similarity distribution between two inputs a and b."
naacl_2024_short_27,3,"L_{kl}=\sum_{j=1}^{K}D_{KL}(d_{sim}^{j},d_{uni})",,"KL(d_{sim}^{j} || d_{uni})=\sum_{x\in\{A,B\}} d_{sim}^{j}(x)\log\frac{d_{sim}^{j}(x)}{d_{uni}(x)}",The KL loss measures the difference between the similarity distribution and a uniform distribution.
naacl_2024_short_27,4,L_{total}=L_{ce}+\lambda L_{kl},where \(L_{ce}\) is the usual cross-entropy loss,L_{total}=L_{kl}+\lambda L_{ce},"The total loss is the sum of the KL loss and the cross-entropy loss, where \(\lambda\) is a hyperparameter controlling the weight of the cross-entropy loss."
naacl_2024_short_28,1,"S(y)=-\frac{1}{|H(x)|}\sum_{y^{\prime}\in H(x)}L(y^{\prime},y)",,"R(y^{\prime}|x)=\sum_{y\in H(x)} P(y|x) L(y,y^{\prime})",The score of each translation is calculated as the expected loss over all possible translations given the input.
naacl_2024_short_28,2,"y^{*}=\operatorname*{arg\,max}_{y\in H(x)}S(y)",,y_{MBR}=\arg\max_{y\in H(x)} S(y),"The MBR hypothesis is the translation with the highest score, found by taking the argmax of the scores over the set of sampled translations."
naacl_2024_short_28,3,"\max_{\pi_{\theta}}E_{x\sim D,y\sim\pi_{\theta}( y|x)}[r_{\phi}(x,y)] || -\betaD_{KL}[\pi_{\theta}(y|x)\parallel\pi_{ref}(y|x)]",,R(y)=\sum_{y^{\prime}\in H(x)}P(y^{\prime}|x)S(y^{\prime}),The reward function R for a translation y is defined as the expected score of the sampled translations.
naacl_2024_short_28,4,"L_{DPO}=-E_{(x,y_{w},y_{l})\sim D}[log\sigma(M(y_{w},y_{l},x,\theta))] || \beta(log\frac{\pi_{\theta}(y_{w}|x)}{\pi_{ref}(y_{w}|x)}-log\frac{\pi_{\theta}( y_{l}|x)}{\pi_{ref}(y_{l}|x)})","where the reward margin \(M(\mathbf{y}_{w},\mathbf{y}_{l},\mathbf{x},\theta)\) is

\[\beta\left(\text{log}\frac{\pi_{\theta}(\mathbf{y}_{w}|\mathbf{x})}{\pi_{ \text{ref}}(\mathbf{y}_{w}|\mathbf{x})}-\text{log}\frac{\pi_{\theta}(\mathbf{ y}_{l}|\mathbf{x})}{\pi_{\text{ref}}(\mathbf{y}_{l}|\mathbf{x})}\right) \tag{5}\]

### Related Work in Translation

Previous work has explored the effectiveness of enhancing the translation performance of LLMs via Reinforcement Learning (RL) algorithms or supervised fine-tuning","\max_{\pi_{\theta}}E_{(x,y_{w},y_{l})\sim D}[\log\frac{\pi_{\theta}(y_{w}|x)}{\pi_{\theta}(y_{l}|x)}-\betaD_{KL}[\pi_{\theta}(y|x)\parallel\pi_{ref}(y|x)]]",The DPO fine-tuning objective maximizes the expected reward margin between the preferred and dispreferred responses while regularizing the model to stay close to the reference model.
naacl_2024_short_32,1,"y^{*}=\operatorname*{arg\,max}_{y\inY}E_{r\sim P_{ human}(\cdot|x)}[u(y,r)]",,"u(y,r)=\underset{y'\inY}{\arg\max}E_{r'\simR}[u(y',r')]","The utility function u(y,r) measures the quality of a model translation y given its reference translation r."
naacl_2024_short_32,2,"y^{*}=\operatorname*{arg\,max}_{y\inY}\frac{1}{|R^{\prime}|}\sum_{r^{\prime}\inR^{\prime}}u(y,r^{\prime})",,"y^{*}=\operatorname*{arg\,max}_{y\inY}\frac{1}{K}\sum_{k=1}^{K}u(y,r'^{(k)}) where r'^{(k)}\sim P_{model}(\cdot|x)","The equation represents the approximation of the expected utility using finite samples drawn from a model, where $r'^{(k)}$ are pseudo-references and $K$ is the number of samples."
naacl_2024_short_33,1,"\min_{P_{n},v_{n}}-\sum_{x_{n},y_{n}}\log p(y_{n}|x_{n},P^{\prime}_{n},\theta)-\sum_{x_{n}}\cos(x_{n},v_{n})",,P^{\prime}_{n}=\sum_{k=1}^{n}\alpha_{k}P_{k},"The composed module $P^{\prime}_{n}$ is a weighted summation of task-specific modules $P_{k}$, where $\alpha_{k}$ represents the contribution weight of each module."
naacl_2024_short_33,2,"FWT=\frac{1}{N-1}\sum_{j=2}^{N}(a_{i,i}-\tilde{a}_{i})","where \(N\) is the number of tasks in the continual learning sequence, \(a_{i,i}\) denotes the performance evaluated on the \(i\)-th task after incremental learning on the first \(i\) tasks, \(\tilde{a}_{i}\) is the task performance of a randomly initialized reference model trained with dataset \(D_{i}\)",FWT=\frac{1}{T-1}\sum_{i=1}^{T-1}\frac{Acc_i^{T}-Acc_i}{Acc_i},"The forward transfer score measures the average influence of all previous tasks on the current task, where Acc_i^T is the accuracy on task i after training on all tasks up to T, and Acc_i is the accuracy on task i after training only on task i."
naacl_2024_short_34,1,x_{k}&=A_{k}x_{k-1}+Bu_{k}\\y_{k}&=h(x_{k}),,h_t=\sigma (W_{ih} x_t+W_{hh} h_{t-1}+b_h),"The equation represents the general formulation of Long Short-Term Memory (LSTM) networks, where \(h_t\) is the hidden state at time \(t\), \(x_t\) is the input at time \(t\), \(W_{ih}\) and \(W_{hh}\) are the input and hidden weight matrices, \(b_h\) is the hidden bias, and \(\sigma\) is the activation function."
naacl_2024_short_34,2,x_{k}=Ax_{k-1}+Bu_{k},,x_{k}=Ax_{k-1}+Bu_{k},"The equation represents the recurrence relation for an input-independent LRNN, where $A$ is a matrix defining the linear recurrence in the state $x_{k}$ and $B$ is a matrix representing the input $u_{k}$."
naacl_2024_short_34,3,"x_{0-1}&=A^{3}z+A^{2}u_{0}+Au_{-}+u_{ 1},\\for ""0-1""\\x_{1-0}&=A^{3}z+A^{2}u_{1}+Au_{-}+u_{0},\\for ""1-0""",,x_{2} &=Az+Bu_{0}+A(Bu_{-}+Bu_{1})\\x'_{2} &=Az+Bu_{1}+A(Bu_{-}+Bu_{0}),"The equation represents the state vectors after processing the sequences ""0-1"" and ""1-0"" using an input-independent LRNN."
naacl_2024_short_34,4,A^{2}u_{0}+Au_{-}+u_{1}\neq A^{2}u_{1}+Au_{-}+u_{0},,A^{2}u_{0}+u_{1}\neq A^{2}u_{1}+u_{0},"The equation represents the inconsistency of an input-independent LRNN in representing subtraction, where the order of input characters matters."
naacl_2024_short_34,5,x_{0-0-1}&=A^{3}x_{0-}+A^{2}u_{0}+Au_ {-}+u_{1}\\x_{0-1-0}&=A^{3}x_{0-}+A^{2}u_{1}+Au_{-}+u_{0},,"x_{0-0-1}&=A^{3}z+A^{2}u_{0}+Au_{-}+u_{0}+A^{2}u_{-}+Au_{1},\\x_{0-1-0}&=A^{3}z+A^{2}u_{0}+Au_{-}+u_{1}+A^{2}u_{-}+Au_{0}","The equation represents the vector representations for the sequences ""0-0-1"" and ""0-1-0"" using an input-independent LRNN."
naacl_2024_short_34,6,A^{2}u_{0}+Au_{-}+u_{1}=A^{2}u_{1}+Au_{-}+u_{0},,A^{2}u_{0}+Au_{-}+u_{1}=A^{2}u_{1}+Au_{-}+u_{0},"The equation represents the condition for input-independent LRNNs to be inconsistent in representing subtraction when considering the sequences ""0-0-1"" and ""0-1-0""."
naacl_2024_short_34,7,x_{k}=diag(v_{k})x_{k-1}+Bu_{k},where \(v_{k}=f(u_{k})\) is a vector that depends on \(u_{k}\),A^{2}u_{0}+Au_{-}+u_{1}=A^{2}u_{1}+Au_{-}+u_{0},The equation represents the contradiction in the input-independent LRNN's ability to represent subtraction.
naacl_2024_short_34,8,x_{k}&=Ax_{k-1}+(Bu_{k})\odot x_{k-1}+Bu_{k}\\&=(A+diag(Bu_{k}))x_{k-1}+Bu_{k},where \(\odot\) denotes the Hadamard product and \(\text{diag}(w)\) constructs a diagonal matrix from \(w\),x_{k}=diag(v_{k})x_{k-1}+Bu_{k},where \(v_{k}=f(u_{k})\) is a vector that depends on \(u_{k}\)
naacl_2024_short_34,9,x_{k}=A_{k}x_{k-1}+Bu_{k},where \(A_{k}=g(u_{k})\) is a block diagonal matrix in practice for the sake of efficiency,x_{k}=A_{k}x_{k-1}+Bu_{k},where \(A_{k}\) is a block-diagonal matrix that depends on the input \(u_{k}\).
naacl_2024_short_34,10,"& A_{k}=diag(A_{k}^{(1)},...,A_{k}^{(h)} )\inR^{bh\timesbh}\\& A_{k}^{(i)}=[v_{k}^{(i,1)}\quad\ldots\quad v_{k}^{(i,b)} ]\inR^{b\times b}\\&\|v_{k}^{(i,j)}\|_{p}\leq 1,\\i\in[1,...,h],\\j\in[1,...,b]","where \(\|\cdot\|_{p}\) denotes the vector p-norm and \(v_{k}^{(i,j)}\) is a column vector that depends on \(u_{k}\)",x_{k}=A_{k}x_{k-1}+Bu_{k},"where \(A_{k}\) is a block-diagonal and input-dependent transition matrix, \(x_{k}\) is the state vector at time step \(k\), \(u_{k}\) is the input vector at time step \(k\), and \(B\) is a learnable matrix."
naacl_2024_short_34,11,&[\|v^{(1)}\|_{1}\quad\ldots\quad\|v^{(b)}\|_{1} ]=1^{\top}|A_{k+1}^{(i)}A_{k}^{(i)}|\\&\leq1^{\top}|A_{k+1}^{(i)} || A_{k}^{(i)} |\leq1^{\top}|A_{k}^{(i)}|\leq1^{\top},,"&\|v^{(j)}\|_{1}=\left\|\sum_{l=1}^{b}A_{k+1}^{(i)}[:,l]\cdot A_{k}^{(i)}[l,j]\right\|_{1}\\&\leq\sum_{l=1}^{b}\left\|A_{k+1}^{(i)}[:,l]\cdot A_{k}^{(i)}[l,j]\right\|_{1}\\&\leq\sum_{l=1}^{b}\left\|A_{k+1}^{(i)}[:,l]\right\|_{1}\cdot\left\|A_{k}^{(i)}[l,j]\right\|_{1}\\&\leq\sum_{l=1}^{b}1\cdot 1=b","The equation represents the derivation of the norm constraint for the block-diagonal input-dependent LRNN, ensuring numerical stability by imposing constraints on the norm of \(A_{k}\)."
naacl_2024_short_38,1,"f(C,P,N_{1},N_{2})=1&if s(C,P)>s(C,N_{1} )\\&and s(C,P)>s(C,N_{2} )\\0&otherwise",where \(s(,"f\left(C,P,N_{1},N_{2}\right)=1 &if P is ranked highest\\0 &otherwise",The evaluation metric f measures the accuracy of a VLM in retrieving the correct image for a given compound noun prompt.
naacl_2024_short_38,2,"Mean Similarity=\frac{1}{n}\sum_{i=1}^{5}s(c,p_{i})","where \(p_{i}\in P\) denotes the generated prompts, \(s(","s(c,P)=\frac{1}{5}\sum_{i=1}^{5}\cos(\phi(c),\phi(P_i))",The mean similarity of an image with the text prompts is calculated by averaging the cosine similarity between the image embedding and each of the 5 text prompt embeddings.
naacl_2024_short_39,1,"\underset{\theta_{P}}{\max}\underset{i}{\sum}\log p_{\theta,\theta_{P}}(y_{i}|[P;x_{i}])",,\max_{\Theta}\sum_{i}^{N}\log p_{\Theta}(y_{i}|x_{i}),"The log-likelihood objective function to be maximized during training, where \(\Theta\) represents the model parameters, \(x_{i}\) is the input text, \(y_{i}\) is the output sequence, and \(N\) is the number of training data points."
naacl_2024_short_39,2,\frac{(Zero-shot\correct)\cap(PoT\incorrect)}{Zero-shot\correct},"where _Zero-shot correct_ is the case of correct responses in a zero-shot setting, and _PoT incorrect_ is the case of incorrect answers after prompt transfer in the target task",F=\frac{1}{T}\sum_{t=1}^{T}\frac{L_{t}-L_{t-1}}{L_{t-1}},"The metric $\mathcal{F}$ measures the average change in loss over all tasks, where $\mathcal{L}_{t}$ is the loss at task $t$ and $\mathcal{L}_{t-1}$ is the loss at the previous task."
naacl_2024_short_43,1,"I_{c,i}\sim f(c_{\ell})",,f(c_{\ell})=\{x_{i}\}_{i=1}^{n},The function f represents a multilingual text-to-image model that generates a set of images given a tangible concept written in language \(\ell\).
naacl_2024_short_43,2,"X_{c}=\frac{1}{n^{2}}\sum_{i=0}^{n}\sum_{j=0}^{n}SIM_{F}(I_{c_{\ell}, i},I_{c_{\ell_{s}},j})","where we sample \(n\) images per-concept per-language (we use 9), and \(\mathrm{SIM}_{F}(\cdot,\cdot)\) measures the cosine similarity in feature space by image feature extractor \(F\)","X_{c}(f,c_{\ell},c_{\ell_{s}})=\frac{1}{n}\sum_{i=1}^{n}1(I_{c,i}\sim f(c_{\ell})\equiv I_{c,i}\sim f(c_{\ell_{s}}))","The cross-consistency score \(X_{c}(f,c_{\ell},c_{\ell_{s}})\) measures the correctness of generated images for a concept \(c\) in language \(\ell\) compared to the source language \(\ell_{s}\)."
naacl_2024_short_43,3,"\Delta X_{c}(c,\ell)=X_{c}(f,c^{\prime}_{\ell},c_{\ell_{s}})-X_{c}(f,c_{\ell}, c_{\ell_{s}})",,"\Delta X_{c}=X_{c}(f,c^{\prime}_{\ell},c_{\ell_{s}})-X_{c}(f,c_{\ell},c_{\ell_{s}})",The change in the CCCL score when using the corrected concept translation \(c^{\prime}_{\ell}\) instead of the original \(c_{\ell}\).
naacl_2024_short_43,4,"\DeltaSEM=SIM_{Ft}(c_{\ell_{s}},c^{\prime}_{\ell})- SIM_{Ft}(c_{\ell_{s}},c_{\ell})",,"\DeltaSEM(c_{\ell_{s}},c_{\ell},c^{\prime}_{\ell})=SIM_{F_{t}}(c_{\ell_{s}},c^{\prime}_{\ell})-SIM_{F_{t}}(c_{\ell_{s}},c_{\ell})","The improvement in semantic similarity is calculated as the difference in cosine similarity between the source language concept and the corrected translation, and the source language concept and the original translation."
naacl_2024_short_45,1,\ell=softmax(affine(ReLU(u_{s}))) || \ell_{i}=softmax(affine(ReLU(u_{i}))) || \nabla_{i}=\ell-\ell_{i},,\hat{y}=softmax(ReLU(u_{s}W+b)),"The equation represents the prediction of the dialect classifier, where \(\mathbf{u}_{s}\) is the sentence representation, \(\mathbf{W}\) and \(\mathbf{b}\) are learnable weights and bias, and \(\hat{y}\) is the predicted label."
naacl_2024_short_45,2,L_{dialect-classifier}=-\sum_{i}\log\ell[y_{i}^{*}],where \(y_{i}^{*}\) is the correct label for instance \(i\),L=-\sum_{j=1}^{N}\log\ell_j,"The loss function is defined as the negative log probability of the true label, summed over all training instances."
naacl_2024_short_45,3,s_{j}=softmax(affine(ReLU(u_{s})-ReLU(u_{j}))) || loss=L_{{{dialect-classifier}}}+\alpha_{1}L_{{{LII}}},,u_{s}-u_{j},where \(\mathbf{u}_{j}\) represents the MLM representation of feature \(x_{i}\).
naacl_2024_short_45,4,r_{j}=[\ell]_{y_{i}^{*}}-[s_{j}]_{y_{i}^{*}},"where higher \(r_{j}\) signifies more relevant features to the prediction, serving as better explanations",r_{i}=\ell[y^{*}]-\ell_{i}[y^{*}],The relevance score of feature \(x_{i}\) is the difference in probability of the correct label \(y^{*}\) between the original input and the input without \(x_{i}\).
naacl_2024_short_45,5,E^{\prime}=\{e\in E\midisCorrect(e)\landisUnique(e)\},,E^{\prime}=\{e\in E\mid e is correct and unique\},"The set of filtered explanations, where each explanation is correct and unique to a specific language variety"
naacl_2024_short_45,6,"TF-IDF(t,d,D)=TF(t,d)\timesIDF(t,D)",,"TF-IDF(t,d,D)=TF(t,d)\timesIDF(t,D)",where TF-IDF represents the importance of term t in document d within corpus D
naacl_2024_short_45,7,"F=\{TF-IDF(t,d,E^{\prime})\mid t\in d,d\in E^{\prime}\}",,"F=\{t\in E'\midTF-IDF(t, d, D) >\theta\}",where \(\theta\) is a predefined threshold for feature selection
naacl_2024_short_46,1,"[x^{i},Q^{k}]=BERT([x^{i},Q^{k}])","where \(\mathbf{x}^{i}\) and \(\mathbf{Q}^{k}\) are the representations of \(x^{i}\) and \(\mathcal{Q}^{k}\), respectively","P^{k}=\{p^{k}_{1},...,p^{k}_{|C^{k}|}\}","The set of soft prompts for task \(\mathcal{T}^{k}\), where \(|\mathcal{C}^{k}|\) is the number of event types in \(\mathcal{T}^{k}\)."
naacl_2024_short_46,2,"Z^{i}_{t}=Linear(FFN([x^{i}_{m},x^{i}_{n}]))","where \(\overline{\mathbf{x}}^{i}_{t}=\text{FFN}([\mathbf{x}^{i}_{m},\mathbf{x}^{i}_{ n}])\) is the span representation, \(m\) and \(n\) denote the start and end index of the span, respectively","[z^{i}_{t},z^{i}_{t'}]=FFN([x^{i}_{t},x^{i}_{t'}])",where \(\mathbf{z}^{i}_{t}\) and \(\mathbf{z}^{i}_{t'}\) are the representations of the start and end tokens of the span \(\overline{x}^{i}_{t}\).
naacl_2024_short_46,3,"L_{new}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\in D^{k}_{train}}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})",,Z_{q}=FFN(Q^{k})\cdot\overline{x}^{i}_{t},"where \(Z_{q}\) is the probability distribution over all prompts, calculated as the inner product of the FFN output of accumulated prompts \(\mathbf{Q}^{k}\) and the span representation \(\overline{\mathbf{x}}^{i}_{t}\)"
naacl_2024_short_46,4,"L_{mem}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\in M}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})",,"L_{replay}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inM}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})",where \(\mathcal{L}_{\text{replay}}\) is the loss function for memory replay to mitigate forgetting.
naacl_2024_short_46,5,"L_{sim}=\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inD^ {k}_{train}}\sum_{e_{t}\inE^{k-1}}\max(0,g(\overline {x}^{i}_{t},e_{t})-m_{1})","where \(\mathcal{E}^{k-1}\) is the prototype set of previous \(k-1\) tasks, \(g(,)\) is the similarity function (cosine similarity) and \(m_{1}\) is the margin for \(\mathcal{L}_{\text{sim}}\)","L_{margin}=\max(0,\gamma-sim(\overline{x}^{i}_{t},p^{k}))","where \(\gamma\) is the margin, \(\text{sim}\) is a similarity function, \(\overline{\mathbf{x}}^{i}_{t}\) is the representation of the new sample, and \(\mathbf{p}^{k}\) is the prototype of the learned event type"
naacl_2024_short_46,6,"L_{cal}=-\sum_{(\overline{x}_{t}^{i},\overline{x}_{t}^{i})\inM}\log\frac{\exp g(\overline{x}_{t}^{i},e_{t}) }{\sum_{j=1}^{|e^{k-1}|}\exp g(\overline{x}_{t}^{i}, e_{j})}",where \(\mathbf{e}_{t}\) is the prototype of \(y_{t}^{i}\),"L_{cal}=\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inM}\sum_{e_{t}\inE^{k-1}}\max(0,m_{2}-g(\overline{x}^{i}_{t},e_{t}))",where \(m_{2}\) is the margin for \(\mathcal{L}_{\text{cal}}\)
naacl_2024_short_46,7,L_{total}=L_{new}+\lambda_{1}L_{sim}+\lambda_{2}(L_{mem}+L_{cal}),where \(\lambda_{1}\) and \(\lambda_{2}\) are loss weights,L_{total}=L_{new}+\lambda_{1}L_{mem}+\lambda_{2}L_{sim}+\lambda_{3}L_{cal},"where \(\lambda_{1}\), \(\lambda_{2}\), and \(\lambda_{3}\) are hyperparameters to balance the losses"
naacl_2024_short_46,8,"e_{j}=\frac{1}{|M_{e_{j}}|}\sum_{(\overline{x}_{t}^{i},\overline{x}_{t}^{i})\inM_{e_{j}}}\overline{x}_{t}^{i}","where \(\mathcal{M}_{e_{j}}=\{(\overline{x}_{t}^{i},y_{t}^{i})|(\overline{x}_{t}^{i}, y_{t}^{i})\in\mathcal{M},y_{t}^{i}=e_{j}\}\)","e_{j}=\frac{1}{|M_{j}|}\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inM_{j}}\overline{x}^{i}_{t}",where \(\mathcal{M}_{j}\) is the set of memory samples labeled as \(e_{j}\) and \(|\mathcal{M}_{j}|\) is the number of samples in \(\mathcal{M}_{j}\)
naacl_2024_short_5,1,"L^{unsup}_{simce}=-\log\frac{e^{sim(h_{i},h_{i}^{\prime})/\tau}}{\sum_{j=1}^{N}e^{ sim(h_{i},h_{j}^{\prime})/\tau}} || L^{unsup}_{skice}=-\log\frac{e^{sim(h_{i},h_{i}^{ski})/\tau}}{\sum_{j=1}^{N}e^{sim(h_{i},h_{j}^{ski})/\tau}}",,"D(h,h^{\prime})+\alpha\cdot D(h,h^{ski})","The equation represents the objective function for unsupervised SKICSE, where \(D\) is a distance metric and \(\alpha\) is a hyperparameter."
naacl_2024_short_5,2,L^{unsup}=(1-\lambda)L^{unsup}_{ simce}+\lambdaL^{unsup}_{skice},where the weight \(\lambda\) is a balanced hyperparameter and reflects the importance of SKI,L^{unsup}=\alphaL^{unsup}_{simce}+(1-\alpha)L^{unsup}_{skice},The variable \(\alpha\) represents the weight for the SimCE loss in the overall unsupervised SKICSE objective function.
naacl_2024_short_5,3,"L^{sup}_{simce}=-\log\frac{e^{sim(h_{i},h_{i}^{+})/\tau}}{\sum_{j=1}^{N}(e^{ sim(h_{i},h_{j}^{+})/\tau}+e^{sim(h_{i},h_{j}^{-})/\tau})} || L^{sup}_{skice_{1}}=-\log\frac{e^{sim(h_{i}^{ski},h_{i}^{+})/\tau}}{\sum_{j=1}^{N} (e^{sim(h_{i}^{ski},h_{j}^{+})/\tau}+e^{sim(h_{i}^{ski},h_{j}^{-})/\tau})} || L^{sup}_{skice_{2}}=-\log\frac{e^{sim(h_{i},h_{i}^{ski})/\tau}}{\sum_{j=1}^{N}(e ^{sim(h_{i},h_{j}^{+})/\tau}+e^{sim (h_{i},h_{j}^{-})/\tau})}",,"L^{sup}_{simce}=-\log\frac{e^{sim(h_{i},h_{i}^{+})/\tau}}{e^{sim(h_{i},h_{i}^{+})/\tau}+e^{sim(h_{i},h_{i}^{-})/\tau}}","The supervised SKICSE loss function measures the similarity between the premise and its entailment hypothesis, while distinguishing it from the contradiction."
naacl_2024_short_5,4,L^{sup}=(1-\lambda_{1}-\lambda_{2})L^{sup}_{simce}+\lambda_{1}L^{sup}_{skice_{1}}+\lambda_ {2}L^{sup}_{skice_{2}},,L^{sup}=(1-\lambda)L^{sup}_{simce}+\lambda(L^{sup}_{skice_{1}}+L^{sup}_{skice_{2}}),where the weight \(\lambda\) is a balanced hyperparameter that reflects the importance of SKI in the supervised setting.
naacl_2024_short_51,1,"R_{d}(w)=\frac{tf(w,d)}{\sum_{d^{\prime}}tf(w,d ^{\prime})}\cdot\log\frac{N}{df(w)}","where \(\operatorname{tf}(w,d)\) is the number of times the word \(w\) occurs in the day \(d\), \(\operatorname{df}(w)\) is the number of days in which the word \(w\) occurs, and \(N\) is the total number of days in the dataset",R_{d}=\frac{TF}{IDF},The relevance \(R_{d}\) of each token is calculated using Term Frequency-Inverse Document Frequency (TF-IDF).
naacl_2024_short_51,2,"sim(x,x^{\prime})=\frac{\sum_{w\in x^{\prime}x^{\prime}}R_{d}(w)}{max(\hat{R}_{d}(x),\hat{R}_{d}(x^{\prime}))}",,\hat{R}_{d}(x)=\sum_{w\in x}R_{d}(w),"The relevance score of an article x that occurs first on day d, calculated as the sum of the TF-IDF scores of the words in its title."
naacl_2024_short_52,1,"& L_{discrete}(y_{i}=t;y_{<i},x)=-\log p(y_{i}=t\midy_{<i},x)\\&\quad=-\langleE(t),h\rangle+\log\sum_{t^{\prime}\in V }\exp\langleE(t^{\prime}),h\rangle","where \(t\) is a token index, \(V\) is the vocabulary, \(\mathbf{E}:V\rightarrow\mathbb{R}^{d}\) is an embedding lookup, and \(\mathbf{h}\) is a transformer hidden state calculated in terms of \(\mathbf{x}\) and the output prefix \(\mathbf{y}_{<i}\)","-\sum_{i=1}^{n}\log p(y_i | y_{<i},x)",The log likelihood of the next word in the sequence given the previous words and the input sequence.
naacl_2024_short_52,2,"L_{cos}(y_{i}=t;y_{<i},x)=1-\cos(E(t),h)",,"L_{continuous}(y_{i};y_{<i},x)=\|E(y_{i})-h\|^{2}","The loss function for continuous-output NMT, where the goal is to minimize the Euclidean distance between the embedding of the target token and the transformer hidden state."
naacl_2024_short_52,3,"E(y_{i})=u_{i}/\|u_{i}\|;\quadu_{i}\simNormal( 0,I_{d})",,"E(y_{i})=\frac{z}{\|z\|},\quadz\simN(0,I_d)",where \(\mathbf{z}\) is a standard normal random vector and \(\mathbf{I}_d\) is the identity matrix of size \(d\).
naacl_2024_short_52,4,E(y_{i})=r_{i}/\sqrt{d};\quadr_{i}\simRademacher(d),,"E(y_{i})=\frac{1}{\sqrt{d}}r_{i};\quadr_{i}\simRademacher(\{-1,1\}^{d})",The embedding \(\mathbf{E}(y_{i})\) is drawn from a scaled Rademacher distribution.
naacl_2024_short_52,5,E_{cmb}(y_{i})=\frac{\alphaE_{pre}(y_{i})+(1-\alpha)E_{rand}(y_{i})}{\|\alphaE_{pre}(y_{i})+(1-\alpha)\bm {E}_{rand}(y_{i})\|},,E_{combined}(y_{i})=\alphaE_{pre-trained}(y_{i})+(1-\alpha)E_{random}(y_{i}),"The combined embedding is a weighted sum of the pre-trained and random embeddings, where $\alpha$ is a hyperparameter that controls the contribution of each embedding type."
naacl_2024_short_53,1,"S(y,\bar{y};x)>S(y,\hat{y};x)",where \(\mathbf{y}\) is the reference sequence,e_{1:L}=f(x;\phi_{e}),\(\mathbf{e}_{1:L}\) represents a sequence of \(L\) encoder embeddings that are consumed by the decoder.
naacl_2024_short_53,2,\delta_{i}=\alpha|e_{i}|\bigg{|}\frac{\partial f(e_{1:L};\phi_{nap})}{\partiale_{i}}\bigg{|}^{-1}\frac{\partial f(e_{1:L};\phi_{nap})}{\partiale_{i}},"where \(i=1,\ldots,L\)",\nabla_{e} f(e;\phi_{nap}),The gradient of the Non-Autoregressive Proxy (NAP) with respect to the encoder outputs.
naacl_2024_short_56,1,X_{all}=L\[SEP]\X_{ori}\[SEP]\P_{C}\[SEP]\P_{L},,"P_{L}=``relation is not  S_{i1}, ..., S_{ij}, ... or  N_{random}''",The Label Prompt \(P_{L}\) is designed to differentiate between relations by including similar relations and a randomly selected non-similar relation.
naacl_2024_short_56,2,L_{MLM}=-{\sum}_{n=1}^{M}\log P(x_{n}),where \(M\) is the number of masked tokens and \(P(x_{n})\) is the predicted probability of token \(x_{n}\) over the vocabulary size,L_{MLM}=-\sum_{i=1}^{n}\log p(x_i | x_{\backslash i}),The loss function of prompt MLM is the negative sum of the logarithmic probabilities of each token given the other tokens.
naacl_2024_short_56,3,"L_{s}=\frac{1}{N}\sum_{p=1}^{N}-\frac{1}{N_{y_{p}}-1}\sum_{q=1}^{N_ {y_{p}}}\log\frac{e^{sim(h_{p},h_{q}^{+})/\tau}}{\sum_{k=1}^{N}1_{p\neq k}e^{sim(h_{p},h_{k})/\tau}}",where \(N\) is the total number of examples in the batch and \(N_{y_{p}}\) is the number of positive pairs in the batch,"L_{SCL}=\sum_{i=1}^{N}\left(-\frac{1}{|P(i)|}\sum_{p\in P(i)}\log\frac{\exp(sim(h_i,h_p)/\tau)}{\exp(sim(h_i,h_p)/\tau)+\sum_{n\in N(i)}\exp(sim(h_i,h_n)/\tau)}\right)","where \(h_i\) and \(h_p\) are the representations of the input utterance and its positive samples, \(P(i)\) and \(N(i)\) denote the sets of positive and negative samples for the \(i^{th}\) input, \(sim\) is a similarity function, and \(\tau\) is a temperature hyperparameter."
naacl_2024_short_56,4,L_{final}=\alphaL_{s}+(1-\alpha)L_{MLM},,L=\alphaL_{MLM}+(1-\alpha)L_{s},where \(\alpha\) is a hyperparameter that controls the weight of the two pre-training objectives
naacl_2024_short_62,1,"P_{ATTN}(n_{i}|Q,A)=softmax(\sum_{t=1}^{T}\alpha_{t} || v_{t} || _{2})",where \(T\) represents the total token count in \(n_{i}\),\alpha_{t}=\frac{\exp(\alpha_{t})}{\sum_{i=1}^{k}\exp(\alpha_{i})},The attention score distribution over the question-relevant documents is calculated using the Softmax operator.
naacl_2024_short_62,2,"P_{RETR}(n_{i}|Q)=\frac{exp(s(n_{i},Q)/\theta)}{\sum_{k=1}^{K}exp(s(n_{k},Q)/\theta)}","where \(s\) denotes the dot-product between the representation vectors of the input question \(Q\) and document candidate \(n_{i}\), and \(\theta\) is the temperature hyper-parameter","p_{RETR}(n_{i}|Q)=\frac{sim(n_{i},Q)}{\sum_{j=1}^{k}sim(n_{j},Q)}","where \(sim(n_{i},Q)\) represents the similarity between the question \(Q\) and the document \(n_{i}\)."
naacl_2024_short_66,1,"y_{t}\sim p_{\theta}(y_{t}\midc,x,y_{ct}) || \propto\explogit_{\theta}(y_{t}\midc,x,y _{ct})",,"p(y|x,c;\theta)","The probability distribution of the response \(\mathbf{y}\) given the input query \(\mathbf{x}\) and context \(\mathbf{c}\), conditioned on the model parameters \(\theta\)."
naacl_2024_short_66,2,"y_{t}\sim\tilde{p}_{\theta}(y_{t}\midc,x,y_{ct}) || \propto p_{\theta}(y_{t}\midc,x,y_{ct})\bigg{(}\frac{p_{\theta}(y_{t}\midc,x,y_{ct})}{p_{\theta}(y_{t}\mid\bm {x},y_{ct})}\bigg{)}^{\alpha}",,"p_{\theta}(y_{t}\midc,x,y_{ct})\propto p_{\theta}(y_{t}\midx,y_{ct})\cdot 2^{PMI(y_{t};c\midx,y_{ct})}","The probability distribution of the model's output given the context, query, and previous output, adjusted using pointwise mutual information."
naacl_2024_short_66,3,"y_{t}\simsoftmax[(1+\alpha)\,logit_{\theta}(y_{t}\midc,x,y_{ct}) || \qquad\qquad-\alpha\,logit_{\theta}(y_{t}\midx,y _{ct})]",,"\tilde{p}_{\theta}(y_{t}\midc,x,y_{ct})=\frac{p_{\theta}(y_{t}\midc,x,y_{ct})\bigg{(}\frac{p_{\theta}(y_{t}\midc,x,y_{ct})}{p_{\theta}(y_{t}\midx,y_{ct})}\bigg{)}^{\alpha}}{\sum_{y'_{t}\inV}p_{\theta}(y'_{t}\midc,x,y_{ct})\bigg{(}\frac{p_{\theta}(y'_{t}\midc,x,y_{ct})}{p_{\theta}(y'_{t}\midx,y_{ct})}\bigg{)}^{\alpha}}","\(\tilde{p}_{\theta}(y_{t}\mid\mathbf{c},\mathbf{x},\mathbf{y}_{ct})\) represents the normalized probability distribution of the model's output given the context, query, and previous output tokens."
naacl_2024_short_67,1,"h_{0}^{x},h_{1}^{x},...,h_{n}^{x}=\textbf{BERT}(w_{0}^{x},w_{1}^{x},...,w_{n}^{x}) || x^{c}=h_{0}^{x},x^{h}=h_{[E_{h}]}^{x},x^{t}=h_{[E_{t}]}^{x}",,H_{h}=Encoder(x)[E_{h}],The representation of the head entity.
naacl_2024_short_67,2,x^{vec}=x^{c}\oplus x^{h}\oplus x^{t},where \(d\) is the hidden dimension of the encoder and \(\oplus\) denotes the concatenation operator,x^{vec}=[x^{c}; x^{h}; x^{t}],"The comprehensive representation \(x^{vec}\) of the input instance is a concatenation of the contextual information \(x^{c}\), head entity \(x^{h}\), and tail entity \(x^{t}\)."
naacl_2024_short_67,3,"h_{0}^{d},h_{1}^{d},...,h_{n}^{d}=\textbf{BERT}(w_{0}^{d},w_{1}^{d},...,w_{n}^ {d}) || d^{c}=h_{0}^{d} || d^{h}=\textit{WeightPooling}_{1}(h_{1}^{d},...,h_{n}^{d}) || d^{t}=\textit{WeightPooling}_{2}(h_{1}^{d},...,h_{n}^{d}) || d^{vec}=d^{c}\oplus d^{h}\oplus d^{t}",,d^{vec}=d^{c}\oplus d^{h}\oplus d^{t},"where \(d^{c}\), \(d^{h}\), and \(d^{t}\) are the contextual, head, and tail representations of the relation description, respectively."
naacl_2024_short_67,4,"H=(h_{1}^{d},...,h_{n}^{d}) || A=\textit{softmax}(HW+b) || d^{*}=AH",,d^{h}=\sum_{i=1}^{n}\alpha_{i} h_{i}^{d},where \(\alpha_{i}\) represents the attention weight for the \(i\)-th token in the relation description.
naacl_2024_short_67,5,"L_{i}=-\log\frac{e^{sim(x_{i}^{vec},d_{i}^{vec})/\tau}}{\sum_ {j=1}^{N}e^{sim(x_{i}^{vec},d_{j}^{vec})/\tau}}",where \(\tau\) is a temperature hyperparameter and \(\text{sim}(\cdot)\) is the cosine similarity,"L_{i}=-\log\frac{\exp(sim(x_{i}^{vec},d_{i}^{vec})/\tau)}{\exp(sim(x_{i}^{vec},d_{i}^{vec})/\tau)+\sum_{j\neq i}\exp(sim(x_{i}^{vec},d_{j}^{vec})/\tau)}","where \(sim\) denotes the cosine similarity function, and \(\tau\) is a temperature hyperparameter."
naacl_2024_short_67,6,O_{i}=\textit{Pooling}(BERT(\langle x\oplus d_{j}\rangle)) || \hat{y}=\textit{MLP}(O_{0}\oplus O_{1}\oplus...O_{k}) || L_{c}=-log(\frac{e^{\hat{y}_{+}}}{\sum_{i=1}^{k}e^{\hat{y}_{i}}}),,"p(d_{+}|x,D)=\frac{e^{sim(x^{vec},d_{+}^{vec})}}{\sum_{d_{j}\in D}e^{sim(x^{vec},d_{j}^{vec})}}","where \(p(d_{+}|x,D)\) represents the probability of selecting the correct relation description \(d_{+}\) given the input instance \(x\) and the set of relation descriptions \(D\)"
naacl_2024_short_69,1,ATE=E[Y^{a=1}-Y^{a=0}],,ATE=E[Y^{a=1}]-E[Y^{a=0}],"The average treatment effect (ATE) of A on Y, representing the difference in expected outcomes between the treatment and control groups."
naacl_2024_short_69,2,A=a\\Rightarrow\Y^{a}=Y,,Y=Y^A=Y^{a=1} &if  A=1\\Y^{a=0} &if  A=0,"The equation represents the consistency assumption in causal inference, where the observed outcome Y is equal to the counterfactual outcome Y^A, which depends on the treatment assignment A."
naacl_2024_short_69,3,"Y^{a}\perp A\mid C\quad\forall a\in\{0,1\}",,Y^{a}\perp A | C,The conditional exchangeability assumption states that the counterfactual outcome $Y^{a}$ is independent of the observed treatment $A$ given all confounders $C$.
naacl_2024_short_69,4,"E[Y^{a}]=\sum_{C}E[Y^{a}\mid C]P(C) || \overset{\eqref{eq:constraint}}{=}\sum_{C}E[Y^{a}\mid A=a,C]P(C)",,E[Y^{a}]=E[E[Y^{a}\mid C]],"The counterfactual expectation of Y given a, which represents the expected outcome if all units had received treatment a."
naacl_2024_short_69,5,"\overset{\eqref{eq:constraint}}{=}\sum_{C}E[Y\mid A=a,C]P(C)",,"E[Y^{a}]=\sum_{C}E[Y\mid A=a,C]P(C)",The equation represents the expected value of the counterfactual outcome \(Y^{a}\) using the conditional exchangeability assumption and the law of total expectation.
naacl_2024_short_69,6,E[Y^{a}]=\frac{1}{N}\sum_{i\in[N]}Y_{i}\frac{\mathds{1}(A_{i}=a)}{P(A_{i}=a\mid T)},,E[Y^{a}]=\frac{1}{N}\sum_{i=1}^{N}\frac{A_i=a}{P(A=a\mid T_i)}Y_i,The equation calculates the expected counterfactual outcome using the Inverse Propensity of Treatment Weighting method.
naacl_2024_short_7,1,"\underset{\theta}{min}\,E_{S^{i}}[\frac{1}{k+1}\sum_{i=0}^{k}l( M_{\theta}(S^{i}),f(x_{i+1}))]",,"l(M_{\theta}(S^{i}), f(x_{i+1}))=(M_{\theta}(S^{i})-f(x_{i+1}))^2",The loss function l measures the squared difference between the model's prediction and the actual output.
naacl_2024_short_7,2,"f(x)=\varphi(\langle x,w\rangle)",,f(x)=\alpha\cdot h(\beta^T x),"The function f is defined as a single-index function, where h is a normalized Hermite polynomial, α is a scalar, β is a d-dimensional vector, and x is the input."
naacl_2024_short_7,3,\varphi_{linear}(t)=t || \varphi_{quadratic}(t)=\frac{1}{\sqrt{2}}(t+\frac{1}{\sqrt{2}}(t^{2}-1)) || \varphi_{cubic}(t)=\frac{1}{\sqrt{3}}(t+\frac{1}{\sqrt{ 2}}(t^{2}-1)+\frac{1}{\sqrt{6}}(t^{3}-3t)),,\varphi_{linear}(t)=t,\( \varphi_{\text{linear}}(t) \) represents a linear function class.
naacl_2024_short_7,4,f\simF_{1}&1\leq t<\frac{T}{3}\\F_{2}&\frac{T}{3}\leq t<\frac{2T}{3}\\F_{3}&\frac{2T}{3}\leq t<T,,T=\sum_{k=1}^{K} T_{k},The total training steps T is the sum of the training steps for each of the K function classes.
naacl_2024_short_7,5,f\simF_{1}&1\leq t<\frac{T}{3}\\\sum_{s=1}^{2}1(\xi=s)F_{s}&\frac{T}{3}\leq t<\frac{2T}{3}\\\sum_{s=1}^{3}1(\zeta=s)F_{s}&\frac{2T}{3}\leq t<T,,"p(f\simF_{k})=\frac{1}{\min(\zeta,k)}\sum_{i=1}^{\min(\zeta,k)}1_{\{k=i\}}",The probability of selecting a task from the k-th function class is determined by the mixed curriculum strategy.
naacl_2024_short_7,6,"f\sim\sum_{s=1}^{3}1(\zeta=s)F_{s},\quad 1\leq t<T",,f\simF_{1}&with probability \frac{1}{3}\\F_{2}&with probability \frac{1}{3}\\F_{3}&with probability \frac{1}{3},"The variable \(f\) represents a function class randomly selected from \(\mathcal{F}_{1}\), \(\mathcal{F}_{2}\), or \(\mathcal{F}_{3}\) with equal probability at each training step."
naacl_2024_short_8,1,"s_{m}(q,d)=T_{\texttt{[CLS]}}W+b","where \(T_{\texttt{[CLS]}}\in\mathbf{R}^{D}\) is the [CLS] representation on the final layer, and \(W\in\mathbf{R}^{D\times 1}\) and \(b\in\mathbf{R}\) are the weight and bias for classification","s_{q,d}=BERT_{[CLS]}([q; d])","The variable \(s_{q,d}\) represents the relevance score between a query \(q\) and a document \(d\)."
naacl_2024_short_8,2,"s_{m}(q,d)=\frac{1}{n}\sum_{i}^{n}(T_{tok_{i}}W+b)","where \(T_{tok_{i}}\) is the final-layer representation of the \(i\)-th token, and \(n\) is the total number of tokens in the input sequence","s_{mp}(q,d)=\frac{1}{n}\sum_{i=1}^{n} T_i W+b","where \(T_i\) represents the token representation on the final layer, \(n\) is the total number of tokens, and \(W\) and \(b\) are the weight and bias for classification."
naacl_2024_short_8,3,v_{q_{i}}=T_{q_{i}}W+b;\quad v_{d_{j}}=T_{d_{j}}W+b,"where \(q_{i}\) and \(d_{j}\) represent the \(i\)-th token of query \(q\) and the \(j\)-th token of document \(d\), respectively","s_{c}(q,d)=\sum_{i}^{n_q}\sum_{j}^{n_d}(T_{tok_{i}}^{q})^TW(T_{tok_{j}}^{d})","where \(T_{tok_{i}}^{q}\) and \(T_{tok_{j}}^{d}\) are the final-layer representations of the \(i\)-th token in the query and the \(j\)-th token in the document, \(n_q\) and \(n_d\) are the total number of tokens in the query and document, and \(W\in\mathbf{R}^{D\times D}\) is the weight matrix for classification"
naacl_2024_short_8,4,"s_{l}(q,d)=\sum_{q_{i}}\max_{d_{j}}(v_{q_{i}}^{T}v_{d_{j}})",,"s_{c}(q,d)=\sum_{i}^{n}\max_{j}(v_{q_{i}}\cdot v_{d_{j}})","where \(v_{q_{i}}\) and \(v_{d_{j}}\) represent the projected token representations of the \(i\)-th query token and the \(j\)-th document token, respectively."
naacl_2024_short_8,5,"L=lce(s_{m}(q,d^{+}),s_{m}(q,d_{1}^{-}),...,s_{m}(q,d_{n}^ {-})) || +lce(s_{l}(q,d^{+}),s_{l}(q,d_{1}^{-}),...,s_{l}(q,d_{n}^ {-}))",,"L_{LCE}=\frac{1}{N}\sum_{i=1}^{N}\left(\log(1+\exp(-s_{m}(q,d)))+\log(1+\exp(-s_{l}(q,d)))\right)","where \(N\) is the total number of training samples, and \(s_{m}(q,d)\) and \(s_{l}(q,d)\) are the relevance scores from the monoBERT and late interaction models, respectively."
naacl_2024_short_9,1,"L_{ir}(q,p_{i})=-\log(\frac{e^{q\cdot p_{t}}}{\sum_{i=1}^{N}e^{q\cdot p_{ i}}})",,"L=\sum_{i=1}^{N}\max(0,\gamma-q\cdot p_{t}+q\cdot p_{i})","The loss function L measures the difference between the inner product of the query embedding q and the gold passage embedding p_t, and the inner product of q and other passage embeddings p_i, with a margin gamma."
naacl_2024_short_9,2,"L_{c}(q_{s},q_{t})=-\log(\frac{e^{q_{s}\cdot q_{t}}}{\sum_{j=1}^{N}e^{q_ {s}\cdot q_{j}}})",,"L_{c}(q_{s},q_{t})=-\log(\frac{e^{q_{s}\cdot q_{t}}}{\sum_{j=1}^{N}e^{q_{s}\cdot q_{j}}})","The contrastive loss term \(L_{c}\) measures the similarity between the English query embedding \(q_{s}\) and its code-mixed counterpart \(q_{t}\), while comparing it to all other code-mixed query embeddings \(q_{j}\) in the batch."
naacl_2024_short_9,3,L=L_{ir}+wL_{c},where \(w\) is a hyperparameter for weighting the contrastive loss,L_{total}=L_{ir}+\lambda L_{c},"The total training objective is a combination of the information retrieval loss and the contrastive loss, where \(\lambda\) is a hyperparameter that controls the weight of the contrastive loss."
neurips_2024_oral_10,1,"q(x_{1:T}|x_{0})\coloneqq\prod_{t=1}^{T}q(x_{t}|x_{t-1}) || q(x_{t}|x_{t-1})\coloneqqN(x_{t};\sqrt{1-\beta_{t}}x _{t-1},\beta_{t}I)",,x_{t}=\sqrt{1-\beta_{t}} x_{t-1}+\sqrt{\beta_{t}}\epsilon_{t},"The equation represents the diffusion process where $x_{t}$ is the noisy feature at step $t$, $x_{t-1}$ is the previous feature, $\beta_{t}$ is the noise schedule, and $\epsilon_{t}$ is the noise added at step $t$."
neurips_2024_oral_10,2,"p_{\theta}(x_{0:T})\coloneqq p(x_{T})\prod_{t=1}^{T}p_{\theta}(x_{t-1}|x_{t}) || p_{\theta}(x_{t-1}|x_{t})\coloneqqN(x_{t-1};\mu_{\theta}(x_{t },t),\Sigma_{\theta}(x_{t},t))",,p(x_{0:T})\coloneqq p(x_{0})\prod_{t=1}^{T}p(x_{t}|x_{t-1}),"The equation represents the reverse process of diffusion modeling, where the goal is to learn the data distribution and generate clean features from noisy ones."
neurips_2024_oral_10,3,"X_{t-1}=\frac{1}{\sqrt{a_{t}}}(X_{t}-\frac{1-a_{t}}{\sqrt{1-\tilde{a_{t}}}}D_{\theta}(X_{t},t))+\sigma_{t}z","where \(a_{t}=1-\beta_{t}\), \(D_{\theta}\) are the parameters of the prediction noise network",W_{fuse}=W_{emb}+W_{denoise},The fused weight matrix is the sum of the embedding layer weight matrix and the denoising layer weight matrix.
neurips_2024_oral_10,4,Y&=WX+b\\\frac{1}{\sqrt{a_{t}}}X_{t}-X_{t-1}&=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}D_{\theta}X_{t}-\sigma_{t}z\\\frac{1}{\sqrt{a_{t}}}Y_{t}-Y_{t-1}&=\frac{1-a_{t} }{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}D_{\theta}Y_{t}-\sigma_{t}z,,\tilde{a_{t}}=\prod_{i=1}^{t}a_{i},where \(\tilde{a_{t}}\) represents the cumulative product of \(a_{i}\) from 1 to t
neurips_2024_oral_10,5,"Y_{t-1}=[W-C_{1}(t)WW_{D}]X_{t}+WC_{2}(t)C_{3}+b\\C_{1}(t)=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}\qquad C _{2}(t)=\frac{1-a_{t-1}^{-}}{1-\tilde{a_{t}}}\beta_{t}\qquad C_{3}=Z\sim N(0,I)","where \(W_{D}\) denotes the parameters of \(D_{\theta}(X_{t},t)\), \(X_{t}\) denotes the input of this linear layer, \(Y_{t}\) denotes the output of this linear layer, and \(Y_{t-1}\) denotes the result after denoising in one step of \(Y_{t}\)",\frac{1}{\sqrt{a_{t}}}Y_{t}-Y_{t-1}=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}D_{\theta}(WX_{t}+b)-\sigma_{t}z,"where \(Y_{t}\) represents the embedding output at step \(t\), \(W\) and \(b\) are the learnable weights and bias of the embedding layer, and \(D_{\theta}\) denotes the parameters of the prediction noise network."
neurips_2024_oral_10,6,\frac{1}{\sqrt{a_{t}}}Y_{t}-Y_{t-1}=C_{1}(t)D_{\theta}Y_{t}-\sigma_{t}z || \frac{1}{\sqrt{a_{t-1}}}Y_{t-1}-Y_{t-2}=C_{1}(t-1)D_{\theta}Y_{t-1}-\sigma_{t-1}z,,Y_{t-2}=[W-C_{1}(t)WW_{D}-C_{1}(t-1)WW_{D}]X_{t}+WC_{2}(t)C_{3}+b,where \(Y_{t-2}\) denotes the result after two-step denoising of \(Y_{t}\).
neurips_2024_oral_10,7,Y_{t-2}=W^{\prime\prime}X_{t}+C^{\prime\prime}\\W^{\prime\prime}=\frac{1}{\sqrt{a_{t}-1}}\{\frac{W}{\sqrt{a_{t} }}-[C_{1}(t)+C_{1}(t-1)]WW_{D}+\sqrt{a_{t}}C_{1}(t-1)C_{1}(t)WW_{D}W_{D}\}\\C^{\prime\prime}=\frac{1}{\sqrt{a_{t}-1}}[WC_{2}(t)+\sqrt{a_{t}}WC_{ 2}(t-1)-\sqrt{a_{t}}C_{1}(t-1)C_{2}(t)WW_{D}]Z+b,,Y_{t-2}=[W-C_{1}(t)WW_{D}][W-C_{1}(t-1)WW_{D}]X_{t}+[W-C_{1}(t)WW_{D}]WC_{2}(t-1)C_{3}+WC_{2}(t)C_{3}+b,"where \(W_{D}\) denotes the parameters of \(D_{\theta}(X_{t},t)\), \(X_{t}\) denotes the input of this linear layer, \(Y_{t}\) denotes the output of this linear layer, and \(Y_{t-1}\) denotes the result after denoising in one step of \(Y_{t}\)"
neurips_2024_oral_10,8,"Loss_{p}=\sum_{i=1}^{N}|\epsilon_{i}-D_{\theta_{i}}(X_{t_{i}},t_{i})|","where \(\epsilon\) denotes the sampled noise, \(N\) denotes the number of denoising layers, \(X_{t}\) denotes the noise sample, \(t\) denotes the diffusion step, and \(D_{\theta}(X_{t},t)\) denotes the noise predicted by the denoising layer",L_{p}=\sum_{i=1}^{N}\left\|F_{i}-\hat{F}_{i}\right\|_{2}^{2},"where \(F_{i}\) is the feature of the i-th layer, and \(\hat{F}_{i}\) is the feature after denoising."
neurips_2024_oral_10,9,Loss=(1-\lambda)Loss_{l}+\lambda Loss_{p},,Loss_{total}=Loss_{l}+\lambda Loss_{p},"where \(Loss_{l}\) is the task-specific supervised loss with label, \(Loss_{p}\) is the loss of denoising layers, and \(\lambda\) is the trade-off parameter between two losses."
neurips_2024_oral_11,1,"sim(f,g)=\int_{x\in D(f)}\frac{\mathds{1}[f(x)=g(x)]}{|D(f)|}\\\approx\sum_{x\in X|X\sim D(f)}\frac{\mathds{1}[f(x)=g(x)]}{|X|}",,"sim(f,g)=\frac{1}{|D(f)|}\sum_{x\in D(f)}1_{f(x)=g(x)}",The similarity between two functions f and g is defined as the proportion of identical outputs when given the same input values.
neurips_2024_oral_11,2,"f^{*}=\textsc{FunConsensus}(F)=\operatorname*{arg\,max}_{f_{(i)}\in F}\sum_{ f_{(j)}\in F\setminus\{f_{(i)}\}}sim(f_{(i)},f_{(j)})",,"sim(f,g)=\left\{1 &if \forall x\in D(f):f(x)=g(x)\\0 &otherwise\right","The similarity function sim(f,g) measures the identicalness of outputs between two functions f and g when given the same input values, reaching 1 if and only if the functions output consistent values for all inputs."
neurips_2024_oral_12,1,"P(X_{1},\ldots,X_{d})=\prod_{i=1}^{d}P(X_{i}\midPA_{i})",,"P(X_{1},\ldots,X_{d})=\prod_{j=1}^{d} P(X_{j}|PA_{j})",The joint distribution of the observable variables given the parental variables in a structural causal model.
neurips_2024_oral_12,2,"P(X_{1},\ldots,X_{d}|do(X=x))=\prod_{i:X_{i}\not\inX }P(X_{i}|PA_{i})\big{|}_{X=x}","where \(|_{\mathbf{X}=\mathbf{x}}\) enforces \(X_{1},\ldots,X_{d}\) to be consistent with realizations of \(\mathbf{X}\) else Eq","P(Y|do(X=x))=\sum_{U} P(Y,U|do(X=x))","The causal effect of set of variables \(\mathbf{X}\) on set of variables \(\mathbf{Y}\), denoted as \(P(\mathbf{Y}|do(\mathbf{X}))\), represents the probability distribution of \(\mathbf{Y}\) after intervening on \(\mathbf{X}\) by setting it to a specific value \(\mathbf{x}\)."
neurips_2024_oral_12,3,"P(X_{\sigma(1)},\ldots,X_{\sigma(N)})=P(X_{1},\ldots,X_{N})",,"P(X_{1},X_{2},\ldots,X_{N})=P(X_{\sigma(1)},X_{\sigma(2)},\ldots,X_{\sigma(N)})","Definition of an exchangeable sequence of random variables, where the joint distribution remains unchanged under any finite permutation of the position indices."
neurips_2024_oral_12,4,"P(X_{::[N]}=x_{:,[N]})=\int\int\prod_{n=1}^{N}\prod_{i=1}^{ d}p(x_{i;n}\mida_{i;n}^{G},\theta_{i})d\nu_{1}(\theta_{1})\ldots d\nu_{d}(\theta_{d})",,"P(X_{::1},X_{::2},\ldots)=\int\prod_{n=1}^{\infty}\prod_{i=1}^{d}P(X_{i;[n]}|PA_{i;[n]})dP_{U}","The joint distribution of the sequence can be represented as a mixture of conditionally i.i.d. data, where each conditional distribution is a product of independent causal mechanisms."
neurips_2024_oral_12,5,"P(Y=y|do(X=x))=p(y|x,\psi_{0})=P(Y=y|x),\psi_{0}\inR",,"P(Y|do(X=x))=\int p(y|x,\theta)p(\theta)d\theta","The causal effect of X on Y in an ICM generative process is defined as the integral of the conditional probability of Y given X and theta, with respect to the distribution of theta."
neurips_2024_oral_12,6,"P(Y=y|do(X=x))=\int p(y|x,\psi)p(\psi)d\psi=P(Y=y|x)",,"P(Y=y|do(X=x))=\int p(y|x,\theta,\psi)d\nu(\theta,\psi)",where \(\nu\) is a probability measure over the parameters \(\theta\) and \(\psi\).
neurips_2024_oral_12,7,"\textbf{i.i.d. generative process}:P(X_{1},Y_{1},\ldots,X_{N},Y_{N})\stackrel{{ ind}}{{=}}\prod_{n=1}^{N}P(X_{n},Y_{n})\stackrel{{ idc}}{{=}}[P(X,Y)]^{N}",,"P(Y=y|do(X=x))=\int p(y|x,\psi)p(\psi)d\psi","The causal effect of X on Y in an ICM generative process is defined as the integral of the conditional probability of Y given X and psi, weighted by the probability of psi."
neurips_2024_oral_12,8,"\textbf{ICM gen. process}:P(x_{1},y_{1},\ldots,x_{N},y_{N})=\int\int\prod_{n=1} ^{N}p(y_{n}|x_{n},\psi)p(x_{n}|\theta)d\mu(\theta)d\nu(\psi)",,"P(X_{1},Y_{1},\ldots,X_{N},Y_{N})=\int\int\prod_{n=1}^{N}p(x_{n},y_{n}|\theta,\psi)d\theta d\psi",Equation 8 represents the joint distribution of a sequence of random variables generated by an ICM generative process.
neurips_2024_oral_12,9,"P(X_{J;n}\mid do(X_{I;n}=x))=P(X_{J;m}\mid do (X_{I;m}=x)),\forall n\neq m",,"P(X_{J;n}|do(X_{I;n}=x_{I}))=P(X_{J;m}|do(X_{I;m}=x_{I})),\forall n\neq m","Equation 9 represents the identical marginal post-interventional distributions in ICM generative processes, which states that the post-interventional distribution of a set of variables is the same regardless of the position in the sequence."
neurips_2024_oral_12,10,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=P(y_{1}|\hat{x})P(y_{2}|x_{2})P(x _{2})1_{x_{1}=\hat{x}}",,P(Y_{1}=y|do(X_{1}=\hat{x}))=P(Y_{1}=y|X_{1}=\hat{x}),Equation 10 represents the causal effect of a hard intervention on variable X1 in an ICM generative process.
neurips_2024_oral_12,11,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=\int p(y_{1}|\hat{x},\psi)p(y_{2 }|x_{2},\psi)p(\psi)d\psi p(x_{2})1_{x_{1}=\hat{x}}",,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=\int\int p(y_{1}|\hat{x},\psi)p(y_{2}|x_{2},\psi)p(x_{2}|\theta)p(x_{1}|\theta)\delta(x_{1}=\hat{x})d\theta d\psi",Causal effect in ICM generative processes after a hard intervention on $X_{1}$
neurips_2024_oral_12,12,"p(x_{:,1},\ldots,x_{:,N}|do(X=\hat{x}))=\prod_{i\in I_{X}}p(x_{i;[-N_{i}]}|pa_{i;[-N_{i}]}^{G})\prod_{i\not\in I_{ X}}p(x_{i;[N]}|pa_{i;[N]}^{G})\big{|}_{X=\hat{x}}",,"p(x,y|do(X=\hat{x}))=\int\prod_{i:X_{i}\not\inX}p(x_{i}|pa_{i},\theta_{i})\prod_{j:X_{j}\inX}\delta(x_{j}=\hat{x}_{j})d\theta","Theorem 1 provides a new formula for truncated factorization in ICM generative processes, which is used to calculate the post-interventional distribution after intervening on a set of variables."
neurips_2024_oral_12,13,"P(X_{\negI;n}|do(X_{I;n}=\hat{x} ),X_{\negS})=\prod_{i\not\inI}P(X_{i;n}|X_{i;S},PA_{i;S\cup\{n\}})|_{ X_{I;n}=\hat{x}}",,"P(X_{[\negI];n}\mid do(X_{I;n}=\hat{x}),X_{[\negI];S}=x_{[\negI];S})=P(X_{[\negI];n}\midX_{I;n}=\hat{x},X_{[\negI];S}=x_{[\negI];S})","Equation 13 represents the conditional intervention effect in ICM generative processes, illustrating how the post-intervention distribution changes when conditioning on other observations."
neurips_2024_oral_12,14,"\int\int\prod_{n}p(y_{n}\mid x_{n},\psi)p(x_{n}\mid\theta)p(\theta)p(\psi)d\theta d\psi","where \(p(\theta),p(\psi)\) are Beta distributions and \(p(y_{n}\mid x_{n},\psi),p(x_{n}\mid\theta)\) are Bernoulli distributions","P(x_{1},y_{1},\ldots,x_{N},y_{N})=\int\int\prod_{n=1}^{N}p(y_{n}|x_{n},\psi)p(x_{n}|\theta)d\mu(\theta)d\nu(\psi)","Equation 14 represents the joint distribution of the observed sequence in the causal Polya urn model, which can be perfectly modeled using the ICM generative process with two variables and a causal structure of X → Y."
neurips_2024_oral_13,1,"X_{q}=clamp(\,\lfloor\frac{X}{\Delta}\rceil\!+\!z,0,2^{b}-1),where \Delta=\frac{\max(X)-\min(X)}{2^{b}-1},z=-\lfloor\frac{\min(X)}{\Delta}\rfloor",,Y=X\cdotW\inR^{T\times C_{out}},"\(\mathbf{Y}\) represents the output, \(\mathbf{X}\) is the activation input, and \(\mathbf{W}\) denotes the weight matrix."
neurips_2024_oral_13,2,"R^{1}=E_{d^{(1)}}\hat{R}QE_{d^{(1)}},\qquadQ=1&Q\\O&Q^{\prime}\!",,\hat{R}=\cos(\theta) &-\sin(\theta)\\\sin(\theta) &\cos(\theta),The rotation matrix \(\hat{\mathbf{R}}\) is used to mitigate the effects of outliers in the activation space by applying a rotation transformation.
neurips_2024_oral_13,3,"\hat{R}= BlockDiag(\hat{R}_{b_{1}},...,\hat{R}_{b_{K}})","where \(\hat{\mathbf{R}}_{b_{i}}\in\mathbb{R}^{2^{n}\times 2^{n}}\) denotes a square matrix of the \(i\)-th block, which is constructed following the three steps mentioned above",\hat{R}\approxR^{1}R^{2}\cdotsR^{n}=\prod_{i=1}^{n}E_{d^{(i)}}\tilde{R}QE_{d^{(i)}},The equation represents the approximated optimal rotation matrix \(\hat{\mathbf{R}}\) for mitigating outliers in the activation space.
neurips_2024_oral_13,4,"Var([M_{b_{1}},M_{b_{2}},...,M_{b_{K}}])",,\sigma^{2}=\frac{1}{K}\sum_{i=1}^{K}(M_{b_{i}}-\frac{1}{K}\sum_{j=1}^{K}M_{b_{j}})^{2},"The variance in activation magnitudes across various blocks, denoted as \(\sigma^{2}\), which represents the spread of the mean outlier values among different blocks."
neurips_2024_oral_13,5,Y=X\cdotW=[(X\cdot\underbrace{A^ {-1}}_{G})\hat{R}_{(1)}\cdotP\cdot\hat{R }_{(2)}]\cdot[\underbrace{\hat{R}_{(2)}^{\top}\cdotP^{\top}\cdot\hat{R}_{(1)}^{\top}(A}_{G^{-1}}\cdotW)],"where the notation \(\mathbf{P}\) denotes the orthogonal permutation matrix learned via the zigzag manner, the \(\hat{\mathbf{R}}_{(1)}\) and \(\hat{\mathbf{R}}_{(2)}\) represent the first and second block-diagonal rotation matrix, respectively",Y=PX\hat{R}P^{\top}\hat{R}^{\top}W,"The linear layer transformation using the DuQuant method, which combines rotation and permutation to mitigate Normal and Massive Outliers."
neurips_2024_oral_13,6,\max_{1\leq j\leq 2^{n}}\O_{j}(X_{b_{i}}\hat{R}_{b_{i}})\leq\max_{1\leq j\leq 2^{n}}\O_{j}(X_{b_{i}}),,O_{j}(X\hat{R}_{b_{i}})\leq\frac{1}{\sqrt{2^{n}}}O_{j}(X),The variable \(O_{j}(\mathbf{X}\hat{\mathbf{R}}_{b_{i}})\) represents the maximum outlier of the \(j\)-th dimension \(d_{j}\) within the input after applying the rotation transformation.
neurips_2024_oral_13,7,"M_{b_{i}}\leq O^{(1)}+\frac{(2^{n}K-1)(2^{n-1}-1)}{2^{n}}\delta,\qquad i=1,2, 3,...,K",,M_{b_{i}}\leq\frac{1}{2^{n}}\left(\sum_{j=1}^{2^{n}}O^{(i\cdot2^{n}-2^{n}+j)}\right)+\frac{\delta}{2},The mean value \(M_{b_{i}}\) within each block is upper bounded by the average of the reordered outliers plus half of the maximum difference between consecutive outliers.
neurips_2024_oral_15,1,"\forall x\inX\colonP[c_{x }=1]=\frac{1}{1+\exp(-2ax^{\top}\theta^{*})},\\E[c_{x}]=\tanh(ax^{\top}\theta^{*})\\V[c_{x}]=1-\tanh^{2}(ax^{\top}\theta^{*}),\\E[t_{x}]=\frac{a}{x^{\top}\theta^{*}}\tanh(ax^ {\top}\theta^{*})&if x^{\top}\theta^{*}\neq 0\\a^{2}&if x^{\top}\theta^{*}=0",,u_{z}=z^{\top}\theta^{*},The human utility for arm z is defined as the dot product of the feature vector z and the human's preference parameters θ∗.
neurips_2024_oral_15,2,\forall x\inX\colon x^{\top}\frac{\theta^{*}}{a}=\frac{E [c_{x}]}{E[t_{x}]},,"\forall x\inX\colon\tanh(ax^{\top}\theta^{*})=E[c_{x}]=\frac{1}{n_{x}}\sum_{i=1}^{n_{x}}c_{x,i},\\E[t_{x}]=\frac{a}{x^{\top}\theta^{*}}\tanh(ax^{\top}\theta^{*})=\frac{1}{n_{x}}\sum_{i=1}^{n_{x}}t_{x,i}","The choice-decision-time estimator combines choices and decision times to estimate the human preference vector \(\theta^{*}\), providing a more accurate estimation than using choices alone."
neurips_2024_oral_15,3,"\widehat{\theta}_{CH,DT}\coloneqq(\sum_{x\inX_{ sample}}n_{x}\;xx^{\top})^{-1}\sum_{x\inX_{sample}}n_{x}\;x\;\frac{\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}",,"\widehat{\theta}_{CH,DT}=\arg\min_{\theta\inR^{d}}\sum_{x\inX_{sample}}\left(\frac{\widehat{E}[c_{x}]}{\widehat{E}[t_{x}]}-x^{\top}\theta\right)^{2}","The choice-decision-time estimator calculates the empirical means of both choices and decision times, aggregates the ratios across all sampled queries, and applies ordinary least squares to estimate \(\theta^{*}/a\)."
neurips_2024_oral_15,4,"\widehat{\theta}_{CH}\coloneqq\operatorname*{arg\,max}_{\theta\inR^{d}}\sum_{x\inX_{sample}}\sum_{i=1}^{n_{x}}\log\mu(c_{x,s_{x,i}}\,x^{\top}\theta)",where \(\mu(y)\coloneqq 1/[1+\exp(-y)]\) is the standard logistic function,"\widehat{\theta}_{CH}\coloneqq\arg\max_{\theta\inR^{d}}\sum_{x\inX_{sample}}\sum_{i=1}^{n_{x}}\left[\frac{1+c_{x,s_{x,i}}}{2}\log\frac{1}{1+\exp(-x^{\top}\theta)}+\frac{1-c_{x,s_{x,i}}}{2}\log\frac{\exp(-x^{\top}\theta)}{1+\exp(-x^{\top}\theta)}\right]",The choice-only estimator is based on logistic regression and maximum likelihood estimation to identify the best arm.
neurips_2024_oral_15,5,"\sqrt{n}\;y^{\top}(\widehat{\theta}_{CHD,n}-\theta^{*}/a)\overset{D}{\longrightarrow}N(0,\zeta^{2}/a^{2})",,"\sqrt{n}(y^{\top}\widehat{\theta}_{CH,DT}-y^{\top}\frac{\theta^{*}}{a})\xrightarrow{d}N(0,y^{\top}V_{CH,DT}y)","where \(V_{\text{CH,DT}}\) is the asymptotic covariance matrix of the choice-decision-time estimator."
neurips_2024_oral_15,6,\zeta^{2}\leq\|y\|_{(\sum_{x\inX_{sample}} [\min_{x^{\prime}\inX_{sample}}E[t_{x^{\prime}}]]\cdot xx^{\top})^{-1}}^{-1},,\zeta^{2}\leq\frac{1}{a^{2}}\left(E\left[\left(\frac{c_{x}}{t_{x}}\right)^{2}\right]-\left(E\left[\frac{c_{x}}{t_{x}}\right]\right)^{2}\right),The variable \(\zeta^{2}\) represents the asymptotic variance of the choice-decision-time estimator.
neurips_2024_oral_15,7,"\sqrt{n}y^{\top}(\widehat{\theta}_{CH,n}-2a\theta^{*})\overset{D}{\longrightarrow}N(0,4a^{2}\|y\|_{(\sum_{x\inX_{sample}}[a^{2}\,V[c_{x}] ]\cdot xx^{\top})^{-1}}^{-1})",,"\sqrt{n}\;y^{\top}(\widehat{\theta}_{CH,n}-2a\theta^{*})\overset{D}{\longrightarrow}N(0,\sigma^{2})",The asymptotic variance \(\sigma^{2}\) depends on the Fisher information matrix of the logistic regression model.
neurips_2024_oral_15,8,"\widehat{u}_{x,CH,DT}\coloneqq\frac{\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}",,"\widehat{u}_{CH,DT,x}:=\frac{\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}","The variable \(\widehat{u}_{\text{CH,DT},x}\) represents an estimate of the utility difference \(u_{x}\) for a query \(x\), using both human choices and decision times."
neurips_2024_oral_15,9,"\widehat{u}_{x,CH}\coloneqq\mu^{-1}(\frac{1}{n_{x}}\sum_{i=1}^{n _{x}}\frac{c_{x,s_{x,i}}+1}{2})","where \((c_{x,s_{x,i}}+1)/2\) is the binary choice coded as 0 or 1, and \(\mu^{-1}(p)\coloneqq\log\left(p/(1-p)\right)\) is the logit function (inverse of \(\mu\) introduced in eq","\widehat{u}_{x,CH}\coloneqq\frac{1}{2a}\log\frac{1+\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}/n_{x}}{1-\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}/n_{x}}","The variable \(u_{x}\) represents the utility difference for a query \(x\), and \(\widehat{u}_{x,\text{CH,DT}}\) and \(\widehat{u}_{x,\text{CH}}\) are estimates of \(u_{x}\) based on the choice-decision-time estimator and the choice-only estimator, respectively."
neurips_2024_oral_15,10,"P(|\widehat{u}_{x,CH,DT}-\frac{u_{x}}{a}|>\epsilon)\leq 4\exp(-[m_{CH,DT}^{non-axym}(x^{\top}\theta^{*})]^{2}\,n_{x}\,[\epsilon\cdot a]^{2} )",,"P\left[\left|\widehat{u}_{x,CH,DT}-\frac{u_{x}}{a}\right|\geq\epsilon\right]\leq2\exp\left(-\frac{n_{x}\epsilon^{2}}{2\left(E\left[t_{x}\right]\right)^{2}}\right)","The variable \(u_{x}\) represents the utility difference for a query \(x\in\mathcal{X}\), and \(\epsilon\) is the error tolerance."
neurips_2024_oral_15,11,"P(|\widehat{u}_{x,CH}-2au_{x}|>\epsilon)\leq 6\exp(-[m_{CH}^{non-asym}(x^{\top}\theta^{*} )]^{2}\,n_{x}\,[\epsilon/(2a)]^{2})",,"P(|\widehat{u}_{x,CH}-2au_{x}|>\epsilon)\leq 2\exp(-n_{x}\cdot\frac{\epsilon^{2}}{2\cdot(1+\epsilon/0.3)^{2}})","where \(\dot{\mu}(y)\coloneqq\exp(-|y|)/(1+\exp(-|y|))^{2}\) is the derivative of the logistic function \(\mu\), and the right-hand side is an upper bound on the probability that the estimate deviates from the true value by more than \(\epsilon\)."
neurips_2024_oral_16,1,"H=GNN(A,X)=\tilde{A}XW^{\prime},h_{i}=\sum_{j\inN_{i}}\alpha_{ij}x_{j}\cdotW^{\prime}=\sum_{j\inN_{i}}\frac{1}{d_{ i}}x_{j}\cdotW^{\prime}","where \(\mathbf{W}^{\prime}=\xi(\mathbf{W}),\mathbf{W}\in\mathbb{R}^{D\times K}\) with \(\xi\) being an activation function like ReLU [22] for ease of understanding, \(\mathcal{N}_{i}\) denotes the set of first-order neighbors of node \(v_{i}\), inclusive of \(v_{i}\) itself","L_{DGI}=-E_{v_i\sim p_{data}} [\logD(v_i,G)]-E_{v_i\sim\tilde{p}_{data}} [\log (1-D(v_i,\tilde{G}))]",The DGI loss function measures the difference between the original graph and its corrupted version.
neurips_2024_oral_16,2,"E[h_{i}]&=E [\sum_{j\inN(i)}\alpha_{ij}x_{j}\cdotW^{\prime}]=\sum_{j\inN(i)}\alpha_{ij}E[x_{j}]\cdotW^{\prime}=\sum_{j\inN(i)}\alpha_{ij}\mu_{i}\cdotW^{\prime},\\Var(h_{i})&=Var(\sum_{ j\inN(i)}\alpha_{ij}x_{j}\cdotW^{\prime})=\sum_{j\inN(i)}\alpha_{ij}Var(x_{j})\cdotW ^{\prime 2}=\sigma_{i}^{2}\sum_{j\inN(i)}\alpha_{ij}^{2}\cdotW^{\prime 2}",,"\mu_{h_{i}}=\sum_{j\inN_{i}}\frac{1}{d_{i}}\mu_{i},\sigma^{2}_{h_{i}}=\sum_{j\inN_{i}}\frac{1}{d_{i}^{2}}\sigma_{i}^{2}","where \(\mu_{h_{i}}\) and \(\sigma^{2}_{h_{i}}\) denote the mean and variance of the aggregated representation \(\mathbf{h}_{i}\) for node \(v_{i}\), respectively."
neurips_2024_oral_16,3,"\tilde{h}_{i}=Trans_{R^{d}\toS^{k}}(h_{i})=\frac{h_{i}}{Max(\|h_{i}\|_{2},\varepsilon)},\quadS^{k}=\{\tilde{h}_{i}:\|\tilde{h }_{i}\|_{2}=1\}","where \(\mathbf{h}_{i}\) is representation for node \(v_{i}\in\mathcal{V}\), generated by the target encoder, \(\|\tilde{\mathbf{h}}_{i}\|_{2}=(\sum_{j=1}^{k}\tilde{\mathbf{h}}_{ij}^{2})^{ \frac{1}{2}}\), and \(\epsilon\) is a small value to avoid division by zero",h_{i}=\frac{h_{i}}{\|h_{i}\|_{2}},"where \(\mathbf{h}_{i}\) is the \(i\)-th row vector in the matrix \(\mathbf{H}_{\text{target}}\), and \(\|\mathbf{h}_{i}\|_{2}\) is the \(\ell_{2}\) norm of \(\mathbf{h}_{i}\)."
neurips_2024_oral_16,4,"L_{scattering}=-\frac{1}{n}\sum\nolimits_{i=1}^{n}\|\tilde{h}_{i}-c\|_{2}^{2},\quadc=\frac{1}{n}\sum\nolimits _{i=1}^{n}\tilde{h}_{i}",,"L_{scattering}=\sum_{i=1}^{n}sim(\tilde{h}_{i},c)","where \(\text{sim}(\cdot)\) denotes the cosine similarity function, and \(\mathbf{c}\) is the scattered center"
neurips_2024_oral_16,5,H_{online}^{topology}=\hat{A}^{k}H_{online}+H_{online},where k represents the order of neighbors and \(\hat{\mathbf{A}}=\mathbf{A}+\mathbf{I}\) is the adjacency matrix with self-loops,H_{online}^{topology}=H_{online}+\hat{A}^{k}H_{online},"where \(\mathbf{H}_{\text{online}}^{\text{topology}}\) represents the topologically aggregated representations of the online encoder, and \(\hat{\mathbf{A}}^{\text{k}}\) denotes the k-order normalized adjacency matrix."
neurips_2024_oral_16,6,"L_{alignment}=-\frac{1}{N}\sum_{i=1}^{N}\frac{Z_{(online,i)}^{\top}H_{(target,i)}}{\|Z_{(\text {online},i)}\|\|H_{(target,i)}\|}","where \(\mathbf{Z}_{\text{online}}\) and \(\mathbf{H}_{\text{target}}\) represent the predicted and scattered representations, respectively",L_{alignment}=\frac{1}{n}\sum_{i=1}^{n}\left\|z_{i}-h_{i}\right\|_{2}^{2},The alignment loss measures the difference between the predicted topology representations and the scattered representations.
neurips_2024_oral_16,7,\phiarrow\tau\phi+(1-\tau)\theta,"where \(\tau\) is a target decay rate and \(\tau\in[0,1]\)",L_{SGRL}=L_{scattering}+L_{alignment},where \(\mathcal{L}_{\text{scattering}}\) is the representation scattering loss and \(\mathcal{L}_{\text{alignment}}\) is the alignment loss between the predicted topology representations and the scattered representations.
neurips_2024_oral_17,1,"L_{cons}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}H\Big{(}p_{m}(y\mid f_{\theta}(\alpha(x))),p_{m}(y\mid f_{\theta}(A(x)))\Big{)}",,L_{cons}=L_{sup}+\lambda (L_{pseudo}+L_{reg}),"The consistency loss function L_cons is composed of supervised loss L_sup, pseudo-labeling loss L_pseudo, and regularization loss L_reg, weighted by hyperparameter lambda."
neurips_2024_oral_17,2,"L_{cons}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}d\Big{(}p_{m}(y\mid f_{\theta}(\alpha(x ))-\Delta\Re),p_{m}(y\mid f_{\theta}(A(x)) )\Big{)}",,L_{align}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}\left\lVert f_{\theta}(\alpha(x))-f_{\theta}(A(x))\right\rVert_{2}^{2},"The alignment loss \(\mathcal{L}_{\text{align}}\) measures the difference between the teacher and student representations, aiming to minimize their discrepancy."
neurips_2024_oral_17,3,"E(\xi;X)=\frac{1}{2}\xi^{\top}\xi-\rm{lse}(X^{\top}\xi,\beta)+c,\quadwith \rm{lse}(v,\beta):=\beta^{-1}\log(\sum_{i=1}^{N}\exp(v_{i}))",,"E(\xi,X)=-\frac{1}{N}\sum_{i=1}^{N}\frac{\xi^{\top}x_{i}}{\|\xi\|\|x_{i}\|}",The energy function E measures the similarity between a query pattern ξ and a set of stored patterns X.
neurips_2024_oral_17,4,\xiarrow\xi-\eta\nabla_{\xi}E(\xi;X)=\xi-\rm{sm}(\beta\xi^{\top}X)X^{\top},,\xi\leftarrow\xi-\nabla_{\xi}E(\xi;X)=X\cdotsoftmax(X^{\top}\xi/\beta)-\xi,"The update rule for a state pattern ξ, which moves closer to the most similar stored pattern."
neurips_2024_oral_17,5,"E(Q_{s};K_{t})=\frac{\alpha}{2}diag(K_{t}K_{t}^{T})-\sum_{i=1}^{N}\rm{lse}(Q_{s}k_{t,i}^{T},\beta)+c || E(K_{t})=\rm{lse}(\frac{1}{2}diag(K_{t}K_{t}^{T}),1)=\log\sum_{i=1}^{N}\exp(\frac{ 1}{2}k_{t,i}k_{t,i}^{T})+c",,"E(Q_{s};K_{t})=\frac{1}{2}Q_{s}^{\top}Q_{s}-\rm{lse}(K_{t}^{\top}Q_{s},\beta)+c","The energy function E measures the alignment between the student query patterns and the teacher key patterns, where lse denotes the log-sum-exp function, and β and c are hyperparameters."
neurips_2024_oral_17,6,p(K_{t}|Q_{s})=\frac{p(Q_{s}|K_{t})p(K_{t})}{p(Q_{s})},,K_{t}^{*}=\arg\max_{K_{t}}p(K_{t}\midQ_{s})=\arg\max_{K_{t}}\log p(K_{t}\midQ_{s})=\arg\max_{K_{t}}\log p(Q_{s}\midK_{t})+\log p(K_{t}),The teacher attention update rule is formulated as a maximum a posteriori probability (MAP) estimate of teacher keys given a set of observed student queries.
neurips_2024_oral_17,7,\nabla_{K_{t}}\log p(K_{t}|Q_{s})&=-(\nabla_{K_{t}}E(Q_{s};K_{t})+\nabla_{K_{t}}E(K_{t}))\\&=sm(\betaQ_{s}K_{t}^{T})Q_ {s}-(\alphaI+D(sm(\frac{1}{2}diag(K_{t}K_{t}^{T}))))K_{t},,\nabla_{K_{t}}\log p(K_{t}|Q_{s})=\nabla_{K_{t}}\log p(Q_{s}|K_{t})+\nabla_{K_{t}}\log p(K_{t}),"The equation represents the gradient of the log posterior probability of the teacher keys given the student queries, which is used to update the teacher attention."
neurips_2024_oral_17,8,"K_{t}^{update}=K_{t}+\gamma_{update}[\,(sm(\betaKQ^{T})QW_{K}^{T})-\gamma_{reg }(\alphaI+D(sm(\frac{1}{2}diag (KK^{T})))KW_{K}^{T})\, ]",,K_{t}\leftarrowK_{t}-\eta\cdot\left(\alphaK_{t}-sm(\betaQ_{s}K_{t}^{T})Q_{s}+D(sm(\frac{1}{2}diag(K_{t}K_{t}^{T})))K_{t}\right),"The update rule for teacher keys \(\mathbf{K}_{t}\) based on the gradient of the log posterior, incorporating the energy functions and the softmax function."
neurips_2024_oral_17,9,L_{rep}^{s}=\frac{1}{|B^{\prime}|}\sum_{i\inB^{\prime}}\frac{1}{|N_{i}|}\sum_{q\inN_{i}}-\log\frac{\exp(z_{i}^{T}z_{q}^{\prime}/\tau_{c})}{\sum_{i^{\prime}\neq i }\exp(z_{i}^{T}z_{i^{\prime}}^{\prime}/\tau_{c})} || L_{rep}^{u}=\frac{1}{|B|}\sum_{i\inB}-\log\frac{\exp(z_{i}^{T}z_{i}^{\prime}/\tau_{u} )}{\sum_{i^{\prime}\neq i}\exp(z_{i}^{T}z_{i^{\prime}}^{\prime}/\tau_ {u})},,L_{FlipClass}=L_{sup}+\lambdaL_{cons}+\muL_{cont},"The total loss function for the FlipClass method, combining supervised loss, consistency loss, and contrastive loss."
neurips_2024_oral_17,10,"L_{cons}=\frac{1}{|B|}\sum_{i\inB }\ell(q^{\prime}_{i},p_{i})-\varepsilon H(\bar{p})&for unlabeled,\\\frac{1}{|B|}\sum_{i\inB}\ell(y_{i},p_{i})&for labeled.",,"L_{cons}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}\ell(p_{m}(y\mid f_{\theta}(\alpha(x))),p_{m}(y\mid f_{\theta}(A(x))))",The consistency loss function measures the difference between the predictions of the teacher and student models.
neurips_2024_oral_18,1,G(x)=\exp(-\frac{1}{2}(x-\mu_{0})^{T}\Sigma_{0}^{-1}(x-\mu_{0})),"where \(\Sigma_{0}\) can be factorized as \(\Sigma_{0}=R_{0}S_{0}S_{0}^{T}R_{0}^{T}\), in which \(R_{0}\) is a rotation matrix represented by a quaternion vector \(r_{0}\in\mathbb{R}^{4}\), and \(S_{0}\) is a a diagonal scaling matrix characterized by a 3D vector \(s_{0}\in\mathbb{R}^{3}\)","\mu_{0}=(x, y, z)","\(\mu_{0}\) represents the central point of a 3D Gaussian in 3D space with coordinates x, y, and z."
neurips_2024_oral_18,2,"I(u)=\sum_{i\in N}T_{i}\alpha_{i}c_{i},\qquad A(u)=\sum_{i\in N}T_{i}\alpha_{i },\qquad D(u)=\sum_{i\in N}T_{i}\alpha_{i}d_{i}","where \(T_{i}=\prod_{j=1}^{i-1}(1-\alpha_{j})\) is the accumulated transmittance, \(\alpha_{i}\) is the probability of termination at point \(i\), and \(d_{i}\) is the depth of the Gaussian point at the specific view","I(u)=\sum_{i=1}^{N}\alpha_{i}(u) c_{i},\quad A(u)=\sum_{i=1}^{N}\alpha_{i}(u),\quad D(u)=\sum_{i=1}^{N}\alpha_{i}(u) d_{i}","where \(I(u)\) is the rendered color, \(A(u)\) is the foreground mask, \(D(u)\) is the depth map, \(\alpha_{i}(u)\) is the blending weight, \(c_{i}\) is the color attribute, and \(d_{i}\) is the depth of each Gaussian point at pixel \(u\)."
neurips_2024_oral_18,3,"\mu(t)=\mu_{0}+\sum_{i=1}^{N_{m}}w_{i}(\mu_{0},t)d\mu_{i}(t),\qquad s(t)=s_{0}+\sum_{i=1}^{N_{m}}w_{i}(\mu_{0},t)ds_{i}(t)",,"\mu_{i}(t)=\mu_{0}+\sum_{j=1}^{N_{m}}w_{j}(\mu_{0},t)d\mu_{j}(t),\qquad d_{i}(t)=s_{0}+\sum_{j=1}^{N_{m}}w_{j}(\mu_{0},t)d{s_{j}(t)}",The deformed position and scale for each Gaussian point are calculated using a linear combination of motion bases and coefficients.
neurips_2024_oral_18,4,"L_{gs}=L_{1}(I,\tilde{I})+\lambda_{1}L_{ssim}(I,\tilde{I})+\lambda_{2}L_{1}(s(t))",where \(\lambda_{1}\) and \(\lambda_{2}\) are balancing hyperparameters,"L=\lambda_{1}\left\| I-\tilde{I}\right\|_{1}-\lambda_{2} SSIM(I,\tilde{I})+\lambda_{3}\left\| s-\tilde{s}\right\|_{1}","The loss function combines L1 norm and SSIM between rendered and ground truth images, and L1 norm on scale attributes."
neurips_2024_oral_18,5,"P_{\tilde{P}}=\{(\tilde{p},s_{\Delta x},\sigma_{F})\}","where \(\tilde{p}\in\tilde{P}\), \(s_{\Delta x}=\Delta x/2^{n_{u}}\), and \(\sigma_{F}=F[Discretize(\tilde{p})]\) (we neglect \(t\) in the notation for simplicity)","P(t)=\{(\mu_{i}(t),s_{i}(t),\sigma_{i}(t))\}","where \(\mu_{i}(t)\) is the position of the particle, \(s_{i}(t)\) is the scale attribute, and \(\sigma_{i}(t)\) is the density attribute of the particle at time \(t\)."
neurips_2024_oral_18,6,"L_{ppe}=\frac{1}{m}\sum_{i=1}^{m}[L_{CD}(S(t_{i}),\tilde{S} (t_{i}))+\frac{1}{n}\sum_{j=1}^{n}L_{1}(A_{j}(t_{i}),\bar{A}_{j}(t_{ i}))]","where \(\mathcal{L}_{CD}\) and \(\mathcal{L}_{1}\) are chamfer distance and L1 norm respectively, \(S(t_{i})\) denotes the simulated surface at time \(t_{i}\), \(A_{j}(t_{i})\) is the rendered mask at view \(j\), and \(\bar{A}_{j}(t_{i})\) represents the object mask of the image extracted from video \(V_{j}\) at time \(t_{i}\)","L_{phy}=\sum_{t}L_{chamfer}(\tilde{S}(t),S(t))+\lambda\sum_{t}L_{mask}(\tilde{M}(t),M(t))","where \(\mathcal{L}_{chamfer}\) is the Chamfer distance between two surfaces, \(\mathcal{L}_{mask}\) is the mask loss, and \(\lambda\) is a hyperparameter to balance the two losses."
neurips_2024_oral_2,1,"\operatorname*{minimize}_{\theta}L(\theta;D_{SFT})=-E_{(x,y)\simD_{SFT}}[\log\pi_{\theta}(y|x)]",,L(\theta)=-\sum_{i=1}^{N}\log\pi_{\theta}^{SFT}(y^{(i)}|x^{(i)}),The training objective is to minimize the negative log likelihood of the target answers given the input prompts.
neurips_2024_oral_2,2,"\pi^{\prime}(y_{c}|x)=\sum_{y_{k}}\mu_{\phi}(y_{c}|y_{k},x)\pi_{\theta}(y_{k}|x)\geqslant\mu_{\phi} (y_{c}|y_{o},x)\pi_{\theta}(y_{o}|x)",where \(\mathbf{y}_{k}\) is a possible answer generated by upstream LLM \(\pi_{\mathbf{\theta}}\),"\mu_{\phi}(y_{c}|y_{o},x)=\frac{\exp(\score_{\phi}(y_{c},y_{o},x))}{\sum_{y'\inY}\exp(\score_{\phi}(y',y_{o},x))}","The variable \(\mu_{\mathbf{\phi}}(\mathbf{y}_{c}|\mathbf{y}_{o},\mathbf{x})\) represents the probability of generating the corrected answer \(\mathbf{y}_{c}\) given the original answer \(\mathbf{y}_{o}\) and the user's query \(\mathbf{x}\)."
neurips_2024_oral_2,3,"-E_{M}[\log\pi^{\prime}(y_{c}|x)]\leqslant-E_{M}[\log\mu_{\phi}(y_{c}|y_{o},x)]-E_{M}[\log\pi_{\theta}(y_{o}|x)]",,"L(\phi;M)=-\sum_{i=1}^{N}\log\mu_{\phi}(y_{c}^{(i)}|y_{o}^{(i)},x^{(i)})",where \(\mathcal{L}(\mathbf{\phi};\mathcal{M})\) represents the empirical loss on the dataset \(\mathcal{M}\) for training the _Aligner_ model \(\mu_{\mathbf{\phi}}\).
neurips_2024_oral_2,4,"\operatorname*{minimize}_{\phi}L_{Aligner}(\phi,M)=-E_{M}[\log\mu_{\phi}(y_{c} |y_{o},x)]",,"\operatorname*{minimize}_{\phi}L(\phi;M)=-E_{M}[\log\mu_{\phi}(y_{c}|y_{o},x)]",The variable \(\mathbf{\phi}\) represents the parameters of the _Aligner_ model.
neurips_2024_oral_21,1,"q(X_{V}^{t}\midX_{V}^{t-1})=Cat(X_{V}^{t};p=X_{V}^{t-1}Q_{V}^{t}),\\q(X_{E}^{t}\midX_{E}^{t-1})=Cat(X_{E}^ {t};p=X_{E}^{t-1}Q_{E}^{t})",where \(\mathrm{Cat}(\mathbf{X};\mathbf{p})\) denotes sampling from a categorical distribution with probability \(\mathbf{p}\),q(G^{1:T}\mid G^{0})=\prod_{t=1}^{T}q(G^{t}\mid G^{t-1}),The diffusion process that corrupts molecular graph data into noisy states.
neurips_2024_oral_21,2,p_{\theta}(\tilde{G}^{0}\mid G^{t})=\prod_{v\in V}p_{\theta}(v^{t-1}\mid G^{t})\prod_{e\in E}p_{\theta}(e^{t-1}\mid G^{t}),,\bar{Q}^{t}=\bar{\alpha}^{t}I+(1-\bar{\alpha}^{t})1m^{\prime},where \(\bar{\alpha}^{t}=\prod_{\tau=1}^{t}\alpha^{\tau}\) represents the cumulative noise schedule at timestep \(t\).
neurips_2024_oral_21,3,"p_{\theta}(v^{t-1}\mid G^{t})=\sum_{\tilde{v}\in\tilde{x}_{v}}q(v^{t-1 }\mid\tilde{v},G^{t})p_{\theta}(\tilde{v}\mid G^{t})",,"p_{\theta}(G^{t-1}\mid G^{t})=\sum_{\tilde{G}^{0}}p_{\theta}(\tilde{G}^{0}\mid G^{t})q(G^{t-1}\mid G^{t},\tilde{G}^{0})",where \(p_{\theta}(G^{t-1}\mid G^{t})\) represents the estimated reverse distribution on the graph at step \(t-1\) given the graph at step \(t\)
neurips_2024_oral_21,4,L=E_{q(G^{0})}E_{q(G^{t}|G^{0})}[-E_{x\in G^{0}}\log p_{\theta}(x\mid G^{t})],,L(\theta)=-E_{q(G^{0:T})}\left[\log p_{\theta}(G^{0:T})\right],The loss function for training the neural network is defined as the negative log-likelihood of the reverse process.
neurips_2024_oral_21,5,Q_{G}=Q_{V}&1_{N}^{\prime}\otimesQ_{VE}\\1_{N}\otimesQ_{EV}&1_{N\times N}\otimesQ_{ E},"where \(\otimes\) denotes the Kronecker product, \(\mathbf{1}_{N}\), \(\mathbf{1}_{N}^{\prime}\), and \(\mathbf{1}_{N\times N}\) represent the column vector, row vector, and matrix with all 1 elements, respectively","q(X_{G}^{t}\midX_{G}^{t-1})=Cat(X_{G}^{t};p=X_{G}^{t-1}Q_{G}^{t}),\\Q_{G}^{t}=Q_{V}^{t} &Q_{VE}^{t}\\Q_{EV}^{t} &Q_{E}^{t}","The transition probability of a graph token relies on the joint distribution of nodes and edges in the prior state, represented by a single matrix \(\mathbf{X}_{G}\) and a transition matrix \(\mathbf{Q}_{G}\)."
neurips_2024_oral_21,6,q(X_{G}^{t}\midX_{G}^{t-1})=\widetilde{Cat}(X_{G}^{t};\tilde{p}=X_{G}^{t-1}Q_{G}^{t} ),"where \(\tilde{\mathbf{p}}\) is the unnormalized probability and \(\widetilde{\mathrm{Cat}}\) denotes categorical sampling: The first \(F_{V}\) columns of \(\tilde{\mathbf{p}}\) are normalized to sample \(\mathbf{X}_{V}^{t}\), while the remaining \(N\cdot E\) dimensions are reshaped and normalized to sample edges \(\mathbf{X}_{E}^{t}\)",q(X_{G}^{t}\midX_{G}^{t-1})=Cat(X_{G}^{t};p=X_{G}^{t-1}Q_{G}^{t}),where \(\mathbf{Q}_{G}^{t}\) is the graph-dependent transition matrix at timestep \(t\)
neurips_2024_oral_21,7,"\hat{p}_{\theta}(G^{t-1}\mid G^{t},C)=\log p_{\theta}(G^{t-1}\mid G^{ t})+s(\log p_{\theta}(G^{t-1}\mid G^{t},C)-\log p_{\theta}(G^{t-1}\mid G^{t}))",where \(s\) denotes the scale of conditional guidance,"\hat{p}_{\theta}(G^{t-1}\mid G^{t},C)=\frac{1}{Z}\left[p_{\theta}(G^{t-1}\mid G^{t})+\sum_{m=1}^{M}\lambda_{m}\log q(c_{m}\mid G^{t-1})\right]",where \(Z\) is the normalization constant and \(\lambda_{m}\) is a hyperparameter controlling the strength of guidance for condition \(c_{m}\).
neurips_2024_oral_21,8,"AdaLN(h,c)=\gamma_{\theta}(c)\odot\frac{h-\mu(h)}{\sigma(h )}+\beta_{\theta}(c)",where \(\mu(\cdot)\) and \(\sigma(\cdot)\) are mean and variance values,"H=AdaLN(H,c)=H\cdot\frac{c}{\|c\|}",where $\mathbf{c}$ is the condition representation and $\|\mathbf{c}\|$ is its Euclidean norm
neurips_2024_oral_21,9,"AdaLN_{gate}(h,c)=\alpha_{\theta}(c)\odotAdaLN(h,c)",,"AdaLN_{gate}(h,c)=\gamma_{\theta}(c)\odot\frac{h-\mu(h)}{\sigma(h )}+\beta_{\theta}(c)","where \(\odot\) indicates element-wise product and \(\gamma_{\theta}(\cdot)\) and \(\beta_{\theta}(\cdot)\) are neural network modules in \(f_{\theta}(\cdot)\), each of which consists of two linear layers with \(\mathrm{SiLU}\) activation in the middle."
neurips_2024_oral_21,10,"\tilde{X}_{G}^{0}=AdaLN(MLP(H),c)",,"\tilde{X}_{V}^{0}=MLP(H),\tilde{X}_{E}^{0}=MLP(H)",where \(\tilde{\mathbf{X}}_{V}^{0}\) and \(\tilde{\mathbf{X}}_{E}^{0}\) are the predicted node and edge probabilities at \(t=0\)
neurips_2024_oral_22,1,"dx_{\sigma}\,=\,-\sigma\nabla_{x_{\sigma}}\!\log p (x_{\sigma};\sigma)\;d\sigma",,"p(x;\sigma)=p_{data}(x)*N(x;0,\sigma^{2}I)",The equation represents the heat diffusion of the data distribution into a sequence of smoothed densities.
neurips_2024_oral_22,2,"\theta\,=\,\arg\min_{\theta}E_{y\sim p_{data},\sigma\sim p_{train},n\simN(0,\sigma^{2}I)}\|D_{\theta}(y+n;\sigma)-y\|_{2}^ {2}",where \(p_{\text{train}}\) controls the noise level distribution during training,\nabla_{x}\log p(x;\sigma)\approx D_{\theta}(x;\sigma),The score function is approximated by a neural network $D_{\theta}(\mathbf{x};\sigma)$ for denoising tasks.
neurips_2024_oral_22,3,"D_{w}(x;\sigma,c)\,=\,wD_{1}(x;\sigma,c)+( 1-w)D_{0}(x;\sigma,c)",,"D_{w}(x;\sigma,c)\,=\,wD_{1}(x;\sigma,c)+(1-w)D_{0}(x;\sigma,c)","where \(D_{0}(\mathbf{x};\sigma,\mathbf{c})\) and \(D_{1}(\mathbf{x};\sigma,\mathbf{c})\) are denoiser networks with and without class conditioning, respectively, and \(w\) is the guidance scale."
neurips_2024_oral_22,4,"D_{w}(x;\sigma,c)\approxx+\sigma^{2}\nabla_{x}\log\underbrace{(p_ {0}(x|c;\sigma)[\frac{p_{1}(x|c;\sigma)}{p_{0}(x|c;\sigma)}]^{w})}_{\propto:\p_{w}(x|c;\sigma)}",,"\nabla_{x}\log p(x|c;\sigma)\approx\frac{1}{\sigma^{2}}(D_{w}(x;\sigma,c)-x)\,=\,\frac{w}{\sigma^{2}}(D_{1}(x;\sigma,c)-x)+\frac{1-w}{\sigma^{2}}(D_{0}(x;\sigma,c)-x)","where \(D_{w}(\mathbf{x};\sigma,\mathbf{c})\) represents the guided denoiser and \(\nabla_{\mathbf{x}}\log p(\mathbf{x}|\mathbf{c};\sigma)\) is the score function for the conditional distribution."
neurips_2024_oral_22,5,\nabla_{x}\log p_{w}(x|c;\sigma)=\nabla_{x}\log p_{1}(x|c;\sigma)+(w-1)\nabla_{x}\log\frac{p_{1}(x|c;\sigma)}{p_{0}(x|c;\sigma)},,"\nabla_{x}\log p_{w}(x|c;\sigma)\,=\,\nabla_{x}\log p_{0}(x|c;\sigma)+w\nabla_{x}\log\frac{p_{1}(x|c;\sigma)}{p_{0}(x|c;\sigma)}","The equation represents the score of the density $p_{w}(\mathbf{x}|\mathbf{c};\sigma)$, which is used for guidance in diffusion models."
neurips_2024_oral_23,1,"|Cov(f(X),Y\mid X\in S)|\leq\alpha",,\sup_{f\inF}\left|E_{x\in S}[f(x)]-E_{x\in S}[Y]\right|\leq\alpha,"The equation represents the definition of an \(\alpha\)-indistinguishable subset \(S\) with respect to a function class \(\mathcal{F}\) and target \(Y\), where the difference between the expected value of any predictor \(f\) in \(\mathcal{F}\) and the expected value of \(Y\) over \(S\) is bounded by \(\alpha\)."
neurips_2024_oral_23,2,"\gamma^{*},\beta^{*}\in\operatorname*{arg\,min}_{\gamma\inR^{K},\beta\inR^{K}}\;E[(Y-\gamma_{J(X)}+\beta_{J(X)}\hat{Y})^{2}]",,"\gamma_{k}^{*}=E_{k}[Y],\quad\beta_{k}^{*}=\frac{Cov_{k}(\hat{Y},Y)}{Var_{k}(\hat{Y})}",\(\gamma_{k}^{*}\) and \(\beta_{k}^{*}\) represent the optimal intercept and slope for predicting \(Y\) using \(\hat{Y}\) within subset \(S_{k}\)
neurips_2024_oral_23,3,"E_{k}[(Y-\gamma_{k}^{*}-\beta_{k}^{*}\hat{Y})^{2} ]+4Cov_{k}(Y,\hat{Y})^{2}\leqE_{k}[(Y-f(X) )^{2}]+2\alpha",,E_{k}[(Y-\gamma^{*}_{k}+\beta^{*}_{k}\hat{Y})^{2}]\leqE_{k}[(Y-f(X))^{2}]+2\alpha,\(\gamma^{*}_{k}\) and \(\beta^{*}_{k}\) are the optimal intercept and slope for predicting \(Y\) using \(\hat{Y}\) within subset \(S_{k}\)
neurips_2024_oral_23,4,E_{S}[(Y-g(H))^{2}]\leqE_{S}[(Y-\gamma-\beta g(H))^{2}]+\eta,,E_{S}[(Y-\gamma-\beta g(H))^{2}]\leqE_{S}[(Y-g(H))^{2}]+\eta,"The equation represents the expected squared error of predicting the target variable Y using a function g of the expert feedback H, with an additive constant γ and a multiplicative coefficient β, and it is bounded by the expected squared error of predicting Y using g(H) alone, plus an error term η."
neurips_2024_oral_23,5,"E_{S}[(Y-g(H))^{2}]+4Cov_{S}(Y,g(H))^{2}\leqE_ {S}[(Y-f(X))^{2}]+2\alpha+\eta",,"E_{S}[(Y-g(H))^{2}]+4Cov_{S}(Y,g(H))^{2}\leqE_{S}[(Y-f(X))^{2}]+2\alpha+2\eta","The equation represents the relationship between the expected squared error of a predictor using expert feedback and the expected squared error of any model in the class $\mathcal{F}$, with an additional term accounting for the covariance between the target $Y$ and the expert feedback $g(H)$"
neurips_2024_oral_23,6,"|Cov_{k}(Y,\hat{Y})|\leq\sqrt{\frac{\alpha}{2}}",,"Cov_{k}(Y,\hat{Y})=0",The covariance between the target outcome Y and the expert prediction \hat{Y} within an indistinguishable subset is zero.
neurips_2024_oral_24,1,y^{\prime}=y+\Delta y=W_{0}x+BAx,where \(y\in R\)d is the output and the \(x\in R\)k denotes the input,y=(W_{0}+AB)x,"y represents the output of the layer, W_{0} represents the pre-trained model weights, A and B represent the low-rank matrices, and x represents the input to the layer"
neurips_2024_oral_24,2,"W&=\,W_{0}+\Delta\,W\\&=\,W_{0}+\sum_{i=1}^{N}\omega_{i}\cdot B_{i}A",,W=W_{0}+\sum_{i=1}^{n} B_{i}A,"where \(W_{0}\) is the pre-trained weight, \(A\) is the shared low-rank matrix, \(B_{i}\) are the distinct low-rank matrices for each sub-domain or task, and \(n\) is the number of sub-domains or tasks"
neurips_2024_oral_24,3,y=W_{0}x+\sum_{i=1}^{N}\omega_{i}E_{i}Ax\quad(MoE),"where \(N\) denotes the number of experts, i",y'=y+\Delta y=W_{0}x+\sum_{i=1}^{N}\omega_{i}B_{i}Ax,"where \(y\in R\)d is the output, \(x\in R\)k denotes the input, \(W_{0}\) is the pre-trained and frozen weight, \(\Delta y\) is the change of the weight, \(B_{i}\) are the distinct matrices, \(A\) is the shared matrix, and \(\omega_{i}\) are the contribution weights for head \(B_{i}\)."
neurips_2024_oral_24,4,\omega_{i}=softmax(W_{g}^{T}x)\quad(Router),,\omega_{i}=\frac{\exp(W_{g}x_{i})}{\sum_{j=1}^{N}\exp(W_{g}x_{j})},where \(\omega_{i}\) represents the gating score for the \(i\)-th expert.
neurips_2024_oral_25,1,"{l}X=Y\beta_{Y\to X}+G^{\intercal}\gamma_{X}+\varepsilon_{X},\\Y=X\beta_{X\to Y}+G^{\intercal}\gamma_{Y}+\varepsilon_{Y}",where \(\beta_{Y\to X}\) is the causal effect of \(Y\) on \(X\) and \(\beta_{X\to Y}\) is that of \(X\) on \(Y\),"X_{i}=\alpha Y_{i}+\gamma^{\intercal}G_{i}+\varepsilon_{X_{i}},\quad Y_{i}=\beta X_{i}+\delta^{\intercal}G_{i}+\varepsilon_{Y_{i}}","The equations represent the bi-directional causal relationships between phenotypes X and Y, influenced by genetic variants G, with error terms \(\varepsilon_{X_{i}}\) and \(\varepsilon_{Y_{i}}\)."
neurips_2024_oral_25,2,"{l}X=(G^{\intercal}\gamma_{X}+G ^{\intercal}\gamma_{Y}\beta_{Y\to X}+\varepsilon_{X}+\varepsilon_{Y}\beta_{Y\to X})\Delta,\\Y=(G^{\intercal}\gamma_{X}\beta_{X\to Y}+G^{\intercal}\gamma_{Y}+\varepsilon_{X}\beta_{X\to Y}+\varepsilon_{Y})\Delta",,"{l}X=\Delta(G^{\intercal}\gamma_{X}+\beta_{Y\to X}G^{\intercal}\gamma_{Y})+\Delta(\varepsilon_{X}+\beta_{Y\to X}\varepsilon_{Y}),\\Y=\Delta(G^{\intercal}\gamma_{Y}+\beta_{X\to Y}G^{\intercal}\gamma_{X})+\Delta(\varepsilon_{Y}+\beta_{X\to Y}\varepsilon_{X})","The reorganized equations representing the relationship between phenotypes X and Y, genetic variants G, and error terms, with Δ as a normalization factor to avoid recursive formulations."
neurips_2024_oral_25,3,\hat{\beta}_{X\to Y}=[X^{\intercal}PX]^{-1}X^{\intercal}PY=\beta_{X\to Y},,"\beta_{X\to Y}=\frac{Cov(G_{V}^{X\to Y},Y)}{Cov(G_{V}^{X\to Y},X)}",The causal effect of X on Y can be identified using the two-stage least squares estimator when valid IVs are known.
neurips_2024_oral_25,4,\hat{\beta}_{X\to Y}=[X^{\intercal}\tilde{P}X]^{-1}X^{\intercal}\tilde{P}Y=\beta_{X\to Y}+\underbrace{[X^{\intercal}\tilde{P}X ]^{-1}X^{\intercal}\tilde{P}(G^{\intercal}\gamma_{Y}+\varepsilon_{Y})}_{\beta_{bias}},,\hat{\beta}_{X\to Y}=[X^{\intercal}PX]^{-1}X^{\intercal}PY,The causal effect of X on Y can be identified by the two-stage least squares estimator.
neurips_2024_oral_25,5,"corr(Y-X\omega_{\{G_{3}\}},G_{1})=0,\qquadcorr(Y-X\omega_{\{ G_{1}\}},G_{3})=0","where \(\mathrm{corr}(\cdot)\) denotes the Pearson's correlation coefficient between two random variables, and \(\omega_{\{G_{i}\}}=\mathrm{TSLS}(X,Y,\{G_{i}\})\) with \(i\in\{1,3\}\)","{l}\hat{\beta}_{X\to Y}=[X^{\intercal}PX]^{-1}X^{\intercal}PY=\beta_{X\to Y},\\\hat{\beta}_{Y\to X}=[Y^{\intercal}PY]^{-1}Y^{\intercal}PX=\beta_{Y\to X}","where \(\beta_{X\to Y}\) and \(\beta_{Y\to X}\) are the causal effects of \(X\) on \(Y\) and \(Y\) on \(X\), respectively."
neurips_2024_oral_25,6,"corr(Y-X\omega_{\{G_{4},G_{5}\}},G_{2})\neq 0,corr(Y-X\omega_{\{ G_{2},G_{5}\}},G_{4})\neq 0,corr(Y-X\omega_{\{G_{2},G_{4}\}},G_{5})\neq 0","where \(\omega_{\{G_{i},G_{j}\}}=\mathrm{TSLS}(X,Y,\{G_{i},G_{j}\})\) with \(i\neq j\) and \(i,j\in\{2,4,5\}\)","corr(Y-X\omega_{\{G_{2}\}},G_{4})\neq0,\qquadcorr(Y-X\omega_{\{G_{4}\}},G_{2})\neq0,\qquadcorr(Y-X\omega_{\{G_{5}\}},G_{2})\neq0,\qquadcorr(Y-X\omega_{\{G_{2}\}},G_{5})\neq0","where \(\omega_{\{G_{i}\}}=\mathrm{TSLS}(X,Y,\{G_{i}\})\) with \(i\in\{2,4,5\}\)"
neurips_2024_oral_25,7,"PR_{(X,Y\,|\,G)}:=Y-X\omega_{G}",,"corr(Y-X\omega_{\{G_{4},G_{5}\}},G_{2})\neq 0,corr(Y-X\omega_{\{ G_{2},G_{5}\}},G_{4})\neq 0,corr(Y-X\omega_{\{G_{2},G_{4}\}},G_{5})\neq 0","where \(\omega_{\{G_{i},G_{j}\}}=\mathrm{TSLS}(X,Y,\{G_{i},G_{j}\})\) with \(i\neq j\) and \(i,j\in\{2,4,5\}\)"
neurips_2024_oral_25,8,"corr(PR_{\langle X,Y\,|\,\{G_{j}\}\rangle},G_{j })\neq 0",,"corr(PR_{(X,Y\,|\,G\setminus\{G_{j}\})},G_{j})\neq 0","where \(\mathcal{PR}_{(X,Y\,|\,\mathbb{G}\setminus\{G_{j}\})}\) is the pseudo-residual of \(\{X,Y\}\) relative to \(\mathbb{G}\setminus\{G_{j}\}\), and \(\mathrm{corr}(\cdot)\) denotes the Pearson's correlation coefficient between two random variables."
neurips_2024_oral_25,9,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=0",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{1})=0","where \(\mathcal{PR}_{\langle X,Y\,|\,\{G_{1}\}\rangle}\) denotes the pseudo-residual of \(\{X,Y\}\) relative to \(\{G_{1}\}\), and \(\mathrm{corr}(\cdot)\) denotes the Pearson's correlation coefficient between two random variables."
neurips_2024_oral_25,10,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle}),G_{ 2})=0",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2})=0","where \(\mathcal{PR}_{\langle X,Y\,|\,\{G_{i}\}\rangle}\) denotes the pseudo-residual of \(\{X,Y\}\) relative to \(\{G_{i}\}\), and \(\mathrm{corr}(\cdot)\) denotes the Pearson's correlation coefficient between two random variables."
neurips_2024_oral_25,11,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=\frac{\gamma_{Y,1}\gamma_{X,2}-\gamma_{Y,2}\gamma_{X,1}}{\beta_{Y\to X }\gamma_{Y,2}+\gamma_{X,2}}",,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=0","where \(\mathrm{corr}(\cdot)\) denotes the Pearson's correlation coefficient between two random variables, and \(\omega_{\{G_{i}\}}=\mathrm{TSLS}(X,Y,\{G_{i}\})\) with \(i\in\{1,2\}\)"
neurips_2024_oral_25,12,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2} )=\frac{\gamma_{Y,2}\gamma_{X,1}-\gamma_{Y,1}\gamma_{X,2}}{\beta_{Y\to X }\gamma_{Y,1}+\gamma_{X,1}}",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2})=\frac{\gamma_{Y,2}\gamma_{X,1}-\gamma_{Y,1}\gamma_{X,2}}{\beta_{Y\to X}\gamma_{Y,1}+\gamma_{X,1}}","where \(\gamma_{X,i}\) and \(\gamma_{Y,i}\) are the direct effects of the genetic variant \(G_{i}\) on \(X\) and \(Y\), respectively."
neurips_2024_oral_25,13,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=0,\qquadcorr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle },G_{2})=0",,"\frac{\gamma_{Y,1}\gamma_{X,2}-\gamma_{Y,2}\gamma_{X,1}}{\beta_{Y\to X }\gamma_{Y,2}+\gamma_{X,2}}=0","where \(\gamma_{X,1}\) and \(\gamma_{X,2}\) are the direct effects of \(G_{1}\) and \(G_{2}\) on \(X\), \(\gamma_{Y,1}\) and \(\gamma_{Y,2}\) are the direct effects of \(G_{1}\) and \(G_{2}\) on \(Y\), and \(\beta_{Y\to X}\) is the causal effect of \(Y\) on \(X\)"
neurips_2024_oral_25,14,"corr(PR_{(X,Y\midG\setminus G_{j})},G_{j})=0",,"corr(PR_{\langle X,Y\,|\,\{G_{j}\}\rangle},G_{j})=0","where \(\mathcal{PR}_{\langle X,Y\,|\,\{G_{j}\}\rangle}\) is the pseudo-residual of \(\{X,Y\}\) relative to \(\{G_{j}\}\), and \(\omega_{\{G_{j}\}}=\mathrm{TSLS}(X,Y,\{G_{j}\})\)."
neurips_2024_oral_26,1,"s_{real}(x_{t},t)=\nabla_{x_{t}}\log p_{real,t}(x_{t})=-\frac{x_ {t}-\alpha_{t}\mu_{real}(x_{t},t)}{\sigma_{t}^{2}}",,"p_{real,t}(x_{t})=\int p_{real}(x)q(x_{t}|x)dx",The probability distribution of the diffused samples at timestep t.
neurips_2024_oral_26,2,"\nablaL_{BMD}=E_{t}(\nabla_{\theta}KL( p_{fake,t}\|p_{real,t}))=-E_{t}(\int(s_{real}(F(G_{\theta}(z),t),t)-s_{fake}(F(G_{\theta}(z),t),t) )\frac{dG_{\theta}(z)}{d\theta}\,dz)","where \(z\sim\mathcal{N}(0,\mathbf{I})\) is a random Gaussian noise input, \(\theta\) are the generator parameters, \(F\) is the forward diffusion process (i","L_{DMD}(G)=E_{t\simU(0, T)}\left[KL(p_{real,t} || p_{fake,t})\right]=E_{t\simU(0, T)}\left[\nabla_{x_{t}}\log p_{real,t}(x_{t})-\nabla_{x_{t}}\log p_{fake,t}(x_{t})\right]",The loss function for Distribution Matching Distillation (DMD) is defined as the expected KL divergence between the diffused target distribution and the diffused generator output distribution over all timesteps.
neurips_2024_oral_26,3,"L_{reg}=E_{(z,y)}d(G_{\theta}(z),y)","where \(d\) is a distance function, such as LPIPS [54] in their implementation","L_{reg}=E_{z,y}(\|G(z)-y\|_2^2)",The regression loss compares the generator output with the teacher's prediction given the same input noise.
neurips_2024_oral_26,4,"L_{GAN}=E_{x\sim p_{noise},t\sim[0,T]}[\log D (F(x,t))]+E_{z\sim p_{noise},t\sim[0,T]}[-\log(D(F(G_{\theta}(z ),t)))]","where \(D\) is the discriminator, and \(F\) is the forward diffusion process (i",L_{GAN}=E_{x\sim p_{real}}[\log(D(x))]+E_{z\sim p(z)}[\log(1-D(G(z)))],where $D$ is the discriminator and $G$ is the generator.
neurips_2024_oral_27,1,"\langle S,A,O,I,T,R,\gamma,\Theta\rangle","where \(S\), \(A\) and \(O\) are the sets of states, actions, and observations, respectively","M=(S,A,O,P,R)","The tuple represents the components of an Underspecified Partially Observable Markov Decision Process, where $\mathcal{S}$ is the state space, $\mathcal{A}$ is the action space, $\mathcal{O}$ is the observation space, $\mathcal{P}$ is the transition function, and $\mathcal{R}$ is the reward function."
neurips_2024_oral_27,2,"PVL^{\theta}(\pi)=\frac{1}{T}\sum_{t=0}^{T}\max(\sum_{k=t}^{T}(\gamma\lambda)^{k-t}\delta_{k}^{\theta},0)","where \(\lambda\) and \(T\) are the GAE discount factor and MDP horizon, respectively","V^{\theta}(\pi)=E_{\pi}[\sum_{t=0}^{T}R(s_{t},a_{t})\gamma^{t}]",where \(V^{\theta}(\pi)\) represents the expected value for the student agent with policy \(\pi\) in environment \(\theta\)
neurips_2024_oral_27,3,"P(\Gamma\mid\lambda_{\Gamma})=\prod_{j=1}^{J}\sum_{k=1}^{K}\alpha_{k}N (x_{j}\mid\mu_{k},\Sigma_{k})",where \(x_{j}\) is a state-action pair sample from \(\Gamma\),"p(\Gamma|\lambda_{\Gamma})=\prod_{x\in\Gamma}\sum_{k=1}^{K}\alpha_{k}N(x|\mu_{k},\Sigma_{k})","where \(\mathcal{N}(x|\mu_{k},\Sigma_{k})\) denotes the probability density function of the Gaussian distribution with mean \(\mu_{k}\) and covariance \(\Sigma_{k}\), and \(\alpha_{k}\) represents the weight of the \(k^{th}\) Gaussian component"
neurips_2024_oral_27,4,\textsc{Novelty}_{l_{\theta}}=-\frac{1}{|X_{\theta}|}\logL(X_{\theta}\mid\lambda_{\Gamma})=-\frac{1}{|X_{\theta}|}\sum_{t=1}^{T}\log p(x_{t}\mid\lambda_{\Gamma}),where \(x_{t}\) is a sample state-action pair from \(X_{\theta}\),"N(l_{\theta})=\frac{1}{|X_{\theta}|}\sum_{x\in X_{\theta}}-\log\left(\sum_{k=1}^{K}\alpha_{k}N(x\mid\mu_{k},\Sigma_{k})\right)","where \(\mathcal{N}(l_{\theta})\) represents the novelty score of level \(l_{\theta}\), \(|X_{\theta}|\) is the number of state-action pairs in \(X_{\theta}\), and \(\mathcal{N}(x\mid\mu_{k},\Sigma_{k})\) is the probability density function of the Gaussian distribution with mean \(\mu_{k}\) and covariance \(\Sigma_{k}\)"
neurips_2024_oral_27,5,P_{S}=\frac{h(S_{i})^{\beta}}{\sum_{j}h(S_{j})^{\beta}},where \(h\) is a prioritization function (e,P_{S}(l_{\theta})=\frac{\textsc{Novelty}_{l_{\theta}}^{\omega}\cdot\textsc{Regret}_{l_{\theta}}^{1-\omega}}{\sum_{l_{\theta^{\prime}}\inB}\textsc{Novelty}_{l_{\theta^{\prime}}}^{\omega}\cdot\textsc{Regret}_{l_{\theta^{\prime}}}^{1-\omega}},"where \(\omega\) is a hyperparameter controlling the trade-off between novelty and regret, and \(\mathcal{B}\) denotes the level buffer"
neurips_2024_oral_27,6,P_{replay}=\alpha\cdot P_{N}+(1-\alpha)\cdot P_{R},"where \(P_{N}\) and \(P_{R}\) are the novelty-prioritized probability and regret-prioritized probability respectively, and \(\alpha\) allows us to adjust the weightage of each probability",P_{S}=\frac{(\textsc{Novelty}_{l_{\theta}}+\textsc{Regret}_{l_{\theta}})^{\beta}}{\sum_{j}(\textsc{Novelty}_{l_{j}}+\textsc{Regret}_{l_{j}})^{\beta}},"where \(\textsc{Novelty}_{l_{\theta}}\) and \(\textsc{Regret}_{l_{\theta}}\) are the novelty and regret scores of level \(l_{\theta}\), respectively"
neurips_2024_oral_31,1,y^{*}=y-f_{\theta}(y)\nabla f_{\theta}(y),"where, by definition, \(f_{\theta}(\mathbf{y})\) is the distance between \(\mathbf{y}\) and \(\mathbf{y}^{*}\), and the gradient \(\nabla f_{\theta}(\mathbf{y})\) points in the opposite direction of the shortest path from \(\mathbf{y}\) to the surface of the object and is unit-norm",f_{\theta}(y)=\min_{y^*\inS} || y-y^* || ,The equation represents the signed distance function that computes the closest point on the object surface to a given point in 3D space.
neurips_2024_oral_31,2,c^{j}_{ik}=n_{ik}-d^{j}_{ik}T_{j}\Big{(}\nabla f_{\theta_{j}}(T^{-1}_{j}(n_{ik}))\Big{)},,c^{j}_{ik}=T_{j}(T^{-1}_{j}(n_{ik})-f_{\theta_{j}}(T^{-1}_{j}(n_{ik}))\nabla f_{\theta_{j}}(T^{-1}_{j}(n_{ik}))),"The closest point on the surface of object $O_{j}$ from node $\mathbf{n}_{ik}$ on object $O_{i}$, computed using the SDF function $f_{\theta_{j}}$ and the transformation $\mathcal{T}_{j}$."
neurips_2024_oral_34,1,"x_{0}\simN(0,I)\quadand\quadx_{t+1}=a_{t}x_{t}+\mu(x_{t},t)+\sigma_{t}\epsilon_{t}\quadfor\quad t=0,1,\dots,T-1","where \(\epsilon_{t}\sim\mathcal{N}(0,I)\) and \(\mu(\mathbf{x},t)\) is the output of a neural network",x_{t}=\sqrt{\bar{\alpha}_{t}}x_{t-1}+\sqrt{1-\bar{\alpha}_{t}}\epsilon_{t},"The equation represents the iterative process of a discrete-time stochastic sampler in a diffusion model, where \(\mathbf{x}_{t}\) is the sample at time step \(t\), \(\bar{\alpha}_{t}\) is the cumulative product of the diffusion coefficients, and \(\epsilon_{t}\) is the noise term at time step \(t\)."
neurips_2024_oral_34,2,"q(x)=\frac{1}{Z}\exp(-E(x)/\tau),\quad E:X\toR","where \(\tau>0\) is temperature, \(\mathcal{X}\) is the compact domain of data, and \(Z=\int_{\mathcal{X}}\exp(-E(\mathbf{x})/\tau)d\mathbf{x}<\infty\) is the normalization constant",q(x)=\frac{\exp(-E(x))}{\int\exp(-E(x))dx},The energy-based model represents a probability distribution using a scalar energy function \(E(\mathbf{x})\).
neurips_2024_oral_34,3,\min_{\pi\in\Pi}KL(\pi(x) || p(x))=\max_{\pi\in\Pi}E _{\pi}[\log p(x)]+H(\pi(x)),"where \(\Pi\) is the set of feasible \(\pi(\mathbf{x})\)'s, and \(\mathcal{H}(\pi)=-\int\pi(\mathbf{x})\log\pi(\mathbf{x})d\mathbf{x}\) is the differential entropy",KL(p || \pi)=\int_{X}p(x)\log(p(x)/\pi(x))dx,The KL divergence between the data density $p(\mathbf{x})$ and the diffusion model $\pi(\mathbf{x})$
neurips_2024_oral_34,4,\min_{\pi\in\Pi}KL(\pi(x) || q(x))\quadand\quad\min_{ q\inQ}KL(p(x) || q(x)),where \(\mathcal{Q}\) is the feasible set of EBMs,\min_{q}\min_{\pi\in\Pi}KL(\pi(x) || q(x))=\max_{q}\max_{\pi\in\Pi}E_{\pi}[\log q(x)]+H(\pi(x)),where the EBM q(x) is used as a surrogate for the data density p(x) to train the diffusion model.
neurips_2024_oral_34,5,\min_{q\inQ}\max_{\pi\in\Pi}KL(p(x) || q(x))-KL(\pi(x) || q(x)),,\min_{\pi\in\Pi}\max_{q\inQ}E_{\pi}[\log q(x)]+E_{p}[\log(1-q(x))],where the expectation over the data distribution is approximated by the empirical average over the training dataset.
neurips_2024_oral_34,6,KL(\pi_{\phi}(x_{T}) || q_{\theta}(x_{T}))\leq KL(\pi_{\phi}(x_{0:T}) || q_{\theta}(x_{T})\tilde{q}(x_{0:T-1}|x_{T})),,"\min_{\phi}\sum_{t=0}^{T-1}E_{\pi_{\phi}(x_{t},x_{t+1})}\left[\frac{1}{T}E_{\theta}(x_{t+1})-\log a_{t}-\frac{D}{2}\log(2\pi\sigma_{t}^{2})\right]",where the expectation is taken over the state-action trajectory distribution induced by the diffusion model.
neurips_2024_oral_34,7,"\tilde{q}(x_{0:T-1}|x_{T})=\prod_{t=0}^{T-1}\tilde{q}(x_{t}|x_{t+1}), where \tilde{q}(x_{t}|x_{t+1})=N(x_{t+1},s_{t}^{2}I),\quad s_{t}>0",,"\tilde{q}(x_{0:T-1}|x_{T})=\prod_{t=0}^{T-1}N(x_{t}|x_{t+1},\sigma_{t}^{2}I)",where \(\sigma_{t}^{2}\) is a variance parameter at time step \(t\).
neurips_2024_oral_34,8,\min_{\phi}\mathop{E}_{\pi_{\phi}(x_{0:T})}[E_{\theta}(x_{T})+\tau\sum_{t=0}^{T-1}\log\pi_{\phi}(x_{t+1}|x _{t})+\tau\sum_{t=0}^{T-1}\frac{1}{2s_{t}^{2}} || x_{t+1}-x_ {t} || ^{2}],,\min_{\phi}E_{\pi_{\phi}(x_{0:T})}\left[\sum_{t=0}^{T-1}\frac{1}{2s_{t}^{2}}\left\|x_{t}-x_{t+1}\right\|^{2}+E_{\theta}(x_{T})/\tau\right],where the expectation is taken with respect to the trajectory distribution of the diffusion model.
neurips_2024_oral_34,9,V_{\psi}^{t}(x_{t})=E_{\pi}[E_{\theta}(x_{T})+\tau\sum_{t^{\prime}=t}^{T-1}\log\pi_{\phi}(x_{t^{\prime}+1}| x_{t^{\prime}})+\sum_{t^{\prime}=t}^{T-1}\frac{\tau}{2s_{t^{\prime}}^{2}} || x_{t^{\prime}+1}-x_{t^{\prime}} || ^{2}\bigg{|}x_{t} ],,V_{\psi}^{t}(x_{t})=E_{\pi_{\phi}(x_{t+1:T}|x_{t})}[E_{\theta}(x_{T})+\tau\sum_{k=t}^{T-1}\log\pi_{\phi}(x_{k+1}|x_{k})+\tau\sum_{k=t}^{T-1}\frac{1}{2s_{k}^{2}} || x_{k+1}-x_{k} || ^{2}],The value function \(V_{\psi}^{t}(\mathbf{x}_{t})\) represents the expected future cost when starting from state \(\mathbf{x}_{t}\) and following policy \(\pi_{\phi}\).
neurips_2024_oral_34,10,"\min_{\psi}E_{x_{t},x_{t+1}\sim\pi}[(sg[V_{\psi}^{t+1}(x_{t+1})]+\tau\log\pi_{\phi}(x_{t+1}|x _{t})+\frac{\tau}{2s_{t}^{2}} || x_{t}-x_{t+1} || ^{2}-V_{\psi}^ {t}(x_{t}))^{2}]",where \(\text{sg}[\cdot]\) denotes a stop-gradient operator indicating that gradient is not computed for the term,V_{\psi}^{t}(x_{t})=E_{\pi}[E_{\theta}(x_{T})+\tau\sum_{t^{\prime}=t}^{T-1}\log\pi_{\phi}(x_{t^{\prime}+1}|x_{t^{\prime}})+\sum_{t^{\prime}=t}^{T-1}\frac{\tau}{2s_{t^{\prime}}^{2}} || x_{t^{\prime}+1}-x_{t^{\prime}} || ^{2}\bigg{|}x_{t}],"The value function, or cost-to-go function, represents the expected sum of future costs starting from a given state and following a policy."
neurips_2024_oral_34,11,\min_{\phi}E_{\pi_{\phi}(x_{t+1}|x_{t})}[V_{\psi}^{t+1}(x_{t+1})+\tau\log\pi_{\phi}(x_{t+1}|x _{t})+\frac{\tau}{2s_{t}^{2}} || x_{t}-x_{t+1} || ^{2}\bigg{|}x_{t}],,\min_{\phi}E_{\pi_{\phi}(x_{0:T})}[\sum_{t=0}^{T-1}V_{\psi}^{t+1}(x_{t+1})+\tau\log\pi_{\phi}(x_{t+1}|x_{t})+\frac{\tau}{2s_{t}^{2}} || x_{t}-x_{t+1} || ^{2}],The diffusion model parameter \(\phi\) is updated to minimize the expected cumulative cost.
neurips_2024_oral_34,12,"\min_{\psi}E_{x_{t},x_{t+1}\sim\pi}[(sg[V_{\psi}(x_{t+1})]+R(t)-V_{\psi}(x_{t}))^{2}]",,V_{\psi}^{t}(x_{t})=E_{\pi}[E_{\theta}(x_{T})+\sum_{t^{\prime}=t}^{T-1}R(t^{\prime})\bigg{|}x_{t}],"The time cost function R(t) is used to replace the running cost terms in the value update equation, allowing for more flexibility in the optimization process."
neurips_2024_oral_35,1,"varrowCrossAttention(Q=\{v\},K=\{p_{i}^{v}\}_{i=1}^{m}+\{v\},V=\{ p_{i}^{v}\}_{i=1}^{m}+\{v\})","Where \(v\) denotes a 3D voxel feature, and \(p_{i}^{v}\) denotes its projected 2D pixel feature from view \(i\), which is a concatenation of the RGB feature \(f_{i}^{v}\), the normal feature \(g_{i}^{v}\), and the RGB and normal values \(c_{i}^{v}\) and \(n_{i}^{v}\), respectively","Q=W_q\cdot x, K=W_k\cdot [x; f_1; ...; f_m], V=W_v\cdot [x; f_1; ...; f_m]","The equation represents the projection-aware cross-attention mechanism, where Q, K, and V are the query, key, and value matrices, respectively, and x is the 3D voxel feature, and f_i are the 2D features projected from the m views."
neurips_2024_oral_35,2,L=\lambda_{1}L_{MSE}^{color}+\lambda_{2 }L_{LPIPS}^{color}+\lambda_{3}L_{MSE}^{normal}+\lambda_{4}L_{LPIPS}^{normal}+\lambda_{5}L_{occ}+\lambda_{6}L _{SDF},"where \(L_{\mathrm{occ}}\) and \(L_{\mathrm{SDF}}\) are MSE losses for occupancy and SDF volumes, and \(\lambda_{i}\) denotes the weight of each loss term",L=\lambda_{sdf}L_{sdf}+\lambda_{render}L_{render},"Where \(\mathcal{L}_{sdf}\) denotes the SDF loss, \(\mathcal{L}_{render}\) denotes the rendering loss, and \(\lambda_{sdf}\) and \(\lambda_{render}\) are the weights for the SDF loss and rendering loss, respectively"
neurips_2024_oral_40,1,"m_{Ada}(\varepsilon,\delta)=O\Bigg{(}\frac{d\ln(\frac{d}{\varepsilon\gamma})\ln(\frac{1}{\varepsilon\gamma})}{\gamma^{2}\varepsilon}+\frac{\ln(1/\delta)}{\varepsilon}\Bigg{)}",,"m_{Ada}(\varepsilon,\delta)=O\left(\frac{d}{\varepsilon^2}\log\frac{1}{\delta}\right)",The sample complexity of the AdaBoost strong learner.
neurips_2024_oral_40,2,L_{D}(f)=O\bigg{(}\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},,L_{D}(f)\leqO\Bigg{(}\frac{d\ln(\frac{dm}{\gamma})\ln(\frac{m}{\gamma})}{m\gamma^{2}}+\frac{\ln(m)}{m}\Bigg{)},The loss of the output classifier f as a function of the number of samples m.
neurips_2024_oral_40,3,p=O\bigg{(}\frac{\ln m}{\gamma^{2}R}\bigg{)}\qquadand\qquad t=e^{O(dR)}\cdot\ln\frac{\ln m}{\delta\gamma^{2}},,"p=O(\gamma^{-2}\ln m/R),\; t=\exp(O(dR^{2}))\ln(1/\gamma)",The parallel complexity of the weak-to-strong learner is defined by the number of rounds p and the number of distributions t queried in each round.
neurips_2024_oral_40,4,L_{D}(A_{R}(S))=O\bigg{(}\frac {d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},,L_{D}(f)=O\bigg{(}\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},"The equation represents the loss of the output classifier f in terms of the number of samples m, the VC-dimension d of the hypothesis set, the accuracy parameter γ, and the confidence parameter δ."
neurips_2024_oral_40,5,p\ln t=O\bigg{(}\frac{d\ln m}{\gamma^{2}}\bigg{)},,p=O\bigg{(}\frac{\ln m}{\gamma^{2}R}\bigg{)}\qquadand\qquad t=e^{O(dR)},The tradeoff between the number of rounds $p$ and the total parallel work per round $t$ in the parallel Boosting algorithm.
neurips_2024_oral_40,6,"p\geq\frac{4\ln m}{\gamma^{2}R},\qquadand\qquad t\geq e^{16C_{ a}dR}\cdot R\ln\frac{pR}{\delta}",,p\ln t=\Omega(\gamma^{-2}d\ln m),"The equation represents the lower bound on the parallel complexity of weak-to-strong learners, where p is the number of rounds, t is the number of parallel queries per round, γ is the advantage of the weak learner, d is the VC-dimension of the hypothesis set, and m is the sample size."
neurips_2024_oral_40,7,L_{D}(sign(g))\leq C\cdot\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m},,L_{D}(f)=O\bigg{(}\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},"The equation represents the sample complexity bound for the output classifier f, which is a linear classifier with large margins."
neurips_2024_oral_40,8,|L_{D}(h)-L_{T}(h)|\leq\varepsilon,where \(\mathcal{L}_{T}(h)\coloneqq\mathcal{L}_{\mathrm{Uniform}(T)}(h)\) is the empirical loss of \(h\) on \(T\),\left\lvertL_{D}(h)-L_{T}(h)\right\rvert\leq\varepsilon,The loss of a hypothesis h with respect to distribution D is within epsilon of the loss with respect to the multiset T.
neurips_2024_oral_40,9,"D_{\infty}(D_{r},D_{0})\coloneqq\ln\bigl{(}\sup_{x\inX}D_{ r}(x)/D_{0}(x)\bigr{)}",,p=O\bigg{(}\frac{\ln m}{\gamma^{2}R}\bigg{)}\qquadand\qquad t=e^{O(dR)}\cdot\ln\frac{\ln m}{\delta\gamma^{2}},The number of rounds and the number of queries to the weak learner per round.
neurips_2024_oral_40,10,KL(D_{r}\parallel D_{0})\coloneqq\sum_{x\inX}D_{r}(x)\ln\frac{D_{r}(x)}{D_{0}(x)},,D_{KL}(D_{r}\|D_{0})\coloneqq\sum_{x\inX}D_{r}(x)\ln\frac{D_{r}(x)}{D_{0}(x)},"The Kullback-Leibler divergence, denoted as \(\mathrm{D}_{\mathrm{KL}}(D_{r}\|D_{0})\), is a measure of the difference between two probability distributions \(D_{r}\) and \(D_{0}\)."
neurips_2024_oral_40,11,\lnE_{P}\big{[}e^{X}\big{]}\geqE_{Q}[X]-KL(Q\parallel P),,KL(D_{r}\parallel D_{0})\coloneqq\sum_{x\inX}D_{r}(x)\ln\frac{D_{r}(x)}{D_{0}(x)},The KL divergence --also known as _relative entropy_-- between two distributions $P$ and $Q$ is always non-negative and equal to zero if and only if $P=Q$.
neurips_2024_oral_40,12,KL(D\parallel\tilde{D})\leq 4\gamma^{2}R,,KL(\tilde{D}\parallel D)\leq\frac{\gamma^{2}}{16C_{n}d},where \(C_{\mathrm{n}}\) is a universal constant.
neurips_2024_oral_40,13,\Pr_{T\sim\tilde{D}^{n}}[T\inG]\geq\exp(-16C_{n}dR),,\Pr_{T\sim\tilde{D}^{n}}[T\inG]\geq1-\exp(-\gamma^{2}n/C_{n}),"where \(\mathcal{G}\) is the family of \(\gamma/2\)-approximations for \(D\), \(c\), and \(\mathcal{H}\)"
neurips_2024_oral_40,14,\prod_{r=1}^{R}Z_{kR+r}<\exp(-\gamma^{2}R/2),,\prod_{r=1}^{R}Z_{kR+r}\leq\exp(-\gamma^{2}R/8),where $\mathbf{Z}_{kR+r}$ is the normalization factor at round $kR+r$.
neurips_2024_oral_41,1,\min_{x\inR^{d}_{c}}\phi(x),where \(\phi:\mathbb{R}^{d}\rightarrow\mathbb{R}\) is a differentiable function bounded from below (e,\min\phi,The objective function \(\phi\) represents the loss to be minimized.
neurips_2024_oral_41,2,x_{i}=x_{j}\quad\Leftrightarrow\quad\exists k\;:\;i\in P_{k} and j\in P_{k},,|V(x)|=c\quadand\quadR^{d}_{c}:=\{x\inR^{d}\:\|V(x)|=c\},The set of all vectors in \(\mathbb{R}^{d}\) whose \(d\) entries take exactly \(c\) distinct values.
neurips_2024_oral_41,3,"M_{P}(x)=M_{P,\phi}(x):=\arg\min_{y\inR^{d}}\{\phi(y)\,:\,P(y)\sqsupseteq P (x)\}",,x^{+}=\arg\min_{y\inR^{d}_{\leq c}}\phi(y)\quadsubject to\quad P(y)\sqsupseteq P(x),"The P step involves optimizing the objective function with a fixed partition, which leads to the update of the vector x to x+"
neurips_2024_oral_41,4,"M_{V}(y)=M_{V,\phi}(y):=\arg\min_{x\inR^{d}}\{\phi(x)\,:\,V(x)\subseteq V (y)\}",,"M_{V}(y)=M_{V,\phi}(y):=\arg\min_{x\inR^{d}_{c}}\{\phi(x)\,:\,V(x)=V(y)\}",The mapping M_V is defined to minimize the objective function φ over the set of vectors in ℝ^d_c with the same distinct values as y.
neurips_2024_oral_41,5,"\phi(x)\approx\widetilde{\phi}_{y}(x):=\phi(y)+\langle\nabla\phi(y),x-y\rangle+\tfrac{L}{2}\norm{x-y}^{2}",where \(L>0\) is a sufficiently large constant,"\min_{x\inR^{d}}\{\phi(y)+\nabla\phi(y)^{T}(x-y)\,:\,V(x)\subseteq V(y)\}","The linearized V step is an approximation of the V mapping, which involves solving a discrete least squares problem using an approximation of \(\phi(x)\) around \(y\)."
neurips_2024_oral_41,6,"M_{V,\phi}(y)\overset{\eqref{eq:v_def}}{\approx}M_{V,\widetilde{\phi}_{y}}(y )\overset{\eqref{eq:v_def}}{=}\arg\min_{x\inR^{d}}\{\widetilde{\phi}_{y}(x)\:\V(x)\subseteq V(y)\}",,"\min_{x\inR^{d}}\left\{\widetilde{\phi}_{y}(x)\,:\,V(x)\subseteq V(y)\right\}",the V step using the simpler convex quadratic function \(\widetilde{\phi}_{y}\) instead of the typically more complicated function \(\phi\).
neurips_2024_oral_41,7,\widehat{\phi}_{y}(x):=\norm{x-(y-\tfrac{1}{L}\nabla\phi(y))}^{2}=\norm{x-y^{+}}^{2}=\sum\limits_{i=1}^{d}(x_{i}-y_{i}^{+})^{2},,"M_{V,\widehat{\phi}_{y}}(y):=\arg\min_{x\inR^{d}}\{\tfrac{1}{2}\norm{x-y^{+}}^{2}\:\V(x)\subseteq V(y)\}","where \(y^{+}:=y-\frac{1}{L}\nabla\phi(y)\) is the point obtained after taking a single GD step from \(y\) with learning rate \(\frac{1}{L}\), disregarding the constraint."
neurips_2024_oral_41,8,"x:=M_{V,\phi}(y)\approx M_{V,\widehat{\phi}_{y}}(y):=\hat{x}",,"x=M_{V,\widetilde{\phi}_{y}}(y)=\arg\min_{x\inR^{d}}\{\norm{x-y^{+}}^{2}\:\V(x)\subseteq V(y)\}","where \(y^{+}=y-\frac{1}{L}\nabla\phi(y)\) is the point obtained after taking a single gradient descent step from \(y\) with learning rate \(\frac{1}{L}\), disregarding the constraint."
neurips_2024_oral_41,9,"\phi(x)\leq\phi(y)+\langle\nabla\phi(y),x-y\rangle+\tfrac{L}{2}\norm{x-y}^{2},\qquad\forall x,y\inR^{d}_{\leq c}",,\norm{\nabla\phi(x)-\nabla\phi(y)}\leq L\norm{x-y},where \(\phi\) is \(L\)-smooth on \(\mathbb{R}^{d}_{\leq c}\).
neurips_2024_oral_41,10,"x^{+}:=M_{V,\widehat{\phi}_{y,S^{k}}}(y):=\operatorname*{arg\,min} _{x\inR^{d}}\{\widehat{\phi}_{y,S^{k}}(x)\:\V(x)\subseteq V(y)\} || where\quad\widehat{\phi}_{y,S^{k}}(x):=\|x-(y-\frac {1}{L_{S^{k}}}Z^{k}(\nabla\phi(y)))\|^{2}",,"\widehat{\phi}_{y,S^{k}}(x):=\left\|x-\left(y-\frac{1}{L}Z^{k}\left(\nabla\phi(y)\right)\right)\right\|^{2}","where \(\widehat{\phi}_{y,\mathcal{S}^{k}}(x)\) is the linearized subspace V step function that measures the squared distance between \(x\) and \(y-\frac{1}{L}Z^{k}\left(\nabla\phi(y)\right)\), with \(Z^{k}\) being a linear mapping that selects the coordinates to be updated."
neurips_2024_oral_42,1,"\min_{Q}\max_{\pi}\alpha(E_{\hat{s}\simD_{img},\alpha\sim\pi(a|\hat{s})}[Q(\hat{s},a)]-E_{\hat{s},\hat{a}\simD_{img}}[Q(\hat{s},\hat{a})]+R(\pi)) || +E_{\hat{s},\hat{a}\simD_{img}}[(Q(\hat{s},\hat{a})-\hat{B}^{\pi}\hat{Q}(\hat{s},\hat{a}))^{2}]",,"Q(s, a)=E_{\tau\simD_{img}}\left[\sum_{t=0}^{\infty}\gamma^t r_t\right]","The learning objective of Conservative Q-learning, where Q(s, a) represents the expected return when taking action a in state s, and the expectation is taken over the collected dataset."
neurips_2024_oral_42,2,"\hat{B}_{T}^{\pi}\hat{Q}(\hat{s},\hat{a}):=\hat{r}-\eta_{R }R_{R}(\hat{s},\hat{a})-\eta_{T}R_{T}(\hat{s},\hat{a})+\gammaE_{\hat{s}^{\prime}\simD_{img},a^{\prime}\sim\pi_{k}(a^{\prime}|\hat{s}^{\prime})}[Q(\hat{s}^{\prime},a^{\prime})]","where \(\hat{s}^{\prime}\sim\mathcal{D}_{\mathrm{img}}\) is to sample the next state given \(\hat{s},\hat{a}\), \(\eta_{R}\) and \(\eta_{T}\) are two hyper-parameters to control the weighting of the uncertainty terms","\hat{Q}^{k+1}(\hat{s},\hat{a})\leftarrow\hat{r}+\gamma\max_{a'}\hat{Q}^{k}(\hat{s}', a')-\lambda_{R}R_{R}(\hat{s},\hat{a})-\lambda_{T}R_{T}(\hat{s},\hat{a})","The equation represents the update rule for the Q-function, incorporating regularization terms for reward and transition uncertainty."
neurips_2024_oral_48,1,"x_{0}=x,\quadx_{\ell}=\sigma_{\ell}(W _{\ell}x_{\ell-1}+b_{\ell}),\quad u_{G,\theta}(x)=x_{L}","where \(L\): the number of layers, \(\mathbf{W}_{i}\in\mathbb{R}^{d_{\ell}\times d_{\ell-1}}\): the weights of the NN, \(\mathbf{b}_{i}\in\mathbb{R}^{d_{\ell}}\): the biases of the NN, \(d_{0}=d_{\text{in}}\), \(d_{L}=d_{\text{out}}\), \(\sigma_{\ell}:\mathbb{R}\to\mathbb{R}\) activation functions applied element-wise","u_{G,\theta}(x)=\sigma\left(W_L\sigma\left(W_{L-1}\cdots\sigma\left(W_1x+b_1\right)\cdots+b_{L-1}\right)+b_L\right)","The equation represents a feedforward neural network with L layers, where \(\mathbf{W}_i\) are the weights, \(\mathbf{b}_i\) are the biases, and \(\sigma\) is the activation function."
neurips_2024_oral_48,2,"W_{\ell}^{\prime}=P_{\ell}W_{\ell}P_{\ell-1}^{-1},\,b_{\ell}^{\prime}=P_{\ell}b_{\ell}\Longrightarrow(W_{\ell}^{\prime},b_{\ell}^{\prime})_ {\ell=1}^{L}=\theta^{\prime}\simeq\theta=(W_ {\ell},b_{\ell})_{\ell=1}^{L}","where \(\ell\in\{1,\ldots,L\}\), \(\mathbf{P}_{0}=\mathbf{P}_{L}=\mathbf{I}\) and \(\mathbf{P}_{\ell}\in\mathbb{R}^{d_{\ell}\times d_{\ell}}\) are arbitrary permutation matrices","\forall\ell\in\{1,\ldots,L\},\forallP_{\ell}\inP_{d_{\ell}},\quad u_{G,\theta}(x)=u_{G,\theta^{\prime}}(x)","where \(\mathcal{P}_{d_{\ell}}\) is the set of permutation matrices of size \(d_{\ell}\) and \(\boldsymbol{\theta}^{\prime}=(\mathbf{P}_{1}\mathbf{W}_{1}\mathbf{P}_{0}^{T},\ldots,\mathbf{P}_{L}\mathbf{W}_{L}\mathbf{P}_{L-1}^{T},\mathbf{P}_{1}\mathbf{b}_{1},\ldots,\mathbf{P}_{L}\mathbf{b}_{L})\)"
neurips_2024_oral_48,3,"h_{V}^{0}(i)=INIT_{V}(x_{V}(i )),\quadh_{E}^{0}(i,j)=INIT_{E}(x_{ E}(i,j))",,"x_{V}^{(t+1)}=\sigma\left(\sum_{j\inN(i)}W(i,j)x_{V}^{(t)}(j)+x_{E}(i,j)\right),\quad t=0,\ldots,T-1","where \(\mathbf{x}_{V}^{(0)}\) are the input vertex features, \(\mathbf{W}(i,j)\) are learnable weights, \(\sigma\) is an activation function, and \(\mathcal{N}(i)\) denotes the set of neighboring vertices of vertex \(i\)"
neurips_2024_oral_48,4,"m_{V}^{t}(i)=\bigoplus_{j\inN(i)}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!where\(h_{V}^{i},h_{E}^{i}\) are vertex and edge representations at iteration\(t\) and\(h_{G}\) is the overall graph (NN) representation. INIT, MSG, UPD are general function approximators (e.g. MLPs), while READ is a permutation invariant aggregator (e.g. DeepSets [81]). The above equations have appeared with several variations in the literature, e.g. in some cases the edge representations are not updated or the readout input involve edge representations as well. Another frequent strategy is to use _positional encodings_\(p_{V},p_{E}\) to break undesired symmetries. In FFNNs, Eq. (2) reveals that input and output vertices are not permutable, while vertices cannot be permuted across layers. Therefore, vertices (or edges) that are permutable share the same positional encoding (see Appendix A.1.2 for more details).**Remark:**Although, typically, the neighbourhood\(N(i)\) contains both incoming and outgoing edges, in Section 5 we will illustrate our method using only incoming edges: _forward neighbourhood_\(N_{FW}(i)=\{j\inV\midlayer\,(i)- layer\,(j)=1\}\) and _backward_ where layer\((i)\) gives the layer neuron\(i\) belongs. Backward neighbourhoods\(N_{BW}(i)\) are defined defined similarly. In Appendix A.2, we show a more elaborate _bidirectional version_ of our method, with both neighbourhoods considered. ## 4 Scaling symmetries in Feedforward Neural Networks**Scaling symmetries (activation functions).**Intuitively, permutation symmetries stem from the _graph structure_ of neural networks, or put differently, from the fact that hidden neurons do not possess any inherent ordering. Apart from the affine layers\(W_{\ell}\) that give rise to the graph structure, it is frequently the case that**activation functions**\(\sigma_{\ell}\) have inherent symmetries that are bestowed to the NN. Let us dive into certain illustrative examples: for the ReLU activation\(\sigma(x)=\max(x,0)\) it holds that\(\sigma(ax)=\max(ax,0)=a\max(x,0),\\forall a>0\). For the tanh and sine activations\(\sigma(x)=\tanh(x)\),\(\sigma(x)=\sin(x)\) respectively, it holds that\(\sigma(ax)=a\sigma(x),\\forall a\in\{-1,1\}\). In a slightly more complex example, polynomial activations\(\sigma(x)=x^{k}\), we have\(\sigma(ax)=a^{d}\sigma(x)\), i.e. the multiplier differs between input and output. In general, we will be talking about _scaling symmetries_ whenever there exist pairs\((a,b)\) for which it holds that\(\sigma(ax)=b\sigma(x)\). To see how such properties affect NN symmetries, let us focus on FFNNs (see Appendix A.3 for CNNs): for a neuron\(i\) (we omit layer subscripts) we have\(\sigma\big{(}aW(i,:)x+ab(i)\big{)}=\textit{b}\big{(}W(i,:)x+b(i)\big{)}\), i.e. _multiplying its bias and all incoming weights with a constant a results in scaling its output with a corresponding constant\(b\)_. Generalising this to linear transformations, we may ask the following: which are the pairs of matrices\((A,B)\) for which we have\(\sigma\big{(}AWx+Ab\big{)}=B\sigma\big{(}Wx+b\big{)}\)? Godfrey et al. [25] provide an answer for _any activation that respects certain conditions_. We restate here their most important results:**Proposition 4.1**(Lemma 3.1. and Theorem E.14 from [25]).: _Consider an activation function\(\sigma:R\toR\). Under mild conditions,5 the following hold:_ Footnote 5: See Appendix A.7.1 for the precise statement and more details about\(\phi_{\sigma,d}\).*_For any_\(d\inN^{+}\)_, there exists a (non-empty) group of invertible matrices defined as:_\(I_{\sigma,d}=\{A\inR^{d\times d}: invertible\mid\exists\B\inR^{d\times d} invertible, such that: \sigma(Ax)=B\sigma(x)\}\) _(_intertwiner group_)_, and a mapping function_\(\phi_{\sigma,d}\) _such that_\(B=\phi_{\sigma,d}(A)\)_._*_Every_\(A\in I_{\sigma,d}\) _is of the form_\(PQ\)_, where_\(P\)_: permutation matrix and_\(Q=\textit{diag}\big{(}q_{1},\ldots q_{d}\big{)}\) _diagonal, with_\(q_{i}\in D_{\sigma}=\{a\inR\setminus\{0\}\mid\sigma(ax)=\phi_{\sigma,1}(a)\sigma(x)\}\)_: the 1-dimensional group, and_\(\phi_{\sigma,d}(A)=P\textit{diag}\big{(}\phi_{\sigma,1}(q_{1} ),\ldots\phi_{\sigma,1}(q_{d})\big{)}\)_._ This is a powerful result that completely answers the question above for most practical activation functions. Importantly, not only does it recover permutation symmetries, but also reveals symmetries to diagonal matrix groups, which can be identified by solely examining\(\phi_{\sigma,1}\), i.e. the one-dimensional case and the set\(D_{\sigma}\) (easily proved to be a group) we have already discussed in our examples above. Using this statement, Godfrey et al. [25] characterised various activation functions (or recovered existing results), e.g. ReLU:\(I_{\sigma,d}\) contains**generalised permutation matrices with positive entries**of the form\(PQ\),\(Q=diag(q_{1},\ldots,q_{d})\),\(q_{i}>0\) and\(\phi_{\sigma,d}(PQ)=PQ\)[56]. Additionally, here we characterise the intertwiner group of sine (used in the popular SIREN architecture [70] for INRs). Not surprisingly, it has the same intertwiner group with tanh [11, 21] (we also recover this here using Proposition 4.1). Formally, (proof in Appendix A.7.1):**Corollary 4.2**.: _Hyperbolic tangent\(\sigma(x)=\tanh(x)\) and sine activation\(\sigma(x)=\sin(\omega x)\), satisfy the conditions of Proposition 4.1, when (for the latter)\(\omega\neq k\pi,k\inZ\). Additionally,\(I_{\sigma,d}\) contains**signed permutation matrices**of the form\(PQ\), with\(Q=diag(q_{1},\ldots,q_{d})\),\(q_{i}=\pm 1\) and\(\phi_{\sigma_{d}}(PQ)=PQ\)._It is straightforward to see that the symmetries of Proposition 4.1, induce equivalent parameterisations for FNNs. In particular, it follows directly from Proposition 3.4. in [25], that for activation functions\(\sigma_{\ell}\) satisfying the conditions of Proposition 4.1 and when\(\phi_{\sigma,\ell}(Q)=Q\), we have that:\[W^{\prime}_{\ell}=P_{\ell}Q_{\ell}W_{\ell}Q_{\ell-1}^{-1}P_{\ell-1}^{-1},\;b^{\prime}_{\ell}=P_{\ell}Q_{\ell}b_{\ell}\implies(W^{\prime }_{\ell},b^{\prime}_{\ell})_{\ell=1}^{L}=\theta^{\prime}\simeq\theta=(W_{\ell},b_{\ell})_{\ell=1}^{L}","where again \(\ell\in\{1,\ldots,L\}\), \(\mathbf{P}_{0}=\mathbf{Q}_{0}=\mathbf{P}_{L}=\mathbf{Q}_{L}=\mathbf{I}\)","h_{V}^{t}(i)=\phi_{V}\left(h_{V}^{t-1}(i),AGG_{V}\left(h_{E}^{t-1}(j,i)\right)_{j\inN_{V}(i)}\right),\quadh_{E}^{t}(i,j)=\phi_{E}\left(h_{E}^{t-1}(i,j),h_{V}^{t-1}(i),h_{V}^{t-1}(j)\right)",The equation describes the update rules for vertex and edge features in a Graph Metanetwork (GMN) at each iteration t.
neurips_2024_oral_48,5,"h^{\prime}_{V}(i)=q_{\ell}(\pi_{\ell}(i))h_{V} (\pi_{\ell}(i)),\quad\ell=layer(i)\in\{1,\ldots,L-1\} || h^{\prime}_{E}(i,j)=q_{\ell}(\pi_{\ell}(i))h_{E} (\pi_{\ell}(i),\pi_{\ell-1}(j))q_{\ell-1}^{-1}(\pi_{\ell-1}(j)),\;\ell=layer(i)\in\{2,\ldots,L-1\}",,"h_{V}^{\prime}(i)=P_{\ell(i)}Q_{\ell(i)}h_{V}(i),\quadh_{E}^{\prime}(i,j)=Q_{\ell(i)}h_{E}(i,j)Q_{\ell(j)}^{-1}",The equation represents the transformation of vertex and edge representations under the equivalence relation of parameters.
neurips_2024_oral_48,6,"g_{i}\big{(}q_{1}x_{1},\ldots,q_{n}x_{n}\big{)}=q_{i}g_{i}(x_{1},\ldots,x_{n}\big{)},\forall q_{i}\in D_{i},i\in\{1,\ldots,n\}",where \(D_{i}\) a 1-dimensional scaling group as defined in Proposition 4,"MSG_{V}(h_{V}(i),h_{E}(i,j))=q_{\ell}(i)MSG_{V}(h_{V}(i)/q_{\ell}(i),h_{E}(i,j)/q_{\ell}(i ))","The message function should be equivariant to scaling, where the scaling factor is given by the multiplier of the central vertex."
neurips_2024_oral_48,7,"ScaleInv^{k}(X)=\rho^{k}(\tilde{x }_{1},\ldots,\tilde{x}_{n})",,f(x)=W\cdot g(x),where \(g\) is a scale-invariant function and \(\mathbf{W}\) is a learnable linear transformation
neurips_2024_oral_48,8,"ScaleEq=f^{K}\circ\cdots\circf^{1},\;f^{k}(X)=\big{(}\Gamma^{k}_{1}x_{1},\ldots,\Gamma^{k}_{n}x_{n}\big{)}\odotScalelInv^{k }(X)",,"ScaleEq^{k}(X)=D^{k}\rho^{k}(\tilde{x}_{1},\ldots,\tilde{x}_{n})","where \(\rho^{k}\) is a permutation invariant function, \(\tilde{\mathbf{x}}_{i}=\mathbf{x}_{i}/\|\mathbf{x}_{i}\|_{2}\) and \(\mathbf{D}^{k}=\text{diag}(\|\mathbf{x}_{1}\|_{2}^{k},\ldots,\|\mathbf{x}_{n}\|_{2}^{k})\)"
neurips_2024_oral_48,9,"g\big{(}q_{1}x_{1},\ldots q_{n}x_{n}\big{)}=g(x_{1},\ldotsx_{n})\prod_{i=1}^{n}q_{i},\forall q_{i}\in D_{i}",,"Rescale(x_{1},\ldots,x_{n})=(q_{1}^{-1}x_{1},\ldots,q_{n}^{-1}x_{n})",The rescaling function that takes a vector of inputs and returns a vector of rescaled inputs.
neurips_2024_oral_48,10,"ReScaleEq(x_{1},\ldotsx_{n})=ScaleEq\big{(}vec(\textbf{X}_{n})\big{)}",,RescaleEq(X)=\bigotimes_{i=1}^{n}x_{i},The Rescale Equivariant Network is defined as the outer product of the input vectors.
neurips_2024_oral_48,11,"MSG_{V}(x,y,e)=ScaleEq ([x,ReScaleEq(y,e) ])","where \([\cdot,\cdot]\) denotes concatenation, \(\mathsf{ReScaleEq}(q_{y}\mathbf{y},q_{x}q_{y}^{-1}\mathbf{e})=q_{x}\mathsf{ ReScaleEq}(\mathbf{y},\mathbf{e})\)","MSG_{V}\left(x,y,e\right)=ReScaleEq\left(x,y,e\right)=\odot_{i=1}^{3}\Gamma_{i}x_{i}",where \(\mathbf{\Gamma}_{i}:\mathcal{X}_{i}\rightarrow\mathbb{R}^{d}\) are learnable linear transformations
neurips_2024_oral_48,12,"UPD_{V}(x,m)=ScaleEq( [x,m])",,"UPD_{V}(x,m)=ScaleEq([x,m])",where \(\mathsf{ScaleEq}\) is a scale equivariant network as defined in Equation 9
neurips_2024_oral_48,13,"READ_{V}(X):=DeepSets(\tilde{x}_{1},\ldots,\tilde{x}_{n}),\quad\tilde{x}_{ i}=canon_{i}(x_{i}) or \tilde{x}_{i}=symm_{i}(x_{i})",,READ(h_{V})=\rho\left(\sum_{i\inV}\tilde{h}_{V}(i)\right),where \(\rho\) is an MLP and \(\tilde{\mathbf{h}}_{V}(i)=\mathsf{canon}(\mathbf{h}_{V}(i))\) or \(\tilde{\mathbf{h}}_{V}(i)=\mathsf{symm}(\mathbf{h}_{V}(i))\)
neurips_2024_oral_54,1,"V^{\pi}(s):=E[\sum_{t=0}^{\infty}\gamma^{t}r(s_{t},a_{t})| s_{0}=s];\quad Q^{\pi}(s,a):=E[\sum_{t=0}^{\infty}\gamma^{t}r (s_{t},a_{t})|s_{0}=s,a_{0}=a]","where \(a_{t}\sim\pi(\cdot|s_{t})\) and \(s_{t+1}\sim P(\,\cdot\,|s_{t},a_{t})\) for all \(t\geq 0\)","V^{\pi}(s)=E_{\pi}\left[\sum_{t=0}^{\infty}\gamma^t r(s_t, a_t)\mid s_0=s\right]","\(V^{\pi}(s)\) and \(Q^{\pi}(s, a)\) represent the expected discounted cumulative reward for a policy \(\pi\) starting from state \(s\) and state-action pair \((s, a)\) respectively."
neurips_2024_oral_54,2,"(TQ)(s,a)=r(s,a)+\gamma\cdotE_{s^{\prime}\sim P(\cdot|s,a) }[\max_{a^{\prime}\inA}Q(s^{\prime},a^{\prime})]",,"Q^{\star}(s,a)=r(s,a)+\gamma\sum_{s^{\prime}}P(s^{\prime}|s,a)\max_{a^{\prime}}Q^{\star}(s^{\prime},a^{\prime})",The optimal Q-function is the unique fixed point of the Bellman operator.
neurips_2024_oral_54,3,"(T_{Z}Q)(s,a)=r(s,a)+\gamma V(Z(s,a))","where \(V(s^{\prime})=\max_{a^{\prime}\in\mathcal{A}}Q(s^{\prime},a^{\prime})\)","(T_{Z}Q)(s,a)=r(s,a)+\gamma\cdot\max_{a^{\prime}\inA}Q(Z_{(s,a)},a^{\prime})","where \(Z_{(s,a)}\) denotes the \((s,a)^{\text{th}}\) coordinate of the random vector \(Z\)."
neurips_2024_oral_54,4,"ER(A;N,M):=\sup_{M=(P,r)}E[\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty }]",where the expectation is taken over the samples and any randomness in the algorithm,"ER(A;N,M):=\sup_{M}\left\lVert\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\right\rVert_{\infty}",The error rate of the algorithm is defined as the supremum over all MDPs of the difference between the estimated and optimal Q-functions.
neurips_2024_oral_54,5,"SC(A;\varepsilon,M):=|S || A|\cdot\min\{N\inN:ER(A;N,M)\leq\varepsilon\}",,"SC(A;\varepsilon,M):=\min\{N\inN:ER(A;N,M)\leq\varepsilon\}",The sample complexity of algorithm \mathscr{A} is the minimum number of samples required to achieve an error rate of at most \varepsilon.
neurips_2024_oral_54,6,"SC(A;\varepsilon,M,\delta):=|S || A|\cdot\min\{N\inN:\Pr(\sup_{M}\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty}\leq\varepsilon)\geq 1-\delta\}",,"ER_{\delta}(A;N,M):=\sup_{M=(P,r)}\inf\{\varepsilon\inR_{+}:P[\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty}>\varepsilon]\leq\delta\}","The high-probability error rate of the algorithm, where the probability is taken over the samples and any randomness in the algorithm."
neurips_2024_oral_54,7,CC_{round}(A;N):=\frac{1}{M}\sum_{m=1}^{M}C^{m}_{round}(A;N);\quadCC_{bit}(A;N ):=\frac{1}{M}\sum_{m=1}^{M}C^{m}_{bit}(A;N),,C_{round}(A;N):=\max_{m\in[M]}C^{m}_{round}(A;N);\quad C_{bit}(A;N):=\sum_{m=1}^{M}C^{m}_{bit}(A;N),"The communication complexity of algorithm \mathscr{A} is measured by the maximum number of rounds and the total number of bits exchanged among all agents,"
neurips_2024_oral_54,8,Q_{t-\frac{1}{2}}^{m}=(1-\eta_{t})Q_{t-1}^{m}+\frac{\eta_{t}}{B}\sum_{b=1}^{B}T_{Zs}(Q_{t-1}^{m}),,Q_{t}^{m}=Q_{t-1}^{m}+\eta_{t}\cdot\frac{1}{B}\sum_{b=1}^{B}\left(\widehat{T}_{Zs}(Q_{t-1}^{m})\right)_{b},where \(Q_{t}^{m}\) denotes the estimate of the optimal Q-function at agent \(m\) after the \(t^{\text{th}}\) iteration.
neurips_2024_oral_54,9,"Q_{t}^{m}=\frac{1}{M}\sum_{j=1}^{M}Q_{t-\frac{1}{2}}^{j}& if t\inC,\\Q_{t-\frac{1}{2}}^{m}& otherwise.",,Q_{t}^{m}=\frac{1}{M}\sum_{m^{\prime}=1}^{M}Q_{t-\frac{1}{2}}^{m^{\prime}},"where the averaging occurs at each communication round, and $M$ denotes the total number of agents."
neurips_2024_oral_54,10,R=\textsf{CC}_{\textsf{round}}(A;N)\leq\frac{c_{0}}{(1-\gamma)\log ^{2}N}; or\textsf{CC}_{\textsf{left}}(A;N)\leq\frac{c_{1}|S || A|}{(1-\gamma)\log^{2}N},,R\leq\frac{1}{32(1-\gamma)^{2}}\cdot\frac{1}{\log(\frac{1}{(1-\gamma)\varepsilon})},Theorem 1 provides a lower bound on the communication complexity of a Federated Q-learning algorithm with intermittent communication.
neurips_2024_oral_54,11,"\textsf{ER}(A;N,M)\geq\frac{C_{\gamma}}{\log^{3}N\sqrt{N}}",,"ER(A;N,M)\geq\frac{c_{2}}{(1-\gamma)\log N}","where $c_{2}>0$ is a universal constant that only depends on $c_{0}$, $c_{1}$, $c_{\eta}$, and $\gamma$."
neurips_2024_oral_56,1,"B_{Acc=K_{1}}(t|m)=\sup_{d}\{d|Acc(t|d,m)\leq K_{1}\}","where \(Acc(t|d,m)\) represents the accuracy of the model's accuracy on task \(t\) with difficulty \(d\)","RB(m, t)=\max_{d}\{d: Accuracy(m, t, d)\geq K_{1}\}",The reasoning boundary RB is the maximum problem difficulty d at which the model's accuracy reaches a predefined threshold K1.
neurips_2024_oral_56,2,"B_{Acc=K_{1}}(t_{1},t_{2},\dots,t_{n}|m)\approx\frac{1}{\sum _{i=1}^{n}\frac{N_{i}}{B_{Acc=K_{1}}(t_{i}|m)-b_{i}}}",where \(\mathcal{B}_{\text{Acc}=K_{1}}(t_{i}|m)\) denotes the reasoning boundary of model \(m\) for task \(t_{i}\),"B_{Acc=K_{1}}(t_{1},t_{2},\dots,t_{n}|m)=\min_{i=1}^{n}\{B_{Acc=K_{1}}(t_{i}|m)\}",The unified reasoning boundary for multiple tasks is the minimum of the individual reasoning boundaries for each task.
neurips_2024_oral_56,3,"B^{\texttt{CGT}}(c,p)=\frac{1}{\frac{N_{1}}{(B(c)-b_{1})}+\frac{N_{2}}{(B(p)-b_{2})}}",,"B_{Acc=K_{1}}(t_{1},t_{2}|m)\approx\frac{1}{\frac{1}{B_{Acc=K_{1}}(t_{1}|m)-b_{1}}+\frac{1}{B_{Acc=K_{1}}(t_{2}|m)-b_{2}}}",where \(\mathcal{B}_{\text{Acc}=K_{1}}(t_{1}|m)\) and \(\mathcal{B}_{\text{Acc}=K_{1}}(t_{2}|m)\) denote the reasoning boundaries of model \(m\) for tasks \(t_{1}\) and \(t_{2}\) respectively.
neurips_2024_oral_56,4,"B^{Tool}(c,p)=\lim_{B(c)arrow+\infty}\frac{ 1}{\frac{N_{1}}{(B(c)-b_{1})}+\frac{N_{2}}{(B(p)-b_{2})}}=\frac{B(p)-b_{2}}{N_{2}}",,"B^{\texttt{Tool}}(c,p)=\frac{1}{\frac{N_{1}}{(B(c)\rightarrow+\infty)}+\frac{N_{2}}{(B(p)-b_{2})}}=\frac{1}{0+\frac{N_{2}}{(B(p)-b_{2})}}=\frac{B(p)-b_{2}}{N_{2}}",where \(\mathcal{B}(p)\) denotes the step planning RB and \(N_{2}\) and \(b_{2}\) are scaling factors.
neurips_2024_oral_57,1,"E_{t\simU[1,T],\;X^{0},C\sim q( X^{0},C)}(\|X^{0}-H(X^{t},t,C)\|^{2})","where \(t\) denotes the time step, \(\mathbf{X}^{0}=\mathbf{X}\) is the raw motion latent sequence, and \(\mathbf{X}^{t}\) is the noisy inputs generated by the diffusion forward process \(q(\mathbf{X}^{t}|\mathbf{X}^{t-1})=\mathcal{N}(\mathbf{X}^{t};\sqrt{1-\beta_{ t}}\mathbf{X}^{t-1},\beta_{t}\text{I})\)",L=\sum_{i=1}^{W}E\left[\left\|\epsilon-\nabla_{z_{i}}\log p(z_{i} |a)\right\|^{2}\right],The loss function L measures the expected difference between the noise epsilon and the gradient of the log probability of the motion sequence given the audio.
neurips_2024_oral_57,2,"\hat{X}^{0}=(1+\sum_{e\inC}\lambda_{e})\cdotH(X^{t},t,C)-\sum_{e\inC}\lambda_{c}\cdotH(X^{t},t,C|_{e=\emptyset})",,"C=[X^{pre},A^{pre};A,g,d,e]","The input condition that includes previous motion and audio features, current audio features, main eye gaze direction, head-to-camera distance, and emotion offset."
neurips_2024_oral_58,1,"p(x_{1},x_{2},\dots,x_{T})=\prod_{t=1}^{T}p(x_{t}\mid x_{1},x_{2},\dots,x_{t-1 })",,"p(x)=\prod_{t=1}^{T} p(x_{t} | x_{1}, x_{2},\dots, x_{t-1})",The equation represents the probability of a sequence of tokens based on the autoregressive next-token prediction model.
neurips_2024_oral_58,2,"f=E(im),\\\\\q=Q(f)","where \(im\) denotes the raw image, \(\mathcal{E}(\cdot)\) a encoder, and \(\mathcal{Q}(\cdot)\) a quantizer","p_{\theta}(x_{t}\mid x_{1},x_{2},\dots,x_{t-1})=\frac{e^{f_{\theta}(x_{t},x_{1},x_{2},\dots,x_{t-1})}}{\sum_{v\in[V]}e^{f_{\theta}(v,x_{1},x_{2},\dots,x_{t-1})}}",The probability of the autoregressive model given the context and parameters.
neurips_2024_oral_58,3,"q^{(i,j)}=(\operatorname*{arg\,min}_{v\in[V]}\|lookup(Z,v)-f^{(i,j)}\|_{2})\in[V]","where \(\text{lookup}(Z,v)\) means taking the \(v\)-th vector in codebook \(Z\)","q^{(i,j)}=\arg\min_{k\in[V]}\left\lVert f^{(i,j)}-z_k\right\rVert_2",where \(z_k\) denotes the \(k\)-th code vector in the codebook \(Z\).
neurips_2024_oral_58,4,"\hat{f}=lookup(Z,q),\\\\\\\\\hat{im}=D(\hat{f}) || L=\|im-\hat{im}\|_{2}+\|f-\hat{f}\|_{2}+\lambda_{P}L_{P}(\hat{im})+\lambda_{G}L_{G}(\hat{im})",,"L=L_{recon}(im,\hat{im})+L_{commit}(f,\hat{f})+L_{dict}(Z)","where \(\mathcal{L}_{\text{recon}}\) measures the difference between the original and reconstructed images, \(\mathcal{L}_{\text{commit}}\) encourages the feature vectors to be close to their corresponding codebook vectors, and \(\mathcal{L}_{\text{dict}}\) regularizes the codebook \(Z\)."
neurips_2024_oral_58,5,"p(r_{1},r_{2},\dots,r_{K})=\prod_{k=1}^{K}p(r_{k}\mid r_{1},r_{2},\dots,r_{k-1 })","where each autoregressive unit \(r_{k}\in[V]^{h_{k}\times w_{k}}\) is the token map at scale \(k\) containing \(h_{k}\times w_{k}\) tokens, and the sequence \((r_{1},r_{2},\dots,r_{k-1})\) serves as the the ""prefix"" for \(r_{k}\)","p(r_{1},r_{2},\dots,r_{K})=\prod_{k=1}^{K}p(r_{k}\mid r_{1},r_{2},\dots,r_{k-1})",The autoregressive likelihood of the multi-scale token maps.
neurips_2024_oral_58,6,"w=64d,\qquad h=d,\qquad dr=0.1\cdot d/24",,"p(r_{k}\mid r_{1},r_{2},\dots,r_{k-1 })=\frac{\exp(score(r_{k},r_{1},r_{2},\dots,r_{k-1}))}{\sum_{v\in[V]}\exp(score(v,r_{1},r_{2},\dots,r_{k-1}))}",where score denotes the logit output from the VAR transformer model
neurips_2024_oral_58,7,"N(d)=\underbrace{d\cdot 4w^{2}}_{self-attention}+\underbrace{d\cdot 8w^{2}} _{feed-forward}+\underbrace{d\cdot 6w^{2}}_{adaptive layernorm}=18\,dw^{2}=73728\,d^{3}",,N=12dw^{2}+12w^{2}+2Vw=12\cdot 64d\cdot d^{2}+12\cdot 64^{2}d+2\cdot 4096\cdot 64d=49152d^{3}+12288d+524288d,"where \(d\) is the depth of the transformer, \(w\) is the width, and \(V\) is the vocabulary size"
neurips_2024_oral_59,1,"c^{(t+1)}(v)\gets f^{(t+1)}(c^{(t)}(v),g^{(t+1)}(\{\{c ^{(t)}(u)\mid u\inN(v)\}\}))",,"v^{(k)}=\sum_{u\inN(v)} M(v, u, v^{(k-1)}, u^{(k-1)})",The equation represents the message passing update rule for node $v$ at iteration $k$.
neurips_2024_oral_59,2,c^{(t)}(G)\coloneqq h(\{\{c^{(t)}(v)\mid v\in V(G)\}\} ),,o(G)=\bigoplus_{v\in V(G)} c^{(t)}(v),The graph output after t iterations is the combination of the colors of all nodes in the graph.
neurips_2024_oral_59,3,"N_{r}(v)\coloneqq\{p\midp simple path of length r,\,p_{1},p_{r+1}\inN(v),v\notinp\}\",,"N_{r}(v)\coloneqq\{p=\{p_{i}\}_{i=1}^{r+1}\mid p_{1}=v,\{p_{i},p_{i+1}\}\in E(G), p_{i}\neq p_{j} for  i\neq j\}","The r-neighborhood of a node v, denoted as \(\mathcal{N}_{r}(v)\), is defined as the set of all simple paths of length r that start at node v."
neurips_2024_oral_59,4,"c_{r}^{(t+1)}(v)arrowHASH_{r}(c_{r}^{(t)}(v),\{\{c _{r}^{(t)}(p)\midp\inN_{0}(v)\}\},\ldots,\{\{c_{r}^{(t)}(p)\midp\inN_{r}(v )\}\})",,"c^{(t+1)}(v)\gets f^{(t+1)}(c^{(t)}(v),g^{(t+1)}(\{\{c^{(t)}(u)\mid u\inN_{r}(v)\}\}))","The color update rule for the r-loop Weisfeiler-Leman test, where the neighborhood of a node v is generalized to include r-neighborhoods."
neurips_2024_oral_59,5,c_{r}^{(t)}(G)=HASH_{r}(\{\{c_{r}^{(t)}(v)\mid v\in V(G)\}\}\}),,c_{r}^{(t)}(G)\coloneqq h(\{\{c_{r}^{(t)}(v)\mid v\in V(G)\}\}),The final graph output after t iterations of r-ℓWL.
neurips_2024_oral_59,6,"m_{k}^{(t+1)}(v)&=f_{k}^{(t+1)}(\{\{c_{k}^{(t)}(p)\midp\inN_{k}(v)\}\}),\\c_{r}^{(t+1)}(v)&=g^{(t+1)}(c_{r}^{(t)}(v),\,m_{0 }^{(t+1)}(v),\ldots,m_{r}^{(t+1)}(v))",,"m_{r,k}^{(t+1)}(v)=AGG_{r,k}\left(\left\{\left\{h_{r,k}^{(t)}(p)\midp\inN_{k}(v)\right\}\right\}\right)",The message function for node $v$ at iteration $t$ in the $r$-$\ell$MPNN model.
neurips_2024_oral_59,7,f_{k}^{(t+1)}(\{\{c_{k}^{(t)}(p)\midp\inN_{k}(v)\}\}):=f(\sum_{p\inN_{k}(v)}g(p)),,AGG_{k}^{(t+1)}(v)=\sum_{p\inN_{k}(v)}c_{k}^{(t)}(p),The aggregation function for node v at iteration t+1.
neurips_2024_oral_59,8,x_{r}^{(t+1)}(v):=MLP(x_{r}^{(t)}(v)+(1+\varepsilon_{0})\sum_{u\inN_{0}(v)}x_{r}^{(t)}(u)+\sum_{k=1}^{r}(1+\varepsilon_{k})\sum_{p\inN_{k}(v)}GIN_{k}(p)),,f_{k}^{(t+1)}(v)=MLP\left(\sum_{p\inN_{k}(v )}GIN(p)\right),"The function $f_{k}^{(t+1)}(v)$ represents the message passing mechanism in the $r$-$\ell$GIN model, where $\mathrm{MLP}$ denotes a multi-layer perceptron and $\mathrm{GIN}$ denotes a graph isomorphic network."
neurips_2024_oral_6,1,"f_{z}(a_{1},a_{2})=E_{i\simS(z)\,,\,A_{1}\simB(a_{1})\,,\,A_{2}\simB(a_{2})}\Big{[}g_{i}(A_{1},A_{2 })\Big{]}=\sum_{i=0}^{15}\frac{\exp(z_{i})}{\sum_{j}\exp(z_{j})}\cdot g_{i}(a_ {1},a_{2})\",,g(a)=\sum_{i=0}^{15} p_i g_i(a)\),"The differentiable logic gate g is a weighted sum of the 16 possible logic gate operations, where the weights are the probabilities of each gate being selected."
neurips_2024_oral_6,2,"f_{3}(\,f_{1}(a_{1},a_{2}),f_{2}(a_{3},a_{4})\,)",,"f_{z_{1},z_{2},z_{3}}(a_{1},a_{2},a_{3},a_{4})=f_{z_{3}}(f_{z_{1}}(a_{1},a_{2}),f_{z_{2}}(a_{3},a_{4}))\","The function \(f_{\mathbf{z}_{1},\mathbf{z}_{2},\mathbf{z}_{3}}\) represents a binary tree of logic gates with learnable parameters \(\mathbf{z}_{1},\mathbf{z}_{2},\mathbf{z}_{3}\) applied to input activations \(a_{1},a_{2},a_{3},a_{4}\)."
neurips_2024_oral_6,3,"A^{\prime}[k,i,j]=f_{3}^{k}\big{(}f_{1}^{k}\big{(}A\big{[}C_{M}[k,\!1]\!,C_{H}[k,\!1]\!+\!i,C_{W}[k,\!1]\!+\! j\big{]},A\big{[}C_{M}[k,\!2]\!,C_{H}[k,\!2]\!+\!i,C_{W}[k,\!2]\!+\!j\big{]}\big{)} || \qquad\qquad\qquad f_{2}^{k}\big{(}A\big{[}C_{M} [k,\!3]\!,C_{H}[k,\!3]\!+\!i,C_{W}[k,\!3]\!+\!j\big{]},A\big{[}C_{M}[k,\!4]\!,C_{H}[k,\!4]\!+\!i,C _{W}[k,\!4]\!+\!j\big{]}\big{)}\big{)}",,"O=\sum_{i=1}^{n} f_{3}(\,f_{1}(A[C_{M}[i,0],C_{H}[i,0],C_{W}[i,0]],A[C_{M}[i,1],C_{H}[i,1],C_{W}[i,1]]),f_{2}(A[C_{M}[i,2],C_{H}[i,2],C_{W}[i,2]],A[C_{M}[i,3],C_{H}[i,3],C_{W}[i,3]]))\,)","The output of the convolutional logic gate network is computed by summing the outputs of each tree kernel over all input channels, heights, and widths."
neurips_2024_oral_60,1,Y^{l}=ESA(LN(X^{l}))+X^{l} || X^{l+1}=SwiGLU(LN(Y^{l}))+Y^{l},,X^{\nicefrac{{L}}{{2}}}=Self-Decoder(X^{0}),The equation represents the self-decoder process that transforms input embeddings \(X^{0}\) into an intermediate vector representation \(X^{\nicefrac{{L}}{{2}}}\).
neurips_2024_oral_60,2,"\hat{K}=LN(X^{\nicefrac{{L}}{{2}}})W_{K},\quad\hat{V}=LN(X^ {\nicefrac{{L}}{{2}}})W_{V}","where \(W_{K},W_{V}\in\mathbb{R}^{d\times d}\) are learnable","\hat{K}=LN(X^{\nicefrac{{L}}{{2}}})\cdot W_{K},\hat{V}=LN(X^{\nicefrac{{L}}{{2}}})\cdot W_{V}",The variables \(\hat{K}\) and \(\hat{V}\) represent the global key and value caches generated from the output of the self-decoder.
neurips_2024_oral_60,3,"Q^{l}=LN(X^{l})W_{Q}^{l} || Y^{l}=Attention(Q^{l},\hat{K},\hat{V})+X^{l} || X^{l+1}=SwiGLU(LN(Y^{l}))+Y^{l}",,"X^{l+1}=ESA(LN(X^{l}),\hat{K},\hat{V})+X^{l}","where \(X^{l}\) represents the input to the \(l\)-th cross-decoder layer and \(\hat{K},\hat{V}\) are the global KV caches."
neurips_2024_oral_60,4,"Q=XW_{Q},\quad K=XW_{K},\quad V=XW_{V}\\head_{i}=softmax(Q_{[i]}K_{[i]}^{\intercal}+B)V,\quad B_{ij}=0,&i-C<j\leq i\\-\infty,&otherwise\\SWA(X)=Concat(head_{1},\cdots,head_{h})W_ {O}","where \(W_{Q},W_{K},W_{V},W_{O}\in\mathbb{R}^{d\times d}\) are learnable matrices, and the window causal mask \(B\) controls each query only attends to the previous keys whose distances are less than \(C\)",Z^{l}_{i}=\sum_{j=i-C+1}^{i}\frac{(X^{l}_{i}W^{l}_{Q})(X^{l}_{j}W^{l}_{K})^{T}}{\sqrt{d}} X^{l}_{j}W^{l}_{V},"where \(Z^{l}_{i}\) is the output of sliding-window attention for the \(i\)-th token at the \(l\)-th layer, \(C\) is the window size, \(d\) is the hidden dimension, and \(W^{l}_{Q},W^{l}_{K},W^{l}_{V}\) are learnable weights."
neurips_2024_oral_60,5,"Q=(XW_{Q})\odot\Theta,\quad K=(XW_{K})\odot\overline{\Theta},\quad V=XW_{V},\quad\Theta_{n}=e^{in\theta}\\\gamma=sigmoid(XW_{\gamma})^{1/\tau},\quad D_{nm}=\prod\nolimits_{i=m+1}^{n}\gamma_{i},&n\geq m\\0,&n<m\\gRet(X)=(QK^{\intercal}\odot D)V","where \(W_{Q},W_{K},W_{V}\in\mathbb{R}^{d\times d}\) and \(W_{\gamma}\in\mathbb{R}^{d\times 1}\) are learnable weights, and the temperature term \(\tau\) encourages \(\gamma\) to 1 for better memorization [46]",g &=\sigma(W_g X)\\h &=\phi(W_h X)\\u &=g\cdot h+(1-g)\cdot u_{prev},"where \(u_{\text{prev}}\) is the previous hidden state, \(W_g\) and \(W_h\) are learnable weights, \(\sigma\) is the sigmoid function, and \(\phi\) is an activation function."
neurips_2024_oral_60,6,"S_{n}=\gamma_{n}S_{n-1}+K_{n}^{\intercal}V_{n}\\gRet(X_{n})=Q_{n}S_{n},\quad n=1,\cdots,|x|","where \(Q,K,V,\gamma\) are the same as in Equation (5)","Q_{n}=(X_{n}W_{Q})\odot\Theta_{n},\quad K_{n}=(X_{n}W_{K})\odot\overline{\Theta}_{n},\quad V_{n}=X_{n}W_{V}\\\gamma_{n}=sigmoid(X_{n}W_{\gamma})^{1/\tau}\\gRet_{n}(X)=(Q_{n}K_{n-1}^{\intercal}\odot D_{n-1,n})V_{n-1}+(Q_{n}K_{n}^{\intercal})V_{n}","where \(X_{n}\) is the input at the \(n\)-th timestep, and \(K_{n-1}\), \(V_{n-1}\) are the keys and values from the previous timestep."
neurips_2024_oral_60,7,"\beta_{(i-1)B+j}&=\prod\limits_{k=(i-1)B+1}^{(i-1)B+j}\gamma_{k},\quad D_{[i]}(j,k)=\frac{\beta_{(i-1)B+k}}{\beta_{ (i-1)B+j}}\\if\\j\leq k\\else\\0\\R_{i}&=K_{[i]}^{\intercal}(V_{[i]}\odot\frac{\beta_{iB}}{\beta_{[i]}})+\beta_{iB}R_{i-1},\\\beta_{[i]}(j,k)=\beta_{(i-1)B+j}\\gRet(X)&=\underbrace{(Q_{[i]}K_{[i]}^{\intercal}\odot D_{[i]})V_{[i]}}_{Inner-Chunk}+\underbrace{(Q_{[i]}R_{i-1})\odot\beta_{[i]}}_{Cross-Chunk}","where \(R_{i}\) is the intermediate state of the \(i\)-th chunk, and \(\beta\) summarizes the data-controlled decay \(\gamma\)","S_{[i]}&=\gamma_{[i]}S_{[i-1]}+K_{[i]}^{\intercal}V_{[i]}\\gRet(X_{[i]})&=Q_{[i]}S_{[i]},\quad i=1,\cdots,\lceil\frac{|x|}{B}\rceil","where \(S_{[i]}\) is the intermediate state for the \(i\)-th chunk, and \(Q_{[i]},K_{[i]},V_{[i]}\) are the query, key, and value for the \(i\)-th chunk."
neurips_2024_oral_60,8,"head_{i}=gRet(X) || Y=GroupNorm_{h}(Concat(head_{1},\cdots,head_{n})) || MHGR(X)=(swish(XW_{G})\odot Y)W_{O}",,"MultiHead(X)=Concat(head_{1},\cdots,head_{h})W_{O}",where each head applies the gated retention mechanism to the input sequence X.
neurips_2024_oral_8,1,w_{i}^{t}=\alpha^{t}W^{t-1}+(1-\alpha^{t})\hat{w}_{i}^{t},where \(\alpha^{t}\) is the fusion factor used to control the quality of the fused global model \(\mathcal{W}^{t-1}\),\hat{w}_{i}^{t}=\alphaW^{t-1}+(1-\alpha)\hat{w}_{i}^{t},"The equation represents the model fusion operation, where \(\alpha\) is the fusion coefficient, \(\mathcal{W}^{t-1}\) is the global model, and \(\hat{\mathbf{w}}_{i}^{t}\) is the fine-tuned local model."
neurips_2024_oral_8,2,"\alpha^{t}=\max\{(1-\epsilon)^{t-1}\alpha_{0},\alpha_{min}\}",,"\alpha^{t}=\max(\alpha_{0}\cdot (1-\epsilon)^{t-1},\alpha_{min})","where \(\alpha^{t}\) is the fusion factor at communication round \(t\), \(\alpha_{0}\) is the initial fusion factor, \(\epsilon\) is the sensitivity factor, and \(\alpha_{min}\) is the minimum fusion factor."
neurips_2024_oral_8,3,L^{DAR}_{i}= || g_{e}(w_{e}\odotM_{e};x_{i}) || _{2}^{2},,L^{DAR}=\sum_{i\inC}\lambda\left\lVertw_{e}\odotM_{e}-\frac{1}{|C|}\sum_{j\inC}w_{e}\odotM_{e}\right\rVert_{2}^{2},where \(\lambda\) is the regularization coefficient that controls the strength of the domain adaptive regularization term.
neurips_2024_oral_8,4,"L^{CE}_{i}=-\frac{1}{|K_{i}|}\sum_{k\inK_{i}}y_{ i,k}\log(\hat{y}_{i,k})","where \(\mathcal{K}_{i}\) denotes the set of possible labels on the client \(i\), \(\hat{y}_{i,k}\) denotes predicting label, and \(y_{i,k}\) denotes ground-truth label","L_{i}^{CE}=-\sum_{c=1}^{C}y_{i,c}\log(\hat{y}_{i,c})","where \(y_{i,c}\) is the true label and \(\hat{y}_{i,c}\) is the predicted probability for class \(c\)."
neurips_2024_oral_8,5,L_{i}=L^{CE}_{i}+\gammaL^{DAR}_{i},where the \(\gamma\) is a pre-defined coefficient controlling the importance of \(\mathcal{L}^{DAR}_{i}\) relative to \(\mathcal{L}^{CE}_{i}\),L_{i}=L^{CE}_{i}+\lambdaL^{DAR}_{i},where \(\lambda\) is a hyperparameter that controls the importance of the DAR regularization term.
neurips_2024_oral_8,6,w^{t}_{i}:=\underbrace{w^{t}_{i}\odotM^{t}_{i}}_{local knowledge}+\underbrace{W^{t-1}\odot\overline{M}^{t}_{i}}_{global knowledge},"where \(\mathcal{W}^{t-1}\) is the global model aggregated at the \((t-1)\)-th round, and \(\overline{\mathbf{M}}^{t}_{i}\) denotes the logical NOT operation applied to \(\mathbf{M}^{t}_{i}\)",w_{i}^{t}=(w_{i}^{t}\odotM_{i}^{t})\oplus0^{|w_{i}^{t}|-|w_{i}^{t}\odotM_{i}^{t}|},where \(\mathbf{0}^{|\mathbf{w}_{i}^{t}|-|\mathbf{w}_{i}^{t}\odot\mathbf{M}_{i}^{t}|}\) denotes a zero tensor with the same shape as the pruned part of \(\mathbf{w}_{i}^{t}\).
neurips_2024_oral_8,7,W^{t}=\sum_{i\inC}\frac{|D_{i}|}{|D|}w_{i}^{t},"where \(|\mathcal{D}_{i}|\) is the sample number in the local dataset on client \(i\), and \(|\mathcal{D}|\) is the total number of samples in the entire FL system",W^{t}=\frac{1}{|C|}\sum_{i\inC}w^{t}_{i},"where \(|\mathcal{C}|\) denotes the total number of clients, and \(\mathbf{w}^{t}_{i}\) denotes the recovered local model of client \(i\) at round \(t\)."
neurips_2024_oral_9,1,"lh_{Q}=(Q_{i}^{d},subqs^{i})(i=1,2,...,K)",,"cos(Q,Q_{i^{d}})=\frac{Q\cdotQ_{i^{d}}}{\|Q\|\|Q_{i^{d}}\|}",The cosine similarity between the representation of question Q and each question-decomposition example \(Q_{i}^{d}\) in the demonstration pool P.
neurips_2024_oral_9,2,"\{q_{t+1}^{j},j=1,...,J\}\gets Decompose(p_{\theta},\;h_{1},\;lh_{Q},\;q_ {t})",,"p(q_{t+1}^{1},...,q_{t+1}^{J}|q_{t})=\frac{1}{Z}\exp(\sum_{i=1}^{K}\alpha_{i}\cdotSim(q_{t}, Q_{i}^{d})\cdotSim(q_{t+1}^{1},...,q_{t+1}^{J}, subqs^{i}))","The probability of decomposing a question $q_{t}$ into sub-questions $q_{t+1}^{1},...,q_{t+1}^{J}$ is calculated based on the similarity between $q_{t}$ and the demonstration questions $Q_{i}^{d}$, as well as the similarity between the generated sub-questions and the human-annotated sub-questions $subqs^{i}$."
neurips_2024_oral_9,3,"r_{t+1}^{j}\gets Solve(p_{\theta},\;h_{2},\;q_{t+1}^{j})",,"r_{t+1}^{j}\gets Reason(p_{\theta},\;q_{t+1}^{j})",The rationale \(r_{t+1}^{j}\) is generated by the LLM for each sub-question \(q_{t+1}^{j}\) at level \(t+1\).
neurips_2024_oral_9,4,"\hat{r}_{t+1}^{j}\gets Self\_Check(p_{\theta},\;h_{3},\;q_{t+1}^{j},\;r_{t+1}^{j})",,"\hat{r}_{t+1}^{j}\gets SelfCheck(p_{\theta},\;h_{3},\;r_{t+1}^{j})",The variable \(\hat{r}_{t+1}^{j}\) represents the corrected rationale for the sub-question \(q_{t+1}^{j}\) after the self-check process.
neurips_2024_oral_9,5,"s_{t+1}^{j}\gets Score(p_{\theta},\;h_{4},\;q_{t+1}^{j},\;\hat{r}_{t+1}^{j })",,"s_{t+1}^{j}=\frac{1}{2} (Sim(\hat{r}_{t+1}^{j}, q_{t+1}^{j})+Sim(\hat{r}_{t+1}^{j}, lh_{Q}))","The coherence score \(s_{t+1}^{j}\) measures the logical coherence between the refined rationale \(\hat{r}_{t+1}^{j}\) and the question \(q_{t+1}^{j}\), as well as the coherence with the logic heuristics \(lh_{Q}\)."
neurips_2024_oral_9,6,"n_{t+1}^{j}=(q_{t+1}^{j},\hat{r}_{t+1}^{j},s_{t+1}^{j})",where \(s_{t+1}^{j}\) can support the current or subsequent cycles in _Rethink_ (4,"s_{t+1}^{j}=Score(p_{\theta},\;h_{4},\;q_{t+1}^{j},\;\hat{r}_{t+1}^{j})",The coherence score \(s_{t+1}^{j}\) represents the logical coherence between the refined rationale \(\hat{r}_{t+1}^{j}\) and the question \(q_{t+1}^{j}\).
neurips_2024_oral_9,7,"L_{k}\gets Extract(p_{\theta},\h_{5},\L,q_{t+1}^{j}),\L_{k}\subseteq L",where \(h_{5}\) is a prompt head (_Appendix_ A,"L_{k}=\underset{\hat{L}\subseteq L,|\hat{L}|=k}{\arg\max}\sum_{n_{l}\in\hat{L}}Corr(n_{l},n_{t+1}^{j})","where \(Corr(n_{l},n_{t+1}^{j})\) measures the correlation between nodes \(n_{l}\) and \(n_{t+1}^{j}\)."
neurips_2024_oral_9,8,"r^{\prime}\gets Update(p_{\theta},\h_{6},\n_{e}(q,r,s),\\hat{r}_{t+1}^{j})",,"\hat{r}_{e}\gets Update(p_{\theta},\;h_{6},\;n_{e},\;\hat{r}_{t+1}^{j})",where \(h_{6}\) is a prompt head that instructs the model to update the rationale based on new information.
neurips_2024_oral_9,9,"n_{e}(q,r^{\prime},s)\gets n_{e}(q,r,s)",,"n_{e}(q,r,s)\leftarrow n_{e}(q,r^{\prime},s)","where \(n_{e}\) represents an extracted node with question \(q\), rationale \(r\), and score \(s\)."
