paper_id,equation_id,ground_truth_eq,ground_truth_description,generated_equation,generated_description
2024.acl-short.12,1,ECE=\sum_{i=1}^{B}\frac{n_{b_{i}}}{N}|acc(b_{i})-conf(b_{i})|,"where \(i\) denotes \(i\)-th bin, \(N\) is the total instance count of the dataset, \(acc(b_{i})\) and \(conf(b_{i})\) represent the accuracy and confidence of the bin \(b_{i}\), and \(n_{b_{i}}\) is the instance number of the bin \(b_{i}\)",ECE=\sum_{k=1}^{K}\frac{|B_k|}{N}\left|acc(B_k)-conf(B_k)\right|,"ECE is calculated by dividing instances into K bins based on confidence intervals, where each bin B_k contains instances with similar confidence levels, and computes the weighted average of the absolute difference between accuracy and confidence within each bin."
2024.acl-short.12,2,"GECE=\frac{|M(pred,ref)-\frac{1}{n}\sum_{i=1}^{n}p(t_{i})|}{\alpha\cdot[E(\bigtriangledown_{ins})\cdot\bigtriangledown_{ins}]}","where \(pred\) and \(ref\) represent the generated text and the referenced ground truth, respectively","GECE=\sum_{i=1}^{B}\frac{n_{b_i}}{N}\left|METEOR(y_{pred}, y_{true})-AvgProb(y_{pred})+\lambda_1\cdotAvgFreq(x)+\lambda_2\cdot\nabla(x)\cdot\nabla_{mean}\right|","where $ \text{METEOR}(y_{\text{pred}}, y_{\text{true}}) $ measures coherence and relevance between predicted and ground truth texts, $ \text{AvgProb}(y_{\text{pred}}) $ is the average token probability of the prediction, $ \text{AvgFreq}(x) $ is the average word frequency in input $ x $, $ \nabla(x) \cdot \nabla_{\text{mean}} $ evaluates the gradient discrepancy, and $ \lambda_1, \lambda_2 $ are weighting coefficients."
2024.acl-short.14,1,"P(cot,T|KG) || =P((s_{1},t_{1}),\cdots,(s_{n},t_{n}),T|KG) || =\prod_{i=1}^{n}P((s_{i},t_{i})|(s_{1},t_{1}),\cdots,(s_{i-1},t_ {i-1}),KG)\cdot || P(T|(s_{1},t_{1}),\cdots,(s_{n},t_{n}),KG) || =\prod_{i=1}^{n}P(t_{i}|(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}),KG)\cdot || \prod_{i=1}^{n}P(s_{i})|t_{i},(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}),KG)\cdot || P(T|(s_{1},t_{1}),\cdots,(s_{n},t_{n}),KG)",,"P(Y|X)=\prod_{t=1}^{T} P(y_t | X, y_{<t})","Equation 1 defines the probability of generating the full text $ Y $ given the input KG $ X $, decomposed as a product of conditional probabilities for each sentence $ y_t $ given $ X $ and the previously generated sentences $ y_{<t} $."
2024.acl-short.14,2,"L_{seq}=-logP((s_{1},t_{1}),\cdots,(s_{n},t_{n}),T|KG) || =-\sum_{i=1}^{n}logP(t_{i}|(s_{1},t_{1}),\cdots,(s_{i-1},t_{i-1}) || KG)-\sum_{i=1}^{n}logP(s_{i})|t_{i},(s_{1},t_{1 }),\cdots,(s_{i-1} || t_{i-1}),KG)-\sum_{i=1}^{n}logP(T|(s_{1},t_{1 }),\cdots,(s_{n} || t_{n}),KG)",,"L=-\sum_{i=1}^{n}\log P(t_i |KG,prefix_i)-\sum_{i=1}^{n}\log P(s_i | t_i,KG,prefix_i)","The loss function combines the negative log-likelihoods of predicting each sentence-specific triplet subset and the corresponding sentence, conditioned on the knowledge graph and previously generated context."
2024.acl-short.14,3,"L_{re}=-\textbf{log}P(r|h,t,T) || =-\textbf{log}\prod_{i=1}^{m}P(r_{i}|r_{<i},h,t,T)",,"L_{b}=-\sum_{(h,r,t)\inKG}logP(r|h,t,T)","The backward relation extraction loss function, which encourages the model to correctly infer relations between head and tail entities given the generated text."
2024.acl-short.14,4,L=\alpha_{1}L_{seq}+\alpha_{2}L_{re},where \(\alpha_{1}\) and \(\alpha_{2}\) are parameters to tune,L_{total}=L_{seq}+\lambda L_{re},Total loss combining sequential generation and relation extraction objectives
2024.acl-short.15,1,"(o^{I},o^{S})=f(x)",where \(f(\cdot)\) is the joint model; \(\mathbf{o}^{I}\) and \(\mathbf{o}^{S}\) denotes an intent label and a slot sequence,y=f_{\theta}(x),"Equation 1 defines the joint SLU model $f_{\theta}$ that maps an input sentence $\mathbf{x}$ to the output $\mathbf{y}$, representing intent and slot labels, in zero-shot cross-lingual settings."
2024.acl-short.15,2,"\hat{Q}_{[i,j]}=norm(Q_{[i,j]})","where \(\mathrm{norm}(\cdot)\) denotes row normalization, which constrains the values to lie between 0 and 1","\hat{Q}=\mathop{argmin}\limits_{Q\in\Pi(h,h^{\prime})}\sum_{i,j}C_{[i,j]}Q_{[i,j]}","where $\Pi(\mathbf{h}, \mathbf{h}^{\prime})$ denotes the set of all possible transport plans between the representations $\mathbf{h}$ and $\mathbf{h}^{\prime}$, and $\mathbf{\hat{Q}}$ is the optimal alignment matrix obtained via IPOT."
2024.acl-short.15,3,"L_{RLA}=-\sum_{[i,j]}\hat{Q}_{[i,j]}\log(\sigma(1-C_{[i,j]}))","where \(\sigma\) denotes the sigmoid function, and \(1-\mathbf{C}_{[i,j]}\) denotes the cosine similarity between \(\mathbf{h}_{i}\) and \(\mathbf{h}^{\prime}_{j}\)","L_{align}=-\sum_{i,j}\hat{Q}_{[i,j]}\log\hat{Q}_{[i,j]}",the training loss for representation-level alignment using the alignment matrix $\mathbf{\hat{Q}}$ as weak supervision
2024.acl-short.15,4,P^{I}_{x}=softmax(W^{I}h_{CLS}+b^{I}) || P^{I}_{x^{\prime}}=softmax(W^{I}h^{\prime}_{CLS}+b^{I}),,p^{I}=softmax(decoder^{I}(h_{CLS})),where $\mathbf{p}^{I}$ denotes the predicted intent probability distribution for the original sentence
2024.acl-short.15,5,P^{S}_{x}=softmax(W^{S}h_{[1:-1]}+b^{ S}) || P^{S}_{x^{\prime}}=softmax(W^{S}h^{\prime}_{[1:-1]}+b^{S}),,P^{S}_{x}=softmax(W^{S}h_{[1:-1]}+b^{S}),where $\mathbf{P}^{S}_{\mathbf{x}}$ denotes the predicted slot sequence probabilities for the original sentence $\mathbf{x}$
2024.acl-short.15,6,"L_{I}=CE(P^{I}_{x},P^{I}) || L_{S}=\frac{1}{L}\sum_{i=1}^{L}CE(P^{S}_{[x,i]},P^{S}_{i})",,L_{I}=-\logP^{I}_{x}(y^{I}),where $y^{I}$ is the ground truth intent label for the original sentence $\mathbf{x}$
2024.acl-short.15,7,L_{PLA}=\underbrace{KL(P^{I}_{x^{\prime}} || P^{I}_{x})}_{Intent PLA}+\underbrace{KL(P^{S}_{x^{\prime}} || P^{S}_{x}) }_{Slot PLA},"where \(\mathrm{KL}(\cdot)\) denotes Kullback-Leibler divergence (Kullback and Leibler, 1951) to measure the difference between two distributions","L_{PLA}=KL(P^{I}_{x}\parallelP^{I}_{x^{\prime}})+\frac{1}{L}\sum_{i=1}^{L}KL(P^{S}_{[x,i]}\parallelP^{S}_{[x^{\prime},i]})",where $\mathrm{KL}(\cdot \parallel \cdot)$ denotes the Kullback-Leibler divergence measuring the difference between two probability distributions
2024.acl-short.15,8,"L_{SD}=\underbrace{KL(P^{[I,t-1]}_{ kT} || P^{[I,t]}_{latent SD})}_{Intent SD}+\underbrace{\frac{1}{L}\sum_{i=1}^{L}KL(P^{[S,t-1]}_{[x,i]} || P^{[S,t]}_{[x,i]}) }_{Slot SD}","where \(\mathbf{P}^{[I,t]}_{\mathbf{x}}\) denotes the probability distribution of intent, \(\mathbf{P}^{[S,t]}_{[\mathbf{x},i]}\) of slot at \(i\)-th token",L_{SD}=\underbrace{KL(P^{t}_{x} || P^{t-1}_{x})}_{Intent SD}+\underbrace{KL(P^{t}_{x^{\prime}} || P^{t-1}_{x^{\prime}} )}_{Slot SD},"where $\mathrm{KL}(\cdot)$ denotes Kullback-Leibler divergence, and the loss encourages consistency between current and previous predictions for both intent and slot tasks"
2024.acl-short.15,9,L=L_{I}+L_{S}+L_{RLA}+L _{PLA}+L_{SD},,L_{total}=L_{I}+L_{S}+\lambda_{1}L_{RLA}+\lambda_{2}L_{PLA}+\lambda_{3}L_{SD},"where $\lambda_{1}$, $\lambda_{2}$, and $\lambda_{3}$ are hyperparameters that balance the contributions of the representation-level alignment, prediction-level alignment, and self-distillation losses, respectively."
2024.acl-short.16,1,Y=W_{0}^{l}X+\Lambda_{b}^{l}B^{l}\Lambda_{d}^{l}A^{l}X,,Y=\sigma\left(X\cdot W+s_{d}\odot\left(lora_{B}\cdot\left(lora_{A}\cdot X\right)\right)+s_{b}\right),"The output $Y$ is computed by applying a non-linear activation $\sigma$ to the sum of the base transformation $X \cdot W$, the scaled low-rank adaptation, and the bias vector $s_{b}$."
2024.acl-short.16,2,"I_{A^{l}}=|\nablaL(\theta)|,\overline{T}^{(t)}_{A^{l }}=\beta_{1}\overline{T}^{(t-1)}_{A^{l}}+(1-\beta_{1})I^{(t)}_{A^{l}} || U^{(t)}_{A^{l}}=|I^{(t)}_{A^{l}}-\overline{I}^{(t)}_{A^{l}}|,\overline{U}^{(t)}_{A^{l}}=\beta_{2}\overline{U}^{(t-1)}_{A^{l}}+(1-\beta_{2} )U^{(t)}_{A^{l}} || s^{(t)}_{A^{l}}=mean(\overline{T}^{(t)}_{A^{l}}\circ\overline{U}^{(t)}_{A^{l}})",,F_{A^{l}}=\frac{1}{T}\sum_{t=1}^{T}\left\|\nabla A^{l}_{t}\right\|_{2}^{2},The freezing score $\mathcal{F}_{A^{l}}$ quantifies the average squared L2 norm of gradients for the LoRA tensor $A^{l}$ over $T$ training steps.
2024.acl-short.16,3,r(t)=\{{ll}0&0\leq t<t_{i}\\1-(1-\frac{t-t_{i}}{T-t_{i}-t_{f}})^{3}&t_{i}\leq t<T-t_{f}\\1&otherwise,"where \(t\) refers to current #step, \(T\) is the total number of fine-tuning steps",r(t)=0 &if  t < t_i\\1-\left(\frac{T-t}{T-t_i}\right)^3 &if  t_i\leq t < T-t_f\\1 &if  t\geq T-t_f,"Freezing fraction $r(t)$ calculated using a cubic schedule, determining the proportion of projection matrices to be frozen at training step $t$."
2024.acl-short.20,1,"E(h,r,t)=\sum_{i=1}^{k}w_{i}(q)M_{i}(h,r,t)","where \(\mathtt{E}(\mathtt{h},\mathbf{r},\mathbf{t})\) is the ensemble score for \(\mathbf{t}\) given query \(\mathtt{q}=(\mathbf{h},\mathbf{r},?)\)","E(h,r,t)=\sum_{i=1}^{k}\alpha_i\cdotM_i(h,r,t)","The ensemble E combines the scores of k KGC models using learnable weights Î±_i, where each model's contribution is weighted by its relevance to the query."
2024.acl-short.20,2,"M_{i}(h,r,t)\getsM_ {i}(h,r,t)-\min_{t^{\prime}\inE}M_{i}(h,r,t^{\prime}) || M_{i}(h,r,t)arrow\frac{M_{i}(h,r,t)}{\max_{t^{\prime}\inE}M_{i}(h,r,t^{\prime})}",,"s_{i}(q,t)=\frac{M_{i}(h,r,t)-\min_{t'\inE}M_{i}(h,r,t')}{\max_{t'\inE}M_{i}(h,r,t')-\min_{t'\inE}M_{i}(h,r,t')}","where $\mathbf{s}_{\mathtt{i}}(\mathtt{q},\mathbf{t})$ is the normalized score for model $\mathtt{M}_{\mathtt{i}}$ and candidate tail $\mathbf{t}$ given query $\mathtt{q}=(\mathbf{h},\mathbf{r},?)$"
2024.acl-short.20,3,"f(M_{i},q)=\underset{t^{\prime}\inE}{mean}(M_{i}(h,r,t^{\prime})) || \underset{t^{\prime}\inE}{ var}(M_{i}(h,r,t^{\prime}))",,"f_{i}(q)=\left\langle\mu_{i}(q),\sigma_{i}(q),top_kscore_{i}(q)\right\rangle","where $\mathbf{f}_{\mathtt{i}}(\mathtt{q})$ represents the feature vector for model $\mathtt{M}_{\mathtt{i}}$ and query $\mathtt{q}$, composed of the mean $\mu_{\mathtt{i}}(\mathtt{q})$, standard deviation $\sigma_{\mathtt{i}}(\mathtt{q})$, and top-k scores of the normalized scores for $\mathtt{M}_{\mathtt{i}}$ over all $\mathbf{t} \in \mathcal{E}$"
2024.acl-short.20,4,"w_{1}(q)=MLP_{1}(f(M_{1},q) || f(M_{2},q) ||  || f(M_ {k},q))",,"w_{i}(q)=MLP_{i}\left(\bigoplus_{j=1}^{k}f(M_{j},q)\right)","where $\mathbf{w}_{\mathtt{i}}(\mathtt{q})$ is the query-dependent weight for model $\mathtt{M}_{\mathtt{i}}$, obtained using a 2-layer MLP that takes as input the concatenated features from all models $\mathtt{M}_{\mathtt{j}}$"
2024.acl-short.20,5,"L=\sum_{t\inN}\max(E(h,r,t)-E(h,r,t^{*})+m,0)",where \(\mathtt{m}\) is the margin hyperparameter,"L(q)=\sum_{t^{-}\inN}\max\left(0,\gamma-E(h,r,t^{*})+E(h,r,t^{-})\right)","where $\gamma$ is the margin hyperparameter and $\mathtt{E}(\mathtt{h}, \mathtt{r}, \mathtt{t})$ is the ensemble score for entity $\mathtt{t}$ given query $(\mathtt{h}, \mathtt{r}, ?)$"
2024.acl-short.25,1,"s_{i}=\sigma(\frac{1}{\beta_{i}}(log\frac{\mu_{i}}{1-\mu_{i}}+\textit{log}\alpha_{i})) || m_{i}=min(1,max(0,s_{i}(\zeta-\gamma)+\gamma))",,"m_{i}\simHardConcrete(\log\alpha_{i},\beta_{i})",Each neuron mask $m_{i}$ is modeled as an independent random variable following a hard concrete distribution parameterized by $\log \alpha_{i}$ and temperature $\beta_{i}$.
2024.acl-short.25,2,"min(1,max(0,\sigma(log\alpha_{i})(\zeta-\gamma)+\gamma))",,"m_{i}=min(1,max(0,\sigma(\log\alpha_{i}) (\zeta-\gamma)+\gamma))","The mask $m_{i}$ is computed using a hard concrete gate during inference, where $\sigma$ is the sigmoid function, $\alpha_{i}$ is the learnable parameter, and $\gamma$, $\zeta$ are constants controlling the gate's behavior."
2024.acl-short.25,3,"L_{m}(f(m\odot\theta),x)=\sum_{i=1}^{I}log(P(x_{p+i}|x_{<p+i}))",,"L_{m}(f(m\odot\theta),x)=-\sum_{t=p}^{p+I}\log P_{f}(x_{t}|x_{<t};m\odot\theta)",This equation defines the training objective for localizing privacy-related neurons by maximizing the negative log-likelihood of PII token sequences.
2024.acl-short.25,4,"L_{adv}(f(m\odot\theta),x)=-\sum_{t=1}^{T}log(P(x_{t}|x_{<t}))",,"L_{adv}(f(m\odot\theta),x)=\sum_{t=1}^{T}log(P(x_{t}|x_{<t}))","This equation defines the adversarial loss as the standard language modeling objective, which maximizes the log-likelihood of the entire token sequence to preserve the model's language generation capability."
2024.acl-short.25,5,R(m)=-\frac{1}{|m|}\sum_{i=1}^{|m|}\sigma(log\alpha_{i}-\beta_{i}log \frac{-\gamma}{\zeta}),,R(m)=\|m\|_0,The regularization term $R(m)$ minimizes the $L_0$ norm of the mask $m$ to reduce the number of selected neurons.
2024.acl-short.3,1,"\Delta(G_{1},G_{2})=\min_{ops}\sum_{i=1}^{n}w(op_{i})",,"\Delta=APTED(G_{1}, G_{2})",The tree edit distance $\Delta$ between predicted AST $G_{1}$ and ground-truth AST $G_{2}$ is computed using the APTED algorithm.
2024.acl-short.3,2,"TSED=\max\{1-\frac{\delta}{MaxNodes(G_{1},G_{2})},0\}",,"Normalized\_TSED(G_{1}, G_{2})=\frac{\Delta(G_{1}, G_{2})}{\max(|G_{1}|, |G_{2}|)+I[\min(|G_{1}|, |G_{2}|) <\tau]}",Normalized tree edit distance with a ramp function to handle extreme cases based on a threshold $\tau$.
2024.acl-short.39,1,"Bio(m,co(m))=f_{gen}(m,co(m))",where biography is generated by the model \(f_{gen}\) given the personal attribute of interest (\(m\)) and the co-occurring attributes (\(co(m)\)),"B=G(A,\theta)","where $ \mathcal{B} $ denotes the generated biography, $ \mathcal{A} $ represents the structured personal attributes from the infobox, and $ G(\cdot; \theta) $ is the generation model parameterized by $ \theta $."
2024.acl-short.39,2,"Bio(\phi,co(m))=f_{gen}(\phi,co(m))",,"\Delta_{sem}=Data-QuestEval(Bio(m,co(m)))-Data-QuestEval(Bio(Masked,co(m)))","Equation 2 defines the semantic matching difference ($\Delta_{sem}$) between biographies generated with a specific attribute $m$ and those generated when the attribute is masked, using the Data-QuestEval metric."
2024.acl-short.39,3,"Bio(f,co(m))=f_{gen}(f,co(m)),do(m\to f)","where \(do(m\to f)\) denotes the do operator (Pearl, 2009), e","Bio(m',co(m))=f_{gen}(m',co(m))",where counterfactual biography is generated by replacing the personal attribute $m$ with $m'$ while keeping the co-occurring attributes $co(m)$ unchanged
2024.acl-short.40,1,"L_{e}=\frac{1}{N}\sum_{i=1}^{N}(\cos(S_{1,i},S_{2,i})-\cos(E_{1,i},E_{2,i}))^{2}","where \(N\) is the batch size, and \(S\) and \(E\) contain the target text SEM vectors and the predicted output SEM vectors respectively","tags, and the description in <description> tags. Also, check if the summation is correctly applied over the vector elements. Alternatively, if the vectors are of dimension d, maybe the summation is over each element. But the context says ""minimum squared error (MSE)"", which is a scalar loss. So yes, the equation as written makes sense. </think>","tags. Also, check if the summation is correctly applied over the vector elements. Alternatively, if the vectors are of dimension d, maybe the summation is over each element. But the context says ""minimum squared error (MSE)"", which is a scalar loss. So yes, the equation as written makes sense.
</think>

<latex>
\begin{equation}
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} \left\| \mathbf{y}_1^{(i)} - \mathbf{y}_2^{(i)} \right\|^2
\end{equation}
</latex>"
2024.acl-short.40,2,"L_{o}=CE(T,O)=-\frac{1}{N}\sum_{i=1}^{N}\sum_{j=1}^{M} (T_{ij}\cdot\log(O_{ij}))","where \(N\) is the batch size, \(M\) the vocabulary size, \(T\) is the target text and \(O\) is the output text","L_{t}=-\frac{1}{N}\sum_{i=1}^{N}\sum_{t=1}^{T}\log P(Y_{i,t} | SEM_i)","where $N$ is the batch size, $T$ is the sequence length, $Y$ contains target text tokens, and $P(Y_{i,t} | SEM_i)$ represents the predicted probability of token $t$ given SEM vector $SEM_i$"
2024.acl-short.41,1,E(y)=h(\beta+\sum_{j=1}^{J}f_{j}(x_{j})),"where \(h(\cdot)\) is the activation function used in the output layer, e",f(x)=\sum_{i=1}^{n} f_i(x_i),"The equation represents the general form of a Neural Additive Model (NAM), where the function $ f(x) $ is expressed as the sum of individual functions $ f_i $ applied to each input feature $ x_i $. This formulation allows for modeling the additive effects of individual features on the target variable."
2024.acl-short.41,2,h(E[y])=\beta+\sum_{j=1}^{J}f_{j}(x_{j(tab)})+\sum_{k=1}^{ K}f_{k}(x_{k(top)}),,E(y)=h\left(\beta+\sum_{j=1}^{J_{tab}}f_{j}(x_{j(tab)})+\sum_{k=1}^{K}f_{J_{tab}+k}(x_{k(top)})\right),"This equation extends the NAM framework by incorporating both tabular features and topic prevalences into the downstream model, maintaining interpretability through additive shape functions."
2024.acl-short.43,1,P(c|s)=\frac{\exp(b_{c}\cdot\frac{1}{T}\sum_{t=1}^{T}x_{t})}{\sum_{c^{\prime}=1}^{N}\exp(b_{c^{\prime}}\cdot\frac{1}{T}\sum_{t=1}^ {T}x_{t})},,p(c\mid s)=\frac{\exp\left(\frac{1}{T}\sum_{i=1}^{T}w_{c}^{\top}x_{i}+b_{c}\right)}{\sum_{c'=1}^{N}\exp\left(\frac{1}{T}\sum_{i=1}^{T}w_{c'}^{\top}x_{i}+b_{c'}\right)},"Equation 1 defines the posterior probability of a language $c$ given a sentence $s$ using the FastText architecture, where $\mathbf{w}_{c}$ and $b_{c}$ are the weight vector and bias term for class $c$, respectively."
2024.acl-short.43,2,"V_{c,t}(s)=b_{c}\cdotx_{t}",,"V_{c,t}(s)=b_{c}\cdotx_{t}","Each element $\mathbf{V}_{c,t}(s)$ represents the contribution (logits) of word-level feature $\mathbf{x}_{t}$ to language $c$ in sentence $s$."
2024.acl-short.49,1,CEF=\frac{\sum_{i=0}^{n}(I_{i}-\overline{I} )(M_{i}-\overline{M})}{\sqrt{\sum_{i=1}^ {n}(I_{i}-\overline{I})^{2}}\sqrt{\sum_{i=1}^ {n}(M_{i}-\overline{M})^{2}}},where \(\overline{x}=\frac{1}{n}\sum_{i=1}^{n}x_{i}\) (the sample mean),CEF=\frac{\sum_{i=1}^{N} (I_i-\bar{I})(M_i-\bar{M})}{\sqrt{\sum_{i=1}^{N} (I_i-\bar{I})^2\sum_{i=1}^{N} (M_i-\bar{M})^2}},"Equation 1 defines the Correlational Explanatory Faithfulness (CEF) metric as the Pearson correlation coefficient between prediction impact ($\mathcal{I}$) and mention importance ($\mathcal{M}$) across $N$ interventions, addressing the limitations of the CT by capturing the continuous relationship between impact and explanation."
2024.acl-short.49,2,"TVD(P,Q)=\frac{1}{2}\sum_{x}|P(x)-Q(x)|",where P and Q are probability distributions over discrete classes,I_{TVD}=\frac{1}{2}\sum_{c\inC}\left| p(c\midx)-p(c\midx')\right|,"where $\mathcal{C}$ is the set of all classes, $\mathbf{x}$ is the original input, and $\mathbf{x}'$ is the modified input with the IA inserted."
2024.acl-short.49,3,CCT=\frac{E_{M}(TVD)-E_{-M}(TVD)}{STD(TVD)}\sqrt{\frac{|M || \neg M|}{|M\cup\neg M|^{2}}},"where \(M\) indicates that the explanation mentions the IA, and \(|M|\) indicates the number of examples with explanation mentions",CCT=\frac{\sum_{i=1}^{n}(TVD_i-\overline{TVD})(M_i-\overline{M})}{\sqrt{\sum_{i=1}^{n}(TVD_i-\overline{TVD})^2}\sqrt{\sum_{i=1}^{n}(M_i-\overline{M})^2}},the point-biserial correlation between prediction impact (measured via TVD) and mention importance (binary indicator of whether the explanation mentions the intervened word)
2024.acl-short.5,1,"s_{ori}(x_{i}|x_{<i})= || \{{ll}\log P_{M_{e}}(x_{i}|x_{<i})-\log P_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{ori,i}^{\alpha}\\-\infty,&x_{i}\notinV_{ori,i}^{\alpha}\\s_{imp}(x_{i}|x_{<i})=\\\{{ll}(1+\beta)Y_{M_{a}}(x_{i}|x_{<i})-\beta Y_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{imp,i}^{\alpha}\\-\infty,&x_{i}\notinV_{imp,i} || s_{int}(x_{i}|x_{<i})= || \{{ll}(1+\beta)Y_{M_{e}}(x_{i}|x_{< i})-\beta Y_{M_{a}}(x_{i}|x_{<i}),&x_{i}\inV_{imp,i}^{\alpha}\\-\infty,&x_{i}\notinV_{imp,i}",,s_{ori}(x_{i}|x_{<i})=\log p_{expert}(x_{i}|x_{<i})-\log p_{amateur}(x_{i}|x_{<i}),Original contrastive decoding logit score as the difference between expert and amateur LM log probabilities.
2024.acl-short.5,2,"V_{ori,i}^{\alpha}=\{w|P_{M_{e}}(w|x_{<i})>\alpha\max_{w\inV}P_{M_{e}}(w|x_{<i})\} || V_{imp,i}^{\alpha}=\{w|Y_{M_{e}}(w| x_{<i})>\log\alpha+\max_{w\inV}Y_{M_{e}}(w|x_{<i})\}",,"V_{\cdot,i}^{\alpha}=\left\{x_{i}\inV\mid P_{M_{e}}(x_{i}|x_{<i})\geq\alpha\cdot\max_{x'\inV}P_{M_{e}}(x'|x_{<i})\right\}","The adaptive plausibility constraint $\mathcal{V}_{\cdot,i}^{\alpha}$ restricts the token generation to those whose expert LM probability is at least a fraction $\alpha$ of the maximum probability among all tokens at position $i$."
2024.acl-short.53,1,"L_{FT}=\frac{1}{|D_{M}|}\sum_{d\inD_{M}}L(d;\Phi _{0},\Delta\Phi)","where \(\mathcal{D}_{M}\) is the KE dataset and \(d\) is a fact edit example, \(L\) is the cross entropy loss function applied to autoregressive models, \(\Phi_{0}\) denotes the set of original weights of the language model that are kept frozen, and \(\Delta\Phi\) denotes the additional parameters used by the PEFT adapters",L=\sum_{i=1}^{N}\left( y_i-\hat{y}_i\right)^2+\lambda\Omega(\theta),Loss function combining prediction error and regularization term for fine-tuning base LLMs with PEFT approaches.
2024.acl-short.53,2,h=W_{0}x+BAx=(W_{0}+BA)x,,\Delta\Phi_{LoRA}=B\cdot A,"Equation defining the PEFT adapter parameters via low-rank matrix decomposition, where $B\in\mathbb{R}^{d\times r}$ and $A\in\mathbb{R}^{r\times k}$ are trainable low-rank matrices with $r\ll\min(d,k)$"
2024.acl-short.56,1,h^{\prime}=SoftMax(h\cdoth^{\prime T})\cdoth^{\prime},,"H=\left( z^{\prime}_{s}+M[1],\cdots, z^{\prime}_{s}+M[k]\right)",Hybrid latent variable $H$ combines continuous variable $z^{\prime}_{s}$ with discrete latent variables $M$ to balance diversity and relevance.
2024.acl-short.56,2,"\mu^{\prime}_{1},...,\mu^{\prime}_{n}\\\log(\sigma^{\prime 2}_{1}),...,\log(\sigma^{\prime 2}_{n})=[h_{1};h^{\prime}_{1}]\\\cdots\\[h_{n};h^{\prime}_{n}]W^{\prime}_{u}\","where \(W^{\prime}_{u}\) is trainable parameters of \(q_{\phi}(z|r,c)\)","q_{\phi}(z|c,r)\simN(\mu^{\prime},\sigma^{\prime 2}I)","Distribution of the continuous latent variable $z$ conditioned on context $c$ and character result $r$, modeled as an isotropic Gaussian with mean $\mu^{\prime}$ and variance $\sigma^{\prime 2}$."
2024.acl-short.57,1,"a_{k}^{pred}=\operatorname*{arg\,max}_{a_{k}}\!P(a_{k}|q_{k},H_{k},D)",,"a_k^{pred}=f(q_k, D, H_k)","The predicted answer $a_k^{\text{pred}}$ is a function of the current question $q_k$, document $D$, and history $H_k$, where $H_k$ contains prior question-answer pairs but only historical questions are utilized in this model."
2024.acl-short.57,2,"P(a_{k}|q_{k},H_{k},D)=P(a_{k}|q_{k},H_{k}^{\star},D)",,"a_{k}^{pred}=\operatorname*{arg\,max}_{a_{k}}\!P(a_{k}|q_{k},H_{k},D)=\operatorname*{arg\,max}_{a_{k}}\!P(a_{k}|q_{k},H_{k}^{\star},D)",Equation 2 enforces robustness by ensuring that the predicted answer remains consistent regardless of whether the original or augmented history is used.
2024.acl-short.57,3,"L_{CE}=CE(QA_{\theta^{\prime}}(q_{k},H_{k},D),a_{k}^{gold}) || L_{Cons}=D_{KL}(QA_{\theta^{\prime}}(q_{k},H_{k},D) || QA_{\theta^{\prime}}(q_{k},H_{k}^{\star},D)) || L_{T}=L_{CE}+\lambda L_{Cons}",,"L_{CE}=-\log P(a_{k}|q_{k},H_{k},D),\quad L_{Cons}=D_{KL}(P(a_{k}|q_{k},H_{k},D)\parallel P(a_{k}|q_{k},H_{k}^{\star},D)),\quad L_{T}=L_{CE}+\lambda L_{Cons}","Equation 3 defines the loss functions used to train the QA network, including cross-entropy loss (L_CE), consistency loss (L_Cons) based on KL-divergence, and the total loss (L_T) as a weighted sum of the two, where Î» is a hyperparameter balancing the contributions of the losses."
2024.acl-short.62,1,R(\tau)=\frac{1}{T}\sum_{t=1}^{T}r_{t},,"R(\tau)=\frac{1}{T}\sum_{t=1}^{T} r_{\phi}(s_t, a_t)",This equation defines the total reward of a trajectory as the average of the token-level rewards obtained at each step in the sequence.
2024.acl-short.62,2,p(\tau^{i}\succ\tau^{j})&=\frac{\exp(R(\tau^{i}))}{\exp(R(\tau^{i}))+\exp(R(\tau^{j}))}\\&=\sigma(R(\tau^{i})-R(\tau^{j})),where \(\tau^{i}\) and \(\tau^{j}\) represent two different responses generated from the same prompt,p_{BT}(y_{i}\succ y_{j})=\frac{e^{\mu_{i}}}{e^{\mu_{i}}+e^{\mu_{j}}}},"where $y_i$ and $y_j$ are two responses to the same prompt, and $\mu_i$, $\mu_j$ are their respective reward scores."
2024.acl-short.62,3,"&L=-E_{(\tau^{i},\tau^{j})\simD}[\log\sigma(R(\tau^{i})-R(\tau^{j}))]\\&=-E_{(\tau^{i},\tau^{j})\simD}[\log\sigma((\frac{1}{T^{i}}-\frac{1}{T^{j}})\sum_{t\in U_{0}}r_{t}\\&+\frac{1}{T^{i}}\sum_{t\in U_{1}}r_{t}^{i}-\frac{1}{T^{j}}\sum_ {t\in U_{1}}r_{t}^{j})]",,"L_{RM} &=-\log\, p(\tau^{i}\succ\tau^{j})\\&=-\log\,\sigma\left(\frac{1}{T}\sum_{t=1}^{T}(r_{t}^{i}-r_{t}^{j})\right)\\&=-\log\,\sigma\left(\frac{1}{T}\sum_{t\in U_{1}}(r_{t}^{i}-r_{t}^{j})\right)","Loss function for the reward model under the assumption that only parts of the response are changed between $\tau^{i}$ and $\tau^{j}$, using the sigmoid function and focusing only on the changed token positions $U_1$."
2024.acl-short.62,4,"L\approx-E_{(\tau^{i},\tau^{j} )\simD}[\log\sigma(\frac{1}{T^{i}}\sum_{t\in U_{1}}r_{t}^{i}-\frac{ 1}{T^{j}}\sum_{t\in U_{1}}r_{t}^{j})]",,"&L_{equal}=-E_{(\tau^{i},\tau^{j})\simD}[\log\sigma(\frac{1}{T}\sum_{t\in U_{1}}r_{t}^{i}-\frac{1}{T}\sum_{t\in U_{1}}r_{t}^{j})]",This equation simplifies the loss function under the assumption of equal response length and consistent reward for unchanged parts.
2024.acl-short.66,1,"H(t,a)=\mathds{1}[\{(i,t)\in a\}=\varnothing]",,"Hallucination(\hat{y}_t)=1 &if \nexists j such that  a_t=j,\\0 &otherwise","This equation defines the hallucination metric for a target word in SiMT based on word alignment, where a target word is considered a hallucination if it has no alignment to any source word."
2024.acl-short.66,2,"HR(x,\hat{y},a)=\frac{1}{|\hat{y}|}\sum_{t=1}^{|\hat{y}|}H(t,a)",,"HR=\frac{1}{T}\sum_{t=1}^{T} H(t, a)","The Hallucination Rate (HR) is calculated as the average of the hallucination metric $H(t, a)$ over all target words $t$ in the translation, where $T$ is the total number of target words."
2024.acl-short.66,3,"H_{wait-k}(t,a)=\mathds{1}[\{(s,t)\in a\mid s\geq t+k\}=\varnothing]",,"H_{GHall}(t, a, s)=\mathds{1}[\{(i, t)\in a\mid x_i\in s\}=\varnothing]","This equation defines the GHall hallucination metric, where a target word is considered hallucinated if it does not align with any source word in the current source segment $s$."
2024.acl-short.66,4,"R(y_{i},x_{j})=P(y_{i}\midy_{<i},x_{\leq i+k-1}) || \quad-P(y_{i}\midy_{<i},x_{\leq i+k-1, (j,\textbf{0})}) || R(y_{i},y_{j})=P(y_{i}\midy_{<i},x_{\leq i+k-1}) || \quad-P(y_{i}\midy_{<i,(j,\textbf{0} )},x_{\leq i+k-1})",,"R(y_i, x_j)=\left|\frac{\partial\log p(y_i\mid x_{1:n}, y_{1:i-1})}{\partialdropout(x_j)}\right|",Relevance of source word $x_j$ to target word $y_i$ measured via dropout sensitivity in Wait-$k$ models.
2024.acl-short.66,5,"R(y_{i})_{source-side}=\max\{|R(y_{i},x_ {j})|\} || R(y_{i})_{target-side}=\max\{|R(y_{i},y _{j})|\}",,"SourceRelevance(i)=\max_{j} |R(y_{i},x_{j})|,\quadTargetRelevance(i)=\max_{j < i} |R(y_{i},y_{j})|",SourceRelevance and TargetRelevance capture the maximum absolute relevance of source and target words to the current target word $\text{y}_{i}$.
2024.acl-short.66,6,TSSR(y_{i})=\frac{R(y_{i})_{target-side}}{R(y_{i} )_{source-side}},,TSSR(y_{i})=\frac{R(y_{i})_{target-side}}{R(y_{i})_{source-side}},"The TSSR measures the ratio of target-side relevance to source-side relevance for a generated word $y_i$, indicating the extent to which target-side context is used during generation."
2024.acl-short.68,1,"T_{i}=\operatorname*{Top\_}{d\inM}k\f(s_{i},d)",,"T_{i}=Top-k_{d\inM}\left(sim\left( R_{Q}(s_{i}), R_{D}(d)\right)\right)",Retrieval of top-k passages from the corpus $\mathcal{M}$ for a medical code $c_i$ based on the surface name $s_i$ using dense vector similarity.
2024.acl-short.68,2,"e_{i}=LLM([Prompt,t_{i,1},\cdots,t_{i,k}])",where \(t_{i}\in\mathcal{T}_{i}\) stands for the retrieved passages in Eq,e_{i}=LLM(T_{i}),where $e_{i}$ denotes the summarized knowledge generated by the LLM from the top retrieved passages $\mathcal{T}_{i}$ for medical code $c_{i}$.
2024.acl-short.68,3,"h_{i}^{k}=PLM(X_{i}^{k}),\;\;\widehat{y}_{i,1}=MLP ( || _{k\inS}h_{i}^{k})",,"X_{i}^{d}=\{[CLS], D_{t}, D_{t-1},\ldots, D_{1}\}, where  D_{i}=\big\Vert_{c\in D_{i}} (c, e)","Flattened document representation for disease codes, incorporating summarized knowledge via concatenation within the i-th visit."
2024.acl-short.68,4,"e_{i}=HyGT(G,V_{i}),\widehat{y}_{i,2}=MLP(e_{i})",where \(\mathbf{e}_{i}\) is the representation of patient \(i\) after hypergraph transformer,"\widehat{y}_{i,2}=f_{\theta}(v_{i})","where $v_{i}$ represents the visit information for patient $p_{i}$, and $f_{\theta}$ is the local model used to generate predictions based on visit-level data."
2024.acl-short.68,5,"L_{aug}=E_{(V_{i},y_{i})\simP}\;\ell(\widehat{y}_{i,1},y_{i})+\lambdaD_{KL}(\widehat{y}_{i,1},\widetilde{y}) || L_{loc}=E_{(V_{i},y_{i})\simP}\;\ell(\widehat{y}_{i,2},y_{i})+\lambdaD_{KL}(\widehat{y}_{i,2},\widetilde{y})",,"L=L_{task}(\widehat{y}_{i,1},y_{i})+L_{task}(\widehat{y}_{i,2},y_{i})+\lambdaL_{consistency}(\widehat{y}_{i,1},\widehat{y}_{i,2})","where the total loss combines task-specific losses from both models and a consistency loss between their predictions, weighted by $\lambda$."
2024.acl-short.71,1,"hyp^{*}=\operatorname*{arg\,max}_{hyp\inhyps}utility(hyp)",,"hyp^{*}=\argmax_{hyp\inhyp}E_{R|S}[U(hyp, R)]",Selects the optimal translation hypothesis by maximizing expected utility under the reference distribution given the source.
2024.acl-short.71,2,"utility(hyp)\approx\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}} metric(hyp,\textit{ref})",,"\hat{U}(hyp)=\frac{1}{m}\sum_{i=1}^{m}metric(hyp,ref_i)",Monte Carlo approximation of expected utility using $m$ pseudo-references sampled from the model distribution
2024.acl-short.71,3,\overline{\textit{ref}}=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textit{ ref},,\overline{\textit{ref}}=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textit{ref},The aggregate reference representation $\overline{\textit{ref}}$ is computed by averaging the individual reference representations across all $m$ sampled references.
2024.acl-short.71,4,"utility(hyp)\approxmetric(hyp,\overline{\textit{ref}})",,"utility(hyp)\approxmetric(hyp,\overline{\textit{ref}})",This equation approximates the utility of a hypothesis by computing a single metric score against the aggregated reference representation $\overline{\textit{ref}}$.
2024.acl-short.71,5,ChrF_{\beta}=\frac{(1+\beta^{2})\cdotChrP\cdotChrR}{\beta^{2}\cdotChrP+ChrR} || ChrP=\frac{|hyp\cap\textit{ref}|}{|hyp|} and ChrR=\frac{|hyp\cap\textit{ref}|}{|\textit{ref}|},"where

\[\text{ChrP}=\frac{|hyp\cap\textit{ref}|}{|hyp|}\text{ and }\text{ChrR}=\frac{|hyp \cap\textit{ref}|}{|\textit{ref}|},\]

and the parameter \(\beta\) controls the relative importance of precision and recall","ChrF(hyp, ref)=\frac{(1+\beta^2)\cdotmatching\_ngrams(hyp, ref)}{\beta^2\cdothyp\_ngrams(hyp)+ref\_ngrams(ref)}","ChrF metric computes an F-score based on character n-grams between a hypothesis and a reference, with $\beta$ balancing precision and recall."
2024.acl-short.71,6,\overline{\textit{ref}}=\frac{1}{m}\underbrace{\biguplus}_{\textit{ref}\in\textit{refs}}\textit{ref},where \(\biguplus\) is an operation that sums up the counts of each n-gram,\overline{\textit{ref}}_{n-gram}=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textit{ref}_{n-gram},The aggregate reference representation for ChrF is obtained by averaging the n-gram counts across all reference samples.
2024.acl-short.71,7,"\textbf{{hyp}},\\textbf{{ref}},\\textbf{{src}}=emb(\textbf{{hyp}}),\emb(\textbf{{ref}}),\emb(\textbf{{src}})",,"utility(hyp)\approxChrF_{\beta}(hyp,\overline{\textit{ref}})",This equation approximates the expected utility of a hypothesis by calculating the ChrF score between the hypothesis and the aggregated reference representation.
2024.acl-short.71,8,"comet(\textbf{{hyp}})=score(\textbf{{hyp}},\\textbf{{ref}},\\textbf{{src}})",,score=FFN([\textbf{hyp};\textbf{ref};\textbf{src}]),"The scalar score is computed by a feed-forward network (FFN) that takes the concatenated embeddings of the hypothesis, reference, and source as input."
2024.acl-short.71,9,\overline{\textbf{{ref}}}=\frac{1}{m}\sum_{\textbf{{ref}}\in\textbf{{ref}}}emb(\textbf{{ref}}),,\overline{\textbf{{ref}}}=\frac{1}{m}\sum_{\textit{ref}\in\textit{refs}}\textbf{{ref}},Average reference embeddings across all references to form a single aggregate reference representation for COMET metric.
2024.acl-short.71,10,"comet(\textbf{{hyp}})\approxscore(\textbf{{hyp}},\\overline{\textbf{{ref}}},\\textbf{{src}})",,"comet(\textbf{{hyp}})=score(\textbf{{hyp}},\\overline{\textbf{{ref}}},\\textbf{{src}})",Reference aggregation is applied to COMET by using the average reference embedding to compute a single score per hypothesis.
2024.acl-short.72,1,h_{i}=XLMRoberta-Layer^{1}(x_{i}),"where \(h_{i}\) is the representation of the ""[CLS]"" token",h_{i}=XLM-Roberta(x_{i}),Equation 1 defines the encoding of the $i$-th DOM node's text representation $x_i$ into a 768-dimensional node representation $h_i$ using the first layer of the XLM-Roberta model.
2024.acl-short.72,2,\hat{h}_{i}=Transformer(Linear(h_{i})),where the linear layer projects \(h_{i}\) to 256-dimensional embeddings for efficient modeling,H'=Transformer(H),where $H'$ denotes the encoded node representations obtained through a 3-layer transformer model with 8 attention heads.
2024.acl-short.72,3,P(y^{k}_{i}=1|x_{i})=Sigmoid(MLP(\hat{h}_{i})),,P(y^{k}_{i}=1|x_{i})=Softmax(\hat{h}_{i} W_{k}+b_{k}),where the probability is obtained through a softmax function over the transformed node representations
2024.acl-short.72,4,"L=\sum_{k=1}^{6}\sum_{i=1}^{n}CrossEntropy(P(y^{k}_{i}|x_{i}), Y^{k}_{i})",where \(\mathcal{Y}^{k}_{i}\) is the ground truth label,L=-\frac{1}{N}\sum_{i=1}^{N}\sum_{k=1}^{K} y_{i}^{k}\log(P(y_{i}^{k}=1|x_{i}))+(1-y_{i}^{k})\log(1-P(y_{i}^{k}=1|x_{i})),where the loss function is a binary cross-entropy over all nodes and label categories
ICLR_2024_oral_1,1,I(\theta):=E_{\Upsilon\sim p_{\theta}} [\nabla_{\theta}\log p_{\theta}(\Upsilon)\cdot\nabla_{\bm {\theta}}\log p_{\theta}(\Upsilon)^{\top}],,I_{\theta} :=E_{p_{\theta}}\left[\nabla_{\theta}\log p_{\theta}(\Upsilon)\cdot\nabla_{\theta}\log p_{\theta}(\Upsilon)^{\top}\right],The Fisher information matrix quantifies the amount of information that an observed trajectory carries about the unknown parameter $\mathbf{\theta}$.
ICLR_2024_oral_1,2,E_{D\sim p_{\theta^{\star}}}([\widehat{\theta} (D)-\theta^{\star})(\widehat{\theta}(D)-\theta^{\star})^{\top}]\succeq T^{-1}\cdotI(\theta^{\star})^ {-1},,Cov(\widehat{\theta}(D))\succeqI(\theta^{\star})^{-1},The covariance of any unbiased estimator of the true parameter Î¸â is lower bounded by the inverse of the Fisher information matrix.
ICLR_2024_oral_1,3,E_{D\sim p_{\theta^{\star}}}[\|\widehat{\theta} (D)-\theta^{\star}\|_{2}^{2}]=tr(E_{ D\sim p_{\theta^{\star}}}[(\widehat{\theta}(D)-\theta^{\star})(\widehat{\theta}(D)-\theta^{\star})^{\top}])\geq T^{-1}\cdottr(I(\theta^{\star})^{-1}),,"E_{D\sim p_{\theta^{\star}},\widehat{\theta}}\left[\left\|\widehat{\theta}(D)-\theta^{\star}\right\|^{2}\right]\geq T^{-1}\cdottr\left(I(\theta^{\star})^{-1}\right)",This equation expresses the lower bound on the expected squared error of an unbiased estimator in terms of the trace of the inverse Fisher information matrix scaled by the number of samples.
ICLR_2024_oral_1,4,"I(\theta^{\star},\pi_{exp}):=E_{\tau\sim p_{\theta^{\star}}(\cdot\mid\pi_{exp})}[\nabla_{\theta}\log p_{\theta^{\star}}(\tau\mid\pi_{exp})\cdot\nabla_{\theta}\log p_{\theta^{\star}}(\tau\mid\pi_{ exp})^{\top}]",,I(\theta^{\star};\pi_{exp}):=E_{\Upsilon\sim p_{\theta^{\star}}(\cdot\mid\pi_{exp})}[\nabla_{\theta}\log p_{\theta}(\Upsilon)\cdot\nabla_{\theta}\log p_{\theta}(\Upsilon)^{\top}]\Big|_{\theta=\theta^{\star}},"The Fisher information matrix conditioned on the exploration policy $\pi_{\mathrm{exp}}$, quantifying how much information a trajectory from this policy provides about the true parameter $\mathbf{\theta}^{\star}$."
ICLR_2024_oral_1,5,"\arg\min_{\pi}tr(I(\theta^{\star},\pi)^{-1})",,"\pi_{exp}^{\star}=\arg\min_{\pi_{exp}}tr(I(\theta^{\star},\pi_{exp})^{-1})","This equation defines the optimal exploration policy as the one that minimizes the trace of the inverse of the Fisher information matrix, corresponding to the A-optimal experiment design criterion."
ICLR_2024_oral_1,6,"s_{h+1}=f_{\theta}(s_{h},a_{h})+w_{h}","where \(s_{h}\) and \(a_{h}\) are the current state and action, \(w_{h}\sim\mathcal{N}(0,\sigma_{w}^{2}\cdot I)\) is Gaussian process noise, and \(f_{\mathbf{\theta}}\) are the nominal dynamics","\nabla_{\theta}\log p_{\theta}(\tau\mid\pi)=\sum_{h=1}^{H}\nabla_{\theta}\log p_{\theta}(s_{h+1}\mid s_{h},a_{h})","This equation decomposes the gradient of the log-likelihood of the trajectory with respect to the parameters into a sum of gradients over transitions, under the assumption of Markovian dynamics."
ICLR_2024_oral_1,7,"I(\theta,\pi)=\sigma_{w}^{-2}\cdotE_{p_{\theta}(\cdot\mid\pi)}[\sum_{h=1}^{H}\nabla_{\theta}f_{\theta}(s_{h},a_ {h})\cdot\nabla_{\theta}f_{\theta}(s_{h},a_{h})^{\top}]",,"I(\theta,\pi)=\frac{1}{\sigma_{w}^{2}}E_{\tau\sim p_{\theta}(\cdot\mid\pi)}\left[\sum_{h=1}^{H}\nabla_{\theta}f_{\theta}(s_{h},a_{h})^{\top}\nabla_{\theta}f_{\theta}(s_{h},a_{h})\right]","The Fisher information matrix under Gaussian process noise dynamics, expressed in terms of the expectation of the sum of outer products of the gradients of the nominal dynamics with respect to the parameters."
ICLR_2024_oral_1,8,"\pi_{exp}=\arg\min_{\pi}E_{\theta\sim q_{0}}[tr (I(\theta,\pi)^{-1})]",,"\arg\min_{\pi}E_{\theta\simU(\Theta)}\left[tr(I(\theta,\pi)^{-1}\right)]","This equation represents the domain randomization approach to exploration policy optimization, where the expectation over $\mathbf{\theta}$ is taken with respect to a uniform distribution over the parameter space $\Theta$."
ICLR_2024_oral_1,9,E_{\theta\sim q_{\theta}}[E_{\tau_{ sim}\sim p_{\theta}(\cdot\midA(\uptau_{real}) )}[\|\uptau_{real}-\uptau_{sim}\|_{2}^{2}]],"where \(p_{\mathbf{\theta}}(\cdot\mid\mathcal{A}(\mathbf{\uptau}_{\mathrm{real}}))\) denotes the distribution over trajectories generated by the simulator with parameter \(\mathbf{\theta}\), and playing the same sequence of actions as were played in \(\mathbf{\uptau}_{\mathrm{real}}\)",\min_{q_{\phi}}KL\left(q_{\phi}(\theta)\|p(\theta)\right)-E_{\theta\sim q_{\phi}}\left[\log p_{\theta}(\uptau_{real}\mid\pi_{exp})\right],
ICLR_2024_oral_10,1,"R=\{r_{1},\dots,r_{m}\}",where each ray \(\mathbf{r}_{i}\in\mathbb{R}^{6}\) is associated with a known pixel coordinate \(\mathbf{u}_{i}\),"C=\left\{r_i=\left(o_i,d_i\right)\mid i=1,\dots, N\right\}","A camera is represented as a collection of rays, where each ray $\mathbf{r}_i$ is defined by its origin $\mathbf{o}_i$ and direction $\mathbf{d}_i$, forming an over-parameterized representation $\mathcal{C}$ consisting of $N$ rays."
ICLR_2024_oral_10,2,"r=\langled,m\rangle\inR^{6}","where \(\mathbf{m}=\mathbf{p}\times\mathbf{d}\in\mathbb{R}^{3}\) is the moment vector, and importantly, is agnostic to the specific point on the ray used to compute it",r=d\\p\timesd,where each ray $\mathbf{r}\in\mathbb{R}^{6}$ is represented by its direction $\mathbf{d}\in\mathbb{R}^{3}$ and the cross product $\mathbf{p} \times \mathbf{d}$ of a point $\mathbf{p}\in\mathbb{R
ICLR_2024_oral_10,3,"d=R^{\top}K^{-1}u,\qquadm=(-R^{\top}t)\timesd",,"d_{i}=\frac{K^{-1}u_{i}}{\|K^{-1}u_{i}\|},\quadm_{i}=p\timesd_{i}","Equation 3 defines how to compute the direction and moment vectors of each ray in the bundle given a known camera and a set of 2D pixel coordinates, using unprojection and the camera center as the reference point."
ICLR_2024_oral_10,4,"c=\operatorname*{arg\,min}_{p\inR^{3}}\\sum_{\langled,m\rangle\inR}\lVertp\timesd-m\rVert^{2}",,c=\arg\min_{x\inR^{3}}\sum_{i=1}^{m}\left\|\left(I-\frac{d_{i}d_{i}^{\top}}{\|d_{i}\|^{2}}\right)(x-p_{i})\right\|^{2},where the camera center $\mathbf{c}$ is estimated by minimizing the geometric distance to all rays in the bundle $\mathcal{R}$
ICLR_2024_oral_10,5,"P=\operatorname*{arg\,min}_{\|H\|=1}\sum_{i=1}^{m}\|Hd_{i}\timesu_{i}\|",,"P=\operatorname*{arg\,min}_{P}\\sum_{i=1}^{m}\lVertd_i^{pred}-Pu_i\rVert^2",where $\mathbf{P} \in \mathbb{R}^{3 \times 3}$ is the homography matrix that aligns predicted ray directions $\mathbf{d}_i^{\text{pred}}$ with pixel coordinates $\mathbf{u}_i$ under an identity camera model.
ICLR_2024_oral_10,6,f_{feat}(I)=f\inR^{p\times p\times d},,F_{i}=\Phi(I_{i})\inR^{m\times d},"where $\mathbf{F}_{i}$ represents the spatial image features extracted from image $I_{i}$, with $m$ patches and feature dimension $d$"
ICLR_2024_oral_10,7,"\{\hat{R}\}_{i=1}^{N}=f_{Regress}(\{f_{i},u_{i}\}_{i=1}^{N\cdot p^{2}})",,"\hat{R}_{1},\dots,\hat{R}_{N}=f_{ray}(\{f_{1},\dots,f_{N}\})",where $f_{\text{ray}}$ is a transformer-based model that predicts ray bundles $\hat{\mathcal{R}}_i$ for each input image $I_i$ by jointly processing spatial features and pixel coordinates.
ICLR_2024_oral_10,8,L_{recon}=\sum_{i=1}^{N}\|\hat{R}_{i}- R_{i}\|_{2}^{2},,"L_{ray}=\sum_{i=1}^{N}\sum_{j=1}^{m}\left\|\hat{r}_{i,j}-r_{i,j}\right\|^{2}","where $\hat{\mathbf{r}}_{i,j}$ is the predicted ray and $\mathbf{r}_{i,j}$ is the ground truth ray for the $j$-th patch in the $i$-th image."
ICLR_2024_oral_10,9,x_{t}=\sqrt{\alpha_{t}}x_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,"where \(\epsilon\sim\mathcal{N}(0,\mathbf{I})\) and \(\alpha_{t}\) is a hyper-parameter schedule of noise weights such that \(x_{T}\) can be approximated as a standard Gaussian distribution","x_{t}=\sqrt{\alpha_{t}}x_{0}+\sqrt{1-\alpha_{t}}\epsilon_{t},\quad\epsilon_{t}\simN(0,I)","where $\mathbf{x}_{t}$ is the noisy sample at time $t$, $\alpha_{t}$ is the time-dependent noise schedule, and $\mathbf{\epsilon}_{t}$ is standard Gaussian noise."
ICLR_2024_oral_10,10,"L(\theta)=E_{t,x_{0},\epsilon}\|x_{0}-f_{\theta }(x_{t},t)\|^{2}",,"\hat{x}_{0}=f_{\theta}(x_{t},t)",The denoising network predicts the original noise-free sample $x_0$ from a noisy input $x_t$ and the noise level $t$.
ICLR_2024_oral_10,11,"\{\hat{R}\}_{i=1}^{N}=f_{Diffusion}(\{f_{i},u_{i},r_{i,t}\}_{i=1}^{N\cdot p^{2}},t) || r_{i,t}=\sqrt{\bar{\alpha}_{t}}r_{i}+\sqrt{1-\bar{\alpha}_{t}}\epsilon","where the noisy rays \(\mathbf{r}_{i,t}\) can be computed as:

\[\mathbf{r}_{i,t}=\sqrt{\bar{\alpha}_{t}}\mathbf{r}_{i}+\sqrt{1-\bar{\alpha}_{t}}\epsilon","\{\hat{R}_{t}\}_{i=1}^{N}=f_{\theta}(\{f_{i},u_{i},r_{i}^{(t)}, t\}_{i=1}^{N\cdot p^{2}})","We modify the ray regression network to condition on noisy rays and a time embedding, enabling it to learn the denoising process for distributed ray representations."
ICLR_2024_oral_11,1,"O_{ij}=\sum_{v=1}^{k}I[y_{ij}\neq y_{ij}^{(v)}],\forall j\in Y_{i}",where \(\mathbb{I}[\cdot]\) is the indicator function and \(y_{ij}\) is the \(j\)-th candidate label of \(\mathbf{x}_{i}\),"O_{ij}=\sum_{\substack{(x_i^{(j)}, Y_i^{(j)})\inN_k(x_i)}}I(y_j\notin Y_i^{(j)})","where $O_{ij}$ quantifies the number of times the $j$-th candidate label is absent in the $k$-NN instances of the $i$-th example, indicating a higher likelihood of being a false label."
ICLR_2024_oral_11,2,\gamma_{i}=\lceil\tau(|Y_{i}|-1)\rceil,where \(\lceil\cdot\rceil\) is the ceiling function that returns the least integer greater than or equal to the given number,E_{i}=\sum_{j\in Y_{i}}I[O_{ij}\geq\tau],"where $E_i$ represents the count of candidate labels in $Y_i$ whose corresponding $O_{ij}$ score meets or exceeds the pruning threshold $\tau$, indicating they are likely false labels and should be removed."
ICLR_2024_oral_11,3,\widetilde{Y}_{i}=Top-\gamma_{i}-argmax_{j\in Y_{i}}(O_{ij}),where \(\mathrm{Top}\text{-}\gamma_{i}\text{-}\mathrm{argmax}_{i}\) returns a subset of indices (i,P_{i}=top_{\gamma_{i}}\{O_{ij}\mid j\in Y_{i}\},which represents the set of candidate labels to be pruned based on the top-$\gamma_i$ highest down-voted labels.
ICLR_2024_oral_11,5,"P(O_{iy}^{(\xi_{i}^{2})}<O_{iy})-P(O_{iy}^{(\xi_{i}^{1})}<O _{iy})\leqslant\sum_{j=1}^{k}\sum_{m=\xi_{i}^{2}}^{\xi_{i}^{1}-1}\binom{|Y^{\prime}_{i}|}{m}\eta^{m}(1-\eta)^{|Y^{\prime}_{i}|-m}b_{\delta_{k}}(k,j)",,"P(O_{iy^{\prime}}^{(\xi_{i}^{2})}<O_{iy})-P(O_{iy^{\prime}}^{(\xi_{i}^{1})}<O_{iy})\leq\sum_{j=1}^{k}\sum_{m=\xi_{i}^{2}}^{\xi_{i}^{1}-1}\binom{|Y_{i}^{\prime}|}{m}\eta^{m}(1-\eta)^{(|Y_{i}^{\prime }|-m)}b_{\delta_{k}}(k,j)","where $\xi_{i}^{1}=(|Y^{\prime}_{i}|-\gamma_{i}^{1}+1)$ and $\xi_{i}^{2}=(|Y^{\prime}_{i}|-\gamma_{i}^{2}+1)$ denote the order statistics corresponding to two different pruning extents $\gamma_{i}^{1}$ and $\gamma_{i}^{2}$, and the bound quantifies the additional pruning error introduced by increasing the number of eliminated candidate labels."
ICLR_2024_oral_13,1,"q(x_{t}|x_{t-1})=N(x_{t};\sqrt{1-\beta_{t}}x_{t},\beta_{t}I ),\quadfor t\in\{1,...,T\}","where \(\beta_{t}\in(0,1)\) is the scheduled variance at step \(t\)","x_t=\sqrt{1-\beta_t} x_{t-1}+\sqrt{\beta_t}\epsilon\quadfor  t=1,\dots,T","Forward diffusion process defining $x_t$ as a Markov chain with Gaussian noise scaled by $\beta_t$, where $\epsilon \sim \mathcal{N}(0, I)$."
ICLR_2024_oral_13,2,x_{t}=\sqrt{\bar{\alpha}_{t}}x_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon,"where, \(\bar{\alpha}_{t}=\prod_{i=1}^{t}(1-\beta_{t})\)","q(x_{t}|x_{0})=N(x_{t};\sqrt{\bar{\alpha}_{t}}x_{0},(1-\bar{\alpha}_{t})I)",where $\bar{\alpha}_{t} = \prod_{s=1}^{t} (1 - \beta_{s})$ represents the cumulative product of the noise schedule up to step $t$.
ICLR_2024_oral_13,3,\hat{x}_{0}^{t}=\frac{x_{t}-\sqrt{1-\bar{\alpha}_{t}}\epsilon_{\theta}(x_{t}) }{\sqrt{\bar{\alpha}_{t}}},,\hat{x}_{0}=\frac{1}{\sqrt{\bar{\alpha}_{t}}}x_{t}-\sqrt{1-\bar{\alpha}_{t}}\epsilon_{\theta}(x_{t}),where $\hat{x}_{0}$ is the estimated original data point from the noisy input $x_{t}$ using the predicted noise $\epsilon_{\theta}(x_{t})$
ICLR_2024_oral_13,4,"x_{t-1}=\sqrt{\bar{\alpha}_{t-1}}\hat{x}_{0}^{t}+\sqrt{1-\Text-conditional diffusion models, such as Stable Diffusion (Rombach et al., 2022), employ classifier-free diffusion guidance (Rombach et al., 2022) to steer the sampling process. Given a text prompt\(p\), its embedding\(e_{p}=f(p)\) is computed using a pre-trained CLIP text encoder\(f(\cdot)\)(Radford et al., 2021; Cherti et al., 2023). In the reverse process, the conditional sampling adheres to Eq. (3) and Eq. (4), but the predicted noise\(\epsilon_{\theta}(x_{t})\) is changed to:\[\epsilon_{\theta}(x_{t},e_{\theta})+s(\underbrace{\epsilon_{\theta}(x_{t},e_ {p})-\epsilon_{\theta}(x_{t},e_{\theta})}_{text-conditional noise prediction})","where, \(e_{\theta}\) represents the prompt embedding of an empty string, and \(s\) determines the guidance strength, controlling the alignment of the generation to the prompt",\hat{x}_{t-1}=\frac{x_{t}-\sqrt{1-\bar{\alpha}_{t}}\epsilon_{\theta}(x_{t})}{\sqrt{\bar{\alpha}_{t}}}\cdot\sqrt{\bar{\alpha}_{t-1}}+\sqrt{1-\bar{\alpha}_{t-1}}\epsilon_{\theta}(x_{t}),Equation predicts the previous step $x_{t-1}$ using the estimated noise $\epsilon_{\theta}(x_{t})$ and the known variance schedule $\bar{\alpha}_{t}$.
ICLR_2024_oral_13,5,"d=\frac{1}{T}\sum_{t=1}^{T}\|\epsilon_{\theta}(x_{t},e_{p})-\epsilon_{\theta} (x_{t},e_{\theta})\|_{2}",,"M(p)=\frac{1}{T}\sum_{t=1}^{T}\left\|\epsilon_{\theta}(x_{t}, e_{p})-\epsilon_{\theta}(x_{t}, e_{\theta})\right\|_{2}",where $\mathcal{M}(p)$ quantifies the average Euclidean norm of the text-conditional noise prediction across all sampling steps for a given prompt $p$.
ICLR_2024_oral_13,6,"L(x_{t},e)=\|\epsilon_{\theta}(x_{t},e)-\epsilon_{\theta}(x_{t},e_{\emptyset})\|_{2}",,"\min_{\delta_{1},...,\delta_{N}}\sum_{t=1}^{T}\|\epsilon_{\theta}(x_{t},e+\delta)-\epsilon_{\theta}(x_{t},e_{\theta})\|_{2}\quadsubject to\quad\|\delta_{i}\|_{2}\leq\lambda,\forall i","where $\delta_{i}$ denotes the perturbation applied to the $i$-th token embedding, and $\lambda$ controls the maximum allowed perturbation magnitude for each token."
ICLR_2024_oral_13,7,"SS_{e^{i}}=\frac{1}{T}\sum_{t=1}^{T}\|\nabla_{e^{i}}L(x_{t}, e)\|_{2}",,"s_{i}=\left\|\frac{\partialL(x_{t},e)}{\partial e_{i}}\right\|_{2}",where the significance score $s_{i}$ quantifies the sensitivity of the text-conditional noise prediction with respect to changes in the embedding of the token at position $i$.
ICLR_2024_oral_14,1,"F^{*}&=\operatorname*{argmax}_{F}p(F|D _{src},D_{tgt})=\operatorname*{argmax}_{F}p(D_{src},D_{tgt}|F)\cdot p(F)\\&=\operatorname*{argmax}_{F}\{\underbrace{\log p(D_{src},D _{tgt}|F)}_{data term}+\underbrace{\log p(F)}_{prior term}\}",,"F^{*}=\arg\max_{F}\left[ p(D_{src}, D_{tgt} | F)\cdot p(F)\right]","The optimal correspondence field $F^{*}$ is obtained by maximizing the product of the likelihood $p(D_{\text{src}}, D_{\text{tgt}} | F)$ and the prior $p(F)$ over all possible correspondence fields $F$."
ICLR_2024_oral_14,2,"X_{t}=\sqrt{\alpha_{t}}X_{0}+\sqrt{1-\alpha_{t}}Z,\quad Z\simN(0,I)",where \(\alpha_{t}=\prod_{i=1}^{t}(1-\beta_{i})\),"q(X_{t}|X_{0})=N(X_{t};\sqrt{\bar{\alpha}_{t}}X_{0},(1-\bar{\alpha}_{t})I)","The forward diffusion process at time step $t$ given the initial sample $X_0$, characterized by a Gaussian distribution with mean $\sqrt{\bar{\alpha}_t}X_0$ and variance $(1-\bar{\alpha}_t)I$."
ICLR_2024_oral_14,3,"X_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(X_{t},t;K)+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t}}}\Big{(}X_{t}-\sqrt{\alpha_{ t}}F_{\theta}(X_{t},t;K)\Big{)}+\sigma_{t}Z",where \(\sigma_{t}\) is the covariance value of Gaussian distribution at time step \(t\),"X_{t-1}=\sqrt{\alpha_{t-1}}\left(\frac{X_{t}-\sqrt{1-\alpha_{t}}Z_{t}}{\sqrt{\alpha_{t}}}\right)+\sqrt{1-\alpha_{t-1}}F_{\theta}(X_{t},t;K)","where $Z_{t} \sim \mathcal{N}(0, I)$ and $\mathcal{F}_{\theta}(X_{t},t;K)$ is the denoising network conditioned on $K$."
ICLR_2024_oral_14,4,"F^{*}=F_{\theta}(D_{src},D_{tgt})\approx\underset{F }{argmax}\\underbrace{\log p(D_{src},D_{tgt}|F)}_{data term}","where \(\mathcal{F}_{\theta}(\cdot)\) and \(\theta\) represent a feed-forward network and its parameters, respectively","F^{*}=\operatorname*{argmax}_{F}\log p(D_{src},D_{tgt}|F)","Estimation of the dense correspondence field by maximizing the data term, which represents the matching evidence between source and target feature descriptors."
ICLR_2024_oral_14,5,"F^{*}=F_{\theta}(D_{src},D_{tgt})\approx\underset{F}{argmax}\p(F|D_{src},D_{tgt}) || =\underset{F}{argmax}\{\underbrace{\log p(D_{ src},D_{tgt}|F)}_{data term}+\underbrace{\log p(F)}_{prior term}\}",,"F^{*}=\operatorname*{argmax}_{F}\left[\log p(D_{src}, D_{tgt} | F)+\log p(F)\right]",where the objective explicitly maximizes the posterior probability of the correspondence field by jointly considering both the data term and the prior term.
ICLR_2024_oral_14,6,"F_{t}=\sqrt{\alpha_{t}}F_{0}+\sqrt{1-\alpha_{t}}Z,\quad Z\simN(0,I)",where \(F_{0}\) is the ground-truth correspondence,"F_{t}=\sqrt{\alpha_{t}}F_{0}+\sqrt{1-\alpha_{t}}Z,\quad Z\simN(0,I)",where $\alpha_{t}=\prod_{i=1}^{t}(1-\beta_{i})$
ICLR_2024_oral_14,7,"F_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(X_{t},t;D_{src},D_{tgt})+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t }}}\Big{(}X_{t}-\sqrt{\alpha_{t}}F_{\theta}(F_{t},t;D_{src },D_{tgt})\Big{)}+\sigma_{t}Z","where \(\mathcal{F}_{\theta}(F_{t},t;D_{\mathrm{src}},D_{\mathrm{tgt}})\) directly predicts the denoised correspondence \(\hat{F}_{0,t}\) with source and target features, \(D_{\mathrm{src}}\) and \(D_{\mathrm{tgt}}\), as conditions","F_{t-1}=\sqrt{\alpha_{t-1}}F_{\theta}(F_{t},t;C^{l},F_{init})+\frac{\sqrt{1-\alpha_{t-1}-\sigma_{t}^{2}}}{\sqrt{1-\alpha_{t}}}\Big{(}F_{t}-\sqrt{\alpha_{t}}F_{\theta}(F_{t},t;C^{l},F_{init})\Big{)}+\sigma_{t}Z","where $C^{l}$ and $F_{\text{init}}$ are the local matching cost and the initial correspondence used as conditions, respectively."
ICLR_2024_oral_14,8,"C(i,j)=\frac{D_{src}(i)\cdot D_{tgt}(j)}{\|D_{src}(i)\|\|D_{tgt}(j)\|}","where \(i\in[0,h_{\text{src}})\times[0,w_{\text{src}})\), \(j\in[0,h_{\text{tgt}})\times[0,w_{\text{tgt}})\), and \(\|\cdot\|\) denotes \(l\)-2 normalization","C(i,j)=\frac{D_{src}(i)^{\top}D_{tgt}(j)}{\|D_{src}(i)\|\cdot\|D_{tgt}(j)\|}","where $C(i,j)$ represents the cosine similarity between feature descriptors at locations $i$ and $j$"
ICLR_2024_oral_14,9,"L=E_{F_{0},t,Z\simN(0,I),D_{src},D_{tgt}}[\|F_{0}-F_{\theta}(F_{t},t;F_{init },C^{l})\|^{2}]",,"L_{diffusion}=E_{F_{0},Z,t}\left[\left\|\epsilon_{\theta}(F_{t},t;F_{init},C^{l})-Z\right\|^{2}\right]","where $ \epsilon_{\theta}(\cdot) $ is the neural network that predicts the noise $ Z $ added to the ground-truth correspondence field $ F_{0} $ at time step $ t $, given the initial correspondence $ F_{\text{init}} $ and the local matching cost $ C^{l} $ as conditions."
ICLR_2024_oral_15,1,"\nabla_{\Theta}L_{SDS}=E_{t,p,\epsilon}[w(t)(\epsilon_{\phi}(I_{RGB}^{p};t,\tilde{I}_{RGB}^{r},\Delta p)-\epsilon)\frac{\partial I_{RGB}^{p}}{\partial\Theta}]","where \(w(t)\) is a weighting function, \(\epsilon_{\phi}(\cdot)\) is the predicted noise by the 2D diffusion prior \(\phi\), and \(\Delta p\) is the relative camera pose change from the reference camera \(r\)","L_{SDS}=E_{t,\epsilon,p}\left[\left\|\nabla_{x}\log p_{\phi}(I_{RGB}^{p}+\sqrt{t}\epsilon\mid t)-\nabla_{x}\log p_{\theta}(I_{RGB}^{p}+\sqrt{t}\epsilon\mid t)\right\|^{2}\right]",The SDS loss minimizes the difference between score gradients of the diffusion prior and the generated image with respect to injected noise.
ICLR_2024_oral_15,2,L_{Ref}=\lambda_{RGB} || I_{RGB}^{r}-\tilde{I}_ {RGB}^{r} || _{2}^{2}+\lambda_{A} || I_{A}^{r}-\tilde{I}_{A}^{r} || _{2}^{2},where \(\lambda_{\text{RGB}}\) and \(\lambda_{\text{A}}\) are the weights which are linearly increased during training,L_{img}=\left\|I_{RGB}^{r}-\tilde{I}_{RGB}^{r}\right\|_{2}+\lambda_{A}\left\|I_{A}^{r}-\tilde{I}_{A}^{r}\right\|_{1},"Additionally, we optimize the reference view image and transparency to align with the input by minimizing the L2 loss between rendered and input images, and the L1 loss between rendered and input transparency."
ICLR_2024_oral_15,3,"\nabla_{\Theta}L_{SDS}=E_{t,p,\epsilon}[w(t)(\epsilon_{\phi}(I_{RGB}^{p};t,e)-\epsilon)\frac{\partial I_{RGB }^{p}}{\partial\Theta}]",where \(e\) is the CLIP embeddings of the input text description,"\nabla_{\Theta}L_{SDS}=E_{t,p,\epsilon}[w(t)(\epsilon_{\phi}(I_{RGB}^{p};t,\tilde{I}_{RGB}^{r},\Delta p)-\epsilon)\frac{\partial I_{RGB}^{p}}{\partial\Theta}]","where $ \epsilon_{\phi}(\cdot) $ is the predicted noise by the 2D diffusion prior $ \phi $, $ w(t) $ is a weighting function, and $ \Delta p $ is the relative camera pose change from the reference camera $ r $"
ICLR_2024_oral_15,4,d(x)=\sum_{i}\alpha_{i}\exp(-\frac{1}{2}(x-x_{i})^ {T}\Sigma_{i}^{-1}(x-x_{i})),where \(\Sigma_{i}\) is the covariance matrix built from scaling \(\mathbf{s}_{i}\) and rotation \(\mathbf{q}_{i}\),\sigma(x)=\sum_{i}\alpha_i\exp\left(-\frac{1}{2} (x-x_i)^TQ_idiag(s_i)^{-2}Q_i^T (x-x_i)\right),"where $\alpha_i$ is the opacity and $\mathbf{x}_i$, $\mathbf{s}_i$, $\mathbf{q}_i$ are the position, scaling, and rotation of the $i$-th Gaussian"
ICLR_2024_oral_15,5,"I^{p}_{fine}=f_{\phi}(I^{p}_{coarse}+\epsilon(t_{start}) ;t_{start},c)","where \(\epsilon(t_{\text{start}})\) is a random noise at timestep \(t_{\text{start}}\), \(c\) is \(\Delta p\) for image-to-3D and \(e\) for text-to-3D respectively",I^{p}_{refined}=f_{\phi}(I^{p}_{coarse}+noise),
ICLR_2024_oral_15,6,L_{MSE}= || I^{p}_{fine}-I^{p}_{coarse} || ^{2}_{2},,L_{MSE}=\lambda_{MSE} || I^{p}_{fine}-I^{p}_{coarse} || _{2}^{2},where $\lambda_{\text{MSE}}$ is the weight for the pixel-wise MSE loss used to refine the texture image
ICLR_2024_oral_16,1,"H(x_{t})=\{{cc}\max\{H(\hat{x}_{t}),R_{t}(s_{t},a_{t })\},&if\ || \hat{x}_{t}-x_{t} || _{2}<\delta\\R_{t}(s_{t},a_{t}),&otherwise\","where \(R_{t}(s_{t},\mathbf{a_{t}})\) is the return of a given \((s_{t},\mathbf{a_{t}})\); \(\delta\) is a threshold value of state-embedding difference; and \(\hat{x}_{t}=f_{\phi}(\hat{s}_{t})\) is \(x_{t}=f_{\phi}(s_{t})\)'s nearest neighbor in \(\mathcal{D}_{E}\)","H(x_t)\leftarrow\max\left(H(x_t), G_t\right)","Updates the highest return $H(x_t)$ in the episodic buffer $\mathcal{D}_{E}$ to the maximum of its current value and the observed return $G_t$, following Lin et al. (2018)."
ICLR_2024_oral_16,2,"Q_{EC}(f_{\phi}(s_{t}),a_{t})=r_{t}(s_{t},a_{t})+\gamma H(f_{\phi}(s_ {t+1}))",,"Q_{EC}(f_{\phi}(s_{t}),a_{t})=R_{t}(s_{t},a_{t})+\gamma\cdot\max_{a} H(f_{\phi}(s_{t+1}))",where $\gamma$ is the discount factor and $H(f_{\phi}(s_{t+1}))$ represents the highest return of the next state's embedding.
ICLR_2024_oral_16,3,"L_{\theta}^{EC}=(y(s,a)-Q_{tot}(s,a;\theta))^{2}+\lambda(Q_{EC}(f_{\phi}(s),a)-Q_{tot}(s,a;\theta))^{2}","where \(y(s,\mathbf{a})\) is one-step TD target; \(Q_{tot}\) is the joint Q-value function parameterized by \(\theta\); and \(\lambda\) is a scale factor","L_{\theta}^{EC}=E_{t}\left[\left(Q_{EC}(f_{\phi}(s_{t}),a_{t})-Q_{\theta}(s_{t},a_{t})\right)^2+\lambda\left(R_{t}(s_{t},a_{t})-Q_{\theta}(s_{t},a_{t})\right)^2\right]","Here, $\lambda$ is a hyperparameter that balances the contribution of the one-step TD error and the Monte Carlo inference error in the loss function."
ICLR_2024_oral_16,4,"L(\phi,\psi)=(H_{t}-f_{\psi}(f_{\phi}(s_{t})))^ {2}",,"\min_{\phi,\psi}E_{s_{t}\simD_{E}}\left[\left(H(f_{\phi}(s_{t}))-f_{\psi}(f_{\phi}(s_{t}))\right)^{2}\right]","where $H(f_{\phi}(s_{t}))$ is the highest return of the embedded state, and $f_{\psi}(f_{\phi}(s_{t}))$ is the predicted return via the decoder structure."
ICLR_2024_oral_16,5,"L(\phi,\psi)=(H_{t}-f_{\psi}^{H}(f_{\phi}(s_{t}|t)|t ))^{2}+\lambda_{rcon} || s_{t}-f_{\psi}^{s}(f_{\phi}(s_{t}|t)|t) || _{2}^{2}",where \(f_{\psi}^{H}\) predicts the highest return; \(f_{\psi}^{s}\) reconstructs \(s_{t}\); \(\lambda_{rcon}\) is a scale factor,"L_{dCAE}(\phi,\psi,\theta)=(H_{t}-f_{\psi}(f_{\phi}(s_{t})))^{2}+\beta || s_{t}-f_{\theta}(f_{\phi}(s_{t}),t) || _{2}^{2}","where the first term ensures accurate prediction of the highest return, the second term reconstructs the state conditioned on the timestep, and $\beta$ is a weighting coefficient balancing the two objectives."
ICLR_2024_oral_16,6,"\eta^{*}(s^{\prime}):=V^{*}(s^{\prime})-\max_{a^{\prime}}\!Q_{\theta^{-}} (s^{\prime},a^{\prime})",,"\eta^{*}(s^{\prime})=V^{*}(s^{\prime})-\max_{a^{\prime}}\!Q_{\theta^{-}}(s^{\prime},a^{\prime})",where $V^{*}(s^{\prime})$ is the optimal value function and $Q_{\theta^{-}}$ is the target network
ICLR_2024_oral_16,7,"r^{p}=\gamma\hat{\eta}(s^{\prime})=\gammaE_{\pi_{\theta}}[\eta(s^{\prime})]\simeq\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}\eta_{\max}(s^{\prime})=\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}(H(f_ {\phi}(s^{\prime}))-\max_{a^{\prime}}\!Q_{\theta^{-}}(s^{\prime},a^{\prime}))",where \(N_{call}(s^{\prime})\) is the number of visits on \(\hat{x}^{\prime}=\mathrm{NN}(f_{\phi}(s^{\prime}))\in\mathcal{D}_{E}\); and \(N_{\xi}\) is the number of desirable transition from \(\hat{x}^{\prime}\),"r^{p}(s,a,s^{\prime})=\gamma\cdot\hat{\eta}(s^{\prime})\cdotI[\xi(s^{\prime})=1]","where $\hat{\eta}(s^{\prime})$ is the estimated advantage of $s^{\prime}$, $\xi(s^{\prime})$ indicates desirability of $s^{\prime}$, and $\mathbb{I}[\cdot]$ is the indicator function."
ICLR_2024_oral_16,8,"L_{\theta}^{p}=(r(s,a)+r^{p}+\gamma\!\max_{a^{\prime}}\!Q_{\theta^{-} }(s^{\prime},a^{\prime})-Q_{\theta}(s,a))^{2}",,"L_{\theta}^{EI}=(y(s,a)+r^{p}(s,a,s^{\prime})-Q_{tot}(s,a;\theta))^{2}","where $L_{\theta}^{EI}$ denotes the loss function incorporating episodic incentive $r^{p}$ as an alternative transition reward in place of $r^{EC}$, aligning with the gradient signal while promoting desirable transitions and avoiding local convergence."
ICLR_2024_oral_16,9,"\nabla_{\theta}L_{\theta}^{p}=-2\nabla_{\theta}Q_{\theta}(s,a)(\Delta\varepsilon _{TD}+r^{p})=-2\nabla_{\theta}Q_{\theta}(s,a)(\Delta\varepsilon_{TD}+\gamma\frac{N_{\xi}(s^{\prime})}{N_{call}(s^{\prime})}\eta_{\max}(s^{\prime}))",,"\nabla_{\theta}L_{\theta}^{p}=2\left(r(s,a)+r^{p}+\gamma\!\max_{a^{\prime}}\!Q_{\theta^{-}}(s^{\prime},a^{\prime})-Q_{\theta}(s,a)\right)\nabla_{\theta}Q_{\theta}(s,a)","where the gradient signal is derived from the episodic incentive-augmented TD loss, encouraging policy updates that favor transitions leading to desirable states with high estimated returns."
ICLR_2024_oral_16,10,"L_{\theta}^{p}=(r(s,a)+r^{p}+\beta_{c}r^{c}+\gamma max_{a^{\prime}}Q_{tot}(s^{\prime},a^{\prime};\theta^{-})-Q_{tot}(s,a;\theta))^{2}",where \(\beta_{c}\) is a scale factor,"L_{\theta}^{final}=L_{\theta}^{p}+\lambda_{c}(Q_{c}(s,a)-Q_{tot}(s,a;\theta))^{2}","where $L_{\theta}^{p}$ is the loss with episodic incentive, $Q_{c}(s,\mathbf{a})$ is the intrinsic reward module, and $\lambda_{c}$ is a scaling factor for the intrinsic reward loss."
ICLR_2024_oral_21,1,"g(G)=\operatorname*{arg\,max}_{c\in\{1,2,\cdots,C\}}N_{c}",where a label with a smaller index is taken by our ensemble classifier when there are ties,"g(G)=\arg\max_{c\in\{1,2,\cdots,C\}} N_c",The ensemble graph classifier $g$ predicts the class $c$ that has the highest count $N_c$ among the predictions of the base classifier $f$ on the sub-graphs of $G$.
ICLR_2024_oral_21,2,"N_{c}-M\leq N_{c}^{p}\leq N_{c}+M,\,\forall c\in\{1,2,\cdots,C\}",,N_{l}^{p}\geq N_{l}-M,The number of sub-graphs predicted as the true class $l$ in the perturbed graph $G^p$ is at least the number of such sub-graphs in the original graph $G$ minus the number of corrupted sub-graphs $M$.
ICLR_2024_oral_21,3,"M\leq M^{p}=\lfloor\frac{N_{l}-\max_{c\in\{1,2,\cdots,C\}\setminus\{l\}}(N_{c }-I(l<c))}{2}\rfloor",,"g(G^{p})=l\,if\,N_{l}-M>\max_{c\in\{1,2,\cdots,C\}\setminus\{l\}}(N_{c}+M-I(l<c))",Condition under which the ensemble graph classifier $g$ predicts the same label $l$ for the perturbed graph $G^{p}$ based on the number of corrupted sub-graphs $M$.
ICLR_2024_oral_23,1,"p_{\sigma}(y)=\int p(y|x)\,p(x)\,dx=\int g_{\sigma}(y-x)\,p(x)\,dx",where \(g_{\sigma}(z)\) is the density of \(z\),"p_{\sigma}(y)=\int p(x)N(y; x,\sigma^2Id)\, dx",Density of noisy images obtained by marginalizing over the original image distribution and the noise distribution.
ICLR_2024_oral_23,2,"D_{KL}(p(x)\,\|\,p_{\theta}(x))\leq\int_{0}^{\infty}E_{y}\big{[}\|\nabla\log p_{\sigma}(y)-s_{\theta}(y)\|^{2}\big{]}\,\sigma\, d\sigma",,KL\left(p(x)\|p_{\theta}(x)\right)=\frac{1}{2}\int_{0}^{\infty}E_{p_{\sigma}(y)}\left[\left\Vert s_{\theta}(y)-\nabla\log p_{\sigma}(y)\right\Vert^{2}\right]d\sigma,The KL divergence between the true data distribution and the model distribution is expressed as an integral of the expected squared error between the learned scores and the true scores across all noise levels.
ICLR_2024_oral_23,3,"\nabla\log p_{\sigma}(y)=(\mathop{E}_{x}[x\,|\,y]-y)/\sigma^{2}",,\nabla\log p_{\sigma}(y)=\frac{1}{\sigma^{2}}\left(E[x|y]-y\right),This equation expresses the score function in terms of the posterior mean of the clean image given the noisy observation.
ICLR_2024_oral_23,4,"MSE(f_{\theta},\sigma^{2})=\mathop{E}_{x,y}\Bigl{[}\|x-f_{\theta}(y)\|^{2}\Bigr{]}",,"E_{x,z}\left[\left\|x-f_{\theta}(y)\right\|^{2}\right]",where the expectation is taken over the clean data $x$ and the noise $z$.
ICLR_2024_oral_23,5,"D_{KL}(p(x)\ || \,p_{\theta}(x))\leq\int_{0}^{\infty}\Bigl{(} MSE(f_{\theta},\sigma^{2})-MSE(f^{\star},\sigma^{2})\Bigr{)}\,\sigma^{-3}\,d\sigma","where \(f^{\star}(y)=\mathop{\mathbb{E}}_{x}[x\,|\,y]\) is the optimal denoiser","D_{KL}(p(x)\,\|\,p_{\theta}(x))\leq\int_{0}^{\infty}\Bigl{(}\mathop{E}_{x,y}\bigl{[}\|x-f_{\theta}(y)\|^{2}\bigr{]}-MMSE(\sigma^{ 2})\Bigr{)}\,\frac{1}{\sigma^{2}}\,d\sigma",This equation bounds the KL divergence between the true data density and the model density in terms of the integrated gap between the denoiser's MSE and the optimal MMSE across noise levels.
ICLR_2024_oral_23,6,"f(y)=\nabla f(y)\,y=\sum_{k}\lambda_{k}(y)\langle y,e_{k}(y)\rangle e_{ k}(y)",,"f(y)=\sum_{k=1}^{d}\lambda_{k}(y)\,\langle e_{k}(y),y\rangle\,e_{k}(y)",
ICLR_2024_oral_23,7,"MSE(f,\sigma^{2})=\mathop{E}_{y}\![2\sigma^{2}\, tr\,\nabla f(y)+\|y-f(y)\|^{2}-\sigma^{2}d]",,"MSE(f_{\theta},\sigma^{2})=\mathop{E}_{y}\Bigl{[}\|x-f_{\theta}(y)\|^{2}\Bigr{]}=\mathop{E}_{y}\Bigl{[}\|y-f_{\theta}(y)\|^{2}+2\sigma^{2}\nabla\cdot f_{\theta}(y)-d\sigma^{2}\Bigr{]}","where the divergence term $\nabla\cdot f_{\theta}(y)$ captures the sensitivity of the denoiser to input perturbations, and $d$ is the dimensionality of the data."
ICLR_2024_oral_23,8,"f^{\star}(y)=y+\sigma^{2}\nabla\log p_{\sigma}(y)=\operatorname*{E}_{ x}[x|y] || \nabla f^{\star}(y)=Id+\sigma^{2}\nabla^{2}\log p_{\sigma}(y)=\sigma^ {-2}Cov[x\,|\,y]",,"f^{\star}(y)=\mathop{E}_{x}[x\,|\,y],\quad\nabla f^{\star}(y)=\frac{1}{\sigma^{2}}\mathop{Cov}_{x}[x\,|\,y]+Id","where the Jacobian of the optimal denoiser incorporates the posterior covariance and identity matrix, reflecting the local geometry of the posterior distribution $p(x|y)$."
ICLR_2024_oral_23,9,"MSE(f^{\star},\sigma^{2})=\operatorname*{E}_{y}[tr \,Cov[x\,|\,y]]=\sigma^{2}\operatorname*{E}_{y}\bigl{[}tr\,\nabla f^{\star}(y)\bigr{]}=\sigma^{2}\operatorname*{E} _{y}\biggl{[}\sum_{k}\lambda_{k}^{\star}(y)\biggr{]}",,"MSE(f^{\star},\sigma^{2})=\mathop{E}_{y}\bigl{[}\|\nabla f^{\star}(y)\|_{F}^{2}\,\sigma^{4}-\sigma^{2}d\bigr{]}","The optimal denoising error is expressed in terms of the Frobenius norm of the Jacobian of the optimal denoiser, scaled by the noise level, minus a term proportional to the dimensionality."
ICLR_2024_oral_23,10,"\operatorname*{E}_{x}\biggl{[}\sum_{k}\Bigl{(}(1-\lambda_{k}(x))^{2}\langle x,e_{k}\rangle^{2}+\lambda_{k}(x)^{2}\sigma^{2}\Bigr{)}\biggr{]}",,"MSE_{oracle}=\sum_{k=1}^{d}\min(\sigma^{2},E_{x}[x_{k}^{2}])",This represents the minimum possible denoising error when shrinkage factors are chosen with knowledge of the clean image $x$ in a fixed basis.
ICLR_2024_oral_23,11,"\sigma^{2}{\sum_{k}\lambda_{k}(x)}=\sum_{k}\frac{\sigma^{2}\langle x,e_{k}\rangle^{2}}{\langle x,e_{k}\rangle^{2}+\sigma^{2}}\sim\sum_{k}\min(\langle x,e_{k}\rangle^{2},\sigma^{2})=M\sigma^{2}+\|x-x_{M}\|^{2}","where \(x_{M}=\sum_{\langle x,e_{k}\rangle^{2}>\sigma^{2}}\langle x,e_{k}\rangle\,e_{k}\) is the \(M\)-term approximation of \(x\) with the \(M\) basis coefficients \(\langle x,e_{k}\rangle\) above the noise level, and \(\sim\) means that the two terms are of the same order up to multiplicative constants (here smaller than 2)","\sum_{k}\frac{\langle x,e_{k}\rangle^{2}\sigma^{2}}{\langle x,e_{k}\rangle^{2}+\sigma^{2}}","This expression quantifies the minimum achievable denoising error in a fixed basis, where shrinkage factors depend on the clean image $x$ and the noise level $\sigma^2$."
ICLR_2024_oral_23,12,M\sigma^{2}+\|x-x_{M}\|^{2}\sim\sigma^{2\alpha/(\alpha+1)},,"\|x-x_{M}\|^{2}\sim\int_{M}^{\infty}k^{-(\alpha+1)}\,dk\sim M^{-\alpha}",The approximation error decays as $M^{-\alpha}$ when the basis coefficients of $x$ decay as $k^{-(\alpha+1)}$.
ICLR_2024_oral_24,1,dx_{t}=f_{t}(x_{t})dt+g(t)d w_{t}\quadx_{0}\sim p_{data}(x),,"dx=-\frac{\beta(t)}{2}x\,dt+\sqrt{\beta(t)}\,dw","The stochastic differential equation governing the diffusion process in Diffusion Models, where Î²(t) is the time-dependent diffusion coefficient and w represents Brownian motion."
ICLR_2024_oral_24,2,"dx_{t}=[f_{t}(x_{t})-g_{t}^{2}\nabla_{ x}\log p(x_{t},t)]dt+g(t)dw_{t},\quadx_{1}\simN(0,I_{d})","where \(p(\cdot,t)\) is the marginal density of (1) at time \(t\) and \(\nabla_{\mathbf{x}}\log p_{t}\) is known as the score function",dx_{t}=\left[-f_{t}(x_{t})+g(t)^{2}\nabla_{x_{t}}\log p_{t}(x_{t})\right]dt+g(t)dw_{t},"The time-reversed SDE derived from Equation 1, where the drift term incorporates both the negative original drift and a score function term $"
ICLR_2024_oral_24,3,"dx_{t}=[f_{t}(x_{t})-\frac{1}{2}g_{t}^{2}\nabla_{x}\log p(x_{t},t)]dt,\quad x_{1}\simN(0,I_{d})",,"\frac{dx_{t}}{dt}=f_{t}(x_{t})-g_{t}^{2}\nabla_{x}\log p(x_{t},t)","Ordinary Differential Equation (ODE) formulation corresponding to the time-reversed SDE (2), sharing the same path-wise measure for generative modeling."
ICLR_2024_oral_24,4,"dx_{t}=v_{t}(x,t)dt+g_{t}dw_{t}\quad s.t.\quad(x_{0},x_{1})\sim\Pi_{0,1}(x_ {0},x_{1}):=p_{0}\times p_{1}",,dx_{t}=\mu_{t}(x_{t})dt+\sigma_{t}(x_{t})dw_{t},"where $\mu_{t}(\cdot)$ and $\sigma_{t}(\cdot)$ denote the drift and diffusion coefficients of the mimicking process, respectively, which are learned to match the conditional dynamics of the reference bridge distribution."
ICLR_2024_oral_24,5,"\min_{a_{t}}\int_{\tau}^{1}\lVerta_{t}\rVert_{2}^{2}dt+(m_{1}-m_{1})^{T} R(m_{1}-m_{1})& s.t\underbrace{dx_{t}\\dv_{t}}_{dm_{t}}&=v_{t}\\a_{t}(x_{t},v_{t},t)dt+\underbrace{0&0\\0&g_{t}}_{g_{t}}dw_{t},\\m_{\tau}:=x_{\tau}\\v_{\tau}&=x_{\tau}\\v_{\tau},&R=r&0\\0&r\otimesI_{d},&x_{1}\sim p_{data}",,"\min_{v_{t}}E\left[\int_{0}^{1}\frac{1}{2\sigma_{t}^{2}}\|v_{t}(x_{t},t)\|^{2}dt\right]\quads.t.\quaddx_{t}=v_{t}dt+\sigma_{t}dw_{t},\quad(x_{0},x_{1})\sim\Pi_{0,1}",The stochastic bridge problem in phase space minimizes the expected kinetic energy of the drift subject to boundary conditions and stochastic dynamics.
ICLR_2024_oral_24,6,"a^{*}(m_{t},t)=g_{t}^{2}P_{11}(\frac{x_{1}-x_{t}}{1-t}-v_{t})\quadwhere:\quad P_{11}=\frac{-4}{g_{t}^{2}(t-1)}",,"dx_{t}\\v_{t}=v_{t}\\-\frac{2}{1-t}v_{t}-\frac{1}{(1-t)^{2}}x_{t}+\frac{1}{1-t}x_{1}dt+0\\g_{t}dw_{t},\quadx_{1}\sim p_{data}(x),\quadx_{t_{i}}=x_{i}","The Phase Space Brownian Bridge formulation describes the dynamics of position and velocity in the proposed Acceleration Generative Model, where the system is driven towards a linear interpolation between the current state and the target data point."
ICLR_2024_oral_24,7,"dx_{t}\\dv_{t}=v_{t}\\F_{t}dt+0&0\\0&h_{t}dw_{t}\quads.t\quadm_{0}:=x_{0}\\v_{0}\simN(\mu_{0},\Sigma_{0}) || Bridge Matching SDE:F_{t}:=F_{t}^{b}(m_{t},t)\equiva_{t}^{*}(m_{t},t), h(t):=g(t) || Probabilistic ODE:F_{t}:=F_{t}^{p}(m_{t},t)\equiva_{t}^{*}(m_{t},t)-\frac{1}{2}g_{t}^{2 }\nabla_{v}\log p(m,t), h(t):=0",,"a^{\theta}(m_{t},t)=g_{t}^{2}P_{11}\left(\frac{x_{1}-x_{t}}{1-t}-v_{t}\right)+g_{t}^{2}\nabla_{v}\log p(m_{t},t)","The acceleration term in the SDE and ODE formulation, combining the optimal control from Proposition 3 with the score function of the velocity."
ICLR_2024_oral_24,8,"m_{t}=\mu_{t}+L_{t}\epsilon=\mu_{t}+L_{t}^{xx}\epsilon_{0}\\L_{t}^{xv}\epsilon_{0}+L_{t}^{vv}\epsilon_{1},\nabla_{v}\log p_{t}:=-\ell_{t}\epsilon_{1}","where \(\boldsymbol{\Sigma}_{t}=\mathbf{L}_{t}\mathbf{L}_{t}^{\mathsf{T}}\), \(\epsilon=\begin{bmatrix}\boldsymbol{\epsilon}_{0}\\ \boldsymbol{\epsilon}_{1}\end{bmatrix}\sim\mathcal{N}(\mathbf{0},\mathbf{I}_{2d})\) and \(\ell_{t}=\sqrt{\frac{\Sigma_{t}^{xx}}{\Sigma_{t}^{xx}\Sigma_{t}^{xx}-(\Sigma _{t}^{xx})^{2}}}\)","m_{t}=\mu_{t}+\Sigma_{t}^{1/2}\epsilon,\quad\epsilon\simN(0,I_{2d})","Reparameterization of the intermediate state $\mathbf{m}_{t}$ for sampling from the multivariate Gaussian distribution using the mean $\boldsymbol{\mu}_{t}$ and the square root of the covariance matrix $\boldsymbol{\Sigma}_{t}$, with $\boldsymbol{\epsilon}$ being standard normal noise."
ICLR_2024_oral_24,9,"a^{*}(m_{t},t)=4x_{1}(1-t)^{2}-g_{t}^{2}P_{11}[ (\frac{L_{t}^{xx}}{1-t}+L_{t}^{xv})\epsilon_{0}+L_{t}^{vv}\epsilon_{1}]",,"F_{t}^{\theta}(m_{t},t)=a_{t}^{*}(m_{t},t)-\frac{1}{2}g_{t}^{2}\nabla_{v}\log p(m_{t},t)=a_{t}^{*}(m_{t},t)+\frac{1}{2}g_{t}^{2}\ell_{t}\epsilon_{1}",The force term is parameterized as the sum of the optimal control and a score correction term involving the noise coefficient and the scaled Stein score.
ICLR_2024_oral_24,10,"\min_{\theta}E_{t\in[0,1]}E_{x_{1}\sim p_{ data}}E_{m_{t}\sim p_{t}(m_{t}|x_{1})}\lambda(t)[\|F_{t}^{\theta}(m_{t},t;\theta)-F _{t}(m_{t},t)\|_{2}^{2}]",Where \(\lambda(t)\) is known as the reweight of the objective function across the time horizon,"L_{t}^{AGM}=E_{m_{t},t}\left\|s_{t}^{\theta}(m_{t},t;\theta)-\nabla_{v}\log p(m_{t},t)\right\|_{2}^{2}","The loss function $\mathcal{L}_{t}^{\text{AGM}}$ is defined for training the neural network to estimate the force term by minimizing the mean squared error between the predicted score function $\mathbf{s}_{t}^{\theta}$ and the true score $\nabla_{\mathbf{v}}\log p(\mathbf{m}_{t},t)$."
ICLR_2024_oral_24,11,"x_{t_{i+1}}\\v_{t_{i+1}}=\Phi(t_{i+1},t_{i})x _{t}\\v_{t}+\sum_{j=0}^{w}\int_{t_{i}}^{t_{i+1} }(t_{i+1}-\tau)z_{\tau}\cdotM_{i,j}(\tau) d\tau\s_{t}^{\theta}(m_{t_{i-j}},t_{i-j}))\\\int_{t_{i}}^{t_{i+1}}z_{\tau}\cdotM_{i,j}(\tau) d\tau\cdots_{t}^{\theta}(m_{t_{i-j}},t_{i-j})",,x_{t+\delta}\\v_{t+\delta}=x_{t}+\deltav_{t}+\frac{\delta^{2}}{2}F_{t}^{\theta}\\v_{t}+\deltaF_{t}^{\theta}.\quad(Exponential Integrator for AGM-ODE),"Exponential Integrator update rule for AGM-ODE, enabling simultaneous injection of learned force into both position and velocity channels for improved sampling efficiency."
ICLR_2024_oral_24,12,"\tilde{x}_{1}^{SDE}=\frac{(1-t)(F_{t}^{\theta}+v_{t })}{g_{t}^{2}P_{11}}+x_{t}, or \quad\tilde{x}_{1}^{ODE}=\frac{F_{t}^{\theta}+g_{t}^{2}P_{ 11}(\alpha_{t}x_{t}+\beta_{t}v_{t})}{4(t-1)^{2}+g_{t}^{2}P_{ 11}(\alpha_{t}\mu_{t}^{x}+\beta_{t}\mu_{t}^{v})}",,"\tilde{x}_{1}=x_{t}+(1-t)v_{t}+\frac{(1-t)^{2}}{4}F_{t}^{\theta}(m_{t},t)","Sampling-hop provides a closed-form expression to estimate the target data point $\mathbf{x}_1$ using the current state, velocity, and force term during sampling, enabling early estimation and reducing required integration steps."
ICLR_2024_oral_25,1,"\underbrace{\nu(x)>0,\\\forall x\inInterior(M_{o})}_{Case 1: inside the open surface},\quad\underbrace{\nu(x)=0,\\\forall x\in\partialM_{o}}_{Case 2: on the surface boundary},\quad\underbrace{\nu(x)<0,\\Otherwise}_{ Case 3: outside the open surface}",where \(\nu\) can be instantiated as the signed geodesic distance to the open surface boundary living on the watertight template,M_{o}=\{x\inM\mid\nu(x) > 0\},"A continuous and differentiable mapping $\nu:\mathcal{M}\rightarrow\mathbb{R}$ defines the subset of the template sphere $\mathcal{M}$ that corresponds to the open surface $\mathcal{M}_{o}$, where points with $\nu(\mathbf{x}) > 0$ belong to $\mathcal{M}_{o}$."
ICLR_2024_oral_25,2,L_{mSDF-reg}(\theta_{mSDF})=\underbrace{\sum_{u:v_{\theta_{ ndSF}}(u)\geq 0}L_{nuber}(v_{\theta_{noster}}(u))}_{ Encourage hole opening}+\underbrace{\tau\cdot\sum_{{c}u^{\prime}:v_{\theta_{ ndSF}}(u^{\prime})=0\\u^{\prime} visible from some q\in Q}L_{nuber}(v_{\theta_{n ober}}(u^{\prime})-\epsilon)}_{Regularize holes from being too large},,"L_{hole}=\sum_{x\inX}\max(0,-\nu(x))","where the ""hole-opening"" loss penalizes negative mSDF values to encourage the formation of topological holes in the reconstructed mesh."
ICLR_2024_oral_25,3,"u^{\prime}=\frac{|\nu_{1}|}{|\nu_{1}-\nu_{2}|}\cdot u_{2}-\frac{|\nu_{2}|}{|\nu_{1}-\nu_{2}|}\cdot u_{1},\quad\nu_{1}<0<\nu_{2}",,\nu^{\prime}=(s_{i}\nu_{j}-s_{j}\nu_{i})/(s_{i}-s_{j}),"Interpolated mSDF value $\nu^{\prime}$ computed from SDF values $s_i, s_j$ and mSDF values $\nu_i, \nu_j$ at grid vertices along an edge"
ICLR_2024_oral_26,1,E=({cccc}W^{(l)\top}&W^{(2)\top}&W^{(l)\top}&W^{(l)\top}\\\hline\ddots&W^{(2)\top}&W^{(2)\top}&W ^{(l)\top}\\),where \(\mathbf{\mathrm{W}}^{(l)\top}\) denotes the transposed weight matrix,"V=diag(b^{(1)},\dots,b^{(L)}),\quadE=\bigoplus_{l=1}^{L}W^{(l)}","Node features are formed by the biases of each layer, and edge features are formed by the weight matrices connecting nodes across layers."
ICLR_2024_oral_26,2,"V_{probe}=\Big{(}x,\alpha\Big{(}W^{(1)}x+b^{(1)}\Big{)},f(x)\Big{)}^{\top}",,V_{probe}=\alpha\left(W^{(1)}x_{probe}+b^{(1)}\right),Extra node feature corresponding to intermediate activations from probe inputs passed through the neural network.
ICLR_2024_oral_26,3,"e_{ij}^{(k+1)}=\phi_{e}^{(k+1)}\Big{(}\Big{[}v_{i}^{(k)},e_{ij}^{(k)},v_{j}^{(k)}\Big{]}\Big{)}",where \(k\) is the layer index in our network,"E^{(k+1)}=\phi_{e}\left(E^{(k)},V_{i}^{(k)},V_{j}^{(k)}\right)",Updating edge features using a lightweight neural network $\phi_e$ at each layer to improve the model's capacity to capture complex relationships between nodes and edges in the neural graph.
ICLR_2024_oral_26,4,"m_{ij}=\phi_{scale}(e_{ij})\odot\phi_{m}([v_ {i},v_{j}])+\phi_{shift}(e_{ij})",,e_{ij}^{(k+1)}=\phi_{e}^{(k+1)}\Big{(}\gamma\Big{(}v_{i}^{(k)}\Big{)}\odote_{ij}^{(k)}+\beta\Big{(}v_{j}^{(k)}\Big{)}\Big{)},where the FiLM layer applies a multiplicative and additive transformation to the edge features based on the node features
ICLR_2024_oral_26,5,v_{ij}=(W_{scale}^{value}e_{ij} )\odot(W_{n}^{value}v_{j})+ W_{shift}^{value}e_{ij},,"V^{(k+1)}=\phi_{mod}(Q^{(k)},K^{(k)},E^{(k)})\odotV^{(k)}",where the value matrix is modulated by the node features through a learnable function
ICLR_2024_oral_27,1,\sum_{i=1}^{N_{k}}W(A_{i}^{k})=W(\bigcup_{i=1}^{N_{k}}A_{i}^{k})=W(A^{0}),,\sum_{i=1}^{N_{k}} W\left(A_{i}^{k}\right)=W\left(\bigcup_{i=1}^{N_{k}} A_{i}^{k}\right)=W\left(A^{0}\right),"This equation expresses the additive property of white Gaussian noise under partitioning, showing that the sum of noise values over refined sub-pixel regions equals the noise value over the original unpartitioned region."
ICLR_2024_oral_27,2,"(W(A^{k})|W(A^{0})=x)\simN(\bar{\mu},\bar{\Sigma}),\quadwith \bar{\mu}=\frac{x}{N_{k}}u,\bar{\Sigma}=\frac{1}{N_{k}} (I_{N_{k}}-\frac{1}{N_{k}}uu^{\top})","where \(\mathbf{u}=(1,\ldots,1)^{\top}\)","N\left(\frac{x}{N_{k}}1,\\nu_{k}\left(I-\frac{1}{N_{k}}11^{\top}\right)\right)","The conditional distribution of sub-pixel noise values given the total pixel value, characterized by a multivariate Gaussian with mean proportional to the pixel value and a covariance matrix that enforces consistency with the total integral."
ICLR_2024_oral_27,3,"(W(A^{k})|W(A^{0})=x)=\bar{\mu}+UZ=\frac{x}{N_{k}} u+\frac{1}{\sqrt{N_{k}}}(Z-\langle Z\rangleu),\quadwith Z\sim(0,I)",where \(\langle Z\rangle\) is the mean of \(Z\),"W(A^{k})=\bar{\mu}+U\epsilon,\quadwith \epsilon\simN(0,I)",where $\mathbf{U}$ is the scaled covariance matrix and $\boldsymbol{\epsilon}$ is a standard Gaussian noise vector used for reparameterization.
ICLR_2024_oral_27,4,T(W)(A)=\int_{x\in A}\frac{1}{|\nablaT(T^{-1}(x))|^{\frac{1}{2}}}W(T^{-1}(x))\dx,where \(\left|\nabla\mathcal{T}\right|\) is the determinant of the Jacobian of \(\mathcal{T}\),T(W)(A)=W(T^{-1}(A)),where the transported noise $\mathcal{T}(W)$ evaluated on subset $A$ is equal to the original noise $W$ evaluated on the pre-image $\mathcal{T}^{-1}(A)$.
ICLR_2024_oral_27,5,G(p)=\frac{1}{\sqrt{|\Omega_{p}|}}\sum_{A_{s}^{k}\in\Omega_ {p}}W_{k}(A_{s}^{k})\,,T(W)_{p}=\frac{1}{\sqrt{|\nablaT(p)|}}\sum_{A_{i}^{k}\inT^{-1}(p)}W(A_{i}^{k}),"where $|\nabla\mathcal{T}(\mathbf{p})|$ is the determinant of the Jacobian at position $\mathbf{p}$, and the summation aggregates sub-pixel integrals from the pre-image of $\mathbf{p}$ under the inverse deformation."
ICLR_2024_oral_27,6,"z_{i}=\alpha x_{i-1}+(1-\alpha)x_{i},\quad z_{i}\simN(0,\,\sigma_{z }^{2}),\quadwith \sigma_{z}^{2}=\alpha^{2}+(1-\alpha)^{2}",,z_{i}=(1-\alpha)x_{i}+\alpha x_{i+1},which results in a linear interpolation between adjacent samples $x_i$ and $x_{i+1}$
ICLR_2024_oral_27,7,"z_{i}|x_{i},x_{i-1}\simN(\mu_{\infty},\sigma_{\infty}^{2}),\quadwith \{{l}\mu_{\infty}=\alpha x_{i-1}+(1-\alpha)x_{i}\\\sigma_{\infty}^{2}=1-(\alpha^{2}+(1-\alpha)^{2})=1-\sigma_{z}^{2}",,"z\simN(\alpha x_{i-1}+(1-\alpha)x_{i},\,\alpha(1-\alpha))",where $z$ follows a Gaussian distribution conditioned on the neighboring values $x_{i-1}$ and $x_{i}$ with a variance that depends on the interpolation parameter $\alpha$
ICLR_2024_oral_28,1,\lVertA\hat{x}^{\star}-b\rVert_{2}^{2}\leq(1+\epsilon)\lVertAx^{\star}-b\rVert_{2}^{2},,\lVertA\hat{x}^{\star}-b\rVert_2^2\leq\alpha\cdot\lVertAx^{\star}-b\rVert_2^2+\epsilon,"Equation 1 defines the objective of the active linear regression problem in the agnostic learning setting, where the goal is to find an approximate solution $\hat{\mathbf{x}}^{\star}$ such that the $\ell_2$ loss is within a multiplicative factor $\alpha$ and an additive error $\epsilon$ of the optimal loss achieved by $\mathbf{x}^{\star}$."
ICLR_2024_oral_28,2,\tau_{i}=\|u_{i}\|_{2}^{2}=a_{i}^{T}(A^{T} A)^{-1}a_{i}=\max_{x\inR^{d}}(a_{i}^{T}x)^{2}/\|Ax\|_{2}^{2},,\tau_{i}(A)=\lVertu_{i}\rVert_{2}^{2}=\max_{x\inR^{d}\setminus\{0\}}\frac{|a_{i}x|^{2}}{\lVertAx\rVert_{2}^{2}},"The leverage score of the i-th row of A measures the influence of that row in the column space of A, defined either through the squared norm of the corresponding row in an orthogonal basis or through the maximum ratio of the squared inner product with any non-zero vector x over the squared norm of A times x."
ICLR_2024_oral_28,3,\|A\tilde{x}^{*}-b\|_{2}^{2}\leq(1+\epsilon)\|Ax^{*}-b\|_{2}^{2},,\lVertA\tilde{x}^{\star}-b\rVert_{2}^{2}\leq(1+\epsilon)\lVertAx^{\star}-b\rVert_{2}^{2},"This equation states the main guarantee of our pivotal sampling method, showing that the learned parameters $\tilde{\mathbf{x}}^{\star}$ achieve a $(1+\epsilon)$-approximation to the optimal regression error, matching the bound in Equation 1 but under a spatially-aware sampling strategy that improves practical performance."
ICLR_2024_oral_28,4,\|\tilde{p}-b\|_{2}^{2}\leq(1+\epsilon)\underset{degree d polynomial p}{\min}\|p-b\|_{2}^{2},,\|\tilde{p}-b\|_{2}^{2}\leq(1+\epsilon)\min_{p:\deg(p)=d}\|p-b\|_{2}^{2},"Equation 4 represents the error bound for polynomial regression using pivotal sampling, showing that the constructed polynomial $\tilde{p}$ approximates the target function $b$ within a $(1+\epsilon)$ factor of the best degree $d$ polynomial fit, with a sample complexity improved by a logarithmic factor compared to independent leverage score sampling."
ICLR_2024_oral_28,5,"I_{\mu}^{S}(i,j)=\Pr_{\mu}[\xi_{j}=1|\xi_{i}=1\wedge\xi_{\ell}=1\forall\ell\inS]-\Pr_{\mu}[\xi_{j}=1|\xi_{\ell}=1\forall\ell\inS]",,"I_{\mu}^{S}(i,j)=\max_{\substack{T\subseteq[n]\backslash(S\cup\{i,j\})\\T is finite}}\left|\Pr_{\mu}[\xi_{j}=1|\xi_{i}=1,\xi_{T}=1]-\Pr_{\mu}[\xi_{j}=1|\xi_{i}=0,\xi_{T}=1]\right|",
ICLR_2024_oral_29,1,"\frac{dx}{d\sigma}=-\sigma\nabla_{x}\log p _{\sigma}(x)\quad\sigma\in[\sigma_{min},\sigma_{max}]",where the term \(\nabla_{\mathbf{x}}\log p_{\sigma}(\mathbf{x})\) is known as the _score function_ of \(p_{\sigma}(\mathbf{x})\)(Song et al,"\frac{dx}{dt}=f(x, t)","where $\mathbf{f}(\mathbf{x}, t)$ represents the drift function that governs the evolution of the data variable $\mathbf{x}$ over time $t$ according to the probability flow ordinary differential equation."
ICLR_2024_oral_29,2,"f_{\theta}(x,\sigma)=c_{skip}(\sigma)x+c_{out}(\sigma)F_{\theta}(x,\sigma)","where \(\mathbf{F}_{\mathbf{\theta}}(\mathbf{x},\sigma)\) is a free-form neural network, while \(c_{\text{skip}}(\sigma)\) and \(c_{\text{out}}(\sigma)\) are differentiable functions such that \(c_{\text{skip}}(\sigma_{\text{min}})=1\) and \(c_{\text{out}}(\sigma_{\text{min}})=0\)","f_{\theta}(x,\sigma)=x+\sigmau_{\theta}(x,\sigma)","where $\mathbf{u}_{\mathbf{\theta}}(\mathbf{x},\sigma)$ is a neural network that ensures the boundary condition $\mathbf{f}_{\mathbf{\theta}}(\mathbf{x},\sigma_{\text{min}})=\mathbf{x}$ is satisfied."
ICLR_2024_oral_29,3,"L^{N}(\theta,\theta^{-})=E[\lambda(\sigma_{i} )d(f_{\theta}(x_{\sigma_{i+1}},\sigma_{i+1}),f_{\theta}_{-}(\tilde{x}_{\sigma_{i}},\sigma_{i}))]",where \(\tilde{\mathbf{x}}_{\sigma_{i}}=\mathbf{x}_{\sigma_{i+1}}-(\sigma_{i}-\sigma_{ i+1})\sigma_{i+1}\nabla_{\mathbf{x}}\log p_{\sigma_{i+1}}(\mathbf{x})|_{\mathbf{x}= \mathbf{x}_{\sigma_{i+1}}}\),"L_{CM}(\theta)=E_{\sigma_{i},\sigma_{j},x_{\sigma_{i}}}\left[\left\Vertf_{\theta}(x_{\sigma_{j}},\sigma_{j})-f_{\theta}(x_{\sigma_{i}},\sigma_{i})\right\Vert ^{2}\right]","where the expectation is taken over pairs of noise levels $\sigma_i, \sigma_j$ and samples $\mathbf{x}_{\sigma_i} \sim p_{\sigma_i}(\mathbf{x})$, enforcing consistency between model predictions across different noise levels."
ICLR_2024_oral_29,4,\theta^{-}arrowstopgrad(\mu\theta^{-}+(1-\mu)\theta),,\theta^{-}=\alpha\theta^{-}+(1-\alpha)\theta,where $\alpha$ is a smoothing factor that controls the update rate of the teacher network parameters $\mathbf{\theta}^{-}$ based on the student network parameters $\mathbf{\theta}$.
ICLR_2024_oral_29,5,"L_{CT}^{N}(\theta,\theta^{-})=E[\lambda(\sigma_{i})d(f_{\theta}(x+\sigma_{i+1}z,\sigma_ {i+1}),f_{\theta^{-}}(x+\sigma_{i}z,\sigma_{i}))]",,\tilde{x}_{\sigma_{i}}=x+\sigma_{i}z,"where $\mathbf{x} \sim p_{\text{data}}(\mathbf{x})$ and $\mathbf{z} \sim \mathcal{N}(\mathbf{0}, \mathbf{I})$, used in the consistency training objective as an approximation derived from shared random variables."
ICLR_2024_oral_29,6,"\lim_{N\to\infty}L^{N}(\theta,\theta^{-})=\lim_{N\to\infty}L^{N}_{CT}(\theta,\theta^{-})=E\Big{[}\big{(} 1-\frac{\sigma_{min}}{\sigma_{i}}\big{)}^{2}(\theta-\theta^{-})^{2}\Big{]}\quadif\theta^{-}\neq\theta || \lim_{N\to\infty}\frac{1}{\Delta\sigma}\frac{d L^{N}(\theta,\theta^{-})}{d\theta}=\{{ll}\frac{dL}{d\theta}E\Big{[}\frac{\sigma_ {min}}{\sigma_{i}^{2}}\Big{(}1-\frac{\sigma_{min}}{\sigma_{i}}\Big{)}(\theta-\xi)^{2}\Big{]},&\theta^{-}=\theta\\+\infty,&\theta^{-}\prec\theta\\-\infty,&\theta^{-}>\theta",,"\lim_{N\to\infty}L^{N}(\theta,\theta^{-})=E_{z}\left[\left(\frac{\sigma_{data}}{\sigma_{max}}\sigma_{max}z+\left(1-\frac{\sigma_{data}}{\sigma_{max}}\right)\theta-\left(\frac{\sigma_{data}}{\sigma_{max}}\sigma_{max}z+\left(1-\frac{\sigma_{data}}{\sigma_{max}}\right)\theta^{-}\right)\right)^{2}\right]",
ICLR_2024_oral_29,7,"d(x,y)=\sqrt{\lVertx-y\rVert_{2}^{2}+c^{2}}-c",,"d_{c}(x,y)=\sqrt{\|x-y\|_{2}^{2}+c^{2}}-c",which smoothly interpolates between the $\ell_1$ and $\ell_2$ metrics depending on the value of the parameter $c > 0$.
ICLR_2024_oral_29,8,"N(k)=\min(s_{0}2^{\lfloor\frac{1}{N}\rfloor},s_{1})+1,\quad K^{\prime}=\Big{|}\frac{K}{\log_{2}[s_{1}/s_{0}]+1}\Big{|}",,"N(k)=\min(s_{0}2^{\frac{k}{K}}|,s_{1})+1","where $s_{0}$ and $s_{1}$ are the initial and maximum number of discretization steps, $k$ is the current training iteration, and $K$ is the total number of training iterations"
ICLR_2024_oral_3,1,"\theta^{*}\in\operatorname*{arg\,min}_{\theta\inR^{d}}f(\theta),\\\where f(\theta)\triangleqE_{X\sim\mu}[F(\theta,X) ]=\sum_{i\inN}\mu_{i}F(\theta,i)",,\min_{x\inX} f(x),"Equation 1 represents the standard form of a stochastic optimization problem, where the objective is to minimize a function $ f(x) $ over the domain $ \mathcal{X} $."
ICLR_2024_oral_3,2,"\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{n+1}),\\\\forall\n\geq 0","where, roughly speaking, \(H(\mathbf{\theta},i)\) contains gradient information \(\nabla_{\mathbf{\theta}}F(\theta,i)\), such that \(\mathbf{\theta}^{*}\) solves \(\mathbf{h}(\mathbf{\theta})\triangleq\mathbb{E}_{X\sim\mathbf{\mu}}[H(\mathbf{\theta},X)]= \sum_{i\in\mathcal{N}}\mu_{i}H(\mathbf{\theta},i)=\mathbf{0}\)","\theta_{n+1}=\theta_{n}-\beta_{n}\nabla_{\theta} F(\theta_{n}, X_{n})",Stochastic approximation update rule for iterative parameter estimation using noisy gradient information.
ICLR_2024_oral_3,3,"K_{ij}[x]\triangleq\frac{P_{ij}(x_{j}/\mu_{j})^{-\alpha}}{\sum_{k\inN}P_{ik}(x_{k}/\mu_{k})^{-\alpha}},\quad\quad\forall\,i,j\in N",,"K[x](i,j)\triangleq\frac{P(i,j)}{1+\alpha(x_{i}-x_{j})_{+}},\\\\forall\i,j\inN","where $\alpha > 0$ is a parameter controlling the strength of self-repellence, and $(\cdot)_+$ denotes the positive part of the expression."
ICLR_2024_oral_3,4,"Draw:\qquad X_{n+1}\simK_{X_{n},\cdot}[x_{n}]",,"\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{n+1}),\quad X_{n+1}\simK[x_{n}](X_{n},\cdot)","Stochastic approximation iteration driven by the Self Repellent Random Walk (SRRW), where the next state $X_{n+1}$ is sampled from the non-linear transition kernel $\mathbf{K}[\mathbf{x}_{n}]$ evaluated at the current empirical distribution $\mathbf{x}_{n}$."
ICLR_2024_oral_3,5,"\quadx_{n+1}=x_{n}+\gamma_{n+1}(\delta_{X_{n+1}}-x_{n}) || \quad\theta_{n+1}=\theta_{n}+\beta_{n+1}H(\theta_{n},X_{ n+1})",,"\theta_{n+1}=\theta_{n}+\beta_{n+1} H(\theta_{n}, X_{n+1})",where the update step follows the standard stochastic approximation framework using the SRRW-driven noise sequence $X_{n+1}$ generated from the non-linear transition kernel $\mathbf{K}[\mathbf{x}_{n}]$.
ICLR_2024_oral_3,6,"\theta_{n}\xrightarrow[n\to\infty]{a.s.}\theta^{*}\quadand\quad(\theta_{n}-\theta^{*})/\sqrt{\beta_{n}}\xrightarrow[n\to\infty]{dist.}N(0,V_{\theta}^{(k)}(\alpha))",,"\sqrt{n}(\theta_{n}-\theta^{*})\overset{d}{\to}N(0,\Sigma_{k}^{(\alpha)})\quadas n\to\infty",Asymptotic normality of the optimization error $\boldsymbol{\theta}_n - \boldsymbol{\theta}^*$ with a covariance matrix $\mathbf{\Sigma}_k^{(\alpha)}$ that depends on the timescale separation $k$ and the self-repellence parameter $\alpha$.
ICLR_2024_oral_3,7,"x_{n}=\frac{\sum_{i=1}^{n}\omega_{i}\theta_{X_{i}}+\omega_{0}x_{0}}{\sum_{i=0}^{n}\omega_{i}},\\where\\\omega_{0}=1,\\and\\\omega_{n}=\frac{\gamma_{n}}{\prod_{i=1}^{n}(1-\gamma_{i})}",,x_{n}=\sum_{k=0}^{n}\gamma_{k+1}\prod_{j=k+2}^{n}(1-\gamma_{j})\delta_{X_{k}},"Weighted empirical measure representation of the SRRW iterate $\mathbf{x}_{n}$, where the step size sequence $\{\gamma_n\}$ governs the influence of past states $X_k$ through a product of decay factors."
ICLR_2024_oral_3,8,"x_{n}\xrightarrow[n\to\infty]{a.s.}\mu,\quadand\quad\gamma_{n}^{-1/2}(x_{n}-\mu)\xrightarrow[n\to\infty]{dist.}N(0,V_{x}(\alpha)) || where\quadV_{x}(\alpha)=\sum_{i=1}^{N-1 }\frac{1}{2\alpha(1+\lambda_{i})+2-\mathds{1}_{\{a=1\}}}\cdot\frac{1+\lambda_ {i}}{1-\lambda_{i}}u_{i}u_{i}^{T}",,"\omega_{n}\approx n^{-a}\, e^{n^{(1-a)}/(1-a)}","Approximation of the weight sequence $\omega_n$ for $a < 1$, showing sub-exponential growth that prioritizes recent visit counts in the weighted empirical measure $\mathbf{x}_n$, enabling faster adaptation to the target distribution $\mathbf{\mu}$."
ICLR_2024_oral_3,9,\tfrac{d}{dt}z(t)=g(z(t))\triangleqH(\theta(t))^{T}\pi[x(t)]\\\pi[x(t)]-x(t)\inR^{D+N},"where matrix \(\mathbf{H}(\boldsymbol{\theta})\triangleq[H(\boldsymbol{\theta},1),\cdot,H( \boldsymbol{\theta},N)]^{T}\in\mathbb{R}^{N\times D}\) for any \(\boldsymbol{\theta}\in\mathbb{R}^{D}\)","\frac{dz(t)}{dt}=h(\theta(t),x(t))\\g(x(t)) ,\quadwhere\quadg(x)\triangleq\sum_{i,j\inN}x_{i}K_{ij}[x]-x","Matrix-vector form of the mean-field ODE governing the coupled dynamics of the optimization iterate $\boldsymbol{\theta}(t)$ and the empirical distribution $\mathbf{x}(t)$, where $\mathbf{g}(\mathbf{x})$ represents the drift of the empirical distribution under the SRRW kernel."
ICLR_2024_oral_3,10,J(\alpha)\!\triangleq\!\nabla g(z^{*})\!=\!\nablah(\theta^{*})&-\alphaH(\theta^{*})^{T}(P^{T}\!+\mathds{I})\\0_{N\!\times\!D}&2\alpha\mu\mathds{1}^{T}\!-\!\alpha\mathds{P}^{T}\!\!-\!(\alpha\!+\!1)\mathds{I}\!\triangleq\!J_{11}&J_{12}(\alpha)\\J_{21}&J_{22}(\alpha),,J(\alpha)\triangleq\frac{\partialg(z)}{\partialz}\Big|_{z=z^{*}}=\nablah(\theta^{*}) &M_{1}(\alpha)\\0 &M_{2}(\alpha),"where the block entries $\mathbf{M}_{1}(\alpha)$ and $\mathbf{M}_{2}(\alpha)$ depend on the self-repellence parameter $\alpha$ and encode the sensitivity of the SRRW stationary distribution $\boldsymbol{\pi}[\mathbf{x}]$ to changes in $\mathbf{x}$, influencing the local dynamics of the coupled mean-field ODE near equilibrium."
ICLR_2024_oral_3,11,"\beta_{n}^{-1/2}(\theta_{n}-\theta^{*} )\\\gamma_{n}^{-1/2}(x_{n}-\mu)\xrightarrow[n\to\infty]{ait.}N(0,V^{(k)}(\alpha))",,"\sqrt{\beta_{n}}\left(\theta_{n}-\theta^{*}\right)\xrightarrow[n\to\infty]{dist.}N\left(0,V_{\theta}^{(k)}(\alpha)\right)","Asymptotic normality of the optimization error $\boldsymbol{\theta}_n - \boldsymbol{\theta}^*$ under different step size regimes, with distinct covariance matrices $\mathbf{V}_{\boldsymbol{\theta}}^{(k)}(\alpha)$ for cases $k = 1, 2, 3$."
ICLR_2024_oral_3,12,U\triangleq\sum_{i=1}^{N-1}\frac{1+\lambda_{i}}{1-\lambda_{i}}\cdotH^{T}u_{i}u_{i}^{T}H&H^{T}u_{i}u_{i}^{T}\\u_{i}u_{i}^{T}H&u_{i}u_{i}^{T}\triangleqU_{11}&U_{12}\\U_{21}&U_{22},,U\triangleqH^{T}diag(\mu)H &0_{D\times N}\\0_{N\times D} &V_{x}(\alpha),Matrix U is a block diagonal matrix combining the Hessian term and the asymptotic covariance of the SRRW empirical measure.
ICLR_2024_oral_3,13,V^{(k)}(\alpha)=V^{(k)}_{\theta }(\alpha)&0_{D\times\!N}\\0_{N\!\times\!D}&V_{x}(\alpha),,V^{(k)}(\alpha)=V_{\theta}^{(k)}(\alpha) &0\\0 &V_{x}(\alpha),"Asymptotic covariance matrix structure for cases (i) and (iii), where the covariance matrices of the optimization iterate $\boldsymbol{\theta}_n$ and the empirical distribution $\mathbf{x}_n$ decouple due to the timescale separation."
ICLR_2024_oral_31,1,P(z;H)=\mathds{1}(H(z)<\bar{H}),where \(\bar{\mathcal{H}}\) is a threshold and \(\mathds{1}(\cdot)\) is indicator function,P(z;H)=1\left\{H(z)\geq\tau\right\},"Static pruning probability function that deterministically retains samples with score $\mathcal{H}(z)$ exceeding threshold $\tau$, where $\mathbb{1}\{\cdot\}$ denotes the indicator function."
ICLR_2024_oral_31,2,P_{t}(z)=P(z;H_{t}),,P_{t}(z;H_{t})=\mathds{1}(H_{t}(z)<\bar{H}_{t}),where $\mathcal{H}_{t}(z)$ is the time-dependent score function at step $t$ and $\bar{\mathcal{H}}_{t}$ is the corresponding time-dependent threshold.
ICLR_2024_oral_31,3,"P_{t}(z)=r,&H_{t}(z)<\bar{H}_{t}\\0,&H_{t}(z)\geq\bar{H}_{t}","where \(\bar{\mathcal{H}}_{t}\) is the mean value of all the scores \(\mathcal{H}_{t}\) and \(r\in(0,1)\) is a predefined hyper-parameter as the pruning probability",P_{t}(z)=\sigma\left(\lambda\left(H_{t}(z)-\bar{H}_{t}\right)\right),"where $\sigma(\cdot)$ is the sigmoid function, $\lambda$ controls the steepness of the pruning probability, $\mathcal{H}_{t}(z)$ is the score of sample $z$ at epoch $t$, and $\bar{\mathcal{H}}_{t}$ is the adaptive threshold at epoch $t$"
ICLR_2024_oral_31,4,"H_{t+1}(z)=H_{t}(z),&z\inD\backslashS_{t}\\L(z),&z\inS_{t}",,"H_{t+1}(z)=H_{t}(z),&z is pruned in t-th epoch\\L_{t}(z),&z is retained in t-th epoch","where $\mathcal{H}_{t+1}(z)$ is updated based on whether the sample $z$ is pruned or retained in the $t$-th epoch, with $\mathcal{L}_{t}(z)$ denoting the loss of sample $z$ in the $t$-th epoch"
ICLR_2024_oral_31,5,"\operatorname*{arg\,min}_{\theta\in\Theta}\mathop{E}_{z\inD }[L(z,\theta)]=\int_{z}L(z,\theta)\rho(z)dz",,E_{z\sim\rho(z)}[\nablaL(z;\theta)]=E_{z\sim\rho(z)}[\nablaL(z;\theta)],representing the expectation of gradient of the loss function with respect to model parameters over the data distribution
ICLR_2024_oral_31,6,"\operatorname*{arg\,min}_{\theta\in\Theta}\mathop{E}_{z\inS _{t}}[\gamma_{t}(z)L(z,\theta)]=\operatorname*{arg\,min}_{\theta\in\Theta}\frac{1}{c_{t}}\int_{z}L(z,\theta)\rho(z)dz","where \(c_{t}=\mathbb{E}_{z\sim\rho}[1-\mathcal{P}_{t}(z)]=\int_{z}\rho(z)(1-\mathcal{ P}_{t}(z))dz\), \(c_{t}\in(0,1)\) is a constant for temporal status \(t\)","\operatorname*{arg\,min}_{\theta\in\Theta}\mathop{E}_{z\inS_{t}}[\gamma_{t}(z)L(z,\theta)]=\int_{z}\gamma_{t}(z)L(z,\theta)(1-P_{t}(z))\rho(z)dz","Rescaled training objective after applying soft pruning and expectation rescaling, showing equivalence to minimizing empirical risk on the original dataset."
ICLR_2024_oral_31,7,\frac{1}{c_{t}}=\frac{|D|}{|\sum_{z\inD}(1-P_{t}( z))|}\simeq\frac{|D|}{|S_{t}|}\RightarrowE[\nabla_{\theta}L(S_{t})]\simeq\frac{|D|}{|S_{t}|}\mathop{E}[\nabla_{\theta}L(D)],,\frac{N_{t}}{N}=1-r,"where $N_{t}$ is the number of samples in $\mathcal{S}_{t}$, and $N$ is the total number of samples in $\mathcal{D}$"
ICLR_2024_oral_31,8,"P_{t}(z)=r,&H_{t}(z)<\tilde{H}_{t}\wedge t<\delta\cdot C\\0,&H_{t}(z)\geq\tilde{H}_{t}\lor t\geq\delta\cdot C",,"S_{t}=SoftPrune(D,H_{t},r),&t\leq\delta\cdot C\\D,&t>\delta\cdot C","where pruning is only applied during the initial $\delta\cdot C$ epochs, and the full dataset is used thereafter to reduce remaining gradient expectation bias"
ICLR_2024_oral_32,1,"sim(I,t)=\langle M_{image}(I),M_{text}(t)\rangle/( || M_{image}(I) || _{2} || M_{text}(t) || _{2})",,"sim(I, t)=\frac{M_{image}(I)^\top M_{text}(t)}{\|M_{image}(I)\|\cdot\|M_{text}(t)\|}",Equation 1 defines the cosine similarity function used in CLIP to measure alignment between image and text embeddings in the shared latent space.
ICLR_2024_oral_32,2,M_{image}(I)=PViT(I),,"tags and provide a one-sentence description. The description should explain that it's the linear projection of the ViT output using matrix P to get the image representation in the joint space. Make sure the LaTeX uses proper notation, like\text for ViT and the subscripts. Also, check if there's any prior equation to reference. Since Equation 1 is the similarity equation, Equation 2 here is the image encoder's projection. No prior equations except Equation 1, which is already given. So the generated equation should be correct. </think>",Linear projection of the ViT output representation to the joint vision-and-language space using matrix $P$.
ICLR_2024_oral_32,3,"\hat{Z}^{l}=MSA^{l}(Z^{l-1})+Z^{l-1},\quad Z^{l}=MLP^{l}(\hat{ Z}^{l})+\hat{Z}^{l}",,"Z^{\ell}=MSA(LN(Z^{\ell-1}))+Z^{\ell-1},\quadfor \ell=1,\dots, L",Update of the image tokens through multi-head self-attention in the ViT architecture.
ICLR_2024_oral_32,4,M_{image}(I)=PViT(I)=P[Z^{0}]_{cls}+\underbrace{\sum_{ l=1}^{L}P[MSA^{l}(Z^{l-1})]_{cls}}_{MSA\terms}+\underbrace{\sum_{l=1}^{L}P[MLP^{l}(\hat{Z}^{l}) ]_{cls}}_{MLP\perms},,M_{image}(I)=P\left( [Z^{0}]_{cls}+\sum_{l=1}^{L}\left(MSA^{l}([Z^{l-1}]_{cls})+MLP^{l}(\hat{Z}^{l}_{cls})\right)\right),"Equation 4 decomposes the ViT output into the cumulative contributions of each layer, showing how the final image representation is built through successive transformations of the class token across all layers."
ICLR_2024_oral_32,5,"[MSA^{l}(Z^{l-1})]_{cls}=\sum_{h=1}^{H}\sum_{i=0}^{N}x_{i} ^{l,h},\\\x_{i}^{l,h}=\alpha_{i}^{l,h}W_{VO}^{l,h}z_{i}^{l-1}","where \(W_{VO}^{l,h}\in\mathbb{R}^{d\times d}\) are transition matrices and \(\alpha_{i}^{l,h}\in\mathbb{R}\) are the attention weights from the class token to the \(i\)-th token (\(\sum_{i=0}^{N}\alpha_{i}^{l,h}=1\))","MSA^{l}(Z^{l-1})=\sum_{h=1}^{H}A_{h}^{l}Z^{l-1}W_{V}^{l,h}+LN(Z^{l-1})W_{O}^{l,h}","Equation 5 decomposes the multi-head self-attention (MSA) output into contributions from individual attention heads and input tokens, enabling fine-grained analysis of their effects on the final image representation."
ICLR_2024_oral_32,6,"\sum_{l=1}^{L}P[MSA^{l}(Z^{l-1})]_{cls}=\sum_{l=1}^{L}\sum_{h=1 }^{H}\sum_{i=0}^{N}c_{i,l,h},\\c_{i,l,h}=Px_{i}^{l,h}",,"M_{image}(I)=P[Z^{0}]_{cls}+\sum_{l=1}^{L}\sum_{h=1}^{H}\sum_{i=0}^{N}P x_{i}^{l,h}+\sum_{l=1}^{L}P[MLP^{l}(\hat{Z}^{l})]_{cls}","This equation decomposes the CLIP image representation into contributions from the initial class token, individual attention heads and input tokens in each MSA layer, and MLP layers."
ICLR_2024_oral_32,7,"V_{explained}(T)=\frac{1}{K}\sum_{k=1}^{K}\| Proj_{T}(c_{k}-c_{avg})\|_{2}^{2}, where c_{avg}=\frac{1}{K}\sum_{k=1}^{K}c_{k}",,"Var_{T}(c)=E_{I}\left[\left\|Proj_{T}(c_{head}^{l,h}(I))\right\|^{2}\right]","Equation 7 defines the variance explained by a set of text directions $\mathcal{T}$, measuring how much of the variation in a head's output is captured by the span of the corresponding text-encoded directions."
ICLR_2024_oral_35,2,"L(P,D)=\frac{A}{P^{\alpha}}+\frac{B}{D^{\beta}}+E\hskip 14.226378pt(3)\hskip 28.452756ptTC\approx 6PD\hskip 14.226378pt(4)\hskip 28.452756ptIC\approx 2PD\hskip 14.226378pt(5)",,L=A P^{-\alpha}+B D^{-\beta}+E\hskip 28.452756pt(3),"Test loss $L$ as a function of parameter count $P$, dataset size $D$, and constants $A$, $B$, $\alpha$, $\beta$, $E$."
ICLR_2024_oral_35,3,eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n }&re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2}&re>n || eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n }&re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2}&re>n,,\eta_{MoE}\approx 0.8\cdot\eta_{dense},MoE LLMs achieve approximately 80% of the optimal hardware efficiency of their dense base models due to additional host-device memory swaps.
ICLR_2024_oral_35,4,energy_{hard}=\sum_{i\in hardware\_set}(P_{i}\cdoteff_{i}\cdot n_{i}\cdot t_{i}) || energy_{oper}=energy_{hard}\cdotPUE,,eff_{re}=\gamma_{0}\cdot\frac{re}{n}\cdoteff_{n}&re<n\\\gamma_{1}\cdot\frac{n}{re}\cdoteff_{n}+\gamma_{2}&re>n,"Hardware efficiency ($\mathit{eff}_{re}$) when using $re$ devices, modeled piecewise with fitting constants $\gamma_0$, $\gamma_1$, $\gamma_2$, peak efficiency $\mathit{eff}_n$, and optimal device count $n$."
ICLR_2024_oral_35,5,CO2eq_{oper}=energy_{oper}\cdot carb\_int,,time_{exec}=\frac{TFLOP}{FLOP_{peak}\cdoteff\cdot n_{dev}}\hskip 14.226378pt(7),"Execution time of a computing device based on FLOP count, peak throughput, hardware efficiency, and device count"
ICLR_2024_oral_35,6,CO2eq_{emb}=\sum_{i\in hardware\_set}\frac{t_{i}\cdotCO2eq_{chip_{i}}}{lifetime_{i}},,CO2eq_{oper}=energy_{oper}\cdot carb\_int,Operational carbon emissions (CO2eq_oper) are calculated by multiplying the total operational energy (energy_oper) with the carbon intensity (carb_int) of the energy source.
ICLR_2024_oral_36,1,"\gamma,\beta=MLP^{mod}(\tilde{c}) || ModLN_{c}(f_{j})=LN(f_{j})\cdot(1+\gamma)+\beta",,ModLN_{c}(f_{j})=f_{j}+f_{j}\cdotW_{scale}(\tilde{c})+b_{shift}(\tilde{c}),Camera feature modulation function that adaptively scales and shifts transformer features using predicted weight and bias terms conditioned on the camera embedding.
ICLR_2024_oral_36,2,f_{j}^{cross}=CrossAttn(ModLN_{c}(f_{j}^{in});\{h_{i}\}_{i=1}^{n})+f_{j}^{in} || f_{j}^{self}=SelfAttn(ModLN_{c}(f_{j}^{cross} );\{ModLN_{c}(f_{j}^{cross})\}_{j})+f_{j}^{cross},,"f_{j}^{out}=MLP^{tfm}\left(SelfAttn\left(CrossAttn\left(ModLN_{c}(f_{j}^{in}),\{h_{i}\}_{i=1}^{n}\right)\right)\right)","Equation 2 describes the transformation of triplane hidden features through a transformer layer, involving camera feature modulation, cross-attention to image features, self-attention, and a multi-layer perceptron."
ICLR_2024_oral_36,3,f_{j}^{out}=MLP^{tfm}(ModLN_{c}(f_{j}^{self}))+f_{j}^{self},,f_{j}^{out}=MLP^{tfm}(ModLN_{c}(f_{j}^{self} ))+f_{j}^{self},"Equation 3 describes the final step in a transformer layer where the triplane hidden features are updated through a multi-layer perceptron sub-layer modulated by camera features, followed by a residual connection."
ICLR_2024_oral_36,4,"L_{recon}(x)=\frac{1}{V}\sum_{v=1}^{V}( L_{MSE}(\hat{x}_{v},x_{v}^{GT})+\lambdaL_{LPIPS}(\hat{x}_{v},x_{v}^{GT}))","where \(\mathcal{L}_{\mathrm{MSE}}\) is the normalized pixel-wise L2 loss, \(\mathcal{L}_{\mathrm{LPIPS}}\) is the perceptual image patch similarity (Zhang et al","L=\sum_{v=1}^{V}\|\hat{x}_v-x_v^{GT}\|_1+\lambda_{ssim} (1-SSIM(\hat{x}_v,x_v^{GT}))",The training loss combines L1 reconstruction error and a structural similarity (SSIM) term across all views to guide the model towards accurate and visually coherent reconstructions.
ICLR_2024_oral_37,1,"z_{t}=z_{0}+\int_{0}^{t}f(z_{s},s)ds","where the hidden state \(z_{t}\in\mathbb{R}^{d}\) evolves with certain dynamics characterized by a neural network \(f:\mathbb{R}^{d}\rightarrow\mathbb{R}^{d}\), \(z_{0}\) is the initial state, and \(s\) represents time in integrals","\frac{dh(t)}{dt}=f(h(t), t,\theta)",Neural ordinary differential equation describing the continuous-time evolution of hidden states with a neural network function $ f $.
ICLR_2024_oral_37,2,"z_{t}=z_{0}+\int_{0}^{t}f(z_{s},s)ds+\int_{0}^{t}g(z_{s},s)dB_{s}","where \(z_{t}\) is a latent state that evolves over time, \(f:\mathbb{R}^{d}\times\mathbb{R}\rightarrow\mathbb{R}^{d}\) is the drift function to capture the evolving dynamics, \(g:\mathbb{R}^{d}\times\mathbb{R}\rightarrow\mathbb{R}^{d\times\omega}\) is the diffusion function to reflect the uncertainties, and \(B_{s}\) is an \(d\)-dimensional Brownian motion (Wiener Process)","dz_{t}=f(z_{t},t)dt+g(z_{t},t)dw_{t}","where $f(z_t, t)$ is the drift term representing deterministic dynamics, $g(z_t, t)$ is the diffusion term modulating the stochastic noise, and $\text{d}w_t$ represents increments of a Wiener process (Brownian motion)."
ICLR_2024_oral_37,3,"\min_{\theta}R_{\nu}(h_{\theta})=\min_{\theta}E_{(z,y)\simD (z_{M+1:M+L},y_{M+1:M+L})}[h_{\theta}(z)\neq y]","where \(\nu\) is the distribution of the stochastic path (Boue & Dupuis, 1998) of \(\mathcal{D}\) along timestamps \(T\) to \(T+T^{*}\), \(z_{M+1:M+L}\) and \(y_{M+1:M+L}\) are short for \(z\) and \(y\) at the timestamps \(\{t_{M+1},\dots,t_{M+L}\}\), \(R_{\nu}\) is the risk of a learning model \(h_{\theta}\) parameterized by parameters \(\theta\)","\min_{\phi,\psi}E_{t\in(T,T+T^{*}],(z,y)\simD(z,y,t)}[\ell(\psi(z),y)]","where $\phi$ is the feature extractor, $\psi$ is the classifier, and $\ell$ is the loss function, aiming to minimize the expected loss over unseen target domains in the path space."
ICLR_2024_oral_37,4,"\hat{z}_{i|m+1}^{k}=\underset{z_{i|m+1}^{k}=\underset{z_{i|m+1}^{k}\in S_{m+1}^{k}}{argmin}}Dist(z_{i|m}^{k},z_{j|m+1}^{k})","where \(\text{Dist}:\mathcal{Z}\times\mathcal{Z}\rightarrow[0,+\infty)\) is a distance metric defined over the embedding space, \(\mathbb{S}_{m+1}^{k}\) be the set of \(N_{B}\) data points sampled from \(\mathcal{D}_{m+1}\) (short for \(\mathcal{D}(z,y|t_{m+1})\)) with class \(y=k\in\{1,",z_{m+1}^{k}=\arg\min_{z'\in S_{m+1}^{k}}\|z_{m}^{k}-z'\|,"where $z_{m}^{k}$ is the datapoint of class $k$ at time $t_{m}$, $S_{m+1}^{k}$ is the set of samples in class $k$ at time $t_{m+1}$, and $\|\cdot\|$ denotes a distance metric (e.g., Euclidean distance) used to establish sample-to-sample correspondence across domains"
ICLR_2024_oral_37,5,"\hat{z}_{i|m+\lambda}=Interp(z_{i|m}^{k},\hat{z}_{i|m+1}^{k},\lambda)=(1-\lambda)z_{i|m}^{k}+\lambda\hat{z}_{i|m+1}^{k},\forall z_{i|m}^{k}\inS_{m}^{k}","where the interpolation rate \(\lambda\in(0,1)\) is sampled from a Beta distribution \(\mathcal{B}(\beta_{1},\beta_{2})\), \(\beta_{1}\) and \(\beta_{2}\) are the parameters of the Beta distribution, and \(\mathbb{S}_{m}^{k}\) consists of instances sampled from \(k\)-th class of \(m\)-th domain","\tilde{z}_{t}^{k}=I(z_{i|m}^{k},\hat{z}_{i|m+1}^{k},t),\quad t\in[t_{m},t_{m+1}]","where $\mathcal{I}:\mathcal{Z}\times\mathcal{Z}\times[t_{m},t_{m+1}]\rightarrow\mathcal{Z}$ is the interpolation function that generates continuous samples along the approximated trajectory between corresponding samples $z_{i|m}^{k}$ and $\hat{z}_{i|m+1}^{k}$ for class $k$ over the time interval $[t_{m},t_{m+1}]$"
ICLR_2024_oral_37,6,"\hat{z}_{m^{\prime}}^{k}=z_{m}^{k}+\int_{t_{m}}^{t_{m^{\prime}}}f_{k}(\hat{z}_ {s}^{k},s)ds+\int_{t_{m}}^{t_{m^{\prime}}}g_{k}(\hat{z}_{s}^{k},s)dB_{s}","where the latent variable \(\hat{z}_{m^{\prime}}^{k}\) is transformed from \(m\)-th domains latent variable \(z_{m}^{k}\), and \(f_{k}\) is the drift function of the \(k\)-th class to capture the evolving patterns, and \(g_{k}\) is the diffusion function of the \(k\)-th class to characterize the stochastics of the latent representations","z_{t_{m^{\prime}}|k}=z_{t_{m}|k}+\int_{t_{m}}^{t_{m^{\prime}}}f_{k}(z_{s},s)ds+\int_{t_{m}}^{t_{m^{\prime}}}g_{k}(z_{s},s)dB_{s}","where $z_{t_{m}|k}$ is the latent representation of class $k$ at time $t_{m}$, $f_{k}:\mathbb{R}^{d}\times\mathbb{R}\rightarrow\mathbb{R}^{d}$ is the class-conditional drift function, and $g_{k}:\mathbb{R}^{d}\times\mathbb{R}\rightarrow\mathbb{R}^{d\times\omega}$ is the class-conditional diffusion function."
ICLR_2024_oral_37,7,J_{mle}=\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_{B}}-\frac{1}{MKN_ {B}}\Big{(}\logD(z=\hat{z}_{i|m+1}^{k}|z=z_{i|m}^{k})+\logD \big{(}z=\hat{z}_{i|m+\lambda}^{k}|z=z_{i|m}^{k}\big{)}\Big{)},,"L_{path}=-\sum_{k=1}^{K}\sum_{m=1}^{M-1}\sum_{z_{i|m}^{k}\inS_{m}^{k}}\log p(\hat{z}_{i|m+\lambda}^{k}|z_{i|m}^{k},\lambda)","where $p(\hat{z}_{i|m+\lambda}^{k}|z_{i|m}^{k},\lambda)$ is the transition probability density of the synthetic interpolated sample $\hat{z}_{i|m+\lambda}^{k}$ given the initial state $z_{i|m}^{k}$ and interpolation rate $\lambda$, induced by the Neural SDE dynamics for class $k$"
ICLR_2024_oral_37,8,"D(y=k|z,t=t_{m})=\frac{D(z|y=k,t=t_{m})\timesD(y=k|t=t_{m})}{\sum_{k^{\prime}=1}^{K}D(z|y=k^{\prime},t=t_{m})\timesD(y=k^{\prime}|t=t_{m})}","where we model \(\mathcal{D}(z|y=k,t=t_{m})\) with non-parametric model, and \(\mathcal{D}(y|t=t_{m})\) as a neural net with input as timestamp \(t\), function denoted as \(r(t)\)","p(y_{m^{\prime}}|x_{m^{\prime}})=\int p(y_{m^{\prime}}|\hat{z}_{m^{\prime}}^{k})p(\hat{z}_{m^{\prime}}^{k}|x_{m^{\prime}},t_{m^{\prime}})d\hat{z}_{m^{\prime}}^{k}","where $p(y_{m^{\prime}}|\hat{z}_{m^{\prime}}^{k})$ is the likelihood of the label given the synthetic latent representation $\hat{z}_{m^{\prime}}^{k}$, and $p(\hat{z}_{m^{\prime}}^{k}|x_{m^{\prime}},t_{m^{\prime}})$ is the posterior distribution of the latent variable conditioned on the input $x_{m^{\prime}}$ and timestamp $t_{m^{\prime}}$"
ICLR_2024_oral_37,9,"D(z|y=k,t=t_{m})=\frac{\sum_{\hat{z}_{i}\in\hat{S}_{m}^{k}}- exp(-Dist(z,\hat{z}_{i}))}{|\hat{S}_{m}^{k}|}",where \(\hat{S}_{m}^{k}\) includes instances sample from learned SDE-EDG belong to \(k\)-th class of \(m\)-th domain,L_{pred}=-\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_{B}}\log\Big{(}\frac{1}{N_{B}}\sum_{j=1}^{N_{B}}\exp\big{(}-\frac{ || z_{i|m}^{k}-z_{j|m}^{k} || ^{2}}{2\sigma^{2}}\big{)}\Big{)},"where $\sigma$ is the bandwidth parameter of the Parzen Window, and the loss approximates the log-likelihood of the latent representation $z_{i|m}^{k}$ under the non-parametric density estimate for class $k$ at timestamp $t_m$"
ICLR_2024_oral_37,10,"J_{cls}=\sum_{m=1}^{M}\sum_{k=1}^{K}\sum_{i=1}^{N_{B}}-\frac{1}{MKN _{B}}\logD(y=k|z=z_{i},t=t_{m})",,"L=-\logD(y|z,t)",where $\mathcal{L}$ is the negative log probability
ICLR_2024_oral_38,1,P_{F}^{\top}(x)\propto\exp(-E(x)),where \(P_{F}^{\top}(x)\) is the distribution of sampling an object \(x\) induced from marginalizing over the trajectories conditioned on \(x=s_{T}\),P_{F}(x)\propto e^{-\betaE(x)},"Equation 1 defines the target Boltzmann distribution over objects $x \in \mathcal{X}$, where $\beta$ is the inverse temperature parameter and $\mathcal{E}(x)$ is the energy function assigned to each object $x$. This distribution represents the desired sampling behavior of the GFlowNet policy $P_F(\cdot|\cdot)$."
ICLR_2024_oral_38,2,"L_{DB}(s,s^{\prime})=(\log F(s)+\log P_{F}(s^{\prime}|s)-\log F(s^{\prime})-\log P_{B}(s|s^{\prime}))^{2}","where the flow \(F(s)\) for the terminal state \(s_{T}=x\) is defined to be identical to the exponent of the negative energy \(\exp\left(-\mathcal{E}(x)\right)\), i","L_{DB}=E_{s\sim\rho, s'\sim P_F(\cdot|s)}\left[\left( F(s) P_F(s'|s)-F(s') P_B(s|s')\right)^2\right]",The detailed balance loss ensures consistency between forward and backward transitions by minimizing the squared difference between the product of flow and policy in both directions.
ICLR_2024_oral_38,3,L_{TB}=(\log Z+\sum_{t=0}^{T-1}\log P_{F}(s_{t+1}|s_{t} )-E(x)-\sum_{t=0}^{T-1}\log P_{B}(s_{t}|s_{t+1}))^{2},,L_{TB}(\tau)=(\log F(s_{0})+\sum_{t=0}^{T-1}\log P_{F}(s_{t+1}|s_{t})-\log F(s_{T})-\sum_{t=0}^{T-1}\log P_{B}(s_{t}|s_{t+1}))^{2},"where $F(s_{0})$ is the initial flow, $F(s_{T})$ is the terminal flow proportional to $\exp(-\mathcal{E}(x))$, and the loss ensures consistency between forward and backward trajectory log-probabilities."
ICLR_2024_oral_38,4,L_{subTB}=(\log F(s_{U})+\sum_{t=U}^{U+L-1}\log P_{F}(s_ {t+1}|s_{t})-\log F(s_{U+L})-\sum_{t=U}^{U+L-1}\log P_{B}(s_{t}|s_{t+1})) ^{2},,L_{subTB}=(\log F(s_{U})+\sum_{t=U}^{U+L-1}\log P_{F}(s_{t+1}|s_{t})-\log F(s_{U+L})-\sum_{t=U}^{U+L-1}\log P_{B}(s_{t}|s_{t+1}))^{2},"This loss function generalizes the detailed and trajectory balance objectives by considering sub-trajectories of variable length $L$, enabling more flexible and localized training of the forward and backward policies using intermediate state transitions."
ICLR_2024_oral_38,5,"L_{FL}(s,s^{\prime})=(\log\tilde{F}(s)+\log P_{F}(s^{\prime}| s)-E(s)+E(s^{\prime})-\log\tilde{F}(s^{\prime})-\log P _{B}(s|s^{\prime}))^{2}",where \(\tilde{F}(s)=F(s)\exp\left(\mathcal{E}(s)\right)\) is the re-parameterized flow function and \(\mathcal{E}(s^{\prime})-\mathcal{E}(s)\) is the energy gain associated with the transition from \(s\) to \(s^{\prime}\),"L_{FL-DB}(s,s^{\prime})=(\log F(s)+\log P_{F}(s^{\prime}|s)-\log F(s^{\prime})-\log P_{B}(s|s^{\prime})+E(s)-E(s^{\prime}))^{2}",This loss function extends detailed balance by incorporating energy differences between consecutive states to provide local credit assignment during training.
ICLR_2024_oral_38,6,E(x)\approx\Phi_{\theta}(\tau)=\sum_{t=0}^{T-1}\phi_{\theta}(s_{t}\to s_{t+1}),"where \(\tau=(s_{0},s_{1},\ldots,s_{T})\), \(x=s_{T}\), and the potential functions are defined on state transition \(s_{t}\to s_{t+1}\)","E(x)=\sum_{t=0}^{T-1}\phi_{\theta}(s_{t},s_{t+1})","where the terminal energy $\mathcal{E}(x)$ is decomposed into a sum of learnable potential functions $\phi_{\theta}(s_{t},s_{t+1})$ defined over state transitions along the trajectory."
ICLR_2024_oral_38,7,"L_{LED}(s,s^{\prime})=(\log\tilde{F}(s)+\log P_{F}(s^{\prime} |s)+\phi_{\theta}(s\to s^{\prime})-\log\tilde{F}(s^{\prime})-\log P_{B}(s|s^{\prime}))^{2}",,L_{LED}=(\log F(s)+\log P_{F}(s^{\prime}|s)-\log F(s^{\prime})-\log P_{B}(s|s^{\prime})-\phi_{\theta}(s\to s^{\prime}))^{2},"LED-GFN introduces a learnable potential function $\phi_{\theta}$ to decompose the terminal energy into local credits, enabling more informative and low-variance training signals for GFlowNet policies and flow model through state transitions."
ICLR_2024_oral_38,8,\ell_{LS}(\tau)=E_{z\simBern(\gamma)} [(\frac{1}{T}E(s_{T})-\frac{1}{C}\sum_{t=0}^{T-1}z_{t}\phi_{\theta}(s_{t}\to s_{t+1}))^{2}],,L_{\phi}(\tau)=\left(E(x)-\sum_{t=0}^{T-1}\phi_{\theta}(s_{t}\to s_{t+1})\right)^{2}+\lambda\sum_{t=0}^{T-1}\left(\phi_{\theta}(s_{t}\to s_{t+1})-\bar{\phi}_{\theta}(s_{t}\to s_{t+1})\right)^{2},where the first term ensures accurate energy estimation through potential summation and the second term regularizes the potentials to minimize variance along the trajectory using a dropout-based approach.
ICLR_2024_oral_39,1,"\epsilon_{\theta}(o_{t}^{(k)},k|h_{t-1},a_{t-1})=(1+\eta)\epsilon_{\theta}(o_{ t}^{(k)},k|h_{t-1},a_{t-1})-\eta\epsilon_{\theta}(o_{t},k|h_{t-1})",where \(\eta\) controls action conditioning strength,"\overline{T}(o_{t}|h_{t-1},a_{t-1})=\prod_{k=1}^{K}\epsilon_{\theta}(o_{t}^{(k)},k|h_{t-1},a_{t-1})","Equation 1 defines the observation prediction model as a product of denoising steps conditioned on the history and action, forming the basis for the universal simulator."
ICLR_2024_oral_39,2,"L_{MSE}=\|\epsilon-\epsilon_{\theta}\Big{(}\sqrt{1-\beta^{(k)}}o_{t}+\sqrt{\beta^{(k)}}\epsilon,\,k\Big{|}h_{t-1},a_{t-1}\Big{)}\|^{2}","where \(\epsilon\sim\mathcal{N}(0,I)\), and \(\beta^{(k)}\in\mathbb{R}\) are a set of \(K\) different noise levels for each \(k\in[1,K]\)","L_{sim}=E_{t,k,o_{t}^{(k)},\epsilon}\left[\left\|\epsilon-\epsilon_{\theta}(o_{t}^{(k)},k|h_{t-1},a_{t-1})\right\|^2\right]",the loss function for training the denoising model by minimizing the mean squared error between predicted and target noise.
ICLR_2024_oral_39,3,"o_{t}^{(k-1)}=\alpha^{(k)}(o_{t}^{(k)}-\gamma^{(k)}\epsilon_{\theta}(o_{t}^{( k)},k|h_{t-1},a_{t-1}))+\xi,\quad\xi\simN\big{(}0,\sigma_{k}^{2}I\big{)}","where \(\gamma^{(k)}\) is the denoising step size, \(\alpha^{(k)}\) is a linear decay on the current denoised sample, and \(\sigma_{k}\) is a time varying noise level that depends on \(\alpha^{(k)}\) and \(\beta^{(k)}\)","o_{t}^{(k-1)}=\mu^{(k)}(o_{t}^{(k)},h_{t-1},a_{t-1})+\Sigma^{(k)}(o_{t}^{(k)},h_{t-1},a_{t-1})\cdot\epsilon_{\theta}(o_{t}^{(k)},k|h_{t-1},a_{t-1})",where $\mu^{(k)}$ and $\Sigma^{(k)}$ are the mean and covariance of the noise distribution at step $k$
ICLR_2024_oral_39,4,RDG=\frac{\|s_{0}-s_{goal}\|_{2}-\|s_{T}-s_{goal}\|_{2}}{\|s_{0}-s_{goal}\|_{2}},"where \(s_{T}\) represents the underlying block locations after executing the policy, \(s_{0}\) and \(s_{\text{goal}}\) represents the initial and goal block locations",RDG=\frac{1}{N}\sum_{i=1}^{N}\left(1-\frac{\|p_i-g_i\|}{\|p_i^{(0)}-g_i\|}\right),"where $p_i$ is the current position of block $i$, $g_i$ is the goal position, and $p_i^{(0)}$ is the initial position, measuring the normalized reduction in distance to the goal across $N$ blocks."
ICLR_2024_oral_4,1,p(Y\mid X)=\sum_{Z}p_{LM}(ZY\mid X)=\sum_{Z}p_{LM}(Y\mid XZ)p_{LM}(Z\mid X),where \(p_{\text{LM}}\) denotes the likelihood assigned to a sequence by a language model and apposition of variables (_e,"p(Y\mid X)=\sum_{Z} p(Y, Z\mid X)","The marginal likelihood of the answer $Y$ given the question $X$, obtained by summing over all possible latent chains of thought $Z$."
ICLR_2024_oral_4,2,"p_{LM}(Z\mid X,Y)=\frac{p_{LM}(XZY)}{\sum_{Z^{\prime}}p_{ LM}(XZY^{\prime}Y)}\propto p_{LM}(XZY)",,"p_{LM}(Z\mid X,Y)=\frac{p_{LM}(XZY)}{\sum_{Z'} p_{LM}(XZ'Y)}","The posterior distribution over latent token sequences $Z$ conditioned on prefix $X$ and suffix $Y$, derived from the autoregressive language model $p_{\text{LM}}$."
ICLR_2024_oral_4,3,L(Z;\theta)=\sum_{0\leq i<j\leq n}(\log\frac{R(z_{1:i}\top)\prod_{k=i+1}^{j}q_{GFN}(z_{k}\mid z_{1:k-1})q_{GFN}(\top\mid z_ {1:j})}{R(z_{1:j}\top)q_{GFN}(\top\mid z_{1:i})})^{2},,L_{SubTB}(Z)=\left(\sum_{i=0}^{n}\log q_{GFN}(z_{i+1}\mid z_{1:i})-\log\tilde{R}(z_{1:i})\right)^2,"where $\tilde{R}(z_{1:i})$ is the reward function defined on partial sequences $z_{1:i}$, and the objective minimizes the squared difference between the log-policy and the log-reward along the generation trajectory."
ICLR_2024_oral_41,1,"q_{0t}(x_{t}|x_{0})=N(x_{ t}|\alpha_{t}x_{0},\sigma_{t}^{2}I)","where \(\alpha_{t}\) and \(\sigma_{t}\) are referred to as the noise schedule, satisfying \(\alpha_{t}^{2}+\sigma_{t}^{2}=1\)","q_{0t}(x_{t}|x_{0})=N(x_{t};\sqrt{\alpha_t}x_{0}, (1-\alpha_t)I)","Equation 1 defines the conditional distribution of the forward process in diffusion models, where the data is gradually corrupted by Gaussian noise over time $t$."
ICLR_2024_oral_41,2,"dx_{t}=f(t)x_{t}dt+g(t )dw_{t},\quadx_{0}\sim q_{0}(x_{0})","where \(\mathbf{w}_{t}\) is the standard Wiener process, \(f(t)=\frac{\mathrm{d}\log\alpha_{t}}{\mathrm{d}t}\) and \(g(t)=2\sigma_{t}^{2}\frac{\mathrm{d}\log(\sigma_{t}/\alpha_{t})}{\mathrm{d}t}\)",dx_{t}=\frac{d}{dt}\left(\frac{\alpha_{t}}{\sigma_{t}}\right)x_{t}dt+\sqrt{\frac{d}{dt}\left(\frac{\alpha_{t}^{2}}{\sigma_{t}^{2}}\right)}dw_{t},Stochastic differential equation (SDE) formulation that matches the transition distribution of the forward process in Equation 1.
ICLR_2024_oral_41,3,"dx_{t}=[f(t)x_{t}-g(t)^{2}\nabla_{x_{t}}\log q_{t}(x_{t})]dt+g (t)d\bar{w}_{t},\quadx_{T}\sim q_{T} (x_{T})",where \(\bar{\mathbf{w}}_{t}\) is a standard Wiener process in the reverse time,dx_{t}=\left[f(t)x_{t}-g(t)^{2}\nabla_{x_{t}}\log q_{t}(x_{t})\right]dt+g(t)dw_{t},where the reverse-time stochastic differential equation (SDE) governs the denoising process by using the score function $\nabla_{\mathbf{x}_{t}}\log q_{t}(\mathbf{x}_{t})$ to guide the generation towards the data distribution.
ICLR_2024_oral_41,4,"L(\theta):=E_{t\simU(0,T),x_{0}\sim q_{0}(x_{0}),\epsilon\simN (0,I)}[\|\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon,t)-\epsilon\|_{2}^{2}]",,"E_{t,x_{0},\epsilon}\left[\left\Vert\epsilon-\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon,t)\right\Vert ^{2}\right]","where the expectation is over the data distribution and the noise schedule, and $\mathbf{\epsilon}_{\theta}(\mathbf{x}_{t},t)$ represents the neural network used to estimate the noise component"
ICLR_2024_oral_41,5,"\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}=\frac{\alpha_{t}}{\sqrt{1-\alpha_{t}^{2}}}\frac{d\alpha_{t}}{dt}\nabla_{x}\log q_{t}(x)-\frac{\partial\nabla_{x }\log q_{t}(x)}{\partial t}\sigma_{t}",,"\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}=-\frac{d\sigma_{t}}{dt}\nabla_{x}\log q_{t}(x)-\sigma_{t}\nabla_{x}\left(\frac{\partial}{\partial t}\log q_{t}(x)\right)","Equation describing the partial derivative of the noise prediction network with respect to time, revealing the source of Lipschitz singularities near t=0 due to the explosion of the derivative of Ïâ."
ICLR_2024_oral_41,6,"\lim\sup_{t\to 0+}\|\frac{\partial\epsilon_{\theta}(x,t )}{\partial t}\|\to\infty;\quad\lim\sup_{t\to 0+}\|\frac{\partial\nabla_{x}\log q_{t}(x)}{\partial t}\sigma_{t}\|\to\infty",,"\limsup_{t\to 0+}\left\|\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}\right\|=\infty","Equation 6 demonstrates that under common noise schedules, the partial derivative of the noise prediction model with respect to time tends to infinity near $t=0$, indicating the presence of Lipschitz singularities in diffusion models."
ICLR_2024_oral_41,7,\nabla_{x}\log q_{t}(x)=\nabla_{x}\log (\frac{1}{\sqrt{2\pi}}\exp(-\frac{\|x\|_{2}^{2}}{2}) )=-x,,\nabla_{x}\log q_{t}(x)=-\frac{x}{\sigma_{t}^{2}+\alpha_{t}^{2}},"Score function for the case where the data distribution follows a standard Gaussian, $p(\mathbf{x}_{0})\sim\mathcal{N}(\mathbf{0},\mathbf{I})$"
ICLR_2024_oral_41,8,"K(t,t^{\prime})=\frac{E_{x_{t}}[\|\epsilon_{\theta} (x_{t},t)-\epsilon_{\theta}(x_{t},t^{\prime})\|_{2}]}{\Delta t}",where \(\Delta t=|t-t^{\prime}|\),"L_{t}(x):=\left\|\frac{\partial\epsilon_{\theta}(x,t)}{\partial t}\right\|","where $\mathcal{L}_{t}(x)$ denotes the Lipschitz constant of the noise prediction network $\mathbf{\epsilon}_{\theta}(\mathbf{x},t)$ with respect to the time variable $t$"
ICLR_2024_oral_41,9,"L(\epsilon_{\theta}):=E_{t\simU(0,T),x_{0}\sim q(x_{0}),\epsilon\simN(0,I)} [\|\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon,f_{T}(t))-\epsilon\|_{2}^{2}]","where \(f_{\mathbb{T}}(t)=\max_{1\leq i\leq n}\{t_{i-1}\in\mathbb{T}:t_{i-1}\leq t\}\) for \(t<\tilde{t}\), while \(f_{\mathbb{T}}(t)=t\) for \(t\geq\tilde{t}\)","L_{E-TSDM}(\theta):=E_{t\simU(0,T),x_{0}\sim q_{0}(x_{0}),\epsilon\simN (0,I)}[\|\epsilon_{\theta}(\alpha_{t}x_{0}+\sigma_{t}\epsilon,\tau(t))-\epsilon\|_{2}^{2}]",where $\tau(t)$ is the shared timestep condition within the sub-interval containing $t$.
ICLR_2024_oral_41,10,"p_{\theta}(x_{t-1}|x_{t})=N(x_{t-1};\frac{\alpha_{t-1}}{\alpha_{t}}(x_{t}-\frac{\beta_{t}}{\sigma_{t}}\epsilon_{\theta}(x_{t},f_{T} (t))),\eta_{t}^{2}I)","where \(\beta_{t}=1-\frac{\alpha_{t}}{\alpha_{t-1}}\), and \(\eta_{t}^{2}=\beta_{t}\)","dx_{t}=[f(t)x_{t}-g(t)^{2}\nabla_{x_{t}}\log q_{t}(x_{t})]dt+g (t)d\bar{w}_{t},\quadx_{T}\sim q_{T} (x_{T})","where $\bar{\mathbf{w}}_{t}$ is a standard Wiener process in the reverse time, and $f_{\mathbb{T}}(t)$ denotes the shared timestep condition"
ICLR_2024_oral_41,11,"\|\epsilon^{*}(x,f_{T}(t)-\epsilon(x,t)\|\leq\sigma_{\tilde{t}}K (x)\Delta t+B(x)\Delta\sigma_{\max}",,"\|\epsilon^{*}(x,f_{T}(t))-\epsilon(x,t)\|_{2}\leq C\Delta t",where $C$ is a constant and $\Delta t$ is the maximum sub-interval length in the partition $\mathbb{T}$
ICLR_2024_oral_41,12,"K(x)=\sup_{t\neq\tau}\frac{\|\nabla_{x}\log q_{t }(x)-\nabla_{x}\log q_{\tau}(x )\|}{|t-\tau|},\quad B(x)=\sup_{t}\|\nabla_{x}\log q_{t}(x)\|",,"\Delta t=\max_{1\leq i\leq n} (t_i-t_{i-1}),\quad\Delta\sigma_{\max}=\max_{t,t'\in [0,\tilde{t})} |\sigma_t-\sigma_{t'}|","where $\Delta t$ is the maximum length of the sub-intervals, $\Delta\sigma_{\max}$ is the maximum difference in $\sigma_t$ within the interval $[0,\tilde{t})$, and $K(\mathbf{x})$, $B(\mathbf{x})$ are bounded functions of $\mathbf{x}$"
ICLR_2024_oral_44,1,"I(S;Z)=D_{KL}(p(s,z)\|p(s)p(z))",,"\max_{\pi}\, I(S; Z)=H(S)-H(S\mid Z)",Equation 1 formulates the objective of maximizing mutual information between states $S$ and skills $Z$ in unsupervised skill discovery methods.
ICLR_2024_oral_44,2,"I_{W}(S;Z)=W(p(s,z),p(s)p(z))",where \(I_{\mathcal{W}}(S;Z)\) is the Wasserstein dependency measure (WDM) (Ozair et al,"\max_{\pi}E_{z\sim p(z)}\left[E_{\tau\sim\pi(\cdot|z)}\left[\sum_{t=0}^{T}\gamma^t d(s_t, s_{t+1})\right]\right]","This objective maximizes the expected temporal distance between consecutive states across skills, encouraging the policy to learn diverse behaviors that span the most temporally extended directions of the state space."
ICLR_2024_oral_44,3,"I_{W}(S;Z)=\sup_{\|f\|_{L}\leq 1}E_{p(s,z)}[f(s,z)]-E_{p(s)p(z)}[f(s,z)]","where \(\|f\|_{L}\) denotes the Lipschitz constant for the function \(f:\mathcal{S}\times\mathcal{Z}\rightarrow\mathbb{R}\) under the given distance metric \(d\), _i","I_{W}(S;Z)=\max_{f\inLip_1}E_{p(z)p(s)}[f(s,z)]-E_{p(s,z)}[f(s,z)]","where the maximum is taken over all 1-Lipschitz functions $f: \mathcal{S} \times \mathcal{Z} \rightarrow \mathbb{R}$, providing a tractable dual form for optimizing the Wasserstein dependency measure."
ICLR_2024_oral_44,4,"I_{W}(S;Z)\approx\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}E_{p( s,z)}[\phi(s)^{\top}\psi(z)]-E_{p(s)}[\phi(s)]^{\top}E_{p(z)}[\psi(z)]",,"I_{W}(S;Z)=\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}E_{p(s,z)}[\phi(s)^{\top}\psi(z)]-E_{p(s)p(z)}[\phi(s)^{\top}\psi(z)]","This equation reformulates the Wasserstein dependency measure using a parameterization of the score function as the inner product between state and skill encoders, enabling more efficient optimization under Lipschitz constraints on the encoders."
ICLR_2024_oral_44,5,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}E_{p(\tau,z)}[\phi(s_{T})^{\top}\psi(z)]-E_{p(\tau)}[\phi(s_{T})]^{\top}E_{p(z)}[\psi(z)] || =\sup_{\phi,\psi}\sum_{t=0}^{T-1}(E_{p(\tau,z)}[(\phi(s_{t+1})-\phi(s_{t}))^{\top}\psi(z)]-E_{p(\tau)}[\phi(s_{t+1})-\phi(s_{t})]^{\top}E_{p(z)}[\psi(z)])",,"I_{W}(S_{T};Z)=\sup_{\|\phi\|_{L}\leq 1,\|\psi\|_{L}\leq 1}\sum_{t=0}^{T-1}E_{p(s_{t},z)}[\phi(s_{t+1})^{\top}\psi(z)-\phi(s_{t})^{\top}\psi(z)]","This equation reformulates the Wasserstein dependency measure using a telescoping sum over state transitions, focusing on the temporal difference in the embedding space to encourage skills that maximize temporal distance."
ICLR_2024_oral_44,6,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1}E_{p(\tau,z)}[\sum_{t=0}^{T-1}(\phi(s_{t+1})-\phi(s_{t}))^{\top}(z-\bar{z}) ]",where \(\bar{z}=\mathbb{E}_{p(z)}[z]\),"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1}\sum_{t=0}^{T-1}(E_{p(\tau,z)}[(\phi(s_{t+1})-\phi(s_{t}))^{\top}z]-E_{p(\tau)}[\phi(s_{t+1})-\phi(s_{t})]^{\top}E_{p(z)}[z])",This final simplification leads to a practical and concise objective for maximizing the Wasserstein dependency measure by focusing on temporal differences in the learned state representations and linearly relating skills to the latent space.
ICLR_2024_oral_44,7,"\sup_{\pi,\phi}\E_{p(\tau,z)}[\sum_{t=0}^{T-1}(\phi(s_{t+1})-\phi(s_{t}))^{\top}z]\\s.t.\\\|\phi(s)-\phi(s^{\prime})\|_{2}\leq 1,\\\forall(s,s^{\prime})\inS_{adj}",where \(\mathcal{S}_{\mathrm{adj}}\) denotes the set of adjacent state pairs in the MDP,"I_{W}(S_{T};Z)\approx\sup_{\|\phi\|_{L}\leq 1}E_{p(\tau,z)}\left[\sum_{t=0}^{T-1}\left(\phi(s_{t+1})-\phi(s_{t})\right)^{\top}z\right]","This final simplified objective maximizes the temporal difference in state representations $\phi(s)$ scaled by the skill vector $z$, under a Lipschitz constraint, effectively encouraging skills to span the most temporally distant directions in the state space."
ICLR_2024_oral_45,1,"x^{\prime}(t)=Ax(t)+Bu(t),\quad y(t)=Cx(t)+Du(t)",,"\dot{x}(t) &=Ax(t)+Bu(t),\\y(t) &=Cx(t)+Du(t)","Continuous-time state space model equations with state variables $x(t)$, control input $u(t)$, and output $y(t)$ parameterized by matrices $\mathbf{A}, \mathbf{B}, \mathbf{C}, \mathbf{D}$."
ICLR_2024_oral_45,2,"x_{n}=\bar{A}x_{n-1}+\bar{B}u_{n},\quad y_{n}=\bar{ C}x_{n}+\bar{D}u_{n}","where \(\bar{\mathbf{A}},\bar{\mathbf{B}},\bar{\mathbf{C}}\), and \(\bar{\mathbf{D}}\) are discrete-time parameters obtained from the continuous-time parameters and \(\Delta\) using methods like zero-order hold and bilinear technique (Smith et al",\bar{A} &amp;=(I+\DeltaA)\\\bar{B} &amp;=\DeltaB\\\bar{C} &amp;=C,"Discretized state space model matrices using a step size $\Delta$, enabling discrete recurrent representation of the continuous system."
ICLR_2024_oral_45,3,"L(\theta)=\operatorname*{E}_{z_{1:T}\sim q_{\theta}}\sum_{ t=1}^{T}L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})+L^{rep}(\theta,h_{t},o_{t})+L^{dyn}(\theta,h _{t},o_{t})",,"h_{t}, x_{t}=f_{\theta}\left((a_{t-1}, z_{t-1}), x_{t-1}\right)=LayerNorm\left(GLU\left(GeLU\left(SSM_{\theta}^{L}\left(\cdotsSSM_{\theta}^{1}\left(a_{t-1}\\z_{t-1}\right)\cdots\right)\right)\right)\right)","This equation defines the deterministic state $h_t$ and hidden state $x_t$ computation in the Structured State-Space Model (S3M), where $f_{\theta}$ consists of $L$ stacked SSM layers followed by GeLU activation, GLU transformation, and LayerNorm, processing the concatenated input $(a_{t-1}, z_{t-1})$ from previous actions $a_{t-1}$ and stochastic states $z_{t-1}$."
ICLR_2024_oral_45,4,"L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})=-\beta_{pred}(\ln p_{\theta}(o_{t}\mid z_{t},h_{t})+\ln p_{\theta}(r_{t}\mid z_{t},h_{t})+\ln p_{\theta}(c_{t}\mid z_{t},h_{t})) || L^{dyn}(\theta,h_{t},o_{t})=\beta_{dyn}\max(1,KL[\lessdot\circ g(q_{\theta}(z_ {t}\mid o_{t}))\parallel p(z_{t}\mid h_{t})\mid)]",,"L^{pred}(\theta,h_{t},o_{t},r_{t},c_{t},z_{t})=-\log p_{\theta}(\hat{o}_{t}\mid z_{t},h_{t})-\log p_{\theta}(\hat{r}_{t}\mid z_{t},h_{t})-\log p_{\theta}(\hat{c}_{t}\mid z_{t},h_{t})","The prediction loss term $\mathcal{L}^{\text{pred}}$ measures the negative log-likelihood of reconstructing the observation $\hat{o}_t$, reward $\hat{r}_t$, and continuation flag $\hat{c}_t$ given the latent state $z_t$ and deterministic state $h_t$."
ICLR_2024_oral_45,5,"L^{rep}(\theta,h_{t},o_{t})=\beta_{rep}\max(1,KL[\quad q_{\theta}(z_{t}\mid o_ {t})\parallel\lessdot\circ g(p(z_{t}\mid h_{t}))\,])",,"L^{rep}(\theta,h_{t},o_{t})=\beta_{rep}KL[q_{\theta}(z_{t}\mid o_{t})\parallel p(z_{t}\mid h_{t})]",The representation loss encourages the posterior distribution $q_{\theta}(z_{t}\mid o_{t})$ to stay close to the prior distribution $p(z_{t}\mid h_{t})$ by minimizing the Kullback-Leibler (KL) divergence between them.
ICLR_2024_oral_45,6,"h_{1:T},x_{1:T}=f_{\theta}((a_{1:T},z_{1:T}),x_{0})",,"L^{dyn}(\theta,h_{t},o_{t})=\beta_{dyn}\max\left(1,KL\left[q_{\theta}(z_{t}\mid o_{t})\parallel p(z_{t}\mid h_{t})\right]\right)","This equation defines the dynamics loss term, which encourages the prior distribution $p(z_t \mid h_t)$ to align with the posterior distribution $q_{\theta}(z_t \mid o_t)$, using the Kullback-Leibler (KL) divergence as a measure of discrepancy."
ICLR_2024_oral_49,1,"e_{i}^{num}=x_{i}^{num}\cdotw_{i}^{num}+b_{i}^{num},\\e_{i}^{cat}=x_{i}^{oh}\cdotW_{i}^{cat }+b_{i}^{cat}","where \(\mathbf{w}_{i}^{\mathrm{num}},\mathbf{b}_{i}^{\mathrm{num}},\mathbf{b}_{i}^{\mathrm{cat}} \in\mathbb{R}^{1\times d}\), \(\mathbf{W}_{i}^{\mathrm{cat}}\in\mathbb{R}^{C_{i}\times d}\) are learnable parameters of the tokenizer, \(\mathbf{e}_{i}^{\mathrm{num}},\mathbf{e}_{i}^{\mathrm{cat}}\in\mathbb{R}^{1\times d}\)","z_{j}^{num} &=W_{j}^{num}\cdot x_{j}^{num}+b_{j}^{num},\quadfor numerical column  j,\\z_{i}^{cat} &=E_{i}\cdotx_{i}^{oh},\quadfor categorical column  i","Equation 1 defines the transformation of numerical and categorical columns into d-dimensional vectors using learnable parameters, where numerical features undergo a linear transformation and categorical features are mapped via an embedding lookup table."
ICLR_2024_oral_49,2,"E=[e_{1}^{num},\cdots,e_{M_{num}}^{ num},e_{1}^{cat},\cdots,e_{M_{cat}}^{cat}]\inR^{M\times d}",,"E=[e_{1}^{num},\cdots,e_{M_{num}}^{num},e_{1}^{cat},\cdots,e_{M_{cat}}^{cat}]\inR^{(M_{num}+M_{cat})\times d}","where $\mathbf{E}$ represents the combined embedding matrix of all numerical and categorical columns for a given record, structured as a matrix with rows corresponding to column embeddings and columns representing the $d$-dimensional feature space."
ICLR_2024_oral_49,3,"&\hat{x}_{i}^{num}=\hat{e}_{i}^{num}\cdot\hat{w}_{i}^{num}+\hat{b}_{i}^{num},\\\hat{e}_{i}^{oh}=Softmax(\hat{e}_{i}^{cat}\cdot\hat{W}_{i}^{cat}+\hat{b}_{i}^{cat}),\\&\hat{x}=[\hat{x}_{1}^{num},\cdots,\hat{x}_{M_{num}}^{num},\hat{x}_{1}^{oh},\cdots,\hat{x }_{M_{cat}}^{oh}]","where \(\hat{\mathbf{w}}_{i}^{\mathrm{num}}\in\mathbb{R}^{d\times 1},\hat{b}_{i}^{ \mathrm{num}}\in\mathbb{R}^{1\times 1}\), \(\mathbf{W}_{i}^{\mathrm{cat}}\in\mathbb{R}^{d\times C_{i}},\hat{\mathbf{b}}_{i}^{ \mathrm{cat}}\in\mathbb{R}^{1\times C_{i}}\) are detokenizer's parameters","\hat{x}_{i}^{num}=MLP_{i}^{num}(\hat{e}_{i}^{num}),\\\hat{x}_{i}^{oh}=Softmax(MLP_{i}^{cat}(\hat{e}_{i}^{cat}))","where $\mathrm{MLP}_{i}^{\mathrm{num}}$ and $\mathrm{MLP}_{i}^{\mathrm{cat}}$ are column-specific multi-layer perceptrons for reconstructing numerical and categorical features, respectively."
ICLR_2024_oral_49,4,"L=\ell_{recon}(x,\hat{x})+\beta\ell_{kl}",,L_{\beta}=E_{q(z|x)}[\log p(x|z)]-\beta\cdot D_{KL}(q(z|x)\| p(z)),where $\beta$ controls the trade-off between reconstruction accuracy and latent space regularization in the $\beta$-VAE framework.
ICLR_2024_oral_49,5,"z_{t}=z_{0}+\sigma(t)\varepsilon,\\varepsilon\simN(0,I), (Forward Process) || dz_{t}=-2\hat{\sigma}(t)\sigma(t)\nabla_{z_{t}}\log p(z_{t})dt+\sqrt{2\hat{\sigma}(t)\sigma(t)}d\omega_{t}, (Reverse Process)",,"&q(z_{t}|z_{t-1})=N(z_{t};\sqrt{1-\beta_{t}}z_{t-1},\beta_{t}I),\\t=1,\cdots,T,\\&p_{\theta}(z_{t-1}|z_{t})=N(z_{t-1};\mu_{\theta}(z_{t},t),\sigma_{t}^{2}I)","where the forward process gradually adds noise to the latent embedding $\mathbf{z}$ over $T$ steps, and the reverse process learns to denoise it back to the original distribution using a neural network parameterized by $\theta$."
ICLR_2024_oral_49,6,"L=E_{z_{0}\sim p(z_{0})}E_{t\sim p (t)}E_{\varepsilon\simN(0,I)}\|\varepsilon_{\theta}(z_{t},t)-\varepsilon)\|_{2}^{2},\\where\z_{t}=z_{0}+\sigma(t)\varepsilon",where \(\mathbf{\epsilon}_{\theta}\) is a neural network (named denoising function) to approximate the Gaussian noise using the perturbed data \(\mathbf{x}_{t}\) and the time \(t\),"L_{diff}=E_{t,z_{0},\varepsilon}\left[\left\|s_{\theta}(z_{t},t)-\varepsilon\right\|^{2}\right]","where $\mathbf{s}_{\theta}(\mathbf{z}_{t},t)$ is the neural network that estimates the score function $\nabla_{\mathbf{z}_{t}}\log p_{t}(\mathbf{z}_{t})$, and the loss minimizes the mean squared error between the predicted score and the true noise $\mathbf{\varepsilon}$."
ICLR_2024_oral_52,1,"p(x(t)\midx(0))=N(x(t);x(0),\sigma^{2}(t)I)\",,"q(x_t\midx_0)=N(x_t;\sqrt{\alpha_t}x_0, (1-\alpha_t)I)",A forward diffusion process that perturbs the data distribution using a Gaussian perturbation kernel parameterized by $\alpha_t$.
ICLR_2024_oral_52,2,"dx(t)=-\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt\",,\frac{dx(t)}{dt}=-\frac{1}{2}\nabla_{x}\log p(x(t))\,This equation describes the probability flow ODE governing the forward evolution of a data point in time under the chosen noise schedule.
ICLR_2024_oral_52,3,"dx(t)=\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt\",,"dx(t)=\sigma(t)\nabla_{x(t)}\log p(x(t))\,dt\","The backward ODE describes the denoising process, inverting the forward evolution of the data point to recover the original signal from the noisy input."
ICLR_2024_oral_52,4,"E_{t\simU([0,T])}E_{x(0)\sim p(x (0))}E_{x(t)\sim p(x(t)|x(0))}\|S^{\theta}(x(t),\sigma(t))-\nabla_{x(t)}\log p (x(t)\midx(0))\|_{2}^{2}",,"L=E_{t,x(0),x(t)}\left[\left\Vert\nabla_{x(t)}\log p(x(t)\midx(0))-S^{\theta}(x(t),\sigma(t))\right\Vert^{2}\right]\",This equation defines the score-matching loss used to train the neural network $S^{\theta}$ by minimizing the discrepancy between the true score and the network's prediction.
ICLR_2024_oral_52,5,"E_{t\simU([0,T])}E_{x(0)\sim p(x (0))}E_{x\simN(0,\sigma^{2}(t)I )}\|D^{\theta}(x(0)+\epsilon,\sigma(t))-x(0)\|_ {2}^{2}\","where we define \(S^{\theta}(\mathbf{x}(t),\sigma(t))=:(D^{\theta}(\mathbf{x}(t),\sigma(t))- \mathbf{x}(t))/\sigma^{2}(t)\)","E_{t\simU([0,T])}E_{x(0)\sim p(x(0))}\left\|S^{\theta}(x(t),\sigma(t))+\frac{x(t)-x(0)}{\sigma^{2}(t)}\right\|_{2}^{2}",This equation represents the simplified score-matching loss after substituting the Gaussian perturbation kernel from Equation 1 into the original loss formulation.
ICLR_2024_oral_52,6,"\nabla_{x(t)}\log p(x(t))=\nabla_{(x_{1}(t),\ldots,x_{N}(t))}\log p(x_{1}(t),\ldots,x_{N}(t))\",,"\nabla_{x(t)}\log p(x(t))\approxS^{\theta}(x(t),\sigma(t))\",where the score function is approximated by the neural network $\mathcal{S}^{\theta}$ as part of the multi-source diffusion model (MSDM) for capturing the prior distribution of the sources.
ICLR_2024_oral_52,7,"S^{\theta}(x(t),\sigma(t)):R^{N\times D}\timesR arrowR^{N\times D}\","where \(\mathbf{x}(t)=(\mathbf{x}_{1}(t),\ldots,\mathbf{x}_{N}(t))\) denotes the sources perturbed with the Gaussian kernel in Eq","S^{\theta}(x(t),\sigma(t))=(S_{1}^{\theta}(x(t),\sigma(t)),\ldots,S_{N}^{\theta}(x(t),\sigma(t)))\","where each component $\mathcal{S}_{n}^{\theta}(\mathbf{x}(t),\sigma(t))$ corresponds to the score estimate for the $n$-th source waveform given the noisy input $\mathbf{x}(t)$ and noise level $\sigma(t)$."
ICLR_2024_oral_52,9,"\nabla_{x_{\overline{I}}(t)}\log p([x_{\overline{I}}(t),\hat{x}_{I}(t)])\","where \(\hat{\mathbf{x}}_{\mathcal{I}}\) is a sample from the forward process: \(\hat{\mathbf{x}}_{\mathcal{I}}(t)\sim\mathcal{N}(\mathbf{x}_{\mathcal{I}}(t) ;\mathbf{x}_{\mathcal{I}}(0),\sigma(t)^{2}\mathbf{I})\)","\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t))=\nabla_{x_{\overline{I}}(t)}\log p(x_{1}(t),\ldots,x_{N}(t))-\nabla_{x_{\overline{I}}(t)}\log p(x_{I}(t))",This equation decomposes the conditional score into the gradient of the joint distribution and the gradient of the marginal distribution of the fixed sources.
ICLR_2024_oral_52,10,"\nabla_{x_{\overline{I}}(t)}\log p(x_{\overline{I}}(t)\midx_{I}(t))\approx S_{\overline{I}}^{\theta}([x_{\overline{I}}(t),\hat{x }_{I}(t)],\sigma(t))\",where \(S_{\overline{\mathcal{I}}}^{\theta}\) denotes the entries of the score network corresponding to the sources indexed by \(\overline{\mathcal{I}}\),"\nabla_{x_{\overline{I}}(t)}\log p([x_{\overline{I}}(t),\hat{x}_{I}(t)])\approx S^{\theta}([x_{\overline{I}}(t),\hat{x}_{I}(t)],\sigma(t))_{\overline{I}}\",Approximation of the conditional score function for the remaining sources in the partial generation task using the trained score network and the concatenation of the noisy fixed sources and the current estimate of the remaining sources.
ICLR_2024_oral_52,12,"p(y(t)\midx(t))=N(y(t)\mid\sum_{n=1}^{N}x_{n}(t),\gamma^{2}(t)I)",,"p(y(0)\midx(t))=N(y(0);x(t),\sigma^{2}(t)I)\",
ICLR_2024_oral_52,13,p(y(t)\midx(t))=1_{y(t)=\sum_{n=1}^{N}x_{ n}(t)}\,,p(y(t)\midx(t))=\delta\left(y(t)-\sum_{n=1}^{N}x_{n}(t)\right)\,where the likelihood is modeled as a Dirac delta function enforcing the mixture condition at time $t$.
ICLR_2024_oral_52,14,"\nabla_{x_{m}(t)}\log p(x(t)\midy(0))\approx S_{m}^{\theta}((x_{1}(t),\dots,x_{N-1}(t),y(0)-\sum_{n=1}^{N-1}x_{n}(t)),\sigma(t)) || -S_{N}^{\theta}((x_{1}(t),\dots,x_{N-1}(t),y(0)-\sum_{n=1}^{N-1}x_{n}(t)),\sigma(t))\",,"\nabla_{x_{1:N-1}(t)}\log p([x_{1:N-1}(t),y(0)-\sum_{n=1}^{N-1}x_{n}(t)])\","where the gradient is computed with respect to the first $N-1$ sources, and the $N$-th source is implicitly constrained via $\mathbf{x}_{N}(t)=\mathbf{y}(0)-\sum_{n=1}^{N-1}\mathbf{x}_{n}(t)$ to enforce the mixture constraint $\sum_{n=1}^{N}\mathbf{x}_{n}(t)=\mathbf{y}(0)$"
ICLR_2024_oral_53,1,L=L_{clip}+\lambdaL_{video},where video-paragraph contrastive loss \(\mathcal{L}_{\text{video}}\) explores the temporal correlations between the long video \(\mathbf{V}_{i}\) and its corresponding paragraph \(\mathbf{T}_{i}\) through a novel noise robust temporal optimal transport distance,"D=\left\{V_i,T_i\right\}_{i=1}^{N}",Defines the instructional video dataset as a collection of video-paragraph pairs indexed by instance number $i$.
ICLR_2024_oral_53,2,"\max_{Q\inQ}&\langleQ,\S\rangle+\varepsilon H(Q)\\s.t.&Q=\{Q\inR _{+}^{n\times m}\midQ1_{m}=\mu,Q^{\top}1_{n}=\nu\}","where \(\mathbf{1}_{m}\) represents the vector of ones in dimension \(m\), \(\boldsymbol{\mu}\in\mathbb{R}^{n}\) and \(\boldsymbol{\nu}\in\mathbb{R}^{m}\) indicate the relative importance of each clip or caption","\min_{Q\inU(n,m)}\langleQ,S\rangle","where $\mathcal{U}(n,m)$ denotes the set of all transport plans satisfying the marginal constraints, representing the optimal transport objective that minimizes the global alignment cost between video clips and captions."
ICLR_2024_oral_53,3,"Q^{*}&=Diag(\kappa_{1})\exp(S/\varepsilon)Diag(\kappa_{2}),\\with iteratively updated \kappa_{1}& arrow\mu./(\exp(S/\varepsilon)\kappa_{2}),\\kappa_{2}arrow\nu_{.}/(\exp(S^{\top}/\varepsilon)\kappa_{1})","where \(\boldsymbol{\kappa}_{1}\in\mathbb{R}^{n}\), \(\boldsymbol{\kappa}_{2}\in\mathbb{R}^{m}\) are the non-negative left and right scaling vectors",Q^{*}=diag(u)\exp\left(\frac{S}{\varepsilon}\right)diag(v),where $\mathbf{u}$ and $\mathbf{v}$ are the scaling vectors obtained through Sinkhorn iterations to satisfy the marginal constraints
ICLR_2024_oral_53,4,"L_{video}=-\sum_{i=1}^{N}(\log\frac{\exp((Q_{ii},\S_{ii})/\tau)}{\sum_{j=1}^{N}\exp((Q_{ ij},\S_{ij})/\tau)}+\log\frac{\exp((Q_{ii},\S_{ii})/\tau)}{\sum_{j=1}^{N}\exp((Q_{ ji},\S_{ji})/\tau)})","where \(\mathbf{S}_{ij}\in\mathbb{R}^{n\times m}\) is the clip-caption similarity matrix between video \(\mathbf{V}_{i}\) and paragraph \(\mathbf{T}_{j}\), \(\mathbf{Q}_{ij}\) is the corresponding transport assignment of \(\mathbf{S}_{ij}\), and \(\tau\) is a learnable temperature initialized as 0","L_{video}=-\log\frac{\exp(-d_{OT}(V_i,T_i)/\tau)}{\sum_{T_j\inB}\exp(-d_{OT}(V_i,T_j)/\tau)}","where $d_{\text{OT}}(\mathbf{V}_i, \mathbf{T}_i)$ denotes the optimal transport distance between video $\mathbf{V}_i$ and its corresponding paragraph $\mathbf{T}_i$, and $\tau$ is a temperature parameter controlling the concentration level of the exponential distribution over the distances."
ICLR_2024_oral_53,5,"[S]_{a,b}=\frac{1}{2}(\frac{1}{f}\sum_{i=1}^{f}\alpha\log(\sum_{j=1}^{w}\exp(\frac{v_{a}^{i}\cdott_{b}^{j}}{\alpha}) )+\frac{1}{w}\sum_{i=1}^{w}\alpha\log(\sum_{j=1}^{f}\exp(\frac{t_{b}^{i}\cdotv_{a}^{j}}{\alpha})))",,"S_{a,b}^{fine}=\log\sum_{j=1}^{f}\sum_{k=1}^{w}\exp\left(\frac{v_{a}^{j}\cdott_{b}^{k}}{\sigma}\right)","where $\mathcal{S}_{a,b}^{\text{fine}}$ represents the fine-grained similarity between frame $j$ in clip $\mathbf{v}_{a}$ and word $k$ in caption $\mathbf{t}_{b}$, computed using a log-sum-exp operator with temperature parameter $\sigma$"
ICLR_2024_oral_53,6,"[\bar{S}]_{a,m+1}=[\bar{S}]_{n+1,b}=[\bar{S}]_{n+1, m+1}=p,\,[\bar{S}]_{a,b}=[S]_{a,b},\\forall a\in[1,n],\b\in[1,m]",,\tilde{S}=S & p1_{n}\\p1_{m}^{\top} & p\inR^{(n+1)\times(m+1)},where $\tilde{\mathbf{S}}$ represents the augmented similarity matrix with an additional alignable prompt bucket to filter out irrelevant clips or captions during optimal transport computation
ICLR_2024_oral_53,7,"\max_{\hat{Q}\in\hat{Q}}\\\\langle\hat{Q},\\hat{S}\rangle+\varepsilon H(\hat{Q})\\\\s.t.\\\\hat{Q}=\{\hat{Q}\inR^{B\times B}_{+}\mid\hat{Q}1_{B}=\frac{1}{B}1_{B},\hat{Q}^{\top}1_{B}=\frac{1}{B}1_{B}\}",where the transport assignment \(\hat{\mathbf{Q}}\) attempts to realign the clips with similar captions (_i,"\max_{\hat{Q}\in\hat{Q}}&\langle\hat{Q},\\hat{S}\rangle+\varepsilon H(\hat{Q})\\s.t.&\hat{Q}=\{\hat{Q}\inR_{+}^{B\times B}\mid\hat{Q}1_{B}=\hat{\mu},\\hat{Q}^{\top}1_{B}=\hat{\nu}\}","where $\hat{\boldsymbol{\mu}},\hat{\boldsymbol{\nu}}\in\mathbb{R}^{B}$ are the marginal distributions over clips and captions in the batch, and $\varepsilon$ controls the entropy regularization strength"
ICLR_2024_oral_53,8,"L_{clip}=-\sum\limits_{i=1}^{B}\sum\limits_{j=1}^{B}[ T]_{i,j}(\log\frac{\exp([\hat{S}]_{i,j}/\tau)}{\sum_{k=1}^{B}\exp([\hat{S}]_{i,k}/\tau)}+\log\frac{\exp([\hat{S}]_{i,j}/\tau)}{\sum_{k=1}^{B}\exp([\hat{S}]_{i,j}/\tau)}),T=(1-\beta )\,I_{B}+\beta\hat{Q}^{*}",where \(\beta\) is a weighted parameter that balances the identity target \(\mathbf{I}_{B}\) and realigned targets \(\hat{\mathbf{Q}}^{*}\),"L_{clip}=-\frac{1}{B}\sum_{i=1}^{B}\sum_{j=1}^{B}[\hat{Q}^{*}]_{i,j}\log\frac{\exp(\hat{S}_{i,j}/\tau)}{\sum_{k=1}^{B}\exp(\hat{S}_{i,k}/\tau)}",where $\mathcal{L}_{\text{clip}}$ leverages the realigned targets from optimal transport to provide enhanced supervision by exploiting faulty negatives in the contrastive learning framework
ICLR_2024_oral_54,1,"\min_{S\inR^{N\times d}}D(\nabla_{\theta}\ell(S;\theta),\nabla_{\theta}\ell(B;\theta))=D( S,B;\theta)","where the function \(D(\cdot)\) is defined as a distance metric such as MSE, \(\theta\) represents the model parameters, and \(\nabla_{\theta}\ell(\cdot)\) denotes the gradient, utilizing either the big dataset \(\mathcal{B}\) or its synthetic version \(\mathcal{S}\)",\min_{S}\left\|\nabla_{\theta}L(\theta;B)-\nabla_{\theta}L(\theta;S)\right\|_2^2,Equation 1 formulates the optimization objective to minimize the squared L2 norm of the gradient difference between the original dataset $\mathcal{B}$ and the synthetic dataset $\mathcal{S}$ with respect to the model parameters $\theta$.
ICLR_2024_oral_54,2,"SarrowS-\lambda\nabla_{S}D( S,B;\theta),\quad\thetaarrow\theta-\eta\nabla_{\theta}\ell(\theta;S)","where \(\lambda\) and \(\eta\) are learning rates designated for \(\mathcal{S}\) and \(\theta\), respectively","\theta^{(t+1)}=\theta^{(t)}-\eta\nabla_{\theta}\ell(S^{(t)};\theta^{(t)}),\quadS^{(t+1)}=S^{(t)}-\gamma\nabla_{S} D(S^{(t)},B;\theta^{(t)})","where $\theta^{(t)}$ and $\mathcal{S}^{(t)}$ denote the model parameters and synthetic dataset at iteration $t$, and $\eta$ and $\gamma$ are the respective learning rates for model and data updates."
ICLR_2024_oral_54,3,"\min_{S\inR^{N\times d}}D(\nabla_{\theta }\ell(S_{[1]},S_{[2]},\ldotsS_{[N]};\theta ),\nabla_{\theta}\ell(B;\theta))","where \(\mathcal{S}_{[n]}=\mathcal{S}_{\{1,2,\ldots,n\}}\subset\mathcal{S}=\mathcal{S}_ {[N]}\) represents \(n_{th}\) subset of the synthetic dataset \(\mathcal{S}\in\mathbb{R}^{N\times d}\)","\min_{S\inR^{N\times d}}\sum_{n=1}^{N}D(\nabla_{\theta}\ell(S_{[n]};\theta),\nabla_{\theta}\ell(B;\theta))","where $\mathcal{S}_{[n]}$ denotes the subset of the synthetic dataset $\mathcal{S}$ with size $n$, and the objective is to minimize the gradient distance between each subset of $\mathcal{S}$ and the original dataset $\mathcal{B}$"
ICLR_2024_oral_54,4,"SarrowS-\lambda(\nabla_{S}D(S,B;\theta)+\nabla_{S_{[n]}}D(S_{[n]},B;\theta)),\hskip 14.226378ptn\in[1,N-1]","where \(\mathcal{S}=\mathcal{S}_{[N]}\) represents the condensed dataset of \(N\) images and is associated with the ""base loss""","\min_{S\inR^{N\times d}}D(\nabla_{\theta}\ell(S_{[N]};\theta),\nabla_{\theta}\ell(B;\theta))+\gamma\sum_{n=1}^{N-1}D(\nabla_{\theta}\ell(S_{[n]};\theta),\nabla_{\theta}\ell(B;\theta))","where the first term is the ""base loss"" for the full synthetic dataset $\mathcal{S}_{[N]}$ and the second term is the ""subset loss"" that incorporates information from all smaller subsets $\mathcal{S}_{[n]}$ with $n < N$, weighted by $\gamma$."
ICLR_2024_oral_54,5,"F_{t}(S_{[n]},B)=D(f_{t}(S _{[n]}),f_{t}(B))","where \(f_{t}(\cdot)\) is the feature extraction function for \(t_{th}\) condensation iteration, and \(D(\cdot)\) is a distance metric like MSE","d_{t}(S_{[n]},B)=\frac{1}{d}\|\mu(S_{[n]})-\mu(B)\|_{2}^{2}+Tr(\Sigma(S_{[n]})+\Sigma(B)-2(\Sigma(S_{[n]})\Sigma(B))^{1/2})","where $d$ is the feature dimension, $\mu(\cdot)$ and $\Sigma(\cdot)$ denote the mean and covariance of features, respectively, and $\text{Tr}(\cdot)$ represents the trace of a matrix"
ICLR_2024_oral_54,6,"F_{t}(S_{[p]},B)>F_{t}(S_{[q]},B),\;\;if\;\;\;1<p<q<N",,"F_{t}(S_{[p]},B) > F_{t}(S_{[q]},B)","where $F_{t}(\cdot)$ denotes the feature distance at condensation iteration $t$, and $\mathcal{S}_{[p]}$, $\mathcal{S}_{[q]}$ are subsets of sizes $p$ and $q$ respectively, with $p < q$."
ICLR_2024_oral_54,7,"\underbrace{F_{t-\Delta t}(S_{[p]},B)>F_{t} (S_{[p]},B)}_{p},\;\;\underbrace{F_{t-\Delta t }(S_{[q]},B)>F_{t}(S_{[q]},B)}_{q}",where \(t-\Delta t\) and \(t\) are two different time points for the condensation process,"F_{t}(S_{[p]},B)-F_{t}(S_{[q]},B)>F_{t+1}(S_{[p]},B)-F_{t+1}(S_{[q]},B),\;\;if\;\;\;1<p<q<N",Equation 7 illustrates that the difference in feature distances between smaller and larger subsets decreases as the condensation process progresses.
ICLR_2024_oral_54,8,"R(S_{[n]},t)=\frac{\Delta F_{S_{[n]}}}{\Delta t}=\frac{ |F_{t}(S_{[n]},B)-F_{t-\Delta t}(S_{[n]},B)|}{\Delta t}","where \(R(\mathcal{S}_{[n]},t)\) represents the rate of change of feature distance for subset \(\mathcal{S}_{[n]}\) at the time point \(t\), and \(\Delta F_{\mathcal{S}_{[n]}}\) denotes the change in feature distance of subset \(\mathcal{S}_{[n]}\) from time \(t-\Delta t\) to \(t\)","r_{t}(S_{[n]},B)=\frac{F_{t-\Delta t}(S_{[n]},B)-F_{t}(S_{[n]},B)}{F_{t-\Delta t}(S_{[n]},B)}","where $r_{t}(\mathcal{S}_{[n]},\mathcal{B})$ represents the feature distance reduction rate for subset $\mathcal{S}_{[n]}$ at iteration $t$, measuring how quickly the subset becomes more representative relative to the big dataset $\mathcal{B}$."
ICLR_2024_oral_54,9,"S_{MLS}(t)=S_{[n_{t}^{*}]}=\operatorname*{arg\, max}_{S_{[n]}}(R(S_{[n]},t))\;\; where\;\;n\in[1,N-1]",,"S_{[n^{*}]}=\arg\max_{S_{[n]}\subsetS}R(S_{[n]},t),\quad n^{*}\in[1,N-1]","The Most Learnable Subset (MLS) at time $t$ is the subset $\mathcal{S}_{[n^{*}]}$ that maximizes the feature distance reduction rate $R(\mathcal{S}_{[n]},t)$ among all subsets $\mathcal{S}_{[n]}\subset\mathcal{S}$ with $n^{*}\in[1,N-1]$."
ICLR_2024_oral_54,10,{l}Using Eq.~{\ref{eq:mLS} to~{}}Update&S\\Update&S\setminusS_{MLS}(t-\Delta t)if\;S_{MLS}(t)\supsetS_{MLS}(t-\Delta t),where \(\setminus\) is the symbol for set minus,"S\leftarrowS-\lambda\left(\nabla_{S} D(S,B;\theta)+I_{\{n_t^*\ne n_{t-\Delta t}^*\}}\cdot\nabla_{S_{[n_t^*]}} D(S_{[n_t^*]},B;\theta)\right)",where $\mathbb{I}_{\{n_t^* \ne n_{t-\Delta t}^*\}}$ is an indicator function that activates the subset loss term only when the MLS changes in size compared to the previous iteration.
ICLR_2024_oral_55,2,"\operatorname*{arg\,max}_{\alpha,\phi}\prod_{\bar{D}_{test}} p(Y_{Q}|f_{\alpha,\phi}(S,X_{Q}))",,"\operatorname*{arg\,max}_{\theta,\alpha}\prod_{\bar{D}_{test}}p(Y_{Q}|f_{\theta,\alpha}(S,X_{Q}))","Equation 2 reformulates the optimisation objective for meta-test by considering both the transferred parameters $\theta$ and the adapter parameters $\alpha$ in the classifier function $f_{\theta,\alpha}$."
ICLR_2024_oral_55,3,"g_{\phi,\phi^{\prime},\alpha}(x)=g_{\phi,\phi^{\prime}}(x)+h_{\alpha}(x)","where \(x\in\mathbb{R}^{W,H,C}\)","\tilde{g}_{\alpha,\phi}(x)=g_{\phi}(x)+h_{\alpha}(x)","where the adapted layer output is the sum of the original layer output and the adapter output, enabling task-specific adaptation through residual connections."
ICLR_2024_oral_55,4,"g_{\phi,\phi^{\prime},\alpha}(x)=z(A_{qkv}[q\;;\;g_{\phi,\phi^{\prime}}(x)]+h _{\alpha 1})+h_{\alpha 2}",where \(x\in\mathbb{R}^{D}\) and \([\cdot\;;\;\cdot]\) denotes the concatenation operation,"g_{\phi,\phi^{\prime},\alpha}(x)=Prefix_{\alpha}(A_{qkv}(x)) &for query, key, value,\\A_{qkv}(x)+Residual_{\alpha}(A_{qkv}(x)) &for attention output,\\z(x)+Residual_{\alpha}(z(x)) &for feed-forward output","Equation 4 defines the adaptation architecture for ViTs using ETT, where tunable prefixes and residual adapters are applied to different components of the self-attention and feed-forward modules."
ICLR_2024_oral_55,5,"L(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\log\frac{e^{-d_{cos}(C_{Q_{i}},f(Q_{i}))}}{\sum_{j=1}^{|C|}e^{-d_{cos}(C_{j},f(Q_{cj}))}}","where \(C_{\mathcal{Q}_{i}}\) denotes the embedding of the class centroid that corresponds to the true class of \(\mathcal{Q}_{i}\), and \(d_{cos}\) denotes the cosine distance","\min_{\alpha,\phi^{\prime}}E_{\bar{D}_{train}}[L(f_{\theta,\alpha,\phi^{\prime}},S,Q)]","where the supernet is trained by minimizing the expected prototypical loss over meta-train tasks, with frozen backbone parameters $\theta$ and learnable adapter/fine-tuned parameters $\alpha,\phi^{\prime}$"
ICLR_2024_oral_55,6,"\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}\E_{p\sim P}E_{S,Q}\L(f^{p}_{\theta,\alpha,\phi^{\prime}},S,Q)",,"\min_{\alpha,\phi^{\prime}}E_{p\sim P}\left[L(f^{p}_{\theta,\alpha,\phi^{\prime}},S,Q)\right]",The supernet training objective minimises the expected prototypical loss over all possible paths sampled from the search space.
ICLR_2024_oral_55,7,"p_{k}=\operatorname*{arg\,max}_{p\in P}E_{S,Q}A(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}},S,Q),\quads.t || \alpha^{*},\phi^{\prime*}=\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}L(f^{p} _{\theta,\alpha,\phi^{\prime}},S,S)",,"\forall n\in\{1,...,N\},\p_{n}\in P\quadand\quad p_{n}\neq p_{m}\\forall n\neq m",Ensuring that each selected path $p_n$ is unique and belongs to the set of all possible paths $P$.
ICLR_2024_oral_55,8,"\quad\forall_{j=1,\dots,k-1}\\d_{cos}(p_{k},p_{j})\geq T",,"A(f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}},S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}\log\frac{e^{-d_{cos}(C_{Q_{i}},f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}}(Q_{i}))}}{\sum_{j=1}^{|C|}e^{-d_{cos}(C_{j},f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}}(Q_{j}))}}","Equation 8 defines the adaptation performance $A$ of a path $p$ on a query set $\mathcal{Q}$, using the cosine distance between class centroids and embeddings of query examples, similar in structure to the prototypical loss in Equation 5 but conditioned on the supernet path $f^{p}_{\theta,\alpha^{\prime},\phi^{\prime\prime}}$."
ICLR_2024_oral_55,9,"A(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}[\operatorname*{arg\,min}_{j}d_{cos}(C_{Q_{j}},f(Q_{i}))=Y_ {Q_{i}}]",,"\quad A(f,S,Q)=\frac{1}{|Q|}\sum_{i=1}^{|Q|}I\left[\operatorname*{arg\,min}_{j} d_{cos}(f(Q_i), C_j)\right]","Classification accuracy of a nearest centroid classifier (NCC), where $\mathbb{I}[\cdot]$ is the indicator function that evaluates to 1 if the predicted class matches the true class, and 0 otherwise."
ICLR_2024_oral_55,10,"p^{*}=\operatorname*{arg\,min}_{p\in\{p_{1},...,p_{N}\}}L(f^{p}_{O_{\alpha^{*}},\phi^{\prime\prime*}},S,S),\quads.t || \alpha^{*},\phi^{\prime*}=\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}L(f^{p}_{O,\alpha,\phi^{\prime}},S,S)",,"p^{*}=\operatorname*{arg\,max}_{p\in\{p_{1},...,p_{N}\}}A(f^{p}_{\theta,\alpha^{*},\phi^{\prime*}},S,Q),\quadwhere\\alpha^{*},\phi^{\prime*}=\operatorname*{arg\,min}_{\alpha,\phi^{\prime}}L(f^{p}_{\theta,\alpha,\phi^{\prime}},S,S)","Final path selection during meta-testing based on accuracy maximisation over pre-selected models, with parameters fine-tuned on the given support set."
ICLR_2024_oral_56,1,"\vec{x}_{n}&=A\vec{x} _{n-1}+Bu_{n}&A\inC^{N\times N},B\inC^{N\times 1}\\y_{n}&=C\vec{x}_{n}&C\inC^{1\times N}",,"\vec{x}_{n+1}=A\vec{x}_{n}+B u_{n},\quad y_{n}=C\vec{x}_{n}+D u_{n}",Equation 1: State Space Model (SSM) equations describing the linear recurrence for hidden state evolution and output generation.
ICLR_2024_oral_56,2,A=A-PQ^{\star} || \bar{A}=(I-\Delta/2\cdotA)^{-1}(I+\Delta/2\cdotA),,"A &\leftarrowdiag(\lambda_{1},\lambda_{2},\dots,\lambda_{N})\quadwith \lambda_{i}\inC\\B &\leftarrowdiag(b_{1}, b_{2},\dots, b_{N})\quadwith  b_{i}\inC\\C &\leftarrowdiag(c_{1}, c_{2},\dots, c_{N})\quadwith  c_{i}\inC","Equation 2 introduces the diagonal parameterization of the state-space matrices used in S4, where each matrix is represented as a diagonal matrix with complex entries, simplifying the model while preserving performance."
ICLR_2024_oral_56,3,\bar{B}=(I-\Delta/2\cdotA)^{-1}\DeltaB\quad\bar{C}=C,,\bar{B}=\sqrt{\Delta}(I-\Delta/2\cdotA)^{-1}B,"Equation 3 defines the transformed input matrix $\mathbf{\bar{B}}$ in the S4 parameterization, scaled by the square root of the step size $\Delta$ and modified through the resolvent of the matrix $\mathbf{A}$."
ICLR_2024_oral_56,4,K_{k}=\bar{C}^{T}\bar{A}^{k}\bar{B},"where \(\mathbf{A},\mathbf{P},\mathbf{Q},\mathbf{B},\mathbf{C},\Delta\) are learnable parameters and \(\mathbf{A}\in\text{{Diag}}(\mathbb{C}^{N\times N}),\mathbf{P},\mathbf{Q}\in\mathbb{C}^{N \times 1}\)",\vec{x}_{n}&=\bar{A}\vec{x}_{n-1}+\bar{B}u_{n}\\y_{n}&=\bar{C}\vec{x}_{n},"Discretized state-space model using the transformed parameters $\bar{\mathbf{A}}$, $\bar{\mathbf{B}}$, and $\bar{\mathbf{C}}$ derived from the continuous-time formulation."
ICLR_2024_oral_56,5,"\vec{x}_{n}&=A\vec{x} _{n-1}+I\,u_{n}&A\in{diag}(C^{N\times N })\\y_{n}&=C\vec{x}_{n}&C\inC^{1\times N}",where \(\mathbf{I}\) is the all-ones vector,\vec{x}_{n} &=\lambda\vec{x}_{n-1}+\beta u_{n}\\y_{n} &=\gamma^{\top}\vec{x}_{n},"Diagonal Linear RNN (DLR) formulation with scalar state transition coefficient $\lambda$, input scaling $\beta$, and output projection $\gamma$."
ICLR_2024_oral_58,2,"\rho_{(i,j),(a,b)}\triangleqE_{(x,y)\simG}[(\upsilon_{i,a}(x)-\mu_{i,a})(\upsilon_{j,b}(x)-\mu_{j,b}) ](\sigma_{i,a}\\sigma_{j,b})^{-1}",,"\rho_{i,j}^{(a,b)}\triangleq\frac{E_{(x,y)\simG}\left[(\upsilon_{i,a}(x)-\mu_{i,a})(\upsilon_{j,b}(x)-\mu_{j,b})\right]}{\sigma_{i,a}\sigma_{j,b}}",Defines the correlation between the $a^{\text{th}}$ feature of model $f_i$ and the $b^{\text{th}}$ feature of model $f_j$.
ICLR_2024_oral_58,3,Acc=p_{d}(1-\frac{1}{2}\binom{t_{d}-c_{d}}{a_{d}}\\\binom{t_{d}}{a_{d}}^{+}p_{r}(1-\frac{1}{2}\binom{t_{r}-c_{r}}{c_{r}}\\\binom{t_{r}}{c_{r}}),,Acc=\frac{1}{2}\left[1-\left(p_{d}\left(1-\frac{c_{d}}{t_{d}}\right)^{n_{d}}+p_{r}\left(1-\frac{c_{r}}{t_{r}}\right)^{n_{r}}\right)\right],"The expected accuracy is derived based on the overlap between features of a model and a data point, considering dominant and rare features separately and their respective probabilities of being learned by the model."
ICLR_2024_oral_59,1,\Pr[A(D)\in R]\leq e^{\epsilon}\Pr[A(D^{\prime})\in R]+\delta,,\Pr[A(D)\in R]\leq e^{\epsilon}\cdot\Pr[A(D^{\prime})\in R]+\delta,"Probability bound defining user-level $(\epsilon,\delta)$-differential privacy for algorithm $A$ over output regions $R$."
ICLR_2024_oral_59,2,"\hat{\epsilon}=\max\{\log\frac{1-\delta-FPR}{FNR},\log\frac{1-\delta-FNR}{FPR}\}",,\epsilon=\log\left(\frac{FNR}{1-FPR}\right),Characterization of the privacy parameter $\epsilon$ in terms of the false negative rate (FNR) and the false positive rate (FPR) for a hypothesis test distinguishing datasets $D$ and $D^{\prime}$.
ICLR_2024_oral_59,3,f_{d}(t)=\frac{\Gamma(\frac{d}{2})}{\Gamma(\frac{d-1}{2})\sqrt{\pi}}(1-t^{2})^{\frac{d-3}{2}},,"f_{\tau_{d}}(t)=\frac{\Gamma\left(\frac{d}{2}\right)}{\sqrt{\pi}\Gamma\left(\frac{d-1}{2}\right)}(1-t^{2})^{\frac{d-3}{2}},\quad t\in[-1,1]",
ICLR_2024_oral_6,1,"\epsilon_{k}(x)\mathop{=}^{def}u_{k}(\texttt{BR}_{k},x_{-k})-u_{k}(x) where \texttt{BR}_{k}\in\operatorname*{arg\,max}_{z}u_{k}(z,x_{-k})",,L(\theta)=\sum_{i=1}^{N}\left\|\nabla_{\theta_i} J_i(\theta)\right\|^2,"Equation 1 defines a loss function $\mathcal{L}(\theta)$ that measures the squared norm of the gradients of each player's cost function $J_i(\theta)$ with respect to their own parameters $\theta_i$, summed over all players $N$."
ICLR_2024_oral_6,2,L(x)=\sum_{k}\eta_{k} || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || ^{2},"where each \(\eta_{k}>0\) represents a scalar weight, or equivalently, a step size to be explained next",L(x)=\sum_{k}\left\|\nabla_{x_{k}} u_{k}(x)\right\|^2,"Proposed loss function measuring the squared norm of the projected gradient for each player, which is amenable to unbiased estimation under sampled play."
ICLR_2024_oral_6,3,\epsilon_{k}(x)\leq\sqrt{2} || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || ,,\epsilon_{k}(x)\leq\frac{1}{2\eta_{k}} || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}) || ^{2},"This inequality provides an upper bound on the exploitability $\epsilon_{k}(\mathbf{x})$ in terms of the squared norm of the projected-gradient, scaled by the step size $\eta_{k}$."
ICLR_2024_oral_6,4,\epsilon\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L(x)}\stackrel{{\tiny def}}{{=}}f(L),,\epsilon(x)\leq\sqrt{2L(x)},"This lemma provides an upper bound on the exploitability of a joint strategy in terms of the loss function $\mathcal{L}(\mathbf{x})$, showing that smaller values of $\mathcal{L}$ correspond to strategies that are closer to being Nash equilibria."
ICLR_2024_oral_6,5,L(x)=E[\sum_{k}\eta_{k}\underbrace{(\hat{\nabla}_{x_{ k}}^{k(1)}-\frac{1}{m_{k}}(1^{\top}\hat{\nabla}_{x_{k}}^{k(1)}))}_{ projected-gradient 1})^{\top}(\underbrace{\hat{\nabla}_{x_{k}}^{k(2)}-\frac{1}{m_{k}}(1^{\top}\hat{\nabla}_{x_{k}}^{k(2)})1)}_{projected-gradient 2}),where \(\hat{\nabla}^{k(p)}_{x_{k}}\) is an unbiased estimator of player \(k\)'s gradient,"E[\langle\Pi_{T\Delta}(\nabla_{x_{k}}^{k(1)}),\Pi_{T\Delta}(\nabla_{x_{k}}^{k(2)})\rangle]= || \Pi_{T\Delta}(E[\nabla_{x_{k}}^{k}]) || ^{2}","Lemma 5 shows that the squared norm of the projected-gradient can be estimated unbiasedly using two independent gradient estimates, enabling unbiased estimation of the loss function $\mathcal{L}(\mathbf{x})$ under mixed strategies."
ICLR_2024_oral_6,6,L^{\tau}(x)=\sum_{k}\eta_{k} || \Pi_{T\Delta}(\nabla^{k\tau}_{x_ {k}}) || ^{2},,L^{\tau}(x)=\sum_{k}\eta_{k} || \Pi_{T\Delta}(\nabla_{x_{k}}^{k}+\tau\frac{dS}{dx_{k}}) || ^{2},"This equation defines the entropy-regularized loss function $\mathcal{L}^{\tau}(\mathbf{x})$, where the gradient of player $k$'s utility is augmented with the derivative of the entropy term, ensuring all equilibria are interior and maintaining unbiased estimation properties."
ICLR_2024_oral_6,7,\epsilon_{QRE}\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L^{\tau}(x)}\overset{\tiny{def}}{=}f(L^{\tau}),,\epsilon_{QRE}\leq\sqrt{\frac{2n}{\min_{k}\eta_{k}}}\sqrt{L^{\tau}(x)}+\tau C,
ICLR_2024_oral_6,8,\epsilon\leq\tau\log\Big{(}\prod_{k}m_{k}\Big{)}+\sqrt{\frac{2n}{\min_{k}\eta_ {k}}}\sqrt{L^{\tau}(x)}\overset{\tiny{def}}{=} f_{\tau}(L^{\tau}),,\lim_{\tau\rightarrow 0}L^{\tau}(x)=L(x),Describing the convergence of the entropy-regularized loss to the original loss as the temperature parameter approaches zero.
ICLR_2024_oral_6,9,\nabla_{x_{l}}L^{\tau}(x)=2\sum_{k}\eta_{k}B_{kl}^{\top}\Pi_{T\Delta}(\nabla_{x_{k}}^{kT}),,\nabla_{x_{l}}L^{\tau}(x)=\sum_{k}\eta_{k}\Big{(}\Pi_{T\Delta}(\nabla^{k\tau}_{x_{k}})\Big{)}^{\top}\frac{\partial}{\partial x_{l}}\Big{(}\Pi_{T\Delta}(\nabla^{k\tau}_{x_{k}})\Big{)},"The gradient of the entropy-regularized loss function with respect to a player's strategy, capturing how changes in that player's strategy affect the overall loss through the projected gradient of each player."
ICLR_2024_oral_6,10,\textsl{Hess}(L^{\tau})=2\big{[}\tilde{B}^{\top}\tilde{B}+T\Pi_{T\Delta}(\tilde{\nabla}^{\tau})\big{]},,\nabla^{2}_{x_{l}x_{m}}L^{\tau}(x)=2\sum_{k}\eta_{k}\Big{(}B_{kl}^{\top}B_{km}\Pi_{T\Delta}(\nabla_{x_{k}}^{k\tau})+B_{kl}^{\top}\Pi_{T\Delta}(H^{k}_{km})\Big{)},where $B_{kl}$ is defined as in Equation 10 and $H^{k}_{km}$ represents the Hessian of player $k$'s entropy-regularized utility with respect to player $m$'s strategy.
ICLR_2024_oral_6,11,"M(x)=-\sqrt{\eta_{1}}\Pi_{T\Delta}(\frac{1}{x_{1}})&\sqrt{\eta_{1}}\Pi_{T\Delta}(H^{1}_{12})&\ldots&\sqrt{\eta_{1}}\Pi_{T\Delta}(H^{1}_{ 1n})\\\vdots&\vdots&\vdots&\vdots\\\sqrt{\eta_{n}}\Pi_{T\Delta}(H^{n}_{n1})&\ldots&\sqrt{\eta_{n}}\Pi_{T\Delta}( H^{n}_{n,n-1})&-\tau\sqrt{\eta_{n}}\Pi_{T\Delta}(\frac{1}{x_{n}})\\1_{1}^{\top}&0&\ldots&0\\\vdots&\vdots&\vdots&\vdots\\0&\ldots&0&1_{n}^{\top}",where \(\Pi_{T\Delta}(z\in\mathbb{R}^{n\times b})=[I_{a}-\frac{1}{a}\mathbf{_{1}}\mathbf{_{ 1}}^{\top}]z\) subtracts the mean from each column of \(z\) and \(\frac{1}{x_{k}}\) is shorthand for \(\texttt{diag}\big{(}\frac{1}{x_{k}}\big{)}\),\textsl{Hess}(L^{\tau})=2\big{[}\tilde{B}^{\top}\tilde{B}+T\Pi_{T\Delta}(\tilde{\nabla}^{\tau})\big{]},"where $\tilde{B}_{kl}=\sqrt{\eta_{k}}B_{kl}$, $\Pi_{T\Delta}(\tilde{\nabla}^{\tau})=[\eta_{1}\Pi_{T\Delta}(\nabla^{1\tau}_{x _{1}}),\ldots,\eta_{n}\Pi_{T\Delta}(\nabla^{n\tau}_{x_{n}})]$, and we augment $T$ (the $3$-player approximation to the game, $T^{k}_{lqk}$) so that $T^{l}_{ll}=\tau\texttt{diag}3\big{(}\frac{1}{x_{l}^{2}}\big{)}$."
ICLR_2024_oral_60,1,y_{i}^{\prime}=I_{\tau}(h)(x_{i}),,y_i'=I_{\tau}(h)(x_i),"This equation formalizes the application of the interpreted rule $I_{\tau}(h)$ to input $x_i$, producing the predicted output $y_i'$ for unseen examples in the rule induction task."
ICLR_2024_oral_60,2,"a_{\tau}=\frac{1}{|D_{\tau}^{u}|}\sum_{(x,y)\inD_{\tau}}\mathbbm{1}\big{[}I_{\tau}(h)(x)=y\big{]}",,"Accuracy_{\tau}(h)=\frac{1}{|D_{\tau}^{u}|}\sum_{(x,y)\inD_{\tau}^{u}}1\left(I_{\tau}(h)(x)=y\right)",Equation 2 defines the accuracy of a rule $h$ on a task $\tau$ as the fraction of unseen examples in $\mathcal{D}_{\tau}^{u}$ for which the interpreter $I_{\tau}(h)$ correctly predicts the output $y$.
ICLR_2024_oral_60,3,c=\frac{1}{|T|}\sum_{\tau\inT}a_{\tau}\hskip 28.452756ptc_{t}=\frac{1}{|T|}\sum_{\tau\inT}\mathbbm{1}\big{[}a_{\tau}=1\big{]},,"c=\frac{1}{|T|}\sum_{\tau\inT} a_{\tau},\quad c_{t}=\frac{1}{|T|}\sum_{\tau\inT}\mathbbm{1}[a_{\tau}=1]","Raw accuracy $c$ is the average task accuracy across all tasks, while task accuracy $c_t$ is the fraction of tasks where the rule achieves perfect accuracy."
ICLR_2024_oral_60,4,"h^{t}\sim P_{LM}\big{(}\cdot\,|d^{t-1},x_{1},y_{1},...,x_{k},y_{k})",where \(d^{t-1}\) is the feedback from previous iterations and which is set to be an empty string at the initial iteration,"H^{t}=\{h_{1}^{t},...,h_{N}^{t}\}\simLM(D_{\tau}^{s};\theta)","where $H^{t}$ denotes the set of $N$ hypotheses generated at iteration $t$ from a prompted language model parameterized by $\theta$, given the seen examples $\mathcal{D}_{\tau}^{s}$."
ICLR_2024_oral_60,5,"s(h,D_{\tau}^{s})=\frac{1}{|D_{\tau}^{s}|}\sum_{(x,y)\inD_{\tau}^{s}}\mathbbm{1}\big{[}I_{\tau}(h)(x)=y\big{]}",,"s(h,D_{\tau}^{s})=\frac{1}{|D_{\tau}^{s}|}\sum_{(x,y)\inD_{\tau}^{s}}\mathbbm{1}\big{[}I_{\tau}(h)(x)=y\big{]}",Scoring function for re-ranking hypotheses based on accuracy over seen examples.
ICLR_2024_oral_60,6,"h^{t^{*}}=\operatorname*{arg\,max}_{h^{\prime}\in H^{t}}s(h^{\prime}, D_{\tau}^{s})",,"h^{*}=\arg\max_{h\in H^{t}} s(h,D_{\tau}^{s})",The best hypothesis $h^{*}$ is selected by maximizing the scoring function $s$ over the set of hypotheses $H^{t}$ and the seen examples $\mathcal{D}_{\tau}^{s}$.
ICLR_2024_oral_61,1,"P(a_{t:t+k}|s_{t},s^{g})=\int_{s_{t+1},\ldots,s_{t+k}}ds_{t+1}\ldots ds_{t+k}\prod_{i=t}^{t+k}P_{\phi}(a_{i}|s_{i},s^{g})P(s_{i+1}|s_{i},a_{i})",where \(s^{g}\in S\) is the goal state,"P_{\phi}(a_t | s_t, g)=Transformer_{\phi}(s_t, g)",The goal-conditioned policy $P_{\phi}$ predicts the action $a_t$ at time $t$ given the current state $s_t$ and the goal state $g$ using a Transformer architecture parameterized by $\phi$.
ICLR_2024_oral_61,2,"L(\phi)=E_{D}[-\log P_{\phi}(a_{i}|s_{i},s^{g})]",,"L_{BC}=-\sum_{i=t}^{t+k}\log P_{\phi}(a_i | s_i, s^g)",where the loss is computed over the $k$-step subsequence with goal state $s^g = s_{t+k}$
ICLR_2024_oral_61,3,L(\psi)=E_{D}[-\log\pi^{p}_{\psi}(a^{h}|s_{t})],,L(\psi)=E_{D}[-\log\pi^{p}_{\psi}(a^{h}|s_{t})],The goal prior model is trained to predict the distribution of future goals given the current state using the clustered goal space $G$.
ICLR_2024_oral_61,4,"J(\theta)=E\pi_{\theta}[\sum_{t=0}^{\infty}\gamma^{t}(\sum _{i=kt}^{(k+1)t}R(s_{i},a_{i})-\alpha D_{KL}(\pi^{p}_{\psi}(a^{h }|s_{kt})\|\pi_{\theta}(a^{h}|s_{kt})))]",where \(t\) represents the number of steps for the high-level policy and \(\alpha\) is a hyperparameter balancing the environmental rewards and the intrinsic rewards,"J(\theta)=E_{\tau\sim\pi_{\theta}, P_{\phi}}\left[\sum_{t=0}^{T}\gamma^{t} (r_{t}+\beta\log\pi^{p}_{\psi}(a^{h}_{t} | s_{t}))\right]","where $r_t$ is the environment reward, $\beta$ controls the influence of the intrinsic reward from the goal prior model $\pi^{p}_{\psi}$, and $\gamma$ is the discount factor."
ICLR_2024_oral_63,1,p_{\theta}(x)\propto e^{-f_{\theta}(x)},,p_{\theta}(x)=\frac{1}{Z(\theta)}\exp(-f_{\theta}(x)),where $Z(\theta)$ is the partition function that normalizes the distribution.
ICLR_2024_oral_63,2,"x_{k+1}=x_{k}-\delta\,\nabla f_{\theta}(x_{k})+\sqrt{2\delta}\,\varepsilon_{k },\,\varepsilon_{k}\simN(0,I_{d})","where \(\nabla\) denotes the gradient of the energy function with respect to inputs, \(k\) is the sampling step, \(\delta\) is the (discretization) step size, and the noise \(\varepsilon_{k}\) is drawn from the normal distribution at each step",x_{t+1}=x_t-\epsilon\nabla f_{\theta}(x_t)+\sqrt{2\epsilon}\xi_t,"Discretized Langevin diffusion update rule for sampling from the EBM's Boltzmann distribution, where $\xi_t \sim \mathcal{N}(0, I)$ represents standard Gaussian noise and $\epsilon$ controls the step size."
ICLR_2024_oral_63,3,\hat{x}(y)=y+\sigma^{2}\nabla\log p(y),where \(p(y)=\int p(y|x)p(x)dx\) is the probability distribution function of the smoothed density,"\hat{x}(y)=E[X|Y=y]=y+\sigma^{2}\,\nabla\log p_{Y}(y)","where $\hat{x}(y)$ is the least-squares estimator of $X$ given the noisy observation $Y=y$, and $\nabla \log p_Y(y)$ is the score function of the noisy data distribution."
ICLR_2024_oral_63,4,\hat{x}_{\phi}(y)=y+\sigma^{2}g_{\phi}(y),,\hat{x}_{\phi}(y)=y+\sigma^{2}g_{\phi}(y),Parametric form of the least-squares estimator using a neural network parameterized score function $g_{\phi}(y)$
ICLR_2024_oral_63,5,"L(\phi)=E_{x\sim p(x),y\sim p(y|x)}\|x-\hat{x}_{\phi}(y)\|^ {2}",,\min_{\phi}E_{p(x)}E_{p(y|x)}\left[\left\Vert x-\hat{x}_{\phi}(y)\right\Vert ^{2}\right],The learning objective minimizes the expected squared error between the true data point $x$ and its estimate $\hat{x}_{\phi}(y)$ obtained from the noisy observation $y$.
ICLR_2024_oral_63,6,"\operatorname*{arg\,max}_{\theta}E_{y\sim p_{Y}}[\log p_{\theta}( y)]=\operatorname*{arg\,max}_{\theta}(E_{y^{-}\sim p_{Y}(y)}[f_{\theta}(y^{-})]-E_{y^{+}\sim p_{Y}}[f_{\theta}(y^{+})])",where \(y^{+}\) are noisy training data and \(y^{-}\) are noisy data sampled from the model,\log p_{\theta}(y)\propto-f_{\theta}(y),"where $p_{\theta}(y)$ denotes the model's distribution over noisy data $y$, and $f_{\theta}(y)$ is the energy function learned by the EBM."
ICLR_2024_oral_63,7,\nabla_{\theta}\log p_{\theta}(y)=-\nabla_{\theta}f_{\theta}(y)-\nabla_{\theta}\log Z(\theta) || =-\nabla_{\theta}f_{\theta}(y)+\frac{\int\nabla_{\theta}f_{\theta}(y)e^{-f_{\theta}(y)}dy}{Z(\theta)} || =-\nabla_{\theta}f_{\theta}(y)+\int\nabla_{\theta}f_{\theta}(y)\cdot p_{\theta}(y)dy || =-\nabla_{\theta}f_{\theta}(y)+E_{y\sim p_{\theta}(y)}[\nabla_{\theta}f_{\theta}(y)],,\frac{d}{d\theta}E_{y\sim p_{\theta}}[f_{\theta}(y)]=E_{y\sim p_{\theta}}[f_{\theta}(y)\nabla_{\theta}\log p_{\theta}(y)]+E_{y\sim p_{\theta}}[\nabla_{\theta}f_{\theta}(y)]-E_{y\sim p_{\theta}}[\nabla_{\theta}f_{\theta}(y)],This identity decomposes the gradient of the expected energy under the model distribution into terms that underpin the contrastive update rule for EBM training.
ICLR_2024_oral_63,8,"P^{\top}argmax\,\hat{x}(y,t)=P^{\top}s",,"y_{0}\simUnif([0,1]^{d})+N(0,\sigma^{2}I_{d})",Initialization of noisy samples with uniform and Gaussian noise.
ICLR_2024_oral_63,9,\chi_{ii^{\prime}}=\frac{ || X_{i}-X_{i^{\prime}} || }{2\sqrt{d}},where \(d\) is the dimension of the data and the \(\frac{1}{2\sqrt{d}}\) scaling comes from the concentration of isotropic Gaussians in high dimensions,\chi_{ij}=E_{x\sim p(x)}[(x_{i}-\mu_{i})(x_{j}-\mu_{j})],"The matrix $\chi$ represents the covariance between elements $i$ and $j$ of the discrete sequence data under the true data distribution, capturing the statistical dependencies across positions in the sequence."
ICLR_2024_oral_63,10,\sigma_{c}=\max_{ii^{\prime}}\chi_{ii^{\prime}},,\sigma_{c}=\min_{i\neq i^{\prime}}\chi_{ii^{\prime}},"The critical noise level $\sigma_{c}$ is defined as the minimum scaled distance between any pair of distinct data points $X_i$ and $X_{i'}$ in the dataset, where the scaling factor $\frac{1}{2\sqrt{d}}$ accounts for the concentration of measure phenomenon in high-dimensional isotropic Gaussian distributions."
ICLR_2024_oral_64,1,Z_{k}\subseteqR^{M}\quadand\quadZ=Z_{1}\times\dots\timesZ_{K}\subseteqR^{KM},,"Z=Z_1\timesZ_2\times\cdots\timesZ_K,\quadwhere Z_k\subseteqR^M for all  k=1, 2,\dots, K","This equation defines the factorization of the latent space $\mathcal{Z}$ into $K$ object-specific slots $\mathcal{Z}_k$, each of dimensionality $M$, forming the basis for object-centric latent representations in multi-object scenes."
ICLR_2024_oral_64,2,"x=f(z),\quadz\sim p_{z},\quadsupp(p_{z })=Z^{S}",,"z^{S}\simZ^{S},\quadx^{S}=f(z^{S})\inX^{S}",Latent and observed variables generated from the slot-supported subset $\mathcal{Z}^S$ during training.
ICLR_2024_oral_64,3,"L_{rec}(X^{S})=L_{rec}\big{(}\hat {g},\hat{f},X^{S}\big{)}:=E_{x\sim p_{x }}\big{[}\big{\|}\hat{f}\big{(}\hat{g}(x)\big{)}-x\big{\|} _{2}^{2}\big{]},\quadsupp(p_{x})=X^{S}",,"\min_{\hat{f},\hat{g}}E_{x\sim p_{x}}[\|x-\hat{f}\circ\hat{g}(x)\|^{2}],\quadsupp(p_{x})=X^{S}",The reconstruction objective minimizes the squared error between original and reconstructed data on the training space $\mathcal{X}^{S}$.
ICLR_2024_oral_64,4,"\frac{\partialf_{n}}{\partialz_{k}}(z)\neq 0\implies\frac{\partialf_{n}}{\partialz_{j}}(z)=0,\quadfor any $k,j\in[K]$, $k\neq j$ and any $n\in[N]$.",,"\forallz\inZ,\,\forall i\in[N],\,\exists!k\in[K]\, s.t. \,\frac{\partialf_{i}}{\partialz_{k}}(z)\neq0","The equation defines compositionality, requiring that each pixel in the generated image depends on exactly one latent slot, ensuring a localized and exclusive relationship between image regions and latent slots."
ICLR_2024_oral_64,5,"z^{\prime}=\big{(}h_{1}(z_{\pi(1)}),\ldots,h_{K}(z_{\pi(K)})\big{)},\quadZ^{\prime}=h_{1}(Z_{\pi(1)})\times\cdots\timesh_{K}(Z_{\pi(K)})",,"\hat{z}_{k}=h_{k}(z_{\pi(k)}),\quadfor all k\in[K]","This equation defines the inferred latent slots $\hat{\mathbf{z}}_{k}$ as diffeomorphic transformations of the ground-truth slots $\mathbf{z}_{\pi(k)}$, enabling compositional generalization across all combinations of slots in $\mathcal{Z}$."
ICLR_2024_oral_64,6,\hat{g}\big{(}f(z)\big{)}=z^{\prime}\quadand\quad\hat{f}(z^{\prime})=f(z),,"\hat{g}\big{(}f(z)\big{)}=z^{\prime}=\big{(}h_{1}(z_{\pi(1)}),\ldots,h_{K}(z_{\pi(K)})\big{)}","This equation formalizes the requirement for an autoencoder to generalize its slot identifiability from the slot-supported subset $\mathcal{Z}^{S}$ to the entire latent space $\mathcal{Z}$, by matching the inferred latent representation to the diffeomorphically transformed ground-truth slots."
ICLR_2024_oral_64,7,"\hat{f}(z)=\sum_{k=1}^{K}\varphi_{k}(\hat{z}_{k}),\quadwhere \varphi_{k}:R^{M}\toR^{N} for any k\in[K] and \hat{z}\inR^{KM}",,\hat{f}(z^{\prime})=\sum_{k=1}^{K}\hat{f}_{k}(z^{\prime}_{k}),"An additive decoder decomposes the reconstruction into independent slot-wise contributions, enabling invariance to slot combinations."
ICLR_2024_oral_64,8,"L_{cons}\big{(}\hat{g},\hat{f},Z^{\prime}\big{)}=E_{z^{\prime}\sim q_{z^{\prime}}}\Big{[}\big{\|}\hat{g}\big{(}\hat{f}(z^{\prime})\big{)}-z^{\prime}\big{\|} _{2}^{2}\Big{]}",,"L_{cons}\big{(}\hat{g},\hat{f},Z^{\prime}\big{)}:=E_{z^{\prime}\sim q_{z^{\prime}}}\big{[}\big{\|}\hat{g}\big{(}\hat{f}(z^{\prime})\big{)}-z^{\prime}\big{\|}_{2}^{2}\big{]}","This loss enforces that the encoder inverts the decoder on the full latent space $\mathcal{Z}^{\prime}$, ensuring compositional consistency between the inferred and ground-truth latents both in-distribution and out-of-distribution."
ICLR_2024_oral_64,9,"L_{rec}\big{(}\hat{g},\hat{f},X^{S}\big{)}+\lambdaL_{cons}\big{(}\hat{g},\hat{f},Z ^{\prime}\big{)}=0,\qquadfor some \lambda>0",,"\min_{\hat{g},\hat{f}}\Big{(}L_{rec}(X^{S})+\lambdaL_{cons}\big{(}\hat{g},\hat{f},Z^{\prime}\big{)}\Big{)},\quad\lambda>0","Equation 9 presents the joint optimization objective for training an autoencoder to achieve compositional generalization, combining the reconstruction loss on the training space and the compositional consistency regularizer on out-of-distribution latent combinations."
ICLR_2024_oral_64,10,"\hat{f}(z)=\sum_{k=1}^{K}\tilde{m}_{k}\odotx_{k},\qquad\tilde{m}_{k}=\sigma(m)_{k},\qquad(m_{k},x_{k})=\varphi _{k}(z_{k})",where \(\odot\) is an element-wise multiplication and \(\sigma(\cdot)\) denotes the softmax function,\hat{f}(z)=\sum_{k=1}^{K}m_{k}(z_{k})\odot\varphi_{k}(z_{k}),"An additive decoder with slot-wise masks, where each slot contributes independently to the final image through a mask and a slot function."
ICLR_2024_oral_64,11,h_{k}(z_{\pi(k)})=\hat{g}_{k}\big{(}f(z)\big{)}\quadand\quadZ^{\prime}=\hat{g}_{1}(X^{S})\times\cdots\times\hat{g}_{K}(X^{S}),,Z^{\prime}=\hat{z}_{1}(Z_{\pi(1)})\times\cdots\times\hat{z}_{K}(Z_{\pi(K)}),"where each inferred slot $\hat{\mathbf{z}}_{k}$ is defined over all possible configurations of the corresponding ground-truth slot $\mathcal{Z}_{\pi(k)}$, enabling OOD combinations through recombination of slot values."
ICLR_2024_oral_64,12,"z^{\prime}=\big{(}\hat{z}^{(\rho_{1})}_{1},\ldots,\hat{z}^{(\rho _{K})}_{K}\big{)},\quadwhere for i\in\{1,2\}\quad\hat{z}^{(i)}=\hat{g}\big{(}x^{(i)}\big{)},\,x^{(i)}\sim p_{z}",,"z^{\prime}_{k}=\hat{g}_{k}\big{(}f(z^{(\rho_{k})})\big{)}\quadfor \rho_{k}\simU\{1,2\}","Constructs out-of-distribution latent slots by randomly shuffling inferred in-distribution latent slots, enabling compositional consistency regularization."
ICLR_2024_oral_66,1,"\theta^{*}\:=\\operatorname*{arg\,min}_{\theta}\E_{(x,t,\ell(x,t),\cdot)\simH}\\Big{[}-\log p(\ell(x,t)\mid x,t,\hat{\ell}(x,t;\theta))\Big{]}",,"\theta^*=\argmin_{\theta}\frac{1}{n}\sum_{i=1}^{n}\left[\hat{\ell}(x_i, t_i;\theta)-\ell(x_i, t_i)\right]^2",Training the surrogate model by minimizing the mean squared error between predicted and observed performance values across all pipelines in the history.
ICLR_2024_oral_66,2,"\gamma^{*}\:=\\operatorname*{arg\,min}_{\gamma}\E_{(x,t,\cdot,c(x,t))\simH}\\Big{[}c(x,t)-\hat{c}(x,t;\gamma)\Big{]}^{2}",,"\gamma^{*}\:=\\operatorname*{arg\,min}_{\gamma}\E_{(x,t,\cdot, c(x,t))\simH}\\Big{[}L_{MAE}\left(c(x,t),\hat{c}(x,t;\gamma)\right)\Big{]}",where $\mathcal{L}_{\text{MAE}}$ denotes the mean absolute error loss function used to train the cost estimator $\hat{c}$ with parameters $\gamma$ on the observed runtime costs from the history $\mathcal{H}$.
ICLR_2024_oral_66,3,"x^{*}:=\operatorname*{arg\,max}_{x\inX}\frac{EI(x,H,\hat{\ell}(x,\tau(x)))}{\hat{c}\Big{(}x,\tau(x)\Big{)}{-}c\Big{(}x,\tau(x)-\Delta t\Big{)}}=\operatorname*{arg\,max}_{x\inX}\frac{E_{\hat{\ell}(x,\tau(x))}[\max(\ell_{\tau(x)}^{\min}-\hat{\ell}(x,\tau(x)),0)]}{\hat{c}\Big{(}x,\tau(x){-}c\Big{(}x,\tau(x){-}\Delta t\Big{)}}",,"\alpha_{EI-C}(x,t)=\frac{E_{\hat{\ell}}\left[\max\left(0,\ell_{best}-\hat{\ell}(x,t;\theta)\right)\right]}{\hat{c}(x,t;\gamma)}",The cost-sensitive Expected Improvement acquisition function balances performance improvement potential against training cost by normalizing the expected improvement with the predicted cost.
ICLR_2024_oral_66,4,"\theta^{(M)} :=\\operatorname*{arg\,min}_{\theta}\E_{(x,t,\ell(x,t,d),c(x,t,d))\simH^{(M)}}\\[-\log p(\ell(x,t,d)\mid x,t,d,\hat{\ell}(x,t,d;\theta))] || \gamma^{(M)} :=\\operatorname*{arg\,min}_{\gamma}\E_{(x,t,\ell(x,t,d),c(x,t,d))\simH^{(M)}}\\(c(x,t,d)-\hat{c}(x,t,d;\gamma))^{2}",,"\theta^{*},\gamma^{*}\:=\\operatorname*{arg\,min}_{\theta,\gamma}\E_{(x,t,\ell(x,t,d),c(x,t,d))\simH^{(M)}}\\Big{[}-\log p(\ell(x,t,d)\mid x,t,d,\hat{\ell}(x,t,d;\theta))\Big{]}+\lambda\Big{[}c(x,t,d)-\hat{c}(x,t,d;\gamma)\Big{]}^{2}","where $\lambda$ is a hyperparameter balancing the two objectives, and the meta-learned estimators generalize across datasets by incorporating dataset features $d$ into the prediction model."
ICLR_2024_oral_66,5,"M=\{m^{*}\,|\,m^{*}\in\operatorname*{arg\,max}_{m\inM _{Timm}}[f_{ImageNet}(m),\-S(m)]\}",,"\theta\leftarrow\theta^{(M)},\quad\gamma\leftarrow\gamma^{(M)}","After meta-learning, the performance and cost predictors are initialized with the meta-learned parameters $\theta$ and $\gamma$."
ICLR_2024_oral_68,1,P(v\middo(x))=\prod_{i:v_{i}\notinx}P(v_{i }\midpa_{v_{i}})&if $v$ consistent with $x$\\0&otherwise.,,P(V\middo(X=x))=\prod_{V_i\inV\setminusX} P(V_i\midPa_{V_i})\quadif  V_i\not\inX,"Equation 1 defines the truncated factorization formula for computing the post-intervention distribution in a causal Bayesian network, where the variables in the intervened set $\mathbf{X}$ are fixed to their specified values $\mathbf{x}$ and are excluded from the product over the remaining variables."
ICLR_2024_oral_68,2,"P(v_{i}\,|pa_{i};\sigma)=\sum_{v_{i}^{\prime}:f(v_{i}^{\prime})=v_{i}}P(v_ {i}^{\prime}\,|pa_{i})",,P^{\prime}(v_{i}\midpa_{v_{i}})=1 &if v_{i}=f(v_{i})\\0 &otherwise.,"A local intervention on variable $V_i$ deterministically assigns $V_i$ to a function of its original value, effectively modifying its conditional probability distribution without dependence on other variables."
ICLR_2024_oral_7,1,"y_{i}=M(x_{i}|\Delta W,W_{0},\theta)",,y_i=(W_0+BA)x_i,"This equation represents the output computation in LoRA-adapted models, where the adapted weight matrix $W_0 + BA$ (composed of the pre-trained weights $W_0$ and low-rank matrices $B,A$) transforms input $\mathbf{x}_i$ into output $\mathbf{y}_i$."
ICLR_2024_oral_7,2,y_{i}=\phi(W_{i}^{T}x_{i}) || =\phi\big{(}(W_{0}^{T}\circ\Delta W_{i}^{T})x_{i}\big{)},,y_{i}=(B_{i} A_{i})x_{i}=W_{i}x_{i},"FLORA computes the output activations for each example in a minibatch using example-specific adapter matrices $B_{i}$ and $A_{i}$, enabling efficient batched computation while maintaining task-specific adaptations."
ICLR_2024_oral_7,3,=\phi\big{(}(W_{0}^{T}\circ(B_{i}A_{i})^{T})x_{i}\big{)},,y_{i}=\phi\left( W_{0}^{T}\circ (A_{i}^{T} B_{i}^{T}) x_{i}\right),"The output activations of a neural network layer in FLORA, where the adapted weight matrix is expressed in terms of the pre-trained weights and example-specific low-rank adapter matrices."
ICLR_2024_oral_7,4,=\phi\Big{(}A_{i}\circ\big{(}W_{0}^{T}(B_{i}\circ x_{i})\big{)}\Big{)},,y_{i}=\phi\left(\left(W_0^T\circ (B_i A_i)^T\right)x_i\right),"Equation 4 reformulates the forward pass in FLORA by substituting the low-rank decomposition of the example-specific adapter matrix $\Delta W_i = B_i A_i$ into the activation computation, emphasizing the element-wise multiplication with the pre-trained weight matrix $W_0$."
ICLR_2024_oral_7,5,Y=\phi\Big{(}A\circ\big{(}(B\circX)W_{0}\big{)}\Big{)},,Y=\phi\left(Reduce\left(A\circ\left(W_0^T (B\circX)\right)\right)\right),"Vectorized forward pass in FLORA, where $\mathbf{A}$ and $\mathbf{B}$ contain example-specific adapters, $\mathbf{X}$ is the batch of inputs, and $\text{Reduce}$ denotes a dimension reduction operation such as torch.mean."
ICLR_2024_oral_7,6,\frac{2c_{1}}{dc_{2}}+\frac{1}{r}\geq 1,,c_{2(r b l d^{2}) < 2c_{1}(d b l r)+c_{2}(b l d^{2})},"The inequality comparing the computational cost of fLoRA and LoRA, where $c_1$ and $c_2$ denote the computational coefficients of batch matrix multiplication and standard matrix multiplication, respectively, and $r$, $b$, $l$, $d$ represent rank, batch size, sequence length, and hidden dimension."
ICLR_2024_oral_73,1,\tilde{x}_{i}=\frac{\mu_{k}+\varepsilon\eta}{\sqrt{1+\varepsilon^{2}}},where \(\eta\) is drawn from the same distribution as the \(\mu_{k}\)'s and \(\varepsilon\) sets the within-class variability,"\tilde{x}_{i}\simN(\mu_{k},\sigma^{2}I_{D})","The content of item $x_i$, $\tilde{x}_i$, is sampled from a Gaussian distribution centered at the class mean $\mu_k$ with covariance $\sigma^2 I_D$."
ICLR_2024_oral_73,2,"v_{i}=u_{i}+V_{1}\sum_{j\leq i}p_{ij}^{(1)}u_{j},\quad w_{i}=v_{i}+V_{2}\sum_{ j\leq i}p_{ij}^{(2)}v_{j} || p_{ij}^{(\mu)}=\frac{e^{(K_{\mu}u_{j})^{T}(Q_{\mu}u_{i})}}{\sum_{k\leq i}e^{(K _{\mu}u_{k})^{T}(Q_{\mu}u_{i})}}","where

\[p_{ij}^{(\mu)}=\frac{e^{(K_{\mu}u_{j})^{T}(Q_{\mu}u_{i})}}{\sum_{k\leq i}e^{(K _{\mu}u_{k})^{T}(Q_{\mu}u_{i})}} \tag{3}\]

is the attention paid by query \(i\) on key \(j\) in the \(\mu\)th layer",v_{i}=softmax\left(\frac{q_{i}k_{1:i}^{T}}{\sqrt{d}}\right)\cdot v_{1:i},"where $v_{i}$ is the output of the first attention layer computed using queries, keys, and values derived from the inputs $u_{i}$, with a causal mask ensuring that predictions depend only on prior elements in the sequence."
ICLR_2024_oral_73,3,"v_{i}^{(b)}=\sum_{j\leq i}q_{ij}^{(1)}u_{j}^{(c)},\quad v_{i}^{(c )}=u_{i}^{(c)} || w_{i}^{(b)}=\sum_{j\leq i}q_{ij}^{(2)}v_{j}^{(c)},\quad w_{i}^{( c)}=v_{i}^{(c)}",,"v_{i}^{(c)} &=u_{i}^{(c)},\quad v_{i}^{(b)}=u_{i}^{(b)}+\sum_{j\leq i} p_{ij}^{(1)} u_{j}^{(c)},\\w_{i}^{(c)} &=v_{i}^{(c)},\quad w_{i}^{(b)}=v_{i}^{(b)}+\sum_{j\leq i} p_{ij}^{(2)} v_{j}^{(b)}","Minimal model of the two-layer induction head, where content and buffer subspaces are updated through attention mechanisms across layers."
ICLR_2024_oral_73,4,"q_{ij}^{(1)}=\frac{e^{\beta_{1}\delta_{i-1,j}}}{\sum_{k\leq i}e^{\beta_{1}\delta_ {i-1,k}}},\quad q_{ij}^{(2)}=\frac{e^{\alpha v_{j}^{(k)},v_{i}^{(c)}+\beta_{2}\Delta_{i,j}}}{\sum_{k\leq i}e^{\alpha v_{k}^{(k)},v_{i}^{(c)}+\beta_{2}\Delta_ {i,k}}}",,q_{ij}^{(\mu)}=\frac{e^{\left(u_{i}^{(c)}\right)^{T}u_{j}^{(b)}}}{\sum_{k\leq i}e^{\left(u_{i}^{(c)}\right)^{T}u_{k}^{(b)}}},"is the attention paid by query $i$ on key $j$ in the $\mu$th layer, based on content-to-buffer matching"
ICLR_2024_oral_74,1,\partial_{k}|s_{k}\rangle=\sum_{l=0}^{k-1}(-1)^{l}|s_{k-1}(l)\rangle,where \(\left|s_{k-1}(l)\right\rangle\) is the _lower_ simplex obtained by leaving out vertex \(l\) (i,\partial_{k}\left|s_{k}\right\rangle=\sum_{i=0}^{k}(-1)^{i}\left|s_{k}\setminus j_{i}\right\rangle,"Definition of the boundary map operator acting on a k-dimensional simplex, which computes the alternating sum of its (k-1)-dimensional faces."
ICLR_2024_oral_74,2,\beta_{k}:=\dim\ker(\Delta_{k}),,\beta_{k}=\dim\ker\Delta_{k},The $k$th Betti number is equal to the dimension of the kernel of the $k$th Hodge Laplacian operator.
ICLR_2024_oral_74,3,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|\leq\epsilon,"where \(|S_{k}|\) is the the number of \(k\)-simplices \(S_{k}\in\Gamma\) or \(\dim\tilde{\mathcal{H}}_{k}\), the dimension of the Hilbert space spanned by the set of \(k\)-simplices in the complex",\left|\chi_{k}-\frac{\beta_{k}}{\dim\tilde{H}_{k}}\right|\leq\epsilon,"This equation defines the normalized Betti number estimation problem, where the goal is to approximate the ratio of the $k$th Betti number to the dimension of the corresponding Hilbert space within a specified precision and confidence level."
ICLR_2024_oral_74,4,"\rank(\Delta_{k})\stackrel{{\tiny{def}}}{{=}}\trace(h(\tilde{\Delta}_{k})), where h(x)=\{{ll}1& if \x>\delta\\0& otherwise",,rank(\Delta_{k})=Tr\left[f_{\delta}(\tilde{\Delta}_{k})\right],"where $f_{\delta}(\cdot)$ is a smooth approximation to the indicator function that identifies non-zero eigenvalues, enabling rank estimation via trace estimation."
ICLR_2024_oral_74,5,n_{v}=O(\frac{\log(1/\eta)}{\epsilon^{2}})\qquad\qquadand\qquad\qquad m>\frac{\log(1/\epsilon)}{\sqrt{\delta}},,h(\tilde{\Delta}_{k})\approx\sum_{j=0}^{m}c_{j}T_{j}(\tilde{\Delta}_{k}),"where $T_{j}(\cdot)$ denotes the $j$th-degree Chebyshev polynomial of the first kind and $c_{j}$ are closed-form coefficients approximating the step function $h(\cdot)$, enabling stochastic trace estimation for $\rank(\Delta_{k})$ via quantum-classical hybrid computation."
ICLR_2024_oral_74,6,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|\leq\epsilon,,|\chi_{k}-\frac{\beta_{k}}{|S_{k}|}|\leq\epsilon,"where $\chi_{k}$ is the estimated normalized Betti number, $\beta_{k}$ is the true $k$th Betti number, and $|S_{k}|$ is the number of $k$-simplices in the given simplicial complex $\Gamma$."
ICLR_2024_oral_74,7,"O(\frac{1}{\epsilon^{2}}\max\{\frac{n\log(1/\epsilon)}{\sqrt{\delta} },\frac{n}{\zeta_{k}}\})",,O\left(\frac{n^{2}}{\epsilon^{2}\delta^{1/2}}\log\frac{1}{\eta}\right),
ICLR_2024_oral_82,1,LayerNorm(x)=\frac{x-E[x]}{\sqrt {Var[x]+\epsilon}}\odot\gamma+\beta,,LayerNorm(x)=\gamma\cdot\frac{x-\mu}{\sqrt{\sigma^2+\epsilon}}+\beta,"LayerNorm normalizes the input $\mathbf{x}$ by subtracting the mean $\mu$ and dividing by the standard deviation $\sqrt{\sigma^2 + \epsilon}$, followed by scaling with $\gamma$ and shifting with $\beta$."
ICLR_2024_oral_82,2,{BiasNorm}(x)=\frac{x}{RMS[x-b]}\cdot\exp(\gamma),"where \(\mathbf{b}\) is the learnable channel-wise bias, \(\mathrm{RMS}[\mathbf{x}-\mathbf{b}]\) is the root-mean-square value taken over channels, and \(\gamma\) is a scalar",BiasNorm(x)=\frac{x}{\sqrt{Var[x]+\epsilon}}\odot\gamma+\beta,"BiasNorm normalizes the input by subtracting only the mean and scaling by the standard deviation, while retaining learnable scale and shift parameters to adjust activation magnitudes and module contributions."
ICLR_2024_oral_82,3,Swish(x)=x\cdot(1+\exp(-x))^{-1},,{Swish}(x)=x\cdot\sigma(\beta x),where $\sigma(\cdot)$ is the sigmoid function and $\beta$ is a learnable parameter.
ICLR_2024_oral_82,4,"\textit{SwooshR}(x)&=\log(1+\exp(x-1))-0.08x-0.313261687,\\\textit{SwooshL}(x)&=\log(1+\exp(x-4))-0.08x-0.035",,"SwooshR(x)=\frac{x+\exp(-x)}{1+\exp(-x)},\quadSwooshL(x)=\frac{x+\max(0, x)}{1+\max(0, x)}","_SwooshR_ is a smooth variant inspired by the Swish function, while _SwooshL_ is a piecewise linear approximation designed for efficiency and stability."
ICLR_2024_oral_82,5,\Delta_{t}=-\alpha_{t}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon},"where \(\alpha_{t}\) is the learning rate typically specified by an external schedule, \(\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{2}}\) is the bias-correction term, and \(\epsilon=10^{-8}\)",\Delta_{t}=-\frac{\alpha}{\sqrt{\hat{v}_{t}}+\epsilon}\odot\hat{m}_{t},"where $\alpha$ is the learning rate, $\hat{\mathbf{m}}_{t}$ and $\hat{\mathbf{v}}_{t}$ are the bias-corrected first and second moments, and $\epsilon$ is a small constant to prevent division by zero."
ICLR_2024_oral_82,6,\Delta^{\prime}_{t}=-\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^ {2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon},,\Delta_{t}=-\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{t}}\cdot\frac{m_{t}}{\sqrt{v_{t}}+\epsilon},"This equation modifies the Adam update rule by scaling the parameter update with the parameter scale $r_{t-1}$, ensuring consistent relative changes across parameters of different scales."
ICLR_2024_oral_82,7,"\Delta^{\prime}_{t,r}&=-\eta\cdot\alpha_{t}\cdot r_{t-1}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta_{1}^{2}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\odot\theta^{\prime}_{t-1}\\&=-\eta\cdot\alpha_{t}\cdot\frac{\sqrt{1-\beta_{t}^{2}}}{1-\beta _{1}^{t}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\odot\theta_{t-1}","where \(\eta\) is a scaling factor on learning rate \(\alpha_{t}\), and we found that setting \(\eta=0","\Delta^{\prime}_{t,r}=\left(-\alpha_{t}\cdot\frac{\sqrt{1-\beta_{2}^{t}}}{1-\beta_{1}^{t}}\cdot\frac{n_{t}}{\sqrt{w_{t}}+\epsilon}\right)\odot\theta^{\prime}_{t-1}","This equation formulates the parameter change caused by updating the parameter scale $r$ in the ScaledAdam optimizer, incorporating the first and second moments of the scale gradients and maintaining scale invariance during optimization."
ICLR_2024_oral_82,8,"\alpha_{t}=\alpha_{base}\cdot(\frac{t^{2}+\alpha_{step }^{2}}{\alpha_{step}^{2}})^{-0.25}\cdot(\frac{e^{2}+\alpha_{epoch}^{2}}{\alpha_{epoch}^{2}})^{-0.25}\cdotlinear(\alpha_{start},t_{warmup},t)",,"\alpha_{t}=\alpha_{0} &if  t\leq T_{0},\\\alpha_{0}\cdot\left(1-\frac{t-T_{0}}{T_{1}-T_{0}}\right) &if  T_{0}<t\leq T_{1},\\\alpha_{0}\cdot\left(\frac{T_{1}-T_{0}}{T_{2}-T_{1}}\right)\cdot\left(\frac{T_{2}-t}{T_{2}-T_{1}}\right) &if  T_{1}<t\leq T_{2},\\0 &if  t>T_{2}","The _Eden_ learning rate schedule linearly decreases the learning rate from $\alpha_0$ to zero over three distinct phases defined by steps $T_0$, $T_1$, and $T_2$, enabling faster convergence without requiring a long warm-up period."
ICML_2024_oral_1,1,"J(\pi)=\sum_{t=0}^{\infty}E_{(s_{t},a_{t})\sim\rho (\pi)}[\gamma^{t}(r(s_{t},a_{t})+\alphaH(\pi(\cdot|s_{t})))]",,"J(\pi)=\sum_{t=0}^{\infty}E_{(s_t, a_t)\sim\rho_\pi}\left[R(s_t, a_t)+\alphaH(\pi(\cdot\mid s_t))\right]","where $\alpha$ is the temperature coefficient that determines the stochasticity of the policy, and $\mathcal{H}(\pi(\cdot \mid s_t))$ denotes the entropy of the policy at state $s_t$."
ICML_2024_oral_1,2,"r_{t}=r_{M}(B_{s\to r|a}\odots_{t},B_{a\to r|s}\odota_{t},\epsilon_{t})","where \(\mathbf{B}_{\mathbf{s}\to r|\mathbf{a}}\in\mathbb{R}^{\mathrm{dim} \mathcal{S}\times 1}\) and \(\mathbf{B}_{\mathbf{a}\to r|\mathbf{s}}\in\mathbb{R}^{\mathrm{dim}\mathcal{A} \times 1}\) are vectors that represent the graph structure 1 from \(\mathbf{s}_{t}\) to \(r_{t}\) given \(\mathbf{a}_{t}\) and from \(\mathbf{a}_{t}\) to \(r_{t}\) given \(\mathbf{s}_{t}\), respectively","r_{t}=f_{r}(s_{t},do(a_{t}),\varepsilon_{r})","The reward at time $t$ is determined by the state $\mathbf{s}_{t}$, the intervened action $\text{do}(\mathbf{a}_{t})$, and exogenous noise $\varepsilon_{r}$ through the function $f_r$."
ICML_2024_oral_1,3,"H_{c}(\pi(\cdot|s))&=-E_{a\inA}[\sum_{i=1}^{\dimA}B_{a_{i}\to r|s}\pi(a_{i}|s)\log\pi(a_{i}|s)],\\&a=(a_{1},\ldots,a_{\dimA})",,H_{c}(\pi)=E_{s_t\sim\rho(\pi)}\left[\sum_{i=1}^{\mathrm{dim,
ICML_2024_oral_1,4,"T_{c}^{\pi}Q(s_{t},a_{t })\triangleq& r(s_{t},a_{t})+\gammaE_{s_{t+1}\sim P}[E_{a_{t}\sim\pi}[Q(s_{t+1},a_{t+1})\\&+\alphaH_{c}(\pi(a_{t+1}|s_{t+1}))]]",,"T_{c}^{\pi}Q(s,a)=r(s,a)+\gammaE_{s'\sim P(\cdot|s,a)}\left[E_{a'\sim\pi(\cdot|s')}[Q(s',a')]+\alphaH_{c}(\pi(\cdot|s'))\right]",The modified Bellman operator incorporates the causality-aware entropy term to update the Q-value for improved policy evaluation.
ICML_2024_oral_1,5,\frac{n_{i}^{l}(x)}{\frac{1}{N^{l}}\sum_{k\in l}n_{k}^{l}}\leq\tau,where \(\tau\) is a constant serving as a threshold to determine the gradient dormancy of neurons in each layer,n_{i}^{l} <\tau\cdot\frac{1}{N^{l}}\sum_{j=1}^{N^{l}} n_{j}^{l},"where $\tau \in (0,1)$ is a threshold hyperparameter that determines the sensitivity for identifying dormant neurons based on the average gradient magnitude in the layer."
ICML_2024_oral_1,6,\alpha_{\tau}=\frac{\sum_{l\in\phi}N_{\tau}^{l}}{\sum_{l\in\phi}N^{l}},,\alpha_{\tau}=\frac{1}{L}\sum_{l=1}^{L}\frac{N_{\tau}^{l}}{N^{l}},"The $\tau$-Dormancy Degree $\alpha_{\tau}$ quantifies the proportion of gradient-dormant neurons across all layers in a neural network, normalized by layer size and total layers $L$."
ICML_2024_oral_1,7,"\theta_{t}=(1-\eta)\theta_{t-1}+\eta\phi_{i},\\phi_{i}\siminitializer",,"\eta_{t}=\eta_{\max}-(\eta_{\max}-\eta_{\min})\cdot\frac{\alpha_{\tau,t}-\alpha_{\tau,\min}}{\alpha_{\tau,\max}-\alpha_{\tau,\min}}","where $\eta_t$ is the reset factor at training step $t$, $\eta_{\max}$ and $\eta_{\min}$ are the maximum and minimum reset factors, and $\alpha_{\tau,t}$ is the $\tau$-dormancy degree at step $t$."
ICML_2024_oral_10,1,"attention(Q,K,V)=softmax(QK)^{T}/\sqrt{d})V",,"Attention(Q, K, V)=softmax\left(\frac{QK^\top}{\sqrt{d_k}}\right)V","where $d_k$ is the dimensionality of the key vectors, ensuring numerical stability during softmax computation."
ICML_2024_oral_10,2,"d\hat{x}_{t}=f(\hat{x}_{t},t)dt+g(t)dw",,"dx=f(x,t)dt+g(t)dw","where $f(x,t)$ denotes the drift coefficient, $g(t)$ is the diffusion coefficient, and $dw$ represents standard Wiener process increments."
ICML_2024_oral_10,3,"d\hat{x}_{t}=[f(\hat{x}_{t},t)-g(t)^{2}s(\hat{x}_{t},t) ]dt+g(t)d\tilde{w}",where \(\mathbf{\tilde{w}}\) is a backward-in-time Wiener process,"d\hat{x}_{t}=\left[f(\hat{x}_{t},t)-g(t)^{2}\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t})\right]dt+g(t)dw",This equation represents the reverse diffusion process used to generate samples from the generative model by incorporating the score function of the marginal probability density.
ICML_2024_oral_10,4,"L(\phi)=E_{t,\hat{x}_{0},\hat{x}_{t}}[\lambda (t)\|s_{\phi}(\hat{x}_{t},t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t}|\hat{x}_{0})\|_{2}^{2}]",where \(\lambda\) denotes a positive weighting function,"L(\phi)=E_{t,\hat{x}_{0},\hat{x}_{t}}\left[\left\| s_{\phi}(\hat{x}_{t},t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t}|\hat{x}_{0})\right\|^{2}\right]",Expected squared error loss for training the score model by comparing predicted scores against the true conditional scores.
ICML_2024_oral_10,5,"\ell(\phi,M_{C},t,\hat{x}_{0},\hat{x}_{t})=\\(1-M_{C})\cdot(s_{\phi}^{M_{E}}(\hat{x}_{t}^{Mc}, t)-\nabla_{\hat{x}_{t}}\log p_{t}(\hat{x}_{t}|\hat{x}_{0}))",where \(s_{\phi}^{M_{E}}\) denotes the score model equipped with a specific attention mask \(M_{E}\),"L(\phi)=E_{t,\hat{x}_{0},\hat{x}_{t},M_{C}}[\lambda (t)\|s_{\phi}(\hat{x}_{t}^{M_{C}},t)-\nabla_{\hat{x}_{t}^{M_{C}}}\log p_{t}(\hat{x}_{t}^{M_{C}}|\hat{x}_{0})\|_{2}^{2}]","where the noisy sample is partially conditioned using the condition mask $M_{C}$, and the score model is trained to predict the gradient of the log conditional density."
ICML_2024_oral_10,6,"L(\phi)=E_{M_{C},t,\hat{x}_{0},\hat{x}_{ t}}[\|\ell(\phi,M_{C},t,\hat{x}_{0},\hat{x}_{t})\|_{2}^{2}]",,"L(\phi)=E_{t, M_C,\hat{x}_0,\hat{x}_t}\left[\lambda(t)\| (1-M_C)\cdot\left( s_\phi^{M_E}(\hat{x}_t^{Mc}, t)-\nabla_{\hat{x}_t}\log p_t(\hat{x}_t |\hat{x}_0)\right)\|_2^2\right]","This loss function extends the denoising score-matching objective by incorporating the condition mask $M_C$ and attention mask $M_E$, enabling training on arbitrary conditionals of the joint distribution."
ICML_2024_oral_10,7,"s(\hat{x}_{t},t|y)\approx s_{\phi}(\hat{x}_{t},t)+\nabla_{\hat{x}_{t}}\log p_{t}(y|\hat{x}_{t})",,"s_{guided}(\hat{x}_{t},t)=s_{\phi}(\hat{x}_{t},t)+\eta\nabla_{\hat{x}_{t}}\log p(y|\hat{x}_{t},t)","where $\eta$ controls the strength of the guidance and $p(\mathbf{y}|\mathbf{\hat{x}}_{t},t)$ represents the likelihood of the context given the noisy sample."
ICML_2024_oral_10,8,"s_{\phi}(\hat{x}_{t},t|c)\approx s_{\phi}(\hat{x}_{t},t)+\nabla_{\hat{x}_{t}}\log\sigma(-s(t)c(\hat{x}_{t}))",,"s(\hat{x}_{t},t|y)\approx s_{\phi}(\hat{x}_{t},t)+\nabla_{\hat{x}_{t}}\log p_{t}(y|\hat{x}_{t})+\gamma\cdot\nabla_{\hat{x}_{t}}\log p(y|\hat{x}_{t})",where $\gamma$ is a guidance scale parameter that controls the strength of the additional constraint derived from the observation interval or prior information.
ICML_2024_oral_101,1,"G(z)=\sum_{j_{1}=0}^{d-1}\cdots\sum_{j_{n}=0}^{d-1}p(j_{1},\ldots,j_{n})z_{1}^ {j_{1}}\cdots z_{n}^{j_{n}}",,"G(z_1,\ldots, z_n)=\sum_{a_1,\ldots, a_n} p(a_1,\ldots, a_n) z_1^{a_1}\cdots z_n^{a_n}","Definition of the probability generating function for categorical variables $X_1, \ldots, X_n$ with joint distribution $p$."
ICML_2024_oral_101,3,"\Pr[V_{1}=1,\ldots,V_{n}=1]=h(1,\ldots,1)=\frac{\#PM(G)}{3^{n}}",,"\Pr[V_{1}=1,V_{2}=1,\ldots,V_{n}=1]=\frac{\#PM(G)}{3^{n}}","The probability of the event $V_{1}=1,V_{2}=1,\ldots,V_{n}=1$ in the normalized distribution $\hat{f}$ is equal to the number of perfect matchings in the graph $G$ divided by $3^n$."
ICML_2024_oral_101,4,"f(z_{1},...,z_{n})=\sum_{s=(s_{1},\ldots,s_{n})\in\{0,1,\ldots,k-1\}^{n}}c_{s}\cdot\prod_{i=1}^{n}z_{i}^{s_{i}}",,"f(z_{1},\ldots,z_{n})=\sum_{j_{1}=0}^{k-1}\cdots\sum_{j_{n}=0}^{k-1}\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}] z_{1}^{j_{1}}\cdots z_{n}^{j_{n}}",Probability generating function for k-nary random variables expressed as a multivariate polynomial.
ICML_2024_oral_101,5,"g(x_{1},\overline{x_{1}},...,x_{n},\overline{x_{n}})=f(\frac{x_{1}}{\overline{ x_{1}}},\frac{x_{2}}{\overline{x_{2}}},...,\frac{x_{n}}{\overline{x_{n}}})\cdot\prod_{i=1}^{n}\overline{x_{i}}",,"\Pr\left[X_{1}\in V_{1},\ldots, X_{n}\in V_{n}\right]=\sum_{\substack{s_{1}\in V_{1},\\\ldots,\\s_{n}\in V_{n}}} c_{s}",This equation expresses the selective marginal probability as the sum of coefficients $c_s$ corresponding to tuples $s$ where each $s_i$ lies in the subset $V_i$.
ICML_2024_oral_101,6,m^{\prime}=c_{S}\cdot(\prod_{i\in S}\frac{x_{i}}{\overline{x_{i}}})\cdot(\prod _{j=1}^{n}\overline{x_{j}})=c_{S}(\prod_{i\in S}x_{i})\cdot(\prod_{i\notin S}\overline{x_{i}}),,m^{\prime}=c_{S}\cdot\prod_{i\in S}\frac{x_{i}}{\overline{x_{i}}}\cdot\prod_{i=1}^{n}\overline{x_{i}}=c_{S}\cdot\prod_{i\in S}x_{i}\cdot\prod_{i\notin S}\overline{x_{i}},"The transformed monomial $m^{\prime}$ represents the corresponding term in the nonmonotone PC, encoding the probability of the binary event associated with subset $S$."
ICML_2024_oral_101,8,"P=\sum_{j_{1}=0}^{d-1}\cdots\sum_{j_{n}=0}^{d-1}\Pr[X_{1}=j_{1},\ldots,X_{n}=j _{n}]z_{1,j_{1}}\cdots z_{n,j_{n}}",,"& f(x_{1}(1+\overline{x_{1}}),x_{2}(1+\overline{x_{2}}))\cdot(1-\overline{x_{1}})(1-\overline{x_{2}})\\&=(0.6x_{1}x_{2}(1+\overline{x_{1}})(1+\overline{x_{2}})\\&\quad+0.4x_{1}(1+\overline{x_{1}}))(1-\overline{x_{1}})(1-\overline{x_{2}})\\&=0.6x_{1}x_{2}+0.4x_{1}(1-\overline{x_{2}})\+\higher degree terms","This equation demonstrates the expansion of the polynomial after substituting first-order approximations for the geometric series inverses, enabling division elimination via Strassen's method while retaining the target multilinear terms."
ICML_2024_oral_101,9,"e_{i,j}=1&if $j=a_{i$},\\0&otherwise",,"e_{i,j}=1 &if j=a_{i},\\0 &otherwise",Input vector $e$ assigns 1 to the variable corresponding to the outcome $a_i$ of $X_i$ and 0 to all other variables in the same partition.
ICML_2024_oral_101,10,"v_{i,j}=1&if $j\in A_{i$},\\0&otherwise",,"z_{i,j}=1&if j\in A_{i},\\0&otherwise","Evaluation point for computing the probability of the event $X_{1} \in A_{1}, \ldots, X_{n} \in A_{n}$ by substituting indicator values into the set-multilinear polynomial $P$."
ICML_2024_oral_101,11,"P(v)=\sum_{j_{1}\in A_{1}}\cdots\sum_{j_{n}\in A_{n}}\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}]\cdot 1 || =\Pr[X_{1}\in A_{1},\ldots,X_{n}\in A_{n}]",,"P(v)=\sum_{j_{1}\in A_{1},\ldots,j_{n}\in A_{n}}\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}}]","The evaluation of the set-multilinear polynomial $P$ at the vector $v$ yields the marginal probability $\Pr[X_{1}\in A_{1},\ldots,X_{n}\in A_{n}]$ by summing over all joint probabilities where each variable $X_i$ takes a value in the subset $A_i$."
ICML_2024_oral_101,12,"f(a)=\sum_{a\in\Delta^{|A|}}\alpha_{a}\prod_{i\in A}z_{i,a_{i}},\quad g(b)=\sum_{b\in\Delta^{|B|}}\beta_{b}\prod_{j\in B}z_{j,b_{j}}",where \(\alpha_{a}=\Pr[X_{A}=a]\) and \(\beta_{b}=\Pr[X_{b}=b]\),"\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}]=f(j_{1},\ldots,j_{n})\quadand\quad\Pr[X_{1}=j_{1},\ldots,X_{n}=j_{n}]=g(j_{1},\ldots,j_{n})",
ICML_2024_oral_101,13,"f(a,b^{\prime})= || (\sum_{a\in\Delta^{|A|}}\alpha_{a}\prod_{i\in A}z_{i,a_{i}} )\prod_{j\in B\setminus A}\frac{1}{d}(z_{j,0}+\cdots+z_{j,d-1})",,"f'(z)=\sum_{a\in\Delta^{|A|}}\sum_{b\in\Delta^{|B|}}\alpha_{a}\prod_{i\in A}z_{i,a_{i}}\prod_{j\in B}z_{j,b_{j}}",
ICML_2024_oral_104,1,call-count(u)=\sum_{v\in Q(u)}(1+call-count(v)),,call\_count(u)=\sum_{v\in Q(u)}\left(1+call\_count(v)\right),"Recursive call count for node $u$ defined as the total number of edges in the recursive tree $\mathcal{T}_u$, computed by summing over all queried neighbors $v \in Q(u)$ the contribution of each neighbor's subtree."
ICML_2024_oral_104,2,\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots || \leq\sigma(u_{L-1})\leq\pi(u_{L-1})\leq\sigma(u_{L})\leq\pi(u_{L}),,"\sigma(u_{i})\geq\pi(u_{i-1})\quadfor all i\in\{1,\ldots,L\}",Condition characterizing a query path in terms of the settlement and permutation ranks of nodes.
ICML_2024_oral_104,4,\sigma(u_{0})<\sigma(u_{1}) and\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq || \cdots\leq\pi(u_{L-2})\leq\sigma(u_{L-1})=\sigma(u_{L}),,"\sigma(u_{0})\leq\pi(u_{0})\leq\sigma(u_{1})\leq\pi(u_{1})\leq\ldots\\\leq\sigma(u_{L-2})\leq\pi(u_{L-2})\leq\min(\sigma(u_{L-1}),\sigma(u_{L}))","An expensive extended query path is characterized by the condition that the first edge is cut by Pivot (due to differing settlement times), while the last edge is not cut (due to identical settlement times), under the constraints imposed by the ordering of settlement and processing times."
ICML_2024_oral_104,5,"E_{\pi}|X|\leq 2E\Big{[}\sum_{(u,v)\in E}1 (\sigma(u)\neq\sigma(v))\Big{]}",,E_{\pi}|X|\leq 4\cdotE_{\pi}[number of edges cut by Pivot],"The expected number of expensive extended query paths is bounded in terms of the expected number of edges cut by the Pivot algorithm, establishing a key relation for proving Lemma 4.2."
ICML_2024_oral_104,6,"\Phi_{t}(a,b)=2|D_{t}(a,b)|+|Q_{t}(a,b)| || \Psi_{t}(a,b)=2|D_{t}(a,b)|+|X_{t}(a,b)|",,"E|X_{t}(a,b)|\leq 2E\Big{[}\sum_{(u,v)\in E}1(\sigma(u)\neq\sigma(v))\Big{]}","This equation bounds the expected number of expensive extended query paths starting with a fixed edge (a, b) by twice the expected number of edges cut by the Pivot algorithm."
ICML_2024_oral_106,1,"p(u)=\prod_{i=1}^{n}p(u_{i}|u_{1},...,u_{i-1},\Theta)",,"p(u_{1},...,u_{n})=\prod_{i=1}^{n} p(u_{i}\mid u_{1},...,u_{i-1}})",The joint probability of a sequence of words modeled autoregressively as the product of conditional probabilities.
ICML_2024_oral_106,2,L=-log\;p(u),,"L=-\sum_{i=1}^{n}\log p(u_{i} | u_{1},...,u_{i-1},\Theta)","This equation represents the negative log-likelihood loss function derived from the autoregressive probability model in Equation 1, which is minimized during GPT training to optimize language modeling performance."
ICML_2024_oral_106,3,"p(x)=\prod_{i=1}^{n}p(x_{i}|x_{1},...,x_{i-1},\Theta)",,"p(x)=\prod_{i=1}^{n}p(x_{i}|x_{1},...,x_{i-1},\Theta)","Image GPT models the probability of each pixel in a flattened image sequence autoregressively, conditioned on all previous pixels."
ICML_2024_oral_106,4,L=-log\;p(x),,L=-\log\; p(x),"Image GPT minimizes the negative log-likelihood of the pixel sequence, analogous to language modeling in GPT."
ICML_2024_oral_106,5,"p(s)=\prod_{i=1}^{n}p(s_{i}|s_{1},...,s_{i-1},\Theta)",,"p(s)=\prod_{i=1}^{n}p(s_{i}|s_{1},...,s_{i-1},\Theta)","The autoregressive probability is now defined over clusters $s_i$ rather than individual pixels, where each cluster represents a group of spatially neighboring image patches."
ICML_2024_oral_106,6,"L_{G}=-\sum_{i=1}^{n}cosine(G(f(x_{s_{1}:s_{i-1}});\theta_{G}),f_{\phi }(x)_{s_{i}})","where \(f(\cdot)\) is the encoder, \(f_{\phi}(x)_{s_{i}}\) is the semantically enriched tokens corresponding to the cluster \(s_{i}\), \(G(\cdot;\ \theta_{G})\) is the generative decoder for autoregressive prediction, and \(cosine\) is the cosine similarity loss",L_{semantic}=-\log\;p(t),This equation represents the semantic-aware negative log-likelihood loss where $t$ denotes the sequence of semantic tokens predicted autoregressively by D-iGPT.
ICML_2024_oral_106,7,"L_{D}=-\sum_{i=1}^{n}cosine(D(f(x_{s_{1}:s_{i-1}});\theta_{D}),f_{\phi}(x)_{s_{1}:s_{i-1}})","where \(D(\cdot;\ \theta_{D})\) is the discriminative decoder, tasked with predicting the semantic tokens of visible pixels",L_{V}=\sum_{i\in V}\left\|f(x_{s_{i}})-f_{\phi}(x)_{s_{i}}\right\|^{2},"where $V$ denotes the set of visible clusters, $f(x_{s_{i}})$ is the model's output for cluster $s_{i}$, and $f_{\phi}(x)_{s_{i}}$ is the corresponding ground truth from the encoder."
ICML_2024_oral_107,1,"L_{eval}=-\log p_{M}(<\)cc\(>\)\(|X_{l},X_{r})",,"L_{eval}=-\log P(<cc>\mid X_l, X_r, Y;\theta)",Self-assessment loss for predicting the insertion of the retrieved context token $<\text{cc}>$ given the input context and target code $Y$.
ICML_2024_oral_107,2,"L_{gen}=-\log p_{M}(Y|X_{l},X_{r},CC),& if label\\-\log p_{M}(Y|X_{l},X_{r}),&otherwise",,"L_{gen}=-\sum_{t=1}^{|Y|}\log p_{M}(y_t | X_{l},X_{r}, (<\)cc\(> CC)^{label}) , <\)fim_middle\(>)","Equation 2 defines the generation loss $\mathcal{L}_{gen}$ as a cross-entropy loss over the tokens in $Y$, conditioned on the input context and optionally the retrieved context $CC$ based on the label."
ICML_2024_oral_107,3,"ES(\hat{Y},Y)=\frac{1-Lev(\hat{Y},Y)}{\max(|\hat{Y}|,|Y|)}",where \(Lev\) is the Levenshtein distance (Levenshtein et al,"ES(\hat{Y},Y)=\frac{Levenshtein(\hat{Y},Y)}{\max(|\hat{Y}|,|Y|)}",Edit Similarity (ES) measures the similarity between the predicted code $\hat{Y}$ and the ground truth $Y$ based on the Levenshtein distance normalized by the maximum length of the two sequences.
ICML_2024_oral_109,1,"\operatorname*{arg\,max}_{k=1,\dots,K}\,\cos(\phi(x),\psi(t_{k}))",,"y=\arg\max_{k=1,\dots,K}\frac{\phi(x)^\top\psi(t_k)}{\|\phi(x)\|_2\|\psi(t_k)\|_2}",Zero-shot classification using cosine similarity between image embedding $\phi(x)$ and text prompt embeddings $\psi(t_k)$
ICML_2024_oral_109,2,"f_{k}(\phi,x)=\cos(\phi(x),\psi(t_{k}))=\langle\frac{\phi(x)}{\|\phi (x)\|_{2}},\frac{\psi(t_{k})}{\|\psi(t_{k})\|_{2}}\rangle",,"f(x)=\left[\cos\left(\phi(x),\psi(t_1)\right),\dots,\cos\left(\phi(x),\psi(t_K)\right)\right]^\top","The classifier $f$ outputs a vector of cosine similarities between the image embedding $\phi(x)$ and each fixed text prompt embedding $\psi(t_k)$, forming the logits for zero-shot classification."
ICML_2024_oral_109,3,"\operatorname*{arg\,max}_{k=1,\dots,K}\,f_{k}(\phi,z)\neq y,\quad\|z-x\|_{p}\leq\varepsilon,\quad z\in I",where \(\varepsilon\) is the perturbation size,"\| z-x\|_p\leq\varepsilon,\\f(\phi, z)\neq y",An adversarial image $z$ must satisfy both the $\ell_p$-norm constraint and misclassification condition.
ICML_2024_oral_109,4,"L_{TeCoA}(y,f(\phi,x))=-\log(\frac{e^{f_{y}(\phi,x)}}{\sum_{k=1}^ {K}e^{f_{k}(\phi,x)}})",,"\min_{\phi}E_{(x,y)\simD}\left[\max_{z\inB_{\infty}(x,\varepsilon)}\left(-\log f_{y}(\phi,z)\right)\right]","the expected value over the data distribution of the maximum cross-entropy loss within the $\ell_{\infty}$-ball around each image $x$, where $\mathcal{B}_{\infty}(x,\varepsilon)$ denotes the set of all images within $\varepsilon$-bounded $\ell_{\infty}$ perturbation of $x$."
ICML_2024_oral_109,5,"\phi_{FT}=\operatorname*{arg\,min}_{\phi}\sum_{i=1}^{n}\max_{\|z-x_{i}\|_{\infty}\leq\varepsilon}L_{TeCoA}(y_{i},f(\phi,z))",where the inner problem is approximately solved with projected gradient descent (PGD) during training and \(\phi_{\mathrm{FT}}\) indicates the weights of the robust CLIP vision encoder,"L_{TeCoA}=\frac{1}{n}\sum_{i=1}^{n}\max_{\|z-x_i\|_\infty\leq\varepsilon}-\log\left(\frac{e^{f_{y_i}(\phi, z)}}{\sum_{k=1}^{K} e^{f_{k}(\phi, z)}}\right)",Standard adversarial training formulation of the TeCoA loss over a training set with $\ell_\infty$-bounded perturbations.
ICML_2024_oral_109,6,"L_{FARE}(\phi,x)=\max_{\|z-x\|_{\infty}\leq\varepsilon}\|\phi(z)-\phi_{Org}(x)\|_{2}^{2}",,"L_{Unsup}(x, z)=\|\phi_{Org}(x)-\phi_{FT}(z)\|_2^2+\lambda\|\phi_{FT}(z)\|_2^2","where the first term preserves the original embedding structure on clean inputs and the second term regularizes the fine-tuned embeddings to maintain a stable norm, preventing arbitrary radial distortions."
ICML_2024_oral_109,7,"\phi_{FT}=\operatorname*{arg\,min}_{\phi}\sum_{i=1}^{n}L_{ FARE}(\phi,x_{i})",,"\phi_{FARE}=\operatorname*{arg\,min}_{\phi}\sum_{i=1}^{n}L_{FARE}(\phi,x_{i})",where the inner maximization is solved via projected gradient descent (PGD) and the outer minimization adjusts the vision encoder to maintain robustness while preserving the original CLIP embedding structure on clean inputs.
ICML_2024_oral_109,8,"|\cos(\phi_{FT}(x),\psi(t))-\cos(\phi_{Org},\psi(t))| || \leq\min(\frac{2}{\|\phi_{Org}(x)\|_{2}},\frac{2}{\|\phi_{FT}(x)\|_{2}})\|\phi_{FT}(x)-\phi_{Org}(x)\|_{2}",,"\left|\cos(\phi_{FT}(x),\psi(t))-\cos(\phi_{Org}(x),\psi(t))\right|\leq\frac{2\left\|\phi_{FT}(x)-\phi_{Org}(x)\right\|_{2}}{\left\|\phi_{Org}(x)\right\|_{2}}","This inequality shows that preserving the ââ-distance between original and fine-tuned image embeddings ensures the preservation of cosine similarities between image and text embeddings, maintaining zero-shot classification performance."
ICML_2024_oral_110,1,F_{iso}=\{f:\Omega\subsetR^{d}\to&R^{D}:\Df^{\top}(s)Df(s)=Id\\&for all s\in\Omega\},,"F_{iso} :=\left\{ f\inF :\forall s\in\Omega,\,\|Df(s)\|_{op}\leq 1+\varepsilon and \|Df^{-1}(f(s))\|_{op}\leq 1+\varepsilon\right\}","where $Df(s)$ denotes the Jacobian of $f$ at $s$, $\|\cdot\|_{\text{op}}$ is the operator norm, and $\varepsilon \geq 0$ controls the deviation from exact isometry."
ICML_2024_oral_110,2,"\Theta_{p}^{p}(f,\Omega)=\int_{\Omega}&dist(Df(s),SO(d))^{p}\\&+dist\big{(}(Df)^{-1}(s),SO(d)\big{)}^{p}\,ds",,\Theta(f)=\sup_{s\in\Omega}\left\|Df^{\top}(s)Df(s)-Id\right\|_{F},"Measure of distance of a function $f$ to the space of local isometries $\mathcal{F}_{\mathrm{iso}}$, defined via the Frobenius norm of the deviation of $Df^{\top}(s)Df(s)$ from the identity matrix at each point $s\in\Omega$."
ICML_2024_oral_110,3,"\Theta_{p}^{p}(f,\Omega)=&\int_{\Omega }dist^{p}(Df(z),SO(d,T_{f(z)}M))\\&+dist^{p}\big{(}(Df)^{-1}(z),SO(T_{f(z)}M,d)\big{)}\,dz","where \(T_{f(z)}M\) denotes the tangent space of \(M\) at \(f(z)\) and \(\mathrm{SO}(d,T_{f(z)}M)\) denotes the set of orthogonal matrices \(Q\in\mathbb{R}^{D\times d}\) (i","\Theta_{p}^{p}(f,\Omega)=\int_{\Omega}&dist(Df(s),SO(d,D))^{p}\\&+dist\big{(}(Df)^{-1}(s),SO(d,D)\big{)}^{p}\,ds","Here, $\mathrm{SO}(d,D)$ denotes the set of linear maps from $\mathbb{R}^d$ to $\mathbb{R}^D$ that are isometric embeddings, generalizing rotations to the case of embeddings into higher-dimensional spaces."
ICML_2024_oral_110,4,"MCC(\tilde{S},\tilde{S})=\max_{\pi\in S_{d}}d^{-1}\sum_{i=1}^{ d}|\rho(S_{i},\tilde{S}_{\pi(i)})|","where \(\rho(X,Y)=\operatorname{Cov}(X,Y)/(\operatorname{Var}(X)\operatorname{Var}( Y))^{1/2}\) denotes the correlation coefficient","MCC(\tilde{S},\tilde{S}^{\prime})=\max_{\pi}\frac{1}{d}\sum_{i=1}^{d}|Corr(\tilde{S}_{i},\tilde{S}^{\prime}_{\pi(i)})|","The mean correlation coefficient (MCC) measures the average absolute correlation between corresponding components of two random variables, maximized over permutations $\pi$, providing a metric for approximate identifiability of latent variables."
ICML_2024_oral_110,5,"MCC(\hat{S},S)\geq 1-C\Theta_{p}^{2}(f)",,"MCC(S,\hat{S})\geq 1-C\,\Theta_{p}(f,\Omega)","Approximate identifiability result showing that the mean correlation coefficient between the true latent variables $S$ and the estimated latent variables $\hat{S} = \tilde{f}^{-1}(X)$ is bounded below by a constant minus a term proportional to the distance $\Theta_p(f, \Omega)$ of the mixing function $f$ to the space of local isometries."
ICML_2024_oral_110,6,"\min_{L}&\|u-L\|_{L^{q}(\Omega)}\\&\leq C(\Omega,p)(\int_{\Omega}dist(Du(s),SO (d))^{p}\,ds)^{\frac{1}{p}}",,"\inf_{Q\inSO(d)}\|Df-Q\|_{L^{p}(\Omega)}\leq C\Theta_{p}(f,\Omega)","where $C$ is a constant depending on the domain $\Omega$ and the dimension $d$, and $\mathrm{SO}(d)$ is the group of $d \times d$ rotation matrices."
ICML_2024_oral_110,7,"M(f_{*}P)=\{&(g,Q,\Omega^{\prime}):g\inF(\Omega^{\prime}), where \\g_{*}Q=f_{*}P,\,supp(Q)=\Omega^{\prime}\}",,"M_{p}(P,\varepsilon)=\{f:\Omega\subsetR^{d}\to&R^{d}:\\Theta_{p}(f,\Omega)\leq\varepsilon,\\&f is a diffeomorphism\}","Set of diffeomorphic mixing functions $f$ that are $\varepsilon$-close to being local isometries in the $\Theta_p$-measure, forming a model class for approximate identifiability analysis."
ICML_2024_oral_110,8,"&(g,Q,\Omega^{\prime})\in\\&\operatorname*{argmin}_{(\bar{g},\bar{Q},\Omega)\inM(f,P)}\int_{\Omega}dist((D\bar{g})^{-1}(g(s)),SO(d))^ {p}\,\bar{Q}(ds)",,"(g_{p},Q_{p},\Omega^{\prime}_{p})=\arg\min_{(g,Q,\Omega^{\prime})\inM(f_{*}P)}&\Theta_{p}(g,\Omega^{\prime})\\&subject to Q=\bigotimes_{i=1}^{d}Q_{i}","Equation 8 defines the triple $(g_p, \mathbb{Q}_p, \Omega'_p)$ that minimizes the deviation from local isometry, measured by $\Theta_p(g, \Omega')$, among all models that generate the same observed distribution as $f_*\mathbb{P}$, under the constraint that the latent distribution $\mathbb{Q}$ has independent components."
ICML_2024_oral_110,9,"\|h\|_{P,q}\leq C_{1}\Theta_{p}(f,\Omega)",,"\|h\|_{L^{q}(\Omega)}\leq C(\Omega,p,d)\bigg(&\int_{\Omega}dist^{p}(Df(s),SO(d))\\&+dist^{p}((Df)^{-1}(s),SO(d))\,ds\bigg)^{\frac{1}{p}}","Bound on the deviation $h$ from linearity of the composition $g^{-1} \circ f$ under approximate local isometry conditions, quantifying robustness in terms of the distance to $\mathrm{SO}(d)$."
ICML_2024_oral_110,10,x=f(s)=As+\eta h(s),where \(h:\mathbb{R}^{d}\to\mathbb{R}^{d}\) is a non-linear function and \(\eta\in\mathbb{R}\) is a small constant,X=AS+\varepsilon(S),"where $ A \in \mathbb{R}^{d \times d} $ is an invertible matrix representing the linear part of the mixing, and $ \varepsilon(S) $ is a small nonlinear perturbation that depends on the latent variables $ S $. This model assumes that the observed data $ X $ is generated by a mixing function that is close to linear, with deviations captured by $ \varepsilon(S) $, which is typically assumed to be smooth and bounded."
ICML_2024_oral_110,11,H(w)=EG(w^{\top}\Sigma_{X}^{-\frac{1}{2}}X),where \(\Sigma_{X}\) denotes the covariance matrix of \(X\) so that \(\Sigma_{X}^{-\frac{1}{2}}X\) is whitened and \(G\) is the so-called contrast function,"x=f(s)=As+&\eta h(s),\\&E(h(S))=0,\,E_{S}(Sh(S)^{\top})=0",where $h:\mathbb{R}^{d}\to\mathbb{R}^{d}$ is a centered nonlinear function and $\eta\in\mathbb{R}$ is a small constant.
ICML_2024_oral_110,12,\bar{w}_{i}=(AA^{\top})^{\frac{1}{2}}A^{-\top}e_{i},,\Sigma_{X}^{-\frac{1}{2}}X=e_{i},"correspond to the independent components when $ w $ is aligned with the rows of $ A $, establishing a link between the extrema of $ H $ and the latent variables $ S $."
ICML_2024_oral_110,13,"|G^{(k)}(x)|\leq C_{g}(1+|x|)^{\max(d_{g}-k,0)}",where \(G^{(k)}\) denotes the \(k\)-th derivative of \(G\),\bar{w}_{i}^{\top}\Sigma_{X}^{-\frac{1}{2}}X=S_{i},Condition under which the rows of the matrix $\bar{W}$ correspond to the independent components in the linear ICA setting.
ICML_2024_oral_110,14,E(|S|^{q})=M,,|G^{(k)}(w^{\top}\Sigma_{X}^{-\frac{1}{2}}X)|\leq M\quada.s. for all k\leq 3,where $G^{(k)}$ denotes the $k$-th derivative of $G$
ICML_2024_oral_110,15,E(S_{i}g(S_{i})-g^{\prime}(S_{i}))=\alpha_{i},,E\left(g^{\prime}\left(e_{i}^{\top}S\right)\right)=\alpha_{i}\neq 0,where $\alpha_{i}$ is a non-zero constant related to the contrast function's sensitivity to the $i$-th component of $S$.
ICML_2024_oral_111,1,"L_{sup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE} (M_{i,j}^{l},Y_{i,j}^{l})","where \(M_{i,j}^{l}\) denotes the prediction mask of Burn-In model for the \(j\)-th pixel of \(i\)-th labeled image, \(Y_{i,j}^{l}\) denotes the corresponding ground truth, \(\mathcal{L}_{BCE}\) denotes binary cross entropy loss (Csiszar, 2008)","L_{Burn-In}=\frac{1}{|D_L|}\sum_{(x,y)\in D_L}CE(f_s(x;\theta_s), y)","Burn-In loss function minimizing cross-entropy (CE) between student model predictions $f_s$ with parameters $\theta_s$ and ground-truth labels $y$ over labeled data $D_L$, initializing the student network before mutual learning."
ICML_2024_oral_111,2,"\theta_{t}arrow\theta,\theta_{s}arrow\theta","where \(\theta_{t},\theta_{s},\theta\) denote the parameters of the teacher, student and Burn-In model, respectively",\theta_{teacher}^{(0)}=\theta_{student}^{(0)}=\theta,"where $\theta_{teacher}^{(0)}$ and $\theta_{student}^{(0)}$ denote the initial parameters of the teacher and student models, respectively, both set equal to the weights $\theta$ obtained from the Burn-In stage."
ICML_2024_oral_111,3,"L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE} (M_{i,j}^{u},\hat{M}_{i,j}^{u})","where \(M_{i,j}^{u}\) and \(\hat{M}_{i,j}^{u}\) denote the predicted mask for \(j\)-th pixel of \(i\)-th unlabeled image by student and teacher, respectively","L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}L_{BCE}(M_{i,j}^{u},\hat{Y}_{i,j}^{u})","where $M_{i,j}^{u}$ denotes the prediction mask of the student model for the $j$-th pixel of the $i$-th unlabeled image, and $\hat{Y}_{i,j}^{u}$ denotes the pseudo-label generated by the teacher model."
ICML_2024_oral_111,4,L=\lambda_{sup}L_{sup}+\lambda_{unsup}L_{unsup},where \(\lambda_{sup}\) and \(\lambda_{unsup}\) is the hyperparameter of supervised loss \(\mathcal{L}_{sup}\) and unsupervised loss \(\mathcal{L}_{unsup}\),L_{total}=L_{sup}+\lambdaL_{unsup},"where $\mathcal{L}_{sup}$ and $\mathcal{L}_{unsup}$ denote the supervised and unsupervised loss components, and $\lambda$ is a weighting factor balancing their contributions."
ICML_2024_oral_111,5,\theta_{t}arrow\alpha\theta_{t}+(1-\alpha)\theta_{s},"where \(\alpha\) is the decay coefficient of EMA, typically set within the small range of 0",\theta_{t}=\alpha\theta_{t}+(1-\alpha)\theta_{s},"where $\theta_{t}$ and $\theta_{s}$ denote the parameters of the teacher and student model, respectively, and $\alpha$ is the EMA decay parameter"
ICML_2024_oral_111,6,"s^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i, j,k}^{u})}{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cup\widetilde{M}_{i, j,k}^{u})}","where \(\hat{M}_{i,j}^{u}\) and \(\widetilde{M}_{i,j,k}^{u}\) denote the pseudo-labels and \(k\)-th segment mask generated by SAM for \(j\)-th pixel of \(i\)-th unlabeled image \(\mathcal{I}_{i}^{u}\), respectively","S_{iom}=\arg\max_{k}\frac{|M_{i,j}^{u}\cap S_{k}|}{|M_{i,j}^{u}\cup S_{k}|}","where $\mathcal{S}_{iom}$ denotes the selected segment via IoU-based Optimal Matching, $S_{k}$ represents the $k$-th candidate segment from the SAM-generated proposal library, and $M_{i,j}^{u}$ denotes the pseudo-label mask for the $j$-th pixel of the $i$-th unlabeled image"
ICML_2024_oral_111,7,"s_{1}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{ i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u})+\epsilon}",where \(\epsilon\) is the smoothing factor to prevent a denominator of zero,"r_{l}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i,j,k}^{u})}{\sum_{j=1}^{H\times W}\hat{M}_{i,j}^{u}}",where $r_{l}^{k}$ denotes the overlap ratio of pseudo-labels with the $k$-th segment mask generated by SAM for the $i$-th unlabeled image
ICML_2024_oral_111,8,"s_{2}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M} _{i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\widetilde{M}_{i,j,k}^{u} )}",,"s_{2}^{k}=\frac{\sum_{j=1}^{H\times W}(\hat{M}_{i,j}^{u}\cap\widetilde{M}_{i,j,k}^{u})}{\sum_{j=1}^{H\times W}(\widetilde{M}_{i,j,k}^{u})+\epsilon}","where $s_{2}^{k}$ computes the overlap ratio between the pseudo-label and the $k$-th SAM-generated segment for over-segmentation correction, with $\epsilon$ preventing division by zero"
ICML_2024_oral_111,9,"\Psi(\hat{M}^{u}_{i,j})=\gamma-\frac{1}{\sqrt{2\pi\sigma}}\exp(-\frac{(\hat{M}^{u}_{i,j}-\mu)^{2}}{2\sigma^{2}})","where \(\gamma,\sigma^{2},\mu\) are hyperparameters, which are set to 1","\Psi(M_{i,j}^{u})=1-\vert M_{i,j}^{u}-0.5\vert^{\gamma}","where $M_{i,j}^{u}$ denotes the predicted probability of the $j$-th pixel in the $i$-th unlabeled image, and $\gamma$ controls the sensitivity of weight assignment to confidence levels"
ICML_2024_oral_111,10,"L_{unsup}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}\Psi(\hat{M}^{u} _{i,j})*L_{BCE}(M^{u}_{i,j},\hat{M}^{u}_{i,j})",,"L_{i}^{u}=\frac{1}{H\times W}\sum_{j=1}^{H\times W}\Psi(\hat{M}^{u}_{i,j})\cdotL_{BCE}(M_{i,j}^{u},\hat{M}_{i,j}^{u})","where $\mathcal{L}_{i}^{u}$ denotes the weighted unsupervised loss for the $i$-th unlabeled image, incorporating pixel-wise confidence weighting via $\Psi(\hat{M}^{u}_{i,j})$"
ICML_2024_oral_113,1,"\nabla_{\theta}J(\pi_{\theta})=\operatorname*{E}_{s\sim\rho_{d},a\sim\pi(\cdot|s)}[\nabla_{\theta}\log(\pi_{\theta}(a))\hat{A}^{\pi_{\theta}}(s,a)]","where \(\hat{A}^{\pi_{\theta}}(s,a)\) is an advantage function that estimates the contribution of the transition to the gradient","\nabla_\thetaJ(\pi_\theta)=E_{\tau\sim\pi_\theta}\left[\sum_{t=0}^{T-1}\nabla_\theta\log\pi_\theta(a_t|s_t)\sum_{t'=t}^{T-1}\gamma^{t'-t} r(s_{t'}, a_{t'})\right]",The policy gradient theorem expresses the gradient of the expected return with respect to policy parameters as an expectation over trajectories of log-policy gradients weighted by cumulative discounted rewards.
ICML_2024_oral_113,2,"L_{on}(\pi_{\theta})&=\operatorname*{E}_{\pi_{old}}[\min(r_{t}(\pi_{\theta}),.\\&.clip(r_{t}(\pi_{\theta}),1-\epsilon,1+\epsilon))A_{t}^{\pi_{old}}]",,"\theta_{k+1}=\arg\max_{\theta}E_{s\sim\rho_{d}, a\sim\pi_{\theta_{k}}(\cdot|s)}\left[\min\left(\frac{\pi_{\theta}(a|s)}{\pi_{\theta_{k}}(a|s)}\hat{A}^{\pi_{\theta_{k}}}(s,a),clip\left(\frac{\pi_{\theta}(a|s)}{\pi_{\theta_{k}}(a|s)}, 1-\epsilon, 1+\epsilon\right)\hat{A}^{\pi_{\theta_{k}}}(s,a)\right)\right]","This equation defines the policy update rule in Proximal Policy Optimization (PPO), which limits the change in the policy using a clipped surrogate objective to ensure stable learning."
ICML_2024_oral_113,3,"& L_{off}(\pi_{i};X)=\frac{1}{|X|}\sum_{j\inX}\operatorname*{E}_{(s,a)\sim\pi_{j}}[\min (r_{\pi_{i}}(s,a),..\\&..clip(r_{\pi_{i}}(s,a),\mu(1-\epsilon),\mu(1+\epsilon)))A^{\pi_{i,old}}(s,a)]","where \(r_{\pi_{i}}(s,a)=\frac{\pi_{i}(s,a)}{\pi_{j}(s,a)}\) and \(\mu\) is an off-policy correction term \(\mu=\frac{\pi_{i,old}(s,a)}{\pi_{j}(s,a)}\)","\nabla_{\theta_{i}}J(\pi_{i})=\operatorname*{E}_{s\sim\rho_{d},a\sim\pi_{j}(\cdot|s)}\left[\nabla_{\theta_{i}}\log(\pi_{i}(a|s))\frac{\pi_{i}(a|s)}{\pi_{j}(a|s)}A^{\pi_{j}}(s,a)\right]","Off-policy gradient update for policy $\pi_i$ using data collected by policy $\pi_j$, incorporating importance sampling to correct for the policy mismatch."
ICML_2024_oral_113,4,L(\pi_{i})=L_{on}(\pi_{i})+\lambda\cdot L_{off}(\pi_{i};X),,L(\pi_{i})=\lambda L_{on}(\pi_{i})+(1-\lambda) L_{off}(\pi_{i};X\setminus\{i\}),Equation 4 combines the on-policy loss $L_{on}(\pi_{i})$ and the off-policy loss $L_{off}(\pi_{i}; \mathcal{X} \setminus \{i\})$ using a mixing coefficient $\lambda$ to balance their contributions in the overall objective function for policy $\pi_{i}$.
ICML_2024_oral_113,5,"V^{target}_{on,\pi_{j}}(s_{t})=\sum_{k=t}^{t+2}\gamma^{k-t}r_{k}+\gamma^{3}V_{\pi_{j},old}(s_{t+3})",,V_{t}^{target}=\sum_{k=0}^{n-1}\gamma^{k} r_{t+k}+\gamma^{n} V_{t+n}^{\pi_{\theta}}(s_{t+n}),"where $V_{t}^{\text{target}}$ is the $n$-step return target for the critic, calculated using rewards $r_{t+k}$ and the value function estimate $V_{t+n}^{\pi_{\theta}}$ at step $t+n$"
ICML_2024_oral_113,6,"V^{target}_{off,\pi_{j}}(s^{\prime}_{t})=r_{t}+\gamma V_{\pi_{j},old}(s^{\prime}_{t+1})",,"V^{target}_{off,\pi_{j}}(s_{t})=r_{t}+\gamma V_{\pi_{i},old}(s_{t+1})",Off-policy value target using a 1-step return approximation for transition $t$ from policy $\pi_j$ evaluated under $\pi_i$
ICML_2024_oral_113,7,"L^{critic}_{on}(\pi_{i})=\operatorname*{E}_{(s,a)\sim\pi_{i}}[( V_{\pi_{i}}(s)-V^{target}_{on,\pi_{i}}(s))^{2}] || L^{critic}_{off}(\pi_{i};X)=\frac{1}{|X|}\sum_{j\inX}\operatorname*{E}_{(s,a)\sim\pi_{j}}[(V_{\pi_{i}}(s)-V^{target}_{off,\pi_{i}}(s))^{2}] || L^{critic}(\pi_{i})=L^{critic}_{on}(\pi_{i})+\lambda\cdot L^{critic}_{off}(\pi_{i})",,"L_{critic}(\pi_{i})=\frac{1}{|X|}\sum_{j\inX}E_{(s, a)\sim\pi_j}\left[\left( V_{\pi_i}(s)-V^{target}_{\pi_j}(s)\right)^2\right]",The critic loss combines both on-policy and off-policy data to update the value function by minimizing the mean squared error between predicted and target values.
ICML_2024_oral_117,1,"Attention(q,K,V)=softmax(\frac{qK^{T}}{\sqrt{d_{model}}})V",,"v=Attention\left(q, K, V\right)=softmax\left(\frac{q\left((\Phi^{k;s}+E_{out})W_{out}^{K}\right)^\top}{\sqrt{d_{model}}}\right)\Phi^{k;s}","Equation 1 defines the scaled dot-product attention mechanism for the output attention head, computing the tentative output vector $\mathbf{v}$ as a function of the query $\mathbf{q}$, keys matrix $K$, and values matrix $V$ derived from preceding policies and positional encodings."
ICML_2024_oral_117,3,"RT=\frac{1}{N}\sum_{i=2}^{N}\max_{j<i}FTr(j,i)","where \(\text{FTr}(j,i)\) is the forward transfer obtained by training a model from scratch in the \(j\)-th task and fine-tuning it in the \(i\)-th task",RT_{i}=\max_{j < i}\left(\frac{AUC_{i}^{(j)}-AUC_{i}^{b}}{1-AUC_{i}^{b}}\right),"Reference forward Transfer (RT) computes the maximum normalized advantage of transferring knowledge from any previous task $j$ to the current task $i$, relative to the baseline performance."
ICML_2024_oral_121,1,"p(x;p^{m})=\sum_{i}^{N}k(x,d_{i})p_{i}^{m}",,p(x)=\sum_{i}\frac{p_i^{m}}{2\sigma} e^{-\frac{|x-d_i|}{\sigma}},"Continuous probability density function obtained by interpolating discrete disparities $\mathbf{d}$ with Laplacian kernels of bandwidth $\sigma$, where $p_i^{m}$ represents the probability mass at discrete disparity $d_i$."
ICML_2024_oral_121,2,"\texttt{argmin}_{y}F(y,p^{m})=\texttt{argmin}_{y}\intL(y,x )p(x;p^{m})dx","where \(F(y,\mathbf{p}^{m})\) is called as the risk at \(y\), and \(\mathcal{L}(y,x)\) is the error function between \(y\) and \(x\)","R(\hat{x})=\int_{-\infty}^{\infty} |\hat{x}-x |\, p(x;p^m)\, dx","The risk function $R(\hat{x})$ represents the expected absolute difference between the predicted disparity $\hat{x}$ and the true disparity $x$, weighted by the interpolated probability density $p(x; \mathbf{p}^m)$."
ICML_2024_oral_121,3,y=\int xp(x;p^{m})dx,,y_{\texttt{expectation}}=\int x p(x;p^{m})dx,Expectation value of the continuous disparity distribution as the final disparity prediction.
ICML_2024_oral_121,4,"\texttt{argmin}_{y}F(y,p^{m})=\texttt{argmin}_{y}\int|y-x|p(x;p^{m})dx",,"\texttt{argmin}_{y}F(y,p^{m})=\texttt{argmin}_{y}\int|y-x|p(x;p^{m})dx","This equation formulates the risk minimization using the $L^{1}$ norm loss, which is more robust to outliers and multi-modal distributions compared to the $L^{2}$ norm."
ICML_2024_oral_121,5,"G(y,p^{m})\triangleq\frac{\partial F(y,p^{m})} {\partial y} || =\sum_{i}p_{i}^{m}\texttt{Sign}(y-d_{i})(1-\exp-\frac{|y-d_{i}|}{\sigma})=0",,\frac{\partial F}{\partial y}=\int\texttt{sign}(y-x)p(x;p^{m})dx=0,The derivative of the risk function with respect to $y$ is set to zero to find the optimal prediction under the $L^{1}$ norm loss.
ICML_2024_oral_121,6,"dG(y,p^{m})=\frac{\partial G}{\partial y}dy+\frac{\partial G}{\partialp^{m}}dp^{m}=0",,"\frac{dy}{dp^{m}}=-\left(\frac{\partial G(y,p^{m})}{\partial y}\right)^{-1}\frac{\partial G(y,p^{m})}{dp^{m}}","Derivative of the optimal disparity $y$ with respect to the discrete distribution $\mathbf{p}^{m}$, computed via the Implicit Function Theorem for enabling end-to-end gradient propagation."
ICML_2024_oral_121,7,"\frac{dy}{dp^{m}}=-\frac{\partial G/\partialp^{m}}{\partial G/\partial y} || =[\dots,\frac{\sigma\texttt{Sign}(d_{i}-y)(1-\exp-\frac{|y-d_{i} |}{\sigma})}{\sum_{j}p_{j}^{m}\exp-\frac{|y-d_{i}|}{\sigma}},\dots]^{T}",,dy=-\left(\frac{\partial G}{\partial y}\right)^{-1}\frac{\partial G}{\partialp^{m}}dp^{m},"This equation expresses the change in the optimal disparity prediction $ y $ with respect to changes in the discrete probability distribution $ \mathbf{p}^m $, derived using the Implicit Function Theorem."
ICML_2024_oral_121,8,"L(x^{\texttt{gt}},x^{\texttt{pred}})=0.5(x^{\texttt{gt}}-x^{\texttt{pred}})^{2},&if |x^{\texttt{gt}}-x^{\texttt{pred}}|<1.0\\|x^{\texttt{gt}}-x^{\texttt{pred}}|-0.5,&otherwise",,"L_{\texttt{smooth}}(x^{\texttt{pred}},x^{\texttt{gt}})=\frac{1}{2}(x^{\texttt{pred}}-x^{\texttt{gt}})^{2} &if |x^{\texttt{pred}}-x^{\texttt{gt}}|<1\\|x^{\texttt{pred}}-x^{\texttt{gt}}|-\frac{1}{2} &otherwise","The smooth $L^{1}$ loss function used to train the network, which combines quadratic and absolute differences to balance robustness and smoothness."
ICML_2024_oral_122,1,"\min_{\theta}\,\sum_{i=1}^{N}(\hat{y}(x;\theta)-y_{i})^{2}",,MSE(\theta)=\frac{1}{N}\sum_{i=1}^{N}\left( y_i-\hat{y}(x_i;\theta)\right)^2,"Mean-squared error objective derived from maximum likelihood estimation under a normal distribution with fixed variance ÏÂ², where Å·(x;Î¸) is the predictor function and {x_i,y_i} are the training data."
ICML_2024_oral_122,2,"\min_{\theta}\,\sum_{i=1}^{N}\int_{Y}p(y\,|\,x_{i})\log(\hat{p}(y\,|\,x_ {i};\theta))dy",,"\min_{\theta}\,D_{KL}\left(p(y\,|\,x)\,\|\,\hat{p}(y\,|\,x;\theta)\right)","Equation 2 formulates the regression problem as minimizing the Kullback-Leibler divergence between the true conditional distribution $p(y\,|\,x)$ and a parameterized approximation $\hat{p}(y\,|\,x;\theta)$."
ICML_2024_oral_122,3,"Z=\{\sum_{i=1}^{m}p_{i}\,\delta_{z_{i}}\,:\,p_{i}\geq 0,\sum_{i=1} ^{m}p_{i}=1\}",where \(p_{i}\) is the probability associated with location \(z_{i}\) and \(\delta_{z_{i}}\) is the Dirac delta function at location \(z_{i}\),"z_{k}=v_{min}+\frac{(v_{max}-v_{min})(k-1)}{m-1},\quad k=1,\dots, m","The $m$ evenly spaced locations or ""classes"" $z_k$ are defined over the interval $[v_{\text{min}}, v_{\text{max}}]$."
ICML_2024_oral_122,4,"\boxed{TD_{MSE}(\theta)=E_{D}[((\tilde{T}Q)(S,A;\tilde{\theta})-\,Q(S,A;\theta))^{2}]} || (\tilde{T}Q)(s,a;\tilde{\theta})=R+\gamma\max_{a^{\prime}}Q(S^{\prime },a^{\prime};\tilde{\theta})\,\big{|}\,S=s,A=a\","where \(\tilde{\theta}\) is a slow moving copy of the parameters \(\theta\) that parameterize the ""target network"" and

\[(\tilde{\mathcal{T}}Q)(s,a;\tilde{\theta})=R+\gamma\max_{a^{\prime}}Q(S^{\prime },a^{\prime};\tilde{\theta})\,\big{|}\,S=s,A=a\,,\]

is the sample version of the Bellman optimality operator which defines our scalar regression target","\min_{\theta}\,E_{(S,A,R,S^{\prime})\simD}\left[\left(R+\gamma\max_{a^{\prime}}Q(S^{\prime},a^{\prime};\theta^{-})-Q(S,A;\theta)\right)^{2}\right]",where $\theta^{-}$ are parameters of a target network used to stabilize training and the expectation is over transitions sampled from the replay buffer $\mathcal{D}$.
ICML_2024_oral_122,5,"\alpha\,E_{D}[\log\big{(}\sum_{a^{\prime}}\exp(Q(S^{\prime},a^{\prime};\theta))\big{)}-Q(S,A;\theta)]",,"\boxed{CQL_{reg}(\theta)=\alpha\,E_{D}\left[\log\left(\sum_{a^{\prime}}\exp\left(Q(S,a^{\prime};\theta)\right)\right)\right]-E_{D}\left[Q(S,A;\theta)\right]}",This loss regularizes the Q-function by penalizing values on the dataset actions while encouraging low values on out-of-distribution actions.
ICML_2024_oral_122,6,"Q(s,a;\theta)=E[\,Z(s,a;\theta)\,],\Z(s,a;\theta)=\sum_{i=1}^{m}\hat{p}_{i}(s,a;\theta)\cdot\delta_{z_{i}} || \hat{p}_{i}(s,a;\theta)=\frac{\exp(l_{i}(s,a;\theta))}{\sum_{j=1} ^{m}\exp(l_{j}(s,a;\theta))}\",,"\hat{p}_{i}(s,a;\theta)=\frac{\exp(l_{i}(s,a;\theta))}{\sum_{j=1}^{m}\exp(l_{j}(s,a;\theta))}","where the categorical probabilities are obtained via softmax activation of logits $l_{i}(s,a;\theta)$ parameterized by $\theta$"
ICML_2024_oral_122,7,"\boxed{TD_{CE}(\theta)=E_{D}[\sum_{i=1 }^{m}p_{i}(S,A;\tilde{\theta})\log\hat{p}_{i}(S,A;\theta)]}",,"TD_{CE}(\theta)=E_{D}\left[-\sum_{i=1}^{m}p_{i}(S,A;\tilde{\theta})\log\left(\hat{p}_{i}(S,A;\theta)\right)\right]",This cross-entropy loss compares the target probabilities $p_i$ derived from the TD target with the predicted probabilities $\hat{p}_i$ from the model.
ICML_2024_oral_122,8,"p_{i}(S,A;\tilde{\theta})=\frac{y-z_{i}}{z_{i+1}-z_{i}},\p_{i+1}(S,A;\tilde{\theta})=\frac{z_{i+1}-y}{z_{i+1}-z_{i}}\",,"p_{i}=\frac{z_{i+1}-y}{z_{i+1}-z_{i}},\quad p_{i+1}=1-p_{i}",where the two-hot distribution assigns probabilities based on the relative distance of the scalar target $y$ to the nearest grid points $z_i$ and $z_{i+1}$
ICML_2024_oral_122,9,"p_{i}(S,A;\tilde{\theta})=\int_{z_{i}-\nicefrac{{\varsigma}}{{2}}}^{z_{i}+\nicefrac{{\varsigma}}{{2}}}f_{Y|S,A}(y|S,A)dy || =F_{Y|S,A}(z_{i}+\nicefrac{{\varsigma}}{{2}}|S,A)-F_{Y|S,A}(z_{i}-\nicefrac{{\varsigma}}{{2}}|S,A)",,"p_{i}(S,A;\tilde{\theta})=\int_{z_{i}-\nicefrac{\varsigma}{2}}^{z_{i}+\nicefrac{\varsigma}{2}}f_{Y|S,A}(y)\,dy=F_{Y|S,A}(z_{i}+\nicefrac{\varsigma }{2})-F_{Y|S,A}(z_{i}-\nicefrac{\varsigma}{2})\","Projects the conditional distribution of the TD target onto a histogram by integrating over intervals centered at each bin location $z_i$, capturing ordinal structure through probability mass distribution across multiple bins."
ICML_2024_oral_122,10,"(\widehat{T}Z)(s,a;\tilde{\theta})\overset{D}{=}\sum_{i=1}^{m}\hat{p}_{i}(S^{\prime},A^{\prime};\tilde{\theta})\cdot\delta_{R+\gamma z_{i}}\bigm{|}S=s,\,A=a\","where \(A^{\prime}=\operatorname*{arg\,max}_{a^{\prime}}Q(S^{\prime},a^{\prime}; \tilde{\theta})\)","p_{i}(S,A;\tilde{\theta})=\Phi\left(\frac{z_{i}+\nicefrac{\varsigma}{2}-(\widehat{T}Q)(S,A;\tilde{\theta})}{\sigma}\right)-\Phi\left(\frac{z_{i}-\nicefrac{\varsigma}{2}-(\widehat{T}Q)(S,A;\tilde{\theta})}{\sigma}\right)","where $\Phi(\cdot)$ is the cumulative distribution function of the standard normal distribution, and the probabilities are computed by integrating the Gaussian density over each bin interval centered at $z_i$."
ICML_2024_oral_122,11,"p_{i}(S,A;\tilde{\theta})=\sum_{j=1}^{m}\hat{p}_{j}(S^{\prime},A ^{\prime};\tilde{\theta})\cdot\xi_{j}(R+\gamma z_{i}) || \xi_{j}(x)=\frac{x-z_{j}}{z_{j+1}-z_{j}}\mathds{1}\{\lfloor x\rfloor=z_{j}\}+\frac{z_{j+1}-x}{z_{j+1}-z_{j}}\mathds{1}\{\lceil x\rceil=z_ {j}\}\",,"p_{i}(S,A;\tilde{\theta})=\sum_{j=1}^{m}\hat{p}_{j}(S^{\prime},A^{\prime};\tilde{\theta})\cdot\frac{z_{j}-\left(R+\gamma z_{i}\right)}{z_{j}-z_{j-1}} &if i=j-1,\\\frac{\left(R+\gamma z_{i}\right)-z_{j-1}}{z_{j}-z_{j-1}} &if i=j,\\0 &otherwise",where the projection redistributes the probability mass from the distributional Bellman update to the nearest neighboring locations based on the shifted and scaled return values
ICML_2024_oral_125,1,"E_{i}=L_{i}(E_{i-1}),\\i=1,...,N || \dot{y}=\texttt{Head}(e_{N}^{0})",,"E_{i+1} &=L_{i+1}(E_i),\quad\forall i\in\{0, 1,\dots, N-1\},\\where E_0 &=\{e_{pos}\cupe_{patch}^j\cupe_{[CLS]}\}_{j=1}^m","Equation 1 defines the iterative transformation of patch embeddings through ViT layers, where each layer $L_{i+1}$ updates the input embeddings $\mathbf{E}_i$ to produce $\mathbf{E}_{i+1}$, initialized with positional tokens, image patch embeddings, and the [CLS] token."
ICML_2024_oral_125,3,"p^{*}=\operatorname*{arg\,min}_{p}L(f_{\Theta}(p;x))","where \(\mathcal{L}(\cdot)\) is a fitness function and \(\mathbf{p}\in\mathbb{R}^{d\times N_{p}}\) consists of \(N_{p}\) prompt embeddings, each of dimension \(d\)","p^{*}=\arg\min_{p}F(x,p;\Theta)",where $\mathcal{F}(\cdot)$ is the unsupervised fitness function designed to guide the covariance matrix adaptation (CMA) optimizer in learning the optimal prompt $\mathbf{p}^{*}$ for test-time adaptation.
ICML_2024_oral_125,4,L(f_{\Theta}(p;X_{t}))=\sum_{ x\inX_{t}}\sum_{c\inC}-\hat{y}_{c}\log\hat{y}_{c} || \qquad+\lambda\sum_{i=1}^{N}\lvert\lvert\mu_{i}(X_ {t})-\mu_{i}^{S}\rvert\rvert_{2}+\lVert\sigma_{i}(X_{t})-\sigma_{i}^{S}\rvert\rvert_{2},,"L(X_{t};p)=\alpha\cdot H\left(\frac{1}{|X_{t}|}\sum_{x\inX_{t}}f_{\Theta}(p;x)\right)+\beta\cdot\sum_{i=0}^{N}d\left(\mu_{i}^{S},\mu_{i}(X_{t})),\sigma_{i}^{S},\sigma_{i}(X_{t})\right)","where $H(\cdot)$ denotes the entropy of predictions, $d(\cdot)$ measures the discrepancy between source and target activation statistics, and $\alpha,\beta$ are trade-off coefficients balancing the two terms."
ICML_2024_oral_125,5,"p_{k}^{(t)}\simm^{(t)}+\tau^{(t)}N(0,\bm {\Sigma}^{(t)})",,"p_{k}^{(t)}\simN(m^{(t)},\sigma^{(t)}C^{(t)}),\\k=1,...,K","where $\mathbf{m}^{(t)}$ is the mean vector, $\sigma^{(t)}$ is the step size, and $\mathbf{C}^{(t)}$ is the covariance matrix of the distribution at iteration $t$, and $K$ is the number of sampled candidate prompts per iteration."
ICML_2024_oral_125,6,e_{N}^{0}arrowe_{N}^{0}+\gammad,where \(\mathbf{d}\) is a shifting direction and \(\gamma\) is a step size,e_{N}^{0}\leftarrowe_{N}^{0}+\eta(\mu_{N}^{S}-\mu_{N}(X_{t})),where $\eta$ is a scaling factor that controls the magnitude of the activation shift towards the source domain mean $\mathbf{\mu}_{N}^{S}$ from the current test batch mean $\mathbf{\mu}_{N}(\mathcal{X}_{t})$.
ICML_2024_oral_125,7,d_{t}=\mu_{N}^{S}-\mu_{N}(t),where \(\boldsymbol{\mu}_{N}^{S}\) is the mean of the \(N\)-th final layer CLS feature \(\mathbf{e}_{N}^{0}\) and calculated over source in-distribution samples \(\mathcal{D}_{S}\) (the same one used in Eqn,d^{(t)}=\mu^{S}-\mu(X_{t}),where $\mathbf{\mu}^{S}$ is the mean of source in-distribution CLS features and $\mathbf{\mu}(\mathcal{X}_{t})$ is the mean of CLS features from the current test batch $\mathcal{X}_{t}$.
ICML_2024_oral_125,8,\mu_{N}(t)=\alpha\mu_{N}(X_{t})+(1-\alpha )\mu_{N}(t-1),where \(\boldsymbol{\mu}_{N}(\mathcal{X}_{t})\) is the mean of the \(N\)-th layer's CLS feature and calculated over the \(t\)-th test batch \(\mathcal{X}_{t}\),\mu_{N}(t)=(1-\beta)\mu_{N}(t-1)+\beta\cdot\frac{1}{|X_{t}|}\sum_{x\inX_{t}}e_{N}^{0}(x),where $\beta$ is a smoothing factor that controls the weight of the current batch statistics in the exponential moving average update of the test set mean $\boldsymbol{\mu}_{N}(t)$.
ICML_2024_oral_127,1,\sup_{x}\mathds{E}_{D^{j}\sim\chi}[\lfloor\frac{j}{i}\hat{f}(x )-f_{D^{j}}(x)\rceil]\geq\frac{\sqrt{k}}{4},,\sup_{x}E_{D^{j}\sim\chi}\left[\left|\frac{j}{i}\hat{f}(x)-f_{D^{j}}(x)\right|\right]\geq\frac{C}{\sqrt{i}}\cdot\left(1-\frac{i}{j}\right),"Equation 1 provides a lower bound on the expected maximum generalization error of a model trained after the i-th insertion and evaluated after k further insertions, capturing the degradation in performance as a function of the initial training size and the number of subsequent insertions."
ICML_2024_oral_127,2,\mathds{P}_{D\sim\chi}[\|f_{\chi}-\hat{f}\|_{\infty}\geq\epsilon]\leq\varkappa_ {1}e^{-\varkappa_{2}(\frac{\epsilon}{\sqrt{n}}-1)^{2}},,"\sup_{x}\mathds{E}_{D\sim\chi}[L(\hat{f}(x), f_{D}(x))]\leqB_{n}^{X}",Expected maximum loss between the model prediction and the true operation value is bounded by the learnability bound $\mathcal{B}_{n}^{\mathfrak{X}}$.
ICML_2024_oral_13,1,"&P\{X_{1}=x_{1}\}\\&P\{X_{2}=x_{2}|X_{1}=x_{1}\}\\&\quad\vdots\\&P\{X_{n}=x_{n}|X_{1}=x_{1},\cdots,X_{n-1}=x_{n-1 }\}",,"P(X_{1}=x_{1},\ldots,X_{n}=x_{n})=\prod_{i=1}^{n} P(X_{i}=x_{i}\mid X_{1}=x_{1},\ldots,X_{i-1}=x_{i-1}})",The joint probability of a sequence of tokens is modeled as the product of conditional probabilities of each token given the previous tokens.
ICML_2024_oral_13,2,"&P\{X_{n}=x_{n}\}\\&P\{X_{n-1}=x_{n-1}|X_{n}=x_{n}\}\\&\quad\vdots\\&P\{X_{1}=x_{1}|X_{n}=x_{n},\cdots,X_{2}=x_{2}\}",,"&P\{X_{n}=x_{n}\}\\&P\{X_{n-1}=x_{n-1}|X_{n}=x_{n}\}\\&\quad\vdots\\&P\{X_{1}=x_{1}|X_{n}=x_{n},\cdots,X_{2}=x_{2}\}","This equation represents the backward-time factorization of the joint probability distribution, where predictions are made in reverse order, starting from the last token and conditioning on future tokens to predict earlier ones."
ICML_2024_oral_13,4,L_{n}^{arrow}=D_{KL}(P_{n}\big{|}\big{|}P_{n}^{arrow})+H(P_{n}),where \(H\) denotes the entropy and \(\mathrm{D}_{\mathrm{KL}}\) the Kullback-Leibler divergence,"L_{n}^{\leftarrow}=E_{P_{n}}\left[-\lnP_{n}^{\leftarrow}\{X_{1}=x_{1},\cdots,X_{n}=x_{n}\}\right]",Equation 4 defines the expected cross-entropy loss of the backward model in terms of the expectation under the true distribution of the negative log of the backward model's estimated joint probability.
ICML_2024_oral_132,1,P(A(D)\in S)\leq e^{\epsilon}P(A(D^{\prime})\in S)+\delta,,"\forallD,D^{\prime} differing in one sample,\forall S:\Pr[A(D)\in S]\leq e^{\epsilon}\Pr[A(D^{\prime})\in S]+\delta","Formal definition of $(\epsilon,\delta)$-differential privacy, requiring that the output distribution of algorithm $\mathcal{A}$ on adjacent datasets $\mathcal{D},\mathcal{D}^{\prime}$ differs by at most multiplicative factor $e^{\epsilon}$ and additive term $\delta$ for all measurable sets $S$."
ICML_2024_oral_132,2,\epsilon=\epsilon_{\alpha}+\log(\frac{\alpha-1}{\alpha})-\frac{\log\delta+\log\alpha}{\alpha-1},,\epsilon=\epsilon_{\alpha}+\frac{\log(1/\delta)}{\alpha-1},"Conversion formula from Renyi differential privacy (RDP) to differential privacy (DP), showing how the RDP parameters $(\alpha, \epsilon_{\alpha})$ relate to the DP parameters $(\epsilon, \delta)$."
ICML_2024_oral_132,3,"\widetilde{g}_{t}=\frac{1}{B}(\sum_{x\inB_{t}}clip_{C}(\nabla_{\theta}\ell(x;\theta_{t})+N(0,\sigma^{2}C^{2}I))","where \(\eta_{t}\) is the learning rate, \(\mathcal{B}_{t}\) is the sampled batch, \(B\) is the average batch size, \(\sigma>0\) is the noise multiplier, and \(\mathsf{clip}_{C}\) is the operation that clips the per-sample gradient norm to at most \(C>0\)","\widetilde{g}_{t}=\frac{1}{B}\sum_{i=1}^{B}clip_{L}(\nabla\ell(\theta_{t};z_{i}))+N(0,\sigma^{2}L^{2}I)",The gradient estimate $\widetilde{\mathbf{g}}_{t}$ in DP-SGD includes per-sample gradient clipping and additive Gaussian noise to ensure differential privacy.
ICML_2024_oral_132,4,"L_{MAE}(\theta):=\frac{1}{n}\sum_{i=1}^{n}\underbrace{\xi_{ MSE}(g\circ\psi(mask(x_{i});\theta),x_{i})}_{\ell(x_{i};\theta)}","where \(n\) is the number of training samples, \(\mathbf{x}_{i}\in\mathbb{R}^{C\times H\times W}\) is the input of the \(i\)-th training image (\(C\)-number of channels, \(H\)-height, \(W\)-width), mask\((\cdot)\) is a function that mask out a fraction of the image, \(\psi:\mathbb{R}^{C\times H\times W}\rightarrow\mathbb{R}^{d}\) is the encoder and \(g:\mathbb{R}^{d}\rightarrow\mathbb{R}^{C\times H\times W}\) is the decoder",L_{MAE}(\theta)=E_{x\simD}\left[\frac{1}{|M(x)|}\sum_{z\inM(x)}\ell_{rec}(z;\theta)\right],"The MAE training objective computes the expected reconstruction loss over masked views of each sample, making it compatible with DP-SGD due to its per-sample independence."
ICML_2024_oral_15,1,\min_{p(T|X)}\quad I(X;T),where \(I(X;T)\) denotes the mutual information of \(X\) and \(T\),T^*=\arg\min_{T}\left\{ D(T) : R(T)\leq R_0\right\},Optimal transform $\mathcal{T}^*$ minimizing distortion $D(\mathcal{T})$ under a rate constraint $R_0$.
ICML_2024_oral_15,2,\min_{p(T|X)} I(X;T),,\min_{p(T|X)}\quad I(X;T)-\beta I(T;Q),"where $I(T;Q)$ denotes the mutual information between $T$ and $Q$, and $\beta$ is a trade-off parameter."
ICML_2024_oral_15,3,I(T;Q)\geq\varepsilon,where \(\varepsilon>0\) is a threshold,"subject to  D(X, T)\leq\epsilon","where $D(X, T)$ represents the distortion measure between $X$ and $T$, and $\epsilon$ is the maximum allowable distortion."
ICML_2024_oral_15,4,L(p(T|X))=I(X;T)-\beta I(T;Q),where \(\beta\) is the Lagrange multiplier,L(p(T|X))=I(X;T)-\beta I(T;Q),where $\beta$ is a Lagrange multiplier balancing the tradeoff between index conciseness and retrieval accuracy.
ICML_2024_oral_15,5,L(p(T|X))=I(X;T)+\beta I(X;Q|T)+constant,,L(p(T|X))=I(X;T)-\beta I(T;Q),where $\beta$ controls the tradeoff between index conciseness and retrieval accuracy
ICML_2024_oral_15,6,"p^{*}(T|X)=\frac{p^{*}(T)}{Z(X,\beta)}\exp\Bigl{(}-\betaKL[p(Q|X)\\big{\|}\p(Q|T)]\Bigr{)}","where \(Z(X,\beta)\) is a probability normalization term, \(p^{*}(T)=\mathbb{E}_{X}[p^{*}(T|X)]\)",p^{*}(T|X)=\frac{p(T)}{Z(X)}\exp\left(-\beta D_{KL}\left(p(Q|X)\parallel p(Q|T)\right)\right),where $Z(X)$ is the normalization constant and $D_{\mathrm{KL}}$ denotes the Kullback-Leibler divergence
ICML_2024_oral_15,7,"p(X,Q|f)\equiv\prod_{x\inX}p^{*}\big{(}X=x\\big{|}\T=f(x)\big{)}",where \(p^{*}\) is given by Formula (5),"p(X,Q|f)=\prod_{x\inX}p^{*}(T=f(x))\exp\Bigl{(}-\betaKL[p(Q|x)\\big{\|}\p(Q|T=f(x))]\Bigr{)}","where $p^{*}(T=f(x))$ is the marginal distribution of $T$, and the exponential term involves the Kullback-Leibler divergence between $p(Q|x)$ and $p(Q|T=f(x))$"
ICML_2024_oral_15,8,"I(X;T)=E_{X,T}\log\frac{p(X|T)}{p(X)} || I(X;Q|T)=E_{X,T,Q}\log\frac{p(X,Q|T)}{p(X|T)p(Q|T)}",,"tags and the description in <description>. The description for Equation 8 should be a one-sentence variable description. Since Equation 8 is defining mutual information, the description could be something like ""where $I(X;T)$ denotes the mutual information between $X$ and $T$"". Wait, but looking back at the previous equations, for Equation 1 the description was ""where $I(X;T)$ denotes the mutual information of $X$ and $T$"", and Equation 4 had a similar description. However, in Equation 8, since it's the definition, the description might just be stating that it's the mutual information definition. But the user instruction says: ""wrap one sentence variable description in <description>..."". So the description should explain what the equation is, not just restate the variables. For example, ""Definition of mutual information between $X$ and $T$"". Putting it all together, the LaTeX code for Equation 8 should be the standard mutual information formula, written in summation form for discrete variables. The description should indicate that this is the definition of mutual information between X and T. </think>",". The description for Equation 8 should be a one-sentence variable description. Since Equation 8 is defining mutual information, the description could be something like ""where $I(X;T)$ denotes the mutual information between $X$ and $T$"".

Wait, but looking back at the previous equations, for Equation 1 the description was ""where $I(X;T)$ denotes the mutual information of $X$ and $T$"", and Equation 4 had a similar description. However, in Equation 8, since it's the definition, the description might just be stating that it's the mutual information definition.

But the user instruction says: ""wrap one sentence variable description in"
ICML_2024_oral_15,9,"=E_{X,T,Q}\log\frac{p(X|Q)}{p(T|Q)}\frac{p(T)}{p(X)}",,"I(X;Q|T)=E_{X,T,Q}\log\frac{p(X,Q|T)}{p(X|T)p(Q|T)}","Conditional mutual information quantifying the information distortion due to the index $T$ in representing the joint distribution $p(X,Q)$"
ICML_2024_oral_22,1,"x_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\Big{(}x_{t}-\frac{1-\alpha_{t}} {\sqrt{1-\bar{\alpha}_{t}}}\epsilon_{\theta}(x_{t},t,c)\Big{)}+\sigma_{t}\epsilon","where \(\mathbf{\epsilon}\sim\mathcal{N}(0,I)\), \(\alpha_{0}:=1\), \(\alpha_{t}\) and \(\bar{\alpha}_{t}\) define the noise schedule, \(\sigma_{t}\) is the sampling standard deviation","x_{t-1}=\frac{1}{\sqrt{\alpha_t}}\left(x_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}}\epsilon_{\theta}(x_t, t,c)\right)+\sigma_tz","Equation 1 defines the reverse process update rule for denoising diffusion probabilistic models (DDPMs), where $\mathbf{x}_t$ is the noisy input at step $t$, $\mathbf{\epsilon}_{\theta}$ is the learned noise prediction network, $\alpha_t$ and $\bar{\alpha}_t$ are variance schedule parameters, $\sigma_t$ controls the noise scale, and $\mathbf{z} \sim \mathcal{N}(0, I)$ is standard Gaussian noise."
ICML_2024_oral_22,2,"x_{T}^{*}=\arg\min_{x_{T}}L(f(x_{0}),y) || x_{0}=\texttt{Sampler}_{T}(\epsilon_{\theta},x_{T},c)",,"x_{T}^{*}=\arg\min_{x_{T}}L\big{(}f(\texttt{Sampler}_{T}(\epsilon_{\theta},x_{T},c)),y\big{)}",Optimization problem formulation to find the optimal initial noise latents $\mathbf{x}_{T}^{*}$ that minimize the loss between the model output features and the target control $\mathbf{y}$.
ICML_2024_oral_24,1,"\omega_{1}(D_{1},D_{2},J)=\frac{1}{N}\sum_{i=1}^{N}\mathds{1}\{J(q_{i},a_{i1}, a_{i2})=a_{i1}\}",,"\omega_{1}=\frac{1}{N}\sum_{i=1}^{N}I\left[J(q_i, a_{i1}, a_{i2})=a_{i1}\right]",Win rate for Debater $D_{1}$ based on the judge's selection frequency of $a_{i1}$ across $N$ questions.
ICML_2024_oral_24,2,"\bar{\omega}_{1}(D_{1},D_{2},J)>\frac{1}{2}",,"\bar{\omega}_{1}(D_{1},D_{2},J)=\frac{1}{2N}\sum_{i=1}^{N}\left[\mathds{1}\{J(q_{i},a_{i1},a_{i2})=a_{i1}\}+\mathds{1}\{J(q_{i},a_{i2},a_{i1})=a_{i2}\}\right]",Average win rate accounting for both argument assignments to eliminate assignment bias.
ICML_2024_oral_24,3,"\bar{\omega}_{1}(D_{1},D_{2},J)=\frac{1}{1+10^{(E_{2}-E_{1})/400}}",,"E_{1}(D_{1},D_{2},J)=E_{1}(D_{1},J)\quadand\quad E_{2}(D_{1},D_{2},J)=E_{2}(D_{2},J)","The aggregate Elo rating for each debater is defined as their latent skill independent of the specific match-up, capturing their overall persuasiveness across a population of co-debaters and judges."
ICML_2024_oral_24,4,"\omega_{C}(D_{1},D_{2},J)=\frac{1}{1+10^{(E^{I}_{2}-E^{C}_{1})/400}}",,"\omega_{C}(D_{1},D_{2},J)=\frac{1}{N_{C}}\sum_{i=1}^{N}\mathds{1}\{J(q_{i},a_{i1},a_{i2})=a_{i1}\land a_{i1} is correct\}+\mathds{1}\{J(q_{i},a_{i1},a_{i2})=a_{i2}\land a_{i2} is correct\}",Conditional win rate $\omega_{C}$ measures the frequency with which the judge selects the correct answer when it is available.
ICML_2024_oral_25,1,"\min_{\theta}KL(p(Y|X)\|q(Y|X,\theta))",,"tags and the description in <description>. Also, check for any possible typos or formatting issues. For example, using\mathcal for the loss function, and ensuring that the subscript CE is properly formatted with\text{} if needed. Yes, in LaTeX, usingCE within\mathcal might not be necessary, but typically, subscripts like CE are in text mode. Wait, actually, in the equation, the subscript is just ""CE"", which is an abbreviation, so it should be in upright text. So usingCE orCE would be appropriate. Since the user's example usesCE, I'll follow that. So the final LaTeX should be",". Also, check for any possible typos or formatting issues. For example, using \mathcal for the loss function, and ensuring that the subscript CE is properly formatted with \text{} if needed. 

Yes, in LaTeX, using \text{CE} within \mathcal might not be necessary, but typically, subscripts like CE are in text mode. Wait, actually, in the equation, the subscript is just ""CE"", which is an abbreviation, so it should be in upright text. So using \mathrm{CE} or \text{CE} would be appropriate. Since the user's example uses \text{CE}, I'll follow that. 

So the final LaTeX should be:

<latex>\min_{\mathbf{\theta}^{(k)}} \mathcal{L}_{\text{CE}}(\mathbf{\theta}^{(k)})</latex>

And the description would be: ""Optimization problem for the k-th model in the deep ensemble, minimizing the cross-entropy loss with respect to its parameters Î¸^{(k)}.""

I think that's correct. Let me double-check the context to make sure I didn't miss anything. The equation is supposed to represent each model's individual optimization problem, which is minimizing cross-entropy loss. Yes, that's exactly what the context says. The parameters are Î¸^{(k)}, and there are K models. 

No other variables or constraints are mentioned, so the equation is straightforward. No need for regularization terms or other components. Just the minimization of the cross-entropy loss for each model.
</think>

<latex>\min_{\mathbf{\theta}^{(k)}} \mathcal{L}_{\text{CE}}(\mathbf{\theta}^{(k)})</latex>"
ICML_2024_oral_25,2,"H(q(Y|X))=\underbrace{I(Y;\theta| X)}_{D}+\underbrace{E_{q(\theta|D)}H(q(Y|X,\theta))}_{D}",where \(\mathcal{I}\) denotes the mutual information under the \(q\) distribution,"Var_{q(Y|X)}[Y]=E_{p(\theta|D)}[Var_{q(Y|X,\theta)}[Y]]+Var_{p(\theta|D)}[E_{q(Y|X,\theta)}[Y]]","This equation decomposes the predictive uncertainty into expected variance and variance of the expectation, reflecting aleatoric and epistemic uncertainty components, respectively."
ICML_2024_oral_25,3,H(q(Y|X))=\underbrace{I(Y;C|X)}_ {Q^{\prime}}+\underbrace{E_{q(C|X)}H( q(Y|X\oplusC))}_{Q^{\prime}},,H(q(Y|X))=\underbrace{I(Y;C| X)}_{Clarification Disagreement}+\underbrace{E_{q(C|X)}H(q(Y|X\oplusC))}_{Clarification Uncertainty},"This equation decomposes the predictive uncertainty into two components: the mutual information between the output and the clarifications (Clarification Disagreement), and the expected entropy of predictions conditioned on each clarification (Clarification Uncertainty)."
ICML_2024_oral_26,2,"& o_{i}=\sum_{j=1}^{n}\frac{e^{q_{i}k_{j}^{\intercal}} }{\sum_{j^{\prime}=1}^{n}e^{q_{i}k_{j^{\prime}}^{\intercal}}v_{j}},\\&where q_{i},k_{i},v_{i}\inR^{1\times d},i=\{1,2,...,n\}",,"o_{i}=\sum_{j=1}^{n}softmax(q_{i}k_{j}^{\intercal}) v_{j},\quad\forall i\in\{1, 2, ..., n\}","Equation 2 reformulates the self-attention mechanism from Equation 1 by expressing the output token $o_i$ as a weighted sum of value vectors $v_j$, with weights determined by the softmax of the dot product between query vector $q_i$ and key vector $k_j$."
ICML_2024_oral_26,3,"o_{i}=\sum_{j=1}^{n}\frac{K(q_{i},k_{j})}{\sum_{j^{\prime}=1}^{n}K( q_{i},k_{j^{\prime}})}v_{j}",,"&Attention(Q,K,V)=\frac{K(Q,K)V}{diag(K(Q,K)1)},\\&where K(Q,K)\inR^{n\times n} with K(Q,K)_{ij}=K(q_{i},k_{j})","This equation reformulates the attention mechanism using a kernel function to measure similarity, reducing computational demands by avoiding explicit softmax normalization."
ICML_2024_oral_26,4,o_{i}=\sum_{j=1}^{n}\frac{\phi(q_{i})\phi(k_{j})^{\intercal}}{\sum_{j^{\prime }=1}^{n}\phi(q_{i})\phi(k_{j^{\prime}})^{\intercal}}v_{j},where \(\phi(\cdot):\mathbb{R}^{d}\rightarrow\mathbb{R}^{m}\) is a projection to map the inputs into \(m\) dimension features,"o_{i}=\frac{\sum_{j=1}^{n}K(q_{i},k_{j})v_{j}}{\sum_{j^{\prime}=1}^{n}K(q_{i},k_{j^{\prime}})}=\frac{\phi(q_{i})^{\intercal}\sum_{j=1}^{n}\phi(k_{j})v_{j}}{\phi(q_{i})^{\intercal}\sum_{j^{\prime}=1}^{n}\phi(k_{j^{\prime}})},\\where \phi(\cdot) is a feature map that projects the input into a reproducing kernel Hilbert space","This equation reformulates the attention mechanism using a linear decomposition enabled by the kernel trick, where the feature map $\phi(\cdot)$ allows the computation to be expressed in terms of inner products in a higher-dimensional space."
ICML_2024_oral_26,5,\phi_{PRF}(x)=e^{\omega x^{\intercal}-\frac{1+x^{2}}{2}},where \(\omega\in\mathbb{R}^{m\times d}\),\phi_{PRF}(x)=\left|\frac{1}{\sqrt{m}}\cos(Gx+b)\right|,"where $G\in\mathbb{R}^{m\times d}$ is a matrix of random Gaussian weights, $b\in\mathbb{R}^{m}$ is a vector of random biases, and $m$ is the number of random features."
ICML_2024_oral_26,6,"K(x,z)=\int_{R^{d}}e^{i(x-z)^{\intercal}w}p(w)dw=E_{w\sim p(\cdot)}[ e^{iw^{\intercal}x}(e^{iw^{\intercal}z})^{\intercal}]",,"K(q,k)=e^{qk^{\intercal}}=\int_{R^{d}}e^{i\omega(q-k)^{\intercal}}p(\omega)d\omega","where $K(q,k)$ represents the Gaussian kernel, $q$ and $k$ are queries and keys, and $p(\omega)$ is the probability measure over frequencies $\omega$ derived from the Fourier transform of the kernel function."
ICML_2024_oral_26,7,"K(x,z)=E_{w\sim p(\cdot)}[e^{iw^{\intercal}x}(e^{iw^{\intercal}z})^{\intercal }]\approx\varphi_{p}(x)^{\intercal}\varphi_{p}^{*}(z)",where \(w_{i}\sim p(\cdot)\) are samples constructed by Monte Carlo methods,"\varphi_{p}(x):=\frac{1}{\sqrt{m}}[e^{-iw_{1}^{\intercal}x},...,e^{-iw_{m}^{\intercal}x}]^{\intercal}","where $w_{1},...,w_{m}$ are sampled i.i.d from $p(\cdot)$ and $m$ is the number of random features"
ICML_2024_oral_26,8,"K_{G}(x,y):=e^{-\frac{\|x-y\|^{2}}{2}}=e^{-\frac{\|x\|^{2}+\|y\|^{2}}{2}}e^{x ^{\intercal}y}",,"K(q_i, k_j)=e^{q_i k_j^\intercal}=E_{w\simN(0, I)}\left[\varphi_p(q_i)^\intercal\varphi_p(k_j)\right]",where $\varphi_p(x)$ represents the feature map derived from the Gaussian kernel using Bochner's theorem
ICML_2024_oral_26,9,"\varphi_{PFF}(x):=\frac{e^{-\|x\|^{2}}}{\sqrt{m}}[e^{\Phi^{-1}(t_{1}) x^{\intercal}v_{1}},...,e^{\Phi^{-1}(t_{m})x^{\intercal}v_{m}}]^{\intercal}",,"\phi_{PFF}(x)=\frac{1}{\sqrt{m}}[\cos(w_{1}^{\intercal}x),\sin(w_{1}^{\intercal}x),...,\cos(w_{m}^{\intercal}x),\sin(w_{m}^{\intercal}x)]^{\intercal}","where $w_i$ are fixed frequency components derived from the Fourier transform of the kernel, enabling efficient and deterministic feature mapping"
ICML_2024_oral_26,10,"\varphi_{WPFF}(x):=\frac{De^{-\|x\|^{2}}}{\sqrt{m}}[e^{\Phi^{-1}(t_{1 })x^{\intercal}v_{1}},...,e^{\Phi^{-1}(t_{m})x^{\intercal}v_{m}}]^{\intercal}",,\varphi_{WPFF}(x):=\frac{e^{-\|x\|^{2}}}{\sqrt{m}}\sum_{l=1}^{m}w_{l}e^{\Phi^{-1}(t_{l})x^{\intercal}v_{l}},where $w_{l}$ are weights assigned to each feature to further enhance the approximation accuracy of the Gaussian kernel.
ICML_2024_oral_26,11,\smallC_{j_{1}j_{2}}=s_{j_{1}}s_{j_{2}}\sum_{i_{1}=0}^{n-1}\sum_{i_{2}=0 }^{d-1}\cos(\frac{\pi(2i_{1}+1)j_{1}}{2d})\cos(\frac{\pi(2i_{2}+1)j_{2}}{2d}),where \(s_{j}=\sqrt{1/d}\) if \(j=0\) and \(s_{j}=\sqrt{2/d}\) otherwise,C_{ij}=\sqrt{\frac{2}{d}}\cos\left(\frac{\pi}{d}i\left(j+\frac{1}{2 }\right)\right),"where $\mathcal{C}_{ij}$ denotes the coefficient at the $i$-th frequency and $j$-th position in the DCT matrix, enabling efficient computation through real-number operations."
ICML_2024_oral_26,12,\small\phi_{WDCF}(x)=De^{TCx^{\intercal}},"where \(\mathcal{C}\in\mathbb{R}^{m\times d}\) is the DCT coefficient, \(D\in\mathbb{R}^{m}\) is a learnable weight, and \(T=\text{diag}(t_{1},\dots,t_{m})\) is a random diagonal matrix following the inverse cumulative distribution","\varphi_{WDCF}(x):=\frac{De^{-\|x\|^{2}}}{\sqrt{m}}[e^{C_{1}^{\intercal}x},...,e^{C_{m}^{\intercal}x}]^{\intercal}","where $D$ is a learnable scaling parameter and $\mathcal{C}_{i}^{\intercal}x$ represents the inner product between the $i$-th DCT basis vector and input $x$, enabling efficient kernel approximation through frequency domain transformation."
ICML_2024_oral_26,13,"\smallFKA(Q,K,V)=\phi_{WDCF}(Q)\phi_{WDCF}(K)^{\intercal}V,\\where Q,K,V\inR^{n\times d}",,"&FKA(Q,K,V)=softmax(QK^{\intercal})V\approx\phi_{WDCF}(Q)^{\intercal}\phi_{WDCF}(K)V,\\&where \phi_{WDCF}(x)=De^{TCx^{\intercal}},\C\inR^{m\times d},\D\inR^{m},\T=diag(t_{1},\dots,t_{m}),\t_{i}\sim U(0,1)","This equation reformulates the attention mechanism using Weighted Discrete Cosine Features (WDCF) in the frequency domain, approximating the original softmax attention with lower computational complexity."
ICML_2024_oral_28,1,f\in\operatorname*{argmin}_{f}\sup_{e\inE}R^{e}(\tilde{f}),"where the risk \(R^{e}(f)=\mathbb{E}_{(x,y)\sim P^{e}}[\ell(f(x),y)]\) measures the average loss \(\ell\) incurred by the predictor \(f\) across examples from environment \(e\), all of them drawn iid from \(P^{e}\)","f:X\rightarrowY,\quadsuch that\quad f(x^e)\perp\!\!\!\perp e\mid y^e\quad\forall e\inE","The predictor $f$ should be invariant across environments $e \in \mathcal{E}$, meaning its predictions depend only on the label $y$ and not on the environment-specific features."
ICML_2024_oral_28,2,(p_{y_{i}^{out}}^{out}-1/n_{classes})\cdot n_{ classes}/(n_{classes}-1),,"H(p_{i}^{out})=-\sum_{j=1}^{n_{classes}} p_{i,j}^{out}\log p_{i,j}^{out}","where $H(p_{i}^{\text{out}})$ computes the entropy of the held-out softmax prediction $p_{i}^{\text{out}}$, quantifying uncertainty in twin classifiers' agreement to guide label flipping for spurious correlation amplification"
ICML_2024_oral_28,3,"\llbracket(y\notin\operatorname*{argmax}_{j}f^{a}(x)_{j})\,\vee\,(y\notin\operatorname*{argmax}_{j}f^{b}(x)_{j})\rrbracket","where ""\(\vee\)"" denotes logical-OR, and ""\(\llbracket\)"" is the Iverson bracket","e(x,y)=I\left[\arg\max f^a(x)\ne y\land\arg\max f^b(x)\ne y\right]","where the environment annotation $e(x,y)$ is set to 1 if both twin classifiers $f^a$ and $f^b$ misclassify the example $(x,y)$, indicating a potential minority group instance, and 0 otherwise."
ICML_2024_oral_28,4,Y\perp E\mid X_{inv},,"P(Y|X_{inv},E)=P(Y|X_{inv})",
ICML_2024_oral_3,2,"1-\frac{C(\Theta_{t},M_{t})}{C(\Theta_{0},M_{0})}\geq\gamma_{t} || \delta(\Theta_{t},M_{t},R_{t})\leq\Delta_{t} || \forall t\in\{0,1,\dots,T\}",,"s.t.\quad\frac{|\Theta_{t}\setminusM_{t}|}{|\Theta_{t}|}\geq\gamma_{t},\quad\forall t=1,\dots, T","Constraint ensuring that at each training step $t$, the sparsity of the language model remains above the threshold $\gamma_t$ by controlling the pruning mask $\mathcal{M}_t$."
ICML_2024_oral_3,3,H_{apt}(X)=m_{o}\circ(W+s\cdot W_{B}W_{A})X\circ m_{i},"where \(s\) is the constant scaling factor following LoRA's implementation, and \(\circ\) denotes the Hadamard product between the masks and their corresponding matrices",H_{apt}(X)=\left(\left( X\odot m_{i}\right) W_{A}^{T}\right) W_{B}^{T}\odot m_{o},"The APT adapter projects input $X$ using dynamic ranks $r_{\text{apt}}$ and binary pruning masks $m_i, m_o$ to control tuning and total parameters during fine-tuning."
ICML_2024_oral_3,4,"S(W_{i,j})=|W_{i,j}\cdot\frac{\partialL}{\partial W_{i,j}}|",,"S_{t}=E_{x\simD}\left[\left|\frac{\partialL(x|\Theta_{t},M_{t})}{\partial W}\odot W\right|\right]","Salience is defined as the expected magnitude of the element-wise product between the weights and their gradients over the training data distribution, which measures the importance of each parameter block for task performance."
ICML_2024_oral_3,5,"\widetilde{S}_{t}(W_{:,j})=\sum_{(x,y)\inD_{t}}\sum_{i}|\frac{\partialL (x,y|\Theta_{t},M_{t})}{\partial H_{j,i}}| || \sum_{(x,y)\inD_{t}}\sum_{i}|H_{j,i}| || \hat{S}((W_{:,j})=\widetilde{S}(W_{:,j})+(Kurt(O_{j:}))^{\frac{1}{2}}",,"\hat{S}(W_{i,j})=\left| A_{i,j}\cdot\frac{\partialL}{\partial A_{i,j}}\right|+\lambda\cdotKurtosis(A_{i,j})",Outlier-aware salience score combining activation-gradient product magnitude and kurtosis to prioritize preserving outlier parameters during pruning
ICML_2024_oral_3,6,C(\Theta_{t};M_{t})\approx d_{m}\sum_{i=1}^{n_{L}}(4n_{h} ^{i}\cdot d_{h}+2n_{f}^{i}),where \(d_{h}\) is the dimension per MHA head,"C(\Theta_{t},M_{t})\approx\sum_{i=1}^{n_{L}}\left(n_{h}^{i}\cdot d_{m}^{2}+2n_{f}^{i}\cdot d_{m}\right)","Approximated total parameter count of the LM considering MHA heads and FFN neurons across all transformer layers, excluding layer norm, bias, and tuning parameters."
ICML_2024_oral_30,1,W^{\prime}=W_{0}+\Delta W=W_{0}+\underline{BA},"where \(W_{0}\) remains static during the fine-tuning process, and the underlined parameters are being trained",W^{\prime}=W_{0}+\Delta W=W_{0}+B A,The fine-tuned weight matrix $W^{\prime}$ is obtained by adding a low-rank update $BA$ to the pre-trained weight matrix $W_{0}$.
ICML_2024_oral_30,2,W=m\frac{V}{ || V || _{c}}= || W || _{c}\frac{W}{ || W || _{c}},"where \(m\in\mathbb{R}^{1\times k}\) is the magnitude vector, \(V\in\mathbb{R}^{d\times k}\) is the directional matrix, with \(||\cdot||_{c}\) being the vector-wise norm of a matrix across each column","W=\alpha\cdot\frac{W}{\|W\|_F},\quadwhere \alpha=\|W\|_F","where $\alpha$ represents the Frobenius norm (magnitude) of $W$, and $\frac{W}{\|W\|_F}$ represents the normalized direction of $W$"
ICML_2024_oral_30,3,"\Delta M_{FT}^{t}=\frac{\sum_{n=1}^{k}|m_{FT}^{n,t}-m_{0}^{n}|}{ k} || \Delta D_{FT}^{t}=\frac{\sum_{n=1}^{k}(1-\bf cos(V_{FT}^{ n,t},W_{0}^{n}))}{k}",,"\Delta m_{FT}= || W_{FT} || _{c}- || W_{0} || _{c},\quad\Delta V_{FT}=\frac{W_{FT}}{ || W_{FT} || _{c}}-\frac{W_{0}}{ || W_{0} || _{c}}",where $\Delta m_{\text{FT}}$ captures the change in magnitude and $\Delta V_{\text{FT}}$ captures the change in direction between the pre-trained weight $W_{0}$ and the fully fine-tuned weight $W_{\text{FT}}$
ICML_2024_oral_30,4,W^{\prime}=\underline{m}\frac{V+\Delta V}{ || V+\Delta V || _{c}}=\underline{m}\frac{W_{0}+\underline{BA}}{ || W_{0}+\underline{BA} || _{c}},"where \(\Delta V\) is the incremental directional update learned by multiplying two low-rank matrices \(B\) and \(A\), and the underlined parameters denote the trainable parameters",W^{\prime}=m^{\prime}\frac{V+\Delta V}{ || V || _{c}}=m^{\prime}\frac{V+\underline{BA}}{ || V || _{c}},"where $m^{\prime}$ is the updated magnitude vector and $\Delta V=BA$ represents the directional update via LoRA, with $B$ and $A$ being low-rank matrices"
ICML_2024_oral_30,5,\nabla_{V^{\prime}}L=\frac{m}{ || V^{\prime} || _{c}}(I-\frac{V^{\prime}V^{\primeT}}{ || V^{\prime} || _{c}^{2}})\nabla_{W^{\prime}}L || \nabla_{m}L=\frac{\nabla_{W^{\prime}}L\cdot V^{\prime}}{ || V^{\prime} || _{c}},,"\nabla_{m}L=\frac{V^{\prime}}{ || V^{\prime} || _{c}}\cdot\nabla_{W^{\prime}}L,\quad\nabla_{V^{\prime}}L=\frac{m}{ || V^{\prime} || _{c}}\left(I-\frac{V^{\prime}(V^{\prime})^{\top}}{ || V^{\prime} || _{c}^{2}}\right)\cdot\nabla_{W^{\prime}}L","where $\nabla_{m}\mathcal{L}$ and $\nabla_{V^{\prime}}\mathcal{L}$ denote the gradients of the loss with respect to the magnitude vector $m$ and the updated directional component $V^{\prime}$, respectively"
ICML_2024_oral_30,6,"cos(\nabla_{w^{\prime}}L,v^{\prime})=cos(\nabla_{w^{\prime}}L,v)=\frac{\nabla_{w^{\prime}}L\cdot v}{ || \nabla_{w^{\prime}}L ||  || v || }",,"\textbf{cos}(\nabla_{w^{\prime}}L,v)=\frac{\nabla_{w^{\prime}}L^{T}v}{ || \nabla_{w^{\prime}}L || \cdot || v || }",cosine similarity between the gradient of the loss with respect to the updated weight and the initial directional component
ICML_2024_oral_30,7,"\nabla_{m_{*}}L=\frac{\nabla_{w^{\prime}}L\cdot v^{\prime }}{ || v^{\prime} || }= || \nabla_{w^{\prime}}L || \cdot cos(\nabla_{w^{\prime}}L,v)",,"\nabla_{m_{*}}L=\frac{\nabla_{w^{\prime}}L\cdot v}{ || v || }= || \nabla_{w^{\prime}}L || \bf cos(\nabla_{w^{\prime}}L,v)","where $\nabla_{m_{*}}\mathcal{L}$ represents the gradient of the loss with respect to the magnitude scalar $m_{*}$, and the inner product term is expressed via cosine similarity"
ICML_2024_oral_30,8," || \nabla_{w^{\prime}}^{S1}L || \cdot|cos(\nabla_{w^{\prime}}^{S1}L,v)|> || \nabla_{w^{\prime}}^{S2}L || \cdot|cos(\nabla_{w^{\prime}}^{S2}L,v)|",,"\Delta D_{S1}<\Delta D_{S2}\Rightarrow|\bf cos(\nabla_{w^{\prime}}^{S1}L,v)|>|\bf cos(\nabla_{w^{\prime}}^{S2}L,v)|\Rightarrow|\nabla_{m_{*}}^{S1}L|>|\nabla_{m_{*}}^{S2}L|","Equation 8 establishes the relationship between directional updates and magnitude gradients, showing that smaller directional updates correspond to larger magnitude gradients under equal update norms."
ICML_2024_oral_30,9,\nabla_{V^{\prime}}L=\frac{m}{C}\nabla_{W^{\prime}}L\text { where }C= || V^{\prime} || _{c},,\nabla_{V^{\prime}}L=\frac{m}{ || V^{\prime} || _{c}}\nabla_{W^{\prime}}L,
ICML_2024_oral_37,1,"P_{t}=\{W_{t},O_{t}\}",,"P_t=\{W_t,O_t\}",Equation 1 defines the neural network checkpoint $\mathcal{P}_t$ at iteration $t$ as the combination of model weights $\mathcal{W}_t$ and optimizer parameters $\mathcal{O}_t$.
ICML_2024_oral_37,2,"P=\{P_{1},P_{2},\cdots,P_{t}\,\cdots,P_{T}\}",,"P=\{P_1,P_2,\dots,P_T\}","Equation 2 defines the sequence of checkpoints $\mathcal{P}$ saved during $T$ training iterations, where each checkpoint $\mathcal{P}_t$ contains the model weights and optimizer parameters at iteration $t$."
ICML_2024_oral_37,3,"O_{t}=\{v_{t},m_{t}\}",,"O_t=\{m_t, v_t\}",where $\mathcal{O}_t$ consists of the first-order moment $m_t$ and second-order moment $v_t$ in the Adam optimizer.
ICML_2024_oral_37,4,"\DeltaP_{t}=\{\DeltaW_{t},O_{t}\}=\{W_ {t}-W_{t-1},O_{t}\}",,"\DeltaP_{t}=\{W_{t}-W_{t-1},O_{t}\}","The residual checkpoint $\Delta\mathcal{P}_{t}$ consists of the difference between the current and previous model weights, and the current optimizer states, enabling more efficient compression by exploiting temporal redundancy in model weights."
ICML_2024_oral_37,5,"r_{w}=\frac{\alpha}{\sqrt{m_{t}}}\timesmedian(W),M _{w}(i)=\mathds{1}_{w_{t}(i)>r_{w}}",,"M_{w}^{(l)}=\left\{ {ll} 1 &if  |w_{i,j}^{(l)}| >\tau_{w}^{(l)}\\0 &otherwise\right","where $\mathcal{M}_{w}^{(l)}$ denotes the pruning mask for weights in layer $l$, $w_{i,j}^{(l)}$ represents the weight element, and $\tau_{w}^{(l)}$ is the layer-specific pruning threshold determined by the second-order moment of gradients."
ICML_2024_oral_37,6,"r_{o}=\beta\timesmean(v_{t}),M_{o}(i)=\mathds{1}_{v_{t}(i)> r_{o} and M_{w}(i)=1}",,"r_{o}=\frac{\beta}{m_{t}}\timesmedian(v_{t}),M_{o}(i)=\mathds{1}_{m_{t}(i)>r_{o}}","The momentum pruning threshold $r_{o}$ is determined using the first-order moment $m_{t}$ and the median of the second-order moment $v_{t}$, with $\beta$ as a hyperparameter controlling the sparsity level."
ICML_2024_oral_37,7,"\tilde{R}(T)\leq\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}\sqrt {T\widehat{v}_{T,i}} || +\frac{\alpha(1+\beta_{1})G_{\infty}}{(1-\beta_{ 1})\sqrt{1-\beta_{2}}(1-\gamma)^{2}}\sum_{i=1}^{d}\|g_{1,\tau,i}\|_{2} || +\frac{D_{\infty}^{2}G_{\infty}\sqrt{1-\beta_{2}}}{2\alpha}\sum_ {i=1}^{d}\sum_{t=1}^{t}\frac{\beta_{1,t}}{(1-\beta_{1,t})}\sqrt{t} || +\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}})",,E\left[\frac{1}{\sqrt{T}}\sum_{t=1}^{T}\left\|\nabla f_{t}(\theta_{t})\right\|_{2}\right]\leq\frac{1}{\sqrt{T}}\left(\frac{D^{2}}{\alpha}+\frac{\alpha}{2}\left(1+\frac{1}{1-\beta_{1}}\right)\right)+\frac{\beta_{1}}{1-\beta_{1}}G_{\infty}\cdot\left\|M_{o}-1\right\|_{1},"The convergence bound of Adam with joint weight-momentum pruning, showing the trade-off between gradient magnitude and pruning mask sparsity."
ICML_2024_oral_37,8,"\Delta\tilde{R}(T)&=\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}})\\&=\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}(1-M_{o})})",,"\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}(\sqrt{T\widehat{v}_{\tau,i}}-\sqrt{T\widehat{v}_{\tau,i}M_{o}})",This term quantifies the impact of momentum pruning on the convergence guarantee of Adam optimizer during checkpoint compression.
ICML_2024_oral_37,9,\lim_{Tarrow\infty}\frac{\tilde{R}(T)}{T}\leq\lim_{Tarrow\infty}\frac{R(T)+\Delta\tilde{R}(T)}{T}=0,,\tilde{R}(T)\leq R(T)+\Delta\tilde{R}(T),The regret bound of the proposed method is bounded by the original Adam regret plus an additional term due to pruning.
ICML_2024_oral_37,10,\frac{R(T)}{T}=O(\frac{1}{\sqrt{T}}),,"\tilde{R}(T)\leq\frac{D^{2}}{2\alpha(1-\beta_{1})}\sum_{i=1}^{d}\sqrt{T\widehat{v}_{T,i}}+\frac{\alpha(1+\beta_{1})G_{\infty}}{(1-\beta_{1})\sqrt{1-\beta_{2}}(1-\gamma)^{2}}\sum_{i=1}^{d}\|g_{1,\tau,i}\|_{2}+\frac{D_{\infty}^{2}G_{\infty}\sqrt{1-\beta_{2}}}{2\alpha}\sum_{i=1}^{d}\sum_{t=1}^{T}\frac{\beta_{1,t}}{(1-\beta_{1,t})}\sqrt{t}","This equation presents the regret bound guarantee for the proposed momentum pruning method, showing that it maintains convergence properties similar to the original Adam optimizer."
ICML_2024_oral_4,1,S_{opt_{t}}=\arg\min_{S\subseteq V_{t}}\{\textsc{Cost}(S):f(S)=f(V_{t})\}\enspace,where \(V_{t}\) denotes the set of the currently present elements after the first \(t\) updates,\textsc{Cost}(S)=\sum_{v\in S} w(v)\quadsubject to\quad f(S)=f(V_t),"Equation 1 formally defines the dynamic submodular cover problem, where the goal at each time $t$ is to select a subset $S \subseteq V_t$ of minimum cost such that the submodular function value $f(S)$ equals $f(V_t)$."
ICML_2024_oral_4,2,"f(S)\geq(1-\epsilon)f(V),\quadand\quad\textsc{Cost}(S)\leq c\textsc{ Cost}(S_{opt})",where \(S_{opt}\) denotes the optimal solution,f(S)\geq(1-\epsilon)f(V)\quadand\quad\textsc{Cost}(S)\leq c\cdot\textsc{OPT}_{\textsc{cost}}\enspace,"A $(1-\epsilon,c)$-bicriteria approximate solution guarantees coverage of at least a $(1-\epsilon)$ fraction of the optimal submodular value while its cost is within a factor $c$ of the optimal cost."
ICML_2024_oral_4,3,"E[\,X(r)\,]\geq 1-2\epsilon for all r\in[1,m^{*}] and || E[\,X(m^{*}+1)\,]\leq 1-\frac{\epsilon}{2}",,"E\left[\,X_{m^{*}}\,\right]\geq (1-\epsilon)\quadand\quadE\left[\,\sum_{j=m^{*}+1}^{|L^{\prime}|}X_{j}\,\right]\leq\epsilon\cdot m^{*}",Definition of a suitable sample size $m^{*}$ ensuring probabilistic guarantees on the expected number of elements added to $G_i$ and the fraction of elements removed during filtering.
ICML_2024_oral_41,1,"\min_{\theta_{1},\theta_{2},...,\theta_{N}}[\frac{1}{N}\sum_{i=1}^{N}L_{i}(\theta_{i})]+R(\theta_{1},\theta_{2},...,\theta_{N})",,"\min_{\theta_{1},\theta_{2},...,\theta_{N}}\sum_{i=1}^{N} w_{i}E_{(x, y)\simD_{i}}\left[\ell(f_{A_{i}}(x;\theta_{i}), y)\right]","where $w_i$ are non-negative weights summing to one, and $\ell(\cdot, \cdot)$ is a loss function measuring the discrepancy between the model prediction and the true label."
ICML_2024_oral_41,2,A_{i}\capA_{i^{\prime}}=\{B_{enc}^{(m)}|\forall m\inI_{i}\capI_{i^{\prime}}\}\cup\{B_{share}\},,"R(\theta_{1},\theta_{2},...,\theta_{N})=\sum_{b\inB_{share}}R_{b}(\{\theta_{i,b}\}_{i=1}^{N})",where $\mathcal{R}_{b}(\cdot)$ denotes the knowledge sharing regularizer applied on the shared block $b$ across all clients.
ICML_2024_oral_41,3,A_{i}\capA_{i^{\prime}}=\emptyset,,A_{i}\capA_{i^{\prime}}=\emptyset,"Equation 3 defines the architecture-personalized MFL (AMFL) setting, where client-specific neural architectures have no predefined shared blocks, indicating a fully heterogeneous and non-compositional model structure across clients."
ICML_2024_oral_41,4,"\theta_{i}:=h(A_{i},c_{i};\phi),\\\\forall i\in[N]","where the first generative factor \(\mathcal{A}_{i}\in\mathcal{G}\) is the local neural architecture from a globally-shared _latent topology space_\(\mathcal{G}\) and the second generative factor \(\mathbf{c}_{i}\in\mathcal{T}\) represents the lo

Figure 1: (a) Local mapping functions per client in Multimodal Federated Learning (MFL)","\theta_{i}=h(G_{i},z_{i};\phi)",where $\mathcal{G}_{i}$ is the topological graph representation of client $i$'s architecture and $\mathbf{z}_{i}$ is a learnable latent code specific to client $i$.
ICML_2024_oral_41,5,"A_{i}:=(V_{i},E_{i},Z_{i}^{(0)})",,"A_{i}=(V_{i},E_{i})","where $\mathcal{V}_{i}$ denotes the set of computational nodes (e.g., layers or modules) and $\mathcal{E}_{i}$ denotes the set of directed edges representing data flow between nodes in client $i$'s architecture."
ICML_2024_oral_41,6,"h(A_{i},c_{i};\phi)=\texttt{Comb}(c_{i},\texttt{Role}(A_{i};\phi_{1});\phi_{2})","where the first stage \(\texttt{Role}(\cdot;\phi_{1})\) parameterized by \(\phi_{1}\) learns the implicit roles of layers such that layers across clients share a unified _layer-role embedding_ space, and the second stage \(\texttt{Comb}(\cdot,\cdot;\phi_{2})\) parameterized by \(\phi_{2}\) aims to combine the two heterogeneity patterns and directly generates the weights","Z_{i}^{(l)}=GNN^{(l)}(A_{i},Z_{i}^{(l-1)}),\\\l=1,2,...,L",where GNN^{(l)} denotes the l-th layer of a graph neural network that updates node features Z_i^{(l)} by aggregating information from neighboring nodes in the architecture graph ð_i.
ICML_2024_oral_41,7,"Z_{i}^{(L)}=\texttt{Role}(A_{i};\phi_{1}) || :=g_{L}\circ g_{L-1}\circ...\circ g_{1}(Z_{i}^{(0)}; V_{i},E_{i})",,"\texttt{Role}(A_{i};\phi_{1})=\texttt{GNN}(V_{i},E_{i},Z_{i}^{(0)};\phi_{1})",which encodes the implicit roles of layers by combining node features and graph structure via a GNN to produce a unified layer-role embedding space across clients.
ICML_2024_oral_41,8,"z_{i,v}^{(l)}=\sigma(W_{self}^{(l)}z_{i,v}^{(l-1)}+W_{in}^{(l)}\sum_{(v^{\prime},v)\inE_{i}}z_{i,v^{\prime}}^ {(l-1)} || \qquad+W_{out}^{(l)}\sum_{(v,v^{\prime})\in E_{i}}z_{i,v^{\prime}}^{(l-1)}+b^{(l)})",,"z_{i,v}^{(l)}=\sigma\left(\sum_{u\inN(v)}W^{(l)}z_{i,u}^{(l-1)}+b^{(l)}\right)","where $\sigma$ is an activation function, $\mathcal{N}(v)$ denotes the neighbors of node $v$, and $\mathbf{W}^{(l)}, \mathbf{b}^{(l)}$ are learnable parameters at layer $l$."
ICML_2024_oral_41,9,"\theta_{i,v}:=g_{node}(c_{i}\oplusz_{i,v}^{(L)};\phi_{ 2}),\;\forall v\inV_{i}",where \(\oplus\) denotes an operation (e,"\theta_{i,v}=g_{node}(z_{i,v}^{(L)},c_{i};\phi_{2}),\\\\forall v\inV_{i}^{param}","Equation 9 defines the node-wise weight generation process in FedMBridge, where each parametric operator's weights Î¸_{i,v} are generated by a hypernetwork g_node conditioned on the layer-role embedding z_{i,v}^{(L)} and client-specific task information c_i."
ICML_2024_oral_41,10,\Deltac_{i}=\nabla_{c_{i}}L_{i}(\theta_{i})=\Delta\theta_{i}\cdot\nabla_{c_{i}}\theta_{i} || \Delta\phi_{2}=\frac{1}{|N_{r}|}\sum_{i\inN_{r}}(\Delta\theta_{i}\cdot\nabla_{\phi_{2}}\theta_{i}) || \Delta\phi_{1}=\frac{1}{|N_{r}|}\sum_{i\inN_{r}}(\Delta\theta_{i}\cdot\nabla_{z_{1}^{(L)}}\theta_{i}\cdot\nabla_{\phi_{i} }Z_{i}^{(L)}),,"\nabla_{\phi}=\sum_{i\inN_{r}}\left[\nabla_{\theta_{i}}L_{i}(\theta_{i})\cdot\nabla_{\phi}h(A_{i},c_{i};\phi)\right]",Applies the chain rule to compute server-side gradient updates for TAHN parameters Ï by aggregating client-specific gradients of local losses with respect to generated weights and bridge function Jacobians.
ICML_2024_oral_44,1,"\operatorname*{arg\,max}_{\theta\in\Theta}E_{G^{\prime}\sim D_{\theta}}[u_{\tau}(G^{\prime})]",where \(D_{\theta}\) is a parameterized distribution and \(\Theta\) represents a feasible set of real-valued parameters,\arg\max_{\theta}E_{G_{E}\sim p_{\theta}}[u_{\tau}(G_{E})],"Equation 1 reformulates the DAG optimization problem as a continuous optimization over probabilistic distributions, aiming to maximize the expected utility over sampled DAGs instead of directly optimizing in discrete space."
ICML_2024_oral_44,2,"\prod_{i=1}^{d}\theta_{i}&if\,(N,E\cup(\{e_{j}\}_{j=1}^{i-1}\capE)\cup\{e_{i}\})\,is a DAG,\\0&otherwise",,p(G^{\prime}=G_{E})=\prod_{e_{i}\inE}\theta_{i}\prod_{e_{j}\notinE}(1-\theta_{j}),"the product of the probabilities of included edges and excluded edges, respectively, under the parameterized distribution $D_{\theta}$"
ICML_2024_oral_44,3,\nabla_{\theta}E_{G_{E}\sim D_{\theta}} [u_{\tau}(G_{E})]\approx\frac{1}{M}\sum_{i=1}^{M}\hat{u}_ {\tau}(G_{i})\nabla_{\theta}\log(p_{\theta}(G_{i})),"where \(G_{1},G_{2},\ldots,G_{N}\sim D_{\theta}\) are mutually independent and \(\hat{u}_{\tau}(G_{i})\) is an independent unbiased estimate of \(u_{\tau}(G_{i})\) for all \(i\) and some \(M\in\mathbb{N}\)",\nabla_{\theta}E_{G^{\prime}\sim D_{\theta}}[u_{\tau}(G^{\prime})]=E_{G^{\prime}\sim D_{\theta}}\left[u_{\tau}(G^{\prime})\nabla_{\theta}\log D_{\theta}(G^{\prime})\right],"The gradient of the expected utility with respect to the parameters is estimated using the REINFORCE algorithm, enabling gradient ascent optimization through unbiased gradient estimation."
ICML_2024_oral_5,1,x_{i}^{\ell+1}=x_{i}^{\ell}+\texttt{MLP}^{\ell}(x_{i}^{\ell}+\texttt{Att}^{\ell}(x_{i}^{\ell})),,x_i=Ew_i,
ICML_2024_oral_5,2,\texttt{MLP}^{\ell}(x^{\ell})=\sigma(W_{K}^{\ell}x^{\ell})W_{V}^{\ell},"where \(W_{K}^{\ell},W_{V}^{\ell}\in\mathbb{R}^{d_{mlp}\times d}\)",\texttt{MLP}^{\ell}(x)=W_2^{\ell}\sigma(W_1^{\ell}x+b_1^{\ell})+b_2^{\ell},"Equation 2 defines the MLP block as composed of two linear transformations with point-wise activations in-between, following the decomposition from Geva et al. (2022)."
ICML_2024_oral_5,3,\texttt{MLP}^{\ell}(x^{\ell})=\sum_{i=1}^{d_{mlp}}\sigma(x^{\ell}\cdotk_{i}^{\ell})v_{i}^{\ell}=\sum_{i=1}^{d_{mlp}}m_{i} ^{\ell}v_{i}^{\ell},,\texttt{MLP}^{\ell}(x^{\ell})=\sum_{i=1}^{d_{mlp}} m_{i}^{\ell}v_{i}^{\ell},"where $m_{i}^{\ell}$ is the $i$-th element of $\mathbf{m}^{\ell} = \sigma(W_{K}^{\ell} \mathbf{x}^{\ell})$, representing the scaled coefficients for the value vectors $\mathbf{v}_{i}^{\ell}$ in the MLP block at layer $\ell$."
ICML_2024_oral_5,4,"p\big{(}w\midx^{\ell}+m_{i}^{\ell}v_{i}^{\ell},E\big{)}\propto\exp\big{(}e_{w}\cdotx^{\ell}\big{)}\cdot\exp\big{(}e_{w}\cdot m_{i}^{\ell}v_{i}^{\ell}\big{)}",where \(\mathbf{e}_{w}\) is the embedding of \(w\),\Delta p(w)\proptov_{i}\cdotu_{w},"where $\mathbf{u}_{w}$ is the unembedding vector of token $w$, and $\Delta p(w)$ denotes the change in logit for token $w$ induced by the sub-update associated with $\mathbf{v}_{i}$."
ICML_2024_oral_5,5,\texttt{GLU}^{\ell}(x^{\ell})=(\sigma(W_{1}x^{\ell})\odot W_{ 2}x^{\ell})W_{V}^{\ell},"where \(W_{1}^{\ell},W_{2}^{\ell},W_{V}^{\ell}\in R^{d_{mlp}\times d}\)",\texttt{GLU}^{\ell}(x^{\ell})=\sigma(W_{K}^{\ell}x^{\ell})\odot(W_{V}^{\ell}x^{\ell})W_{O}^{\ell},where $W_{O}^{\ell}\in\mathbb{R}^{d\times d_{\text{mlp}}}$ is the output projection matrix and $\odot$ denotes the element-wise product.
ICML_2024_oral_5,6,"P(Toxic|\bar{x}^{L-1})=softmax(W_{Toxic}\bar{x}^{L-1}),W_{Toxic}\inR^{d}",,p_{toxic}=\sigma\left(W_{Toxic}\bar{x}^{L-1}\right),"where $\mathbf{p}_{\text{toxic}}$ is the probability of a sequence being toxic, and $\sigma$ is the sigmoid function."
ICML_2024_oral_5,7,x^{L-1}=x^{L-1}-\alpha*W,where \(a\) is a heuristic scale value and \(W\) is one of our toxicity vectors,x^{L,
ICML_2024_oral_5,8,"L_{DPO}=-E[\log\sigma(\beta\log P-\beta\log N)] || P=\frac{\pi_{\theta}(y_{+}\midw)}{\pi_{ref}(y_{+}\midw)},N=\frac{\pi_{\theta}(y_{-}\midw)}{\pi_{ref}(y_{-}\midw)}",,L_{DPO}(\theta)=\log\sigma\left(\beta\left(\log p_{\theta }(y^{+}\mid x)-\log p_{\theta}(y^{-}\mid x)\right)\right),"where $\beta$ is a temperature parameter that controls the strength of the preference optimization, and $\sigma$ is the sigmoid function."
ICML_2024_oral_5,9,p(y\mid a)\propto p(y)p(a\mid y),,\nabla_{x}\log p(a\midw)\propto\nabla_{x}\log p(a\midx)\cdot\frac{\partialx}{\partialw},Gradient computation in PPLM for steering the language model towards generating text with a desired attribute $a$.
ICML_2024_oral_5,10,"\gamma(k_{i}^{\ell}):=\{g|g\inR^{d},\sigma(k_{i}^{\ell}\cdotg)>0\}",where \(\sigma\) is a non-linear activation,x_{DPO}^{\ell}\cdotMLP.k_i^{\ell} <x^{\ell}\cdotMLP.k_i^{\ell},"Equation comparing residual stream projections onto toxic key vectors before and after DPO, showing reduced alignment with toxic activation regions."
ICML_2024_oral_5,11,"\forall j<\ell,\forall i<d_{mlp}:cos(\delta_{x}^{\ell\_midmid},\delta_{MLP,v_{i}}^{j})",,"\delta_{x}^{\ell\_mid}\propto\sum_{j=1}^{\ell-1}cos(\delta_{x}^{\ell\_mid},\delta_{MLP,v}^{j})\|\delta_{MLP,v}^{j}\|","Equation 11: Formalization of the shift in residual streams in terms of preceding layer value vector differences, showing how minimal parameter changes across layers cumulatively steer the stream away from toxic regions."
ICML_2024_oral_53,1,generalization gap\leq\sqrt{\frac{CMI_{D}(A_{n})}{n}},,gen(A)\leq\sqrt{\frac{2 I(S;W)}{n}},Generalization error bound in terms of conditional mutual information (CMI) and sample size n.
ICML_2024_oral_53,3,CMI_{D}(A_{n})\triangleq I(A_{n}(S_{n}) ;U|\tilde{Z}),,CMI_{D}(A_{n})=I\left(A_{n}(S_{n});U\mid\tilde{Z}\right),"where $I(\cdot;\cdot \mid \cdot)$ denotes the conditional mutual information, quantifying the dependence between the algorithm's output and the membership indicators $U$ given the dataset $\tilde{\mathbf{Z}}$."
ICML_2024_oral_53,4,E[F_{D}(A_{n}(S_{n}) )]-\min_{\theta\in\Theta}F_{D}(\theta) || \leqEGE_{D}(A_{n})+E\big{[}\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\big{]},,F_{D}(A_{n}(S_{n}))-\min_{\theta\in\Theta}F_{D}(\theta)\leq\underbrace{F_{D}(A_{n}(S_{n}))-\hat{F}_{S_{n}}(A_{n}(S_{n}))}_{generalization error}+\underbrace{\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)}_{optimization error},Decomposition of the excess population error into generalization error and optimization error for stochastic convex optimization problems.
ICML_2024_oral_53,5,E[F_{D}(A_{n}(S_{n}) )]-\min_{\theta\in\Theta}F_{D}(\theta) || \leq LR\sqrt{\frac{8CMI_{D}(A_{n})}{ n}}+E\big{[}\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\big{]},,E[F_{D}(A_{n}(S_{n}))]-\min_{\theta\in\Theta}F_{D}(\theta)\leq LR\sqrt{\frac{8CMI_{D}(A_{n})}{n}}+E\big{[}\hat{F}_{S_{n}}(A_{n}(S_{n}))-\min_{\theta\in\Theta}\hat{F}_{S_{n}}(\theta)\big{]},This inequality bounds the expected excess population error of a learning algorithm in terms of its CMI and empirical risk minimization performance.
ICML_2024_oral_53,7,E[\sum_{i=1}^{n}\sum_{k=1}^{d}(\frac{144\varepsilon^{2}-d(\mu^{(k)})^{2}}{1-d(\mu^{(k)})^{2}})(\hat{\theta} ^{(k)})(Z_{i}^{(k)}-\mu^{(k)})] || \quad\geq 2\varepsilon-4\delta,,"E\left[\left\langle\hat{\theta},\mu\right\rangle\right]\geq\left\|\mu\right\|-\varepsilon-2\delta",The expected correlation between the learner's output and the mean of the data distribution is bounded below by the norm of the mean minus the accuracy parameter and a term involving the confidence parameter.
ICML_2024_oral_55,1,"D_{LCA}(y^{\prime},y):=f(y)-f(N_{LCA}(y,y^{\prime}))","where \(f(y)\geq f(N_{LCA}(y,y^{\prime}))\) and \(N_{LCA}(y^{\prime},y)\) denotes the lowest common ancestor class node for classes \(y\) and \(y^{\prime}\) within the hierarchy, and \(f(\cdot)\) represents a function of a node, such as the tree depth or entropy","LCA\_distance(y, y')=d(y)+d(y')-2\cdot d(LCA(y, y'))",The LCA distance is calculated as the sum of the depths of the ground truth class and the predicted class minus twice the depth of their lowest common ancestor in the taxonomy hierarchy.
ICML_2024_oral_55,2,"D_{LCA}(model,M):=\frac{1}{n}\sum_{i=1}^{n}D_{LCA}(\widehat{y}_{i},y _{i})\iff y_{i}\neq\widehat{y}_{i}","where \(\widehat{y}_{i}\) is the predicted class for sample \(X_{i}\) using the model, \(y_{i}\) is the ground truth class for sample \(X_{i}\), and \(y_{i}\neq\widehat{y}_{i}\)","D_{LCA}^{IC}(y^{\prime}, y) :=IC(y)-IC(N_{LCA}(y, y^{\prime}))","where $IC(y)$ denotes the information content of the ground truth class $y$, and $IC(N_{LCA}(y, y^{\prime}))$ denotes the information content of the lowest common ancestor node between $y$ and $y^{\prime}$ in the class hierarchy"
ICML_2024_oral_58,1,"Sequence model:\hat{z}_{t},\,h_{t}=seq(z_{t-1},\,h_{t-1},\,a_{t-1}) || Multimodal encoder: z_{t}\simenc(x_{t},\,l_{t},\,h_{t}) || Multimodal decoder:\hat{x}_{t},\,\hat{l}_{t},\,\hat{r}_{t},\,\hat{c}_{t}=dec(z_{t},\,h_{t})",,"z_{t}=E(x_{t}, l_{t}),\quad h_{t}=R(h_{t-1}, [z_{t}, a_{t}]),\quad\hat{z}_{t+1}=D(h_{t})","Equation 1 defines the encoding of the current observation into a latent representation, the recurrence over the latent and action space, and the decoding of the next latent state in the world model."
ICML_2024_oral_58,2,"Image loss:\qquad\quadL_{x}=\|\hat{x}_{t}-x_{t}\|_{2}^{2} || Language loss:\qquad\quadL_{t}=catext(\hat {t}_{t},l_{t}) || Reward loss:\qquad\quadL_{r}=catext(\hat {r}_{t},twoot(r_{t})) || Continue loss:\qquad\quadL_{c}=binkent(\hat{c}_{t},c_{t}) || Regularizer:\qquad\quadL_{reg}=\beta_{reg}\max(1,KL\big{[}z_{t}\bigm{\|}\\sg(\hat{z}_{t})\big{]})",,"L_{repr}=\underbrace{E_{t}\left[-\logenc(z_{t}\mid x_{t}, l_{t}, h_{t})\right]}_{Latent encoding}+\underbrace{E_{t}\left[\beta_{reg}\cdotcatxent(z_{t},sg(\hat{z}_{t}))\right]}_{Latent regularization}+\underbrace{E_{t}\left[binxent(r_{t},\hat{r}_{t})+binxent(c_{t},\hat{c}_{t})\right]}_{Observation reconstruction}","The representation learning loss $\mathcal{L}_{\mathrm{repr}}$ combines latent encoding, latent regularization, and observation reconstruction terms to train the world model's encoder and decoder."
ICML_2024_oral_58,3,"Prediction loss:\quadL_{pred}=\beta_{pred}\\max(1,KL\big{[}\,sg(z_{t})\bigm{\|}\hat{z}_{t}\big{]})",where the gradient around the target distribution for \(z_{t}\) is stopped since it is also a learned representation and \(\beta_{\mathrm{pred}}=0,"L_{pred}=\sum_{k=1}^{K}\beta_{k}\cdotKL\left[ z_{t+k}\,\middle\|\,\hat{z}_{t+k}\right]","The future prediction loss $\mathcal{L}_{\mathrm{pred}}$ is defined as a weighted sum of Kullback-Leibler divergences between the actual and predicted latent representations over $K$ future steps, where $\beta_k$ are weights that may vary with the prediction horizon $k$."
ICML_2024_oral_58,4,"Actor net:\quad\pi(a_{t}|h_{t},z_{t})\qquadCritic net:\quadV(h_{t},z_{t})",,"Actor:\quad a_{t}=MLP_{\theta}(z_{t}),\quadCritic:\quad V_{t}=MLP_{\phi}(z_{t})","The actor network maps latent representations to actions, while the critic network estimates the value of each state for guiding policy optimization."
ICML_2024_oral_60,1,"\min_{M}\alphaL_{in}(f(M\odot X),y) || -\betaL_{out}(f((1-M)\odot X),y)+R(M)",,"L_{mask}=E_{(x, y)\simD}\left[\log p_{\theta}(y\mid x_{in})-\log p_{\theta}(y\mid x_{out})\right]",The masking loss aims to maximize the log probability of the true class given the masked-in audio portion while minimizing it for the masked-out portion.
ICML_2024_oral_60,2,"\min_{\theta}\lambda_{in}L_{in}(\log f(M_{\theta}(h)\odot X),y) || -\lambda_{out}L_{out}(\log f((1-M_{\theta}(h))\odot X),y)+R(M_{\theta}(h))",,"\min_{\theta}\alphaL_{in}(f(M_{\theta}\odot X),y)-\betaL_{out}(f((1-M_{\theta})\odot X),y)+R(M_{\theta})","The optimization objective when parameterizing the mask $M$ with a neural decoder, where $\theta$ represents the decoder parameters."
ICML_2024_oral_60,3,R(M_{\theta}(h))=\lambda_{g}\|M_{\theta}(h)\odot X-X\|+\lambda_{s}\|M_{\theta} (h)\|_{1},"where \(\lambda_{g}\) and \(\lambda_{s}\) are regularization coefficients, and \(X\) represents the spectrogram of the original signal","\min_{\theta}\lambda_{in}L_{in}(\log f(M_{\theta}(h)\odot X),y)-\lambda_{out}L_{out}(\log f((1-M_{\theta}(h))\odot X),y)+R(M_{\theta}(h))+\gammaL_{refine}(M_{\theta}(h))","Equation 3 extends the mask optimization objective by incorporating a refinement term $\mathcal{L}_{\text{refine}}$ weighted by $\gamma$, aimed at improving the quality of the interpretation mask during fine-tuning."
ICML_2024_oral_60,4,x_{interpretation}=ISTFT((M_{\theta}(h)\odot X)e^{jX_{ phase}}),,\hat{x}=F^{-1}(M_{\theta}(h)\odot X),where $\mathcal{F}^{-1}$ denotes the inverse Fourier transform used to reconstruct the audio waveform from the masked linear spectrogram.
ICML_2024_oral_60,5,FF_{n}:=f(X_{n})_{c}-f(X_{n}\odot(1-M_{\theta}(h)))_{c},,FF=f_{y}((1-M)\odot X)-f_{y}(X),"Faithfulness on Spectra (FF) measures the drop in class-specific logit when the masked-out portion is input to the classifier, indicating the importance of the interpretation mask."
ICML_2024_oral_60,6,AI:=\frac{1}{N}\sum_{n=1}^{N}1_{[f(X_{n}\odot M_{\theta}(h))>f (X_{n})_{c}]}\cdot 100,where \(\mathbf{1}_{[,AI_{n}:=f(X_{n}\odot M_{\theta}(h))_{c}-f(X_{n})_{c},"where $f(X_n)_c$ denotes the logit for the predicted class $c$ of the original input $X_n$, and $M_{\theta}(h)$ is the learned interpretation mask."
ICML_2024_oral_60,7,"AD:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n})_{c}-f(X_{n}\odot M_ {\theta}(h))_{c})}{f(X_{n})_{c}}\cdot 100",,"AD:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max\left(0,f(X_{n})_{c}-f(X_{n}\odot M_{\theta}(h))_{c}\right)}{f(X_{n})_{c}}\cdot 100","where the numerator computes the drop in confidence for the true class when the input is masked, normalized by the original confidence, and zero values are clamped to avoid division by zero; smaller values indicate better performance."
ICML_2024_oral_60,8,"AG:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n}\odot M_{\theta}(h))_ {c}-f(X_{n})_{c})}{1-f(X_{n})_{c}}\cdot 100",,"AG:=\frac{1}{N}\sum_{n=1}^{N}\frac{\max(0,f(X_{n}\odot M_{\theta}(h))_{c}-f(X_{n})_{c})}{1-f(X_{n})_{c}}\cdot 100","For this metric, larger is better."
ICML_2024_oral_60,9,Fid-In=\frac{1}{N}\sum_{n=1}^{N}1_{[\arg\max_{c}f(X_{n})_{c}=\arg\max_{c}f_{c}(X_{n}\odot M_{\theta}(h))]},,Fid-In:=\frac{1}{N}\sum_{n=1}^{N}1_{[\arg\max_{c'}f_{c'}(X_{n}\odot M_{\theta}(h))=c]},"This metric evaluates whether the masked-in portion of the input retains the original class prediction, with a higher value indicating better input fidelity."
ICML_2024_oral_66,1,"cost(P,S)=\sum_{p\in P}\min_{s\in S}dist(p,s)^{ z}",,"cost(P, S)=\sum_{p\in P}\min_{c\in S}\|p-c\|^z","The cost function for the (k,z)-clustering problem, which sums the z-th power of the minimum distance from each point to the set of centers S."
ICML_2024_oral_66,2,P(M(P)\in S)\leq\exp(\varepsilon)\cdotP( M(P^{\prime})\in S)+\delta,,"\textsc{opt}_{k,z}=\min_{S\subseteqR^d,\, |S|=k}cost(P, S)","The optimal cost for the $(k,z)$-clustering problem."
ICML_2024_oral_66,3,\sum_{p\in P}\|p-\mu\|^{z}\leq 2^{z}\sum_{p\in P}\|p-\mu_{z}\|^{z},,"cost(P,\mu_{2})\leq 2^{z}\cdotcost(P,\mu_{z})","This equation relates the optimal centers for (1,2)-clustering (Î¼â) and (1,z)-clustering (Î¼_z), showing that the cost of using Î¼â is at most 2^z times the optimal cost for (1,z)-clustering, enabling dimension reduction generalization to (k,z)-clustering."
ICML_2024_oral_66,4,"cost(E,\mu(E))=\sum_{p\in E}\|p\|_{2}^{2}-\frac{\|\sum_{p\in E }p\|_{2}^{2}}{|E|}",,"\sum_{p\in E}\|p-\mu(E)\|^{2}=\frac{1}{2|E|}\sum_{p,q\in E}\|p-q\|^{2}","The k-means cost of a cluster can be expressed as the average squared distance between all pairs of points in the cluster, providing a way to compute the cost without explicitly knowing the cluster center."
ICML_2024_oral_72,1,"L_{mask}=\underset{X\inD,t\in[0,T]}{ E}-\sum_{i=1}^{N}m_{t,i}\cdot\log(p_{\theta}(x_{i}|X_{t},X^{p},C))",,"L(\theta)=-\log p_{\theta}(X_{0}\midX_{t},X^{p},C)","Equation 1 defines the negative log-likelihood loss function for training the diffusion model parameters Î¸, where the model predicts the original token sequence Xâ conditioned on the masked sequence Xâ, prompt tokens Xáµ, and condition C."
ICML_2024_oral_72,2,"p(X_{t-\Delta t}|X_{t},X^{p},C)=\underset {X_{0}\sim p_{\theta}(X_{0}|X_{t},X^{p},C)}{E}q(X_{t-\Delta t}|\hat{X}_{0},X_{t})",,"p_{\theta}(X_{t-\Delta t}|X_{t},X^{p},C)=\prod_{i=1}^{N}p_{\theta}(x_{i}|X_{t},X^{p},C)^{m_{t-\Delta t,i}}",The reverse transition distribution is derived by factorizing the probability of each token being restored based on the binary mask at the previous time step.
ICML_2024_oral_73,1,"\theta_{t+1}=\theta_{t}-\eta_{t}(\sum_{i=1}^{n}\nabla\ell(\theta_{t},z_{i})+N(0,\frac{G^{2}}{2\rho}I_{p}))",,"\theta_{t+1}=\theta_{t}-\eta\left(\nablaL(\theta_{t})+N(0,\sigma^{2} I)\right)","Equation 1 describes the parameter update rule for the Noisy Gradient Descent (NoisyGD) algorithm, where $\theta_{t}$ is the model parameter at iteration $t$, $\eta$ is the learning rate, $\nabla \mathcal{L}(\theta_{t})$ is the gradient of the loss function, and $\mathcal{N}(0, \sigma^{2} I)$ represents isotropic Gaussian noise added for differential privacy."
ICML_2024_oral_73,2,M=\sqrt{\frac{K}{K-1}}P(I_{K}-\frac{1}{K}1_{K}1_{K}^{T })\inR^{p\times K},"where \(P=[P_{1},\cdots,P_{K}]\in\mathbb{R}^{p\times K}\) is a partial orthogonal matrix such that \(P^{T}P=I_{K}\)",\mu_{y}=\sqrt{\frac{p}{K-1}}\left(I_{K}-\frac{1}{K}1_{K}1_{K}^{\top}\right)e_{y},"where $\mu_y$ represents the class-specific feature vector in the equiangular tight frame (ETF) structure induced by Neural Collapse, with $p$ being the feature dimension and $K$ the number of classes."
ICML_2024_oral_73,3,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}}) || +\exp(-\frac{n}{8(\beta^{4}p^{2}+\frac{1}{3}\beta^{2} p)}),,"\widehat{\theta}_{NoisyGD}=\eta\sum_{i=1}^n y_i x_i+N\left(0,\frac{\eta^2 (1+\beta^2 p)}{2\rho} I_p\right)",The NoisyGD update rule for the last-layer parameter Î¸ with gradient noise added to ensure Ï-zCDP.
ICML_2024_oral_73,4,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}}) || +\exp(-\frac{n}{8(\beta^{4}p+\frac{1}{3}\beta^{2} )}),,\Pr[y\widehat{\theta}_{NoisyGD}^{T}x<0]\leq\exp\left(-\frac{n^{2}\rho}{2(1+\beta^{2}p)^{2}}\right)+\exp\left(-\frac{n}{8(\beta^{4}p+\frac{1}{3}\beta^{2})}\right),"This equation refines the misclassification error bound for NoisyGD by incorporating the independence assumption on the components of the feature shift vector $v$, leading to a tighter exponential decay rate in terms of $p$, $\beta$, and $\rho$."
ICML_2024_oral_73,5,\nablaL(\theta)=\frac{n}{2}\cdot 0.5\cdot-(-e_{1}+v)+\frac{n}{2}\cdot 0.5\cdot(e_{1}+v)=\frac{n}{2}e_{1},,\sum_{i=1}^{n}y_{i}(e_{1}+v_{i})=ne_{1}+\sum_{i=1}^{n}y_{i}v_{i}=ne_{1}+n v-nv=ne_{1},The gradient remains unaffected by the offset perturbation in the training data due to cancellation of the shift terms.
ICML_2024_oral_75,1,"J(\pi)=E_{(s_{t},\tau)\inD}[E_{a_{t}=\pi} [Q^{\pi}(s_{t},a_{t},\tau)]-\etaD_{KL}[\pi,\tilde{\pi}|s_{t},\tau]]",where \(\eta\) is a hyperparameter determining the strength of the regularization towards the reference policy \(\tilde{\pi}\),"J(\pi)=E_{\tau\sim\pi}\left[\sum_{t=0}^{T}\gamma^t\left( r(s_t, a_t)-\frac{1}{\beta} D_{KL}\left(\pi(\cdot|s_t)\parallel\tilde{\pi}(\cdot|s_t)\right)\right)\right]","Equation 1 defines the KL-regularized reinforcement learning objective $J(\pi)$, which incorporates both the expected cumulative reward and a KL-divergence penalty term to encourage policies close to the reference policy $\tilde{\pi}$."
ICML_2024_oral_75,2,"\pi_{imp}(a_{t}|s_{t},\tau)\propto\exp(Q^{\pi_{imp}(s_{t},a_{t},\tau)}/\eta)\tilde{\pi}(a_{t}|s_{t},\tau) || \propto\exp(A^{\pi_{imp}(s_{t},a_{t},\tau)}/\eta)\tilde{\pi}(a_{t}|s_{t},\tau)",,"\pi_{imp}(a_{t}|s_{t},\tau)\propto\tilde{\pi}(a_{t}|s_{t},\tau)\exp\left(\frac{1}{\eta}A^{\tilde{\pi}}(s_{t},a_{t},\tau)\right)",The improved policy $\pi_{\text{imp}}$ is proportional to the reference policy $\tilde{\pi}$ weighted by the exponentiated advantage function $A^{\tilde{\pi}}$ scaled by the inverse of the regularization hyperparameter $\eta$.
ICML_2024_oral_75,3,"L^{Q}(\theta)=E\Big{[} (1-\alpha)D_{KL}[\pi_{imp},\pi_{\theta}|s_ {t},\tau,\tilde{\pi}=\pi_{\theta^{\prime}}] || +\alphaD_{KL}[b,\pi_{\theta}|s_{t},\tau] || +\betaD_{KL}[\Gamma_{\theta^{\prime}}(q|s_{t},a_{t },\tau),p_{\theta}(q|s_{t},a_{t},\tau)]\Big{]} || =-E\Big{[} (1-\alpha)\operatorname*{E}_{d^{\prime}\sim\pi_{\theta^{\prime}}}[w(a^{\prime},s_{t},\tau)\log\pi_{\theta}(a^{\prime}|s_{t},\tau)] || +\alpha\log\pi_{\theta}(a_{t}|s_{t},\tau) || +\beta\operatorname*{E}_{q\sim\Gamma_{\theta^{\prime}}}\log p_{\theta}(q|s_{t},a_{t},\tau)\Big{]}+K_{H}",,"L(\theta)=E_{(s_t,\tau)\inD}\left[\alpha_1 D_{KL}\left[\pi_{imp},\pi_\theta | s_t,\tau\right]+\alpha_2 D_{KL}\left[\tilde{\pi},\pi_\theta | s_t,\tau\right]+\alpha_3 D_{KL}\left[\Gamma_{\theta'}(q | s_t, a_t,\tau), p_\theta(q | s_t, a_t,\tau)\right]\right]","where $\alpha_1$, $\alpha_2$, and $\alpha_3$ are coefficients balancing the policy improvement, behavior cloning, and Q-value distribution learning objectives, respectively."
ICML_2024_oral_75,4,"N(C)=N_{0}*C^{a},\;\;\;D(C)=D_{0}*C^{b}",,C=6DN=6N^{2}/\kappa,"This equation defines the relationship between compute operations (C), number of tokens (D), and number of parameters (N) for performance-optimal models, where $\kappa$ is a constant representing the compute efficiency."
ICML_2024_oral_79,1,"L_{dyn}[\theta_{F,G,P}](o_{t,T},a_{t})= || -\bf cos\_sim\big{(}Q(P(T(z_{t},e_{t}))), stopgrad(P(z_{t+1}))\big{)}",,"L_{forward}=E_{(o,a,o')\simD}\left[\|T(G(o), a)-G(o')\|_2^2\right]","Equation 1 defines the forward latent dynamics loss, which minimizes the squared error between the predicted next state embedding and the actual next state embedding, encouraging the model to accurately predict future states based on the current state and action."
ICML_2024_oral_79,2,"L[\theta_{F,G,G,P,\psi}]=L_{dyn}[\theta_{F,G,P}]+\betaL_{act\_decode}[\theta_{F,G,\psi}]",,L_{pretrain}=L_{dyn}+\lambda\cdotL_{act\_decode},"The combined pretraining objective is the sum of the latent dynamics loss and a weighted action decoding loss, where $\lambda$ balances the contribution of the two terms."
ICML_2024_oral_79,3,"L_{\textbf{CE}}(\pi(stopgrad(z_{t})),\xi_{t})[\theta_{\pi}]",,L_{policy}[\theta_{\pi}]=-\sum_{i=1}^{|D|}\sum_{t=0}^{H_{i}}\log\pi(\xi_{t}^{(i)}|z_{t}^{(i)}),"This equation represents the cross-entropy loss for training the high-level skill-token policy Ï using expert demonstration trajectories, where Î¾ââ± denotes the expert token and zââ± the latent state at timestep t in episode i."
ICML_2024_oral_79,4,"L_{\textbf{FT\_DECODER}}[\theta_{\pi,\psi}]=E_{\xi_{t}\sim\pi(stopgrad(z_{t}))}\Big{[}L[\theta_{\psi}](\xi_{t})\Big{]} || L[\theta_{\psi}](\xi_{t})=\sum_{i=0}^{\hat{K}}L_{ action}(\psi(stopgrad(z_{t+i}),\xi_{t}[i]),a_{t+i})","where

\[\mathcal{L}[\theta_{\psi}](\xi_{t})=\sum_{i=0}^{\hat{K}}\mathcal{L}_{\text{ action}}(\psi(\text{stopgrad}(z_{t+i}),\xi_{t}[i]),a_{t+i}) \tag{5}\]

In this equation, \(\hat{K}=\min(K,L_{\xi})\), where \(K\) is a hyperparameter, the motivation behind which is explained at the end of Section 3","L_{act\_decode}[\theta_{\psi}]=\|\psi(z_{t},e_{t})-a_{t}\|_{1}",Objective for fine-tuning the action decoder $\psi$ using $L1$-loss during downstream adaptation to unseen tasks.
ICML_2024_oral_79,5,"L[\theta_{\pi,\psi}]=L_{\textbf{CE}}(\pi(stopgrad(z _{t})),\xi_{t})+L_{\textbf{FT\_DECODER}}[\theta_{\pi,\psi}]",,"L_{\textbf{FT}}[\theta_{\pi,\psi}]=L_{\textbf{CE}}[\theta_{\pi}]+\lambdaL_{\textbf{FT\_DECODER}}[\theta_{\pi,\psi}]",The overall finetuning objective combines the cross-entropy loss for the skill-token policy with a weighted decoder finetuning loss.
ICML_2024_oral_84,1,\max_{\pi}E_{\hat{e}\sim\hat{p}(e)}J(\pi;\hat{e}),,"\max_{\theta}E_{e\sim\hat{p}(e)} [J(\theta, e)]",Maximizing the expected performance objective $J$ under the oracle environment distribution $\hat{p}(e)$ with respect to policy parameters $\theta$.
ICML_2024_oral_84,2,\hat{e}\sim\hat{p}(e),,\hat{e}\sim\hat{p}(e),A specific instance $\hat{e}$ drawn from the oracle environment distribution $\hat{p}(e)$ represents a single sample environment used for behavior generation and evaluation.
ICML_2024_oral_84,3,"E^{test}=\{\langle\hat{e}_{sim,i},r\rangle\}_{i=1,\cdots,n}",where the generated behavior \(\pi\) will be evaluated in,"E^{test}=\left\{\left(\hat{e}_{sim,1}, r\right),\ldots,\left(\hat{e}_{sim,n}, r\right)\right\}",Test environment defined as a finite set of tuples containing simulated sample environments and task specifications for behavior evaluation under oracle distribution
ICML_2024_oral_84,4,f:E^{ref}arrowE^{shaped},,E^{shaped}=f(E^{ref}),where the transformation function $f$ modifies the reference environment to enhance learnability and optimize performance in the test environment
ICML_2024_oral_84,5,"\max_{\pi}E_{\tau\sim\pi}[\sum_{t=0}^{T}\gamma^{t}r _{t}(s_{t},a_{t}))] || s.t.\\\s_{t+1}\sim p(s_{t},a_{t};E^{shaped })",,\pi^{shaped}=\arg\max_{\pi}E_{e\simE^{shaped}} J(\pi; e),Optimal behavior trained on the shaped environment to maximize expected performance across environments in $\mathcal{E}^{\text{shaped}}$.
ICML_2024_oral_84,6,H:f_{k}\times J(\pi^{\star}_{k};E^{test})\to f_{k+1},,"\pi^{\star}=\arg\max_{\pi}E_{\tau\sim\pi}[\sum_{t=0}^{T}\gamma^{t}r_{t}(s_{t},a_{t}))]\s.t.\s_{t+1}\sim p(s_{t},a_{t};E^{shaped})","Optimal behavior $\pi^{\star}$ obtained via RL training on the shaped environment $\mathcal{E}^{\text{shaped}}$, maximizing expected cumulative reward under the learned policy dynamics."
ICML_2024_oral_84,7,"f_{k+1}=H(f_{k},J(\pi^{\star}_{k};E^{test})) || where\\\pi^{\star}_{k}=\underset{\pi}{argmax}\J(\pi;E^{shaped}_{k}) || E^{shaped}_{k}=f_{k}(E^{ref}),\f_{0}=I_{identity}",,"&Given E^{ref},\E^{test},\\&\pi_{0}^{\star}\leftarrowRL(E^{shaped}=f_{0}(E^{ref})),\\&For  k=0,1,\dots,K:\\&\quad f_{k+1}\leftarrowH(f_{k},\J(\pi_{k}^{\star};\E^{test})),\\&\quadE_{k+1}^{shaped}\leftarrow f_{k+1}(E^{ref}),\\&\quad\pi_{k+1}^{\star}\leftarrowRL(E_{k+1}^{shaped})","This iterative process alternates between RL training on a shaped environment, behavior evaluation on the test environment, and human-guided reflection to refine the shaping function for improved robustness and generalization."
ICML_2024_oral_84,8,"\max_{f\inF} J(\pi^{\star};E^{test}) || s.t.\\\\pi^{\star}\in\arg\max_{\pi}J(\pi;E^{shaped }),\\E^{shaped}=f(E^{ref})",,\max_{f\inF}\J\left(\underset{\pi}{argmax}\J(\pi;f(E^{ref}));\E^{test}\right),"Equation 8 formulates the bi-level optimization problem that aims to find the optimal environment shaping function $f$ by maximizing the performance of the RL-trained policy $\pi$ on the test environment $\mathcal{E}^{\text{test}}$, where $\pi$ itself is obtained by maximizing its performance on the shaped reference environment $f(\mathcal{E}^{\text{ref}})$."
ICML_2024_oral_93,1,c(\pi)=\|x_{\pi_{n}}-x_{\pi_{1}}\|_{2}+\sum_{i=1}^{n-1}\| x_{\pi_{i}}-x_{\pi_{i+1}}\|_{2},where \(\|\cdot\|_{2}\) denotes the \(\ell_{2}\) norm,c(\pi)=\sum_{i=1}^{n-1}\lVert x_{\pi_i}-x_{\pi_{i+1}}\rVert_2+\lVert x_{\pi_n}-x_{\pi_1}\rVert_2,"Equation 1 defines the total path length $c(\mathbf{\pi})$ as the sum of Euclidean distances between consecutive vertices in the tour permutation $\mathbf{\pi}$, including the return from the last vertex to the first."
ICML_2024_oral_93,2,"L(\theta)=E_{\pi\simS}[E_{\Phi\sim f_{\theta}(s)}[E_{\pi\sim g(s,\Phi)}[c(\bm {\pi})]]]","where \(s\) represents an instance from distribution \(\mathcal{S}\), \(\theta\) is the trainable parameters of model \(f\), \(\mathbf{\pi}\) is the solution outputed by post-hoc search algorithm \(g\) given \(\Phi\), and \(c(\mathbf{\pi})\) is calculated based on Equation 1","\max_{\pi}\sum_{(i,j)\in E(\pi)}\Phi_{i,j}","where $E(\mathbf{\pi})$ denotes the set of edges in the tour defined by permutation $\mathbf{\pi}$, and the objective maximizes the sum of heatmap values for edges in the tour."
ICML_2024_oral_93,3,"L_{\textit{surrogate}}(\theta)=E_{s\simS}[E_{\Phi\sim f_{\theta}(s)}[\ell(s,\Phi)]]",,"L_{surrogate}(\theta)=E_{s\simS}\left[\ell\left(s, f_{\theta}(s)\right)\right]","where $\ell(s, \Phi)$ is a differentiable surrogate loss function that approximates the expected cost of solutions generated by the search algorithm $g$ given the heatmap $\Phi$."
ICML_2024_oral_93,4,"p(\pi_{i}|\pi_{i-1})=\frac{Z_{\pi_{i-1},\pi_{i}}}{\sum_{l\inX_{\pi_{ i-1}}}Z_{\pi_{i-1},l}}",,"p(\pi_{i}|\pi_{i-1})=\frac{Z_{\pi_{i-1},\pi_{i}}}{\sum_{j\notinV_{visited}}Z_{\pi_{i-1},j}}","where $\mathcal{V}_{\text{visited}}$ denotes the set of vertices already included in the partial tour, ensuring that each vertex is visited only once during the tour construction process."
ICML_2024_oral_95,1,"K_{img}(i,j)=\langle f_{img}(x_{i}),f_{img}(x_{j})\rangle || K_{text}(i,j)=\langle f_{text}(y_{i}),f_{text}(y_{j})\rangle",,"K_{text}(y_i, y_j)=\langle f_{text}(y_i), f_{text}(y_j)\rangle,\quad K_{vision}(x_i, x_j)=\langle f_{vision}(x_i), f_{vision}(x_j)\rangle",Equation 1 defines the text and vision kernels used to measure cross-modal alignment between language and vision models using paired image-caption data.
ICML_2024_oral_95,2,"P_{\texttt{coor}}(x_{a},x_{b})\propto\sum_{(t,t^{\prime})\colon|t-t^{\prime}|\leq T_{\texttt{ window}}}P(X_{t}=x_{a},X_{t^{\prime}}=x_{b})",,"Alignment(K_{img}, K_{text})=\frac{Tr(K_{img} K_{text})}{\|K_{img}\|_F\|K_{text}\|_F}","Cross-modal alignment between image and text kernels is quantified by the normalized trace of their product, measuring their similarity."
ICML_2024_oral_95,3,"\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle\approx\log\frac{P(\texttt{pos}\mid x_{a},x_{b})}{ P(\texttt{neg}\mid x_{a},x_{b})}+\tilde{c}_{X}(x_{a}) || =\log\frac{P_{\texttt{coor}}(x_{a}\mid x_{b})}{P_{\texttt{coor}} (x_{a})}+c_{X}(x_{a})",,"\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle\approx\log\frac{P_{\texttt{coor}}(x_{a},x_{b})}{P(x_{a})P(x_{b})}+offset","This equation defines the objective of a contrastive learner, where the dot product of representations approximates the log odds ratio of co-occurrence versus independence, indicating how much more likely two observations are to co-occur compared to being independent."
ICML_2024_oral_95,4,"=K_{\texttt{PMI}}(x_{a},x_{b})+c_{X}(x_{a})","where \(K_{\texttt{PMI}}\) is the pointwise mutual information (PMI) kernel, and \(c_{X}(x_{a})\) is constant in \(x_{b}\)","\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle\approx\log\frac{P_{\texttt{coor}}(x_{a}, x_{b})}{P_{\texttt{coor}}(x_{a}) P_{\texttt{coor}}(x_{b})}+c_{X}(x_{a})+c_{X}(x_{b})","This equation formalizes the contrastive learning objective by approximating the log ratio of joint and marginal co-occurrence probabilities using a dot-product kernel, with additive bias terms for each observation."
ICML_2024_oral_95,5,"\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle=K_{\texttt{PMI}}(x_{a},x_{b})+c_{X}",where we observed that \(c_{X}(x_{a})\) from Eq,f_{X}(x)=\Phi^{-1}\left(\frac{d}{dx}P(Z\leq x)\right),A representation $f_X$ that exactly recovers the PMI kernel under mild smoothness assumptions on the world's distribution.
ICML_2024_oral_95,6,"P_{\texttt{coor}}(x_{a},x_{b})=P_{\texttt{coor}}(x_{a},x_{b}),\,K_{\texttt{PMI }}(x_{a},x_{b})=K_{\texttt{PMI}}(z_{a},z_{b})",where we use \(P_{\texttt{coor}}\) and \(K_{\texttt{PMI}}\) modality-agnostically to emphasize that different modalities share these same quantities,"K_{\texttt{PMI}}(x_{a},x_{b})=\log\frac{P(x_{a},x_{b})}{P(x_{a})P(x_{b})}","Equation 6 defines the pointwise mutual information (PMI) kernel between two observations $x_a$ and $x_b$, which quantifies the log ratio of their joint probability to the product of their marginals, capturing the statistical dependence between them."
ICML_2024_oral_95,7,"K_{\texttt{PMI}}(z_{a},z_{b})=\langle f_{X}(x_{a}),f_{X}(x_{b})\rangle-c_{X} || =\langle f_{Y}(y_{a}),f_{Y}(y_{b})\rangle-c_{Y}",,"K_{\texttt{PMI}}(x_{a},x_{b})=K_{\texttt{PMI}}(y_{a},y_{b})=K_{\texttt{PMI}}(z_{a},z_{b})","This equation shows that the PMI kernel is modality-agnostic, being invariant under bijective transformations of the observation space, and thus represents a shared structure across modalities."
ICML_2024_oral_99,1,"\min_{(\pi,\hat{\Delta})}\max_{\nu\inE_{0}}(R_{\nu}(n,\pi),\max_{1\leq j\leq M}e_{\nu}(n,\hat{\Delta}(X_{j})))",where we use the subscript \(\nu\) to denote the contextual bandit instance,"\min_{\pi,\hat{\Delta}}\max\left\{R(n,\pi),\max_{1\leq j\leq M}e\left(n,\hat{\Delta}(X_{j})\right)\right\}","This equation formulates the minimax multi-objective optimization problem for the optimal design of contextual bandit experiments, balancing the trade-off between minimizing the worst-case accumulative regret and minimizing the maximum mean square error of the treatment effect estimators across all features."
ICML_2024_oral_99,2,"\inf_{(\pi,\hat{\Delta}_{n})}\max_{\nu\inE_{0}}[e_{\nu}(n,\hat{\Delta}_{n})R_{\nu}(n,\pi)]\geq\Omega (M)",,"\max_{\nu\inE_{0}}\max_{1\leq j\leq M}e_{\nu}\left(n,\hat{\Delta}(X_{j})\right)\geq\Omega\left(\frac{M}{R_{\nu}(n,\pi)}\right)",Lower bound showing the inverse relationship between the maximum estimation error of CATE and the regret in the absence of privacy constraints.
ICML_2024_oral_99,3,"e_{\nu}(n,\hat{\Delta}_{n})=\max_{1\leq j\leq M}E[(\hat{\Delta}_{n}(X_{j})-\Delta(X_{j}))^{2}]=O(\frac{1}{ f_{\min}(n)})",,"\max_{1\leq j\leq M}e_{\nu}(n,\hat{\Delta}(X_{j}))=O\left(\frac{1}{f_{min}(n)}\right)","The equation characterizes the optimal estimation error when using random control trials (RCT), showing that the maximum mean square error across all features decays inversely with the minimum expected feature occurrence $f_{min}(n)$."
ICML_2024_oral_99,4,"R_{\nu}(n,\pi)\leqO(M\max\{f_{min}(n)^{1-\alpha},\log n\}) || e_{\nu}(n,\hat{\Delta}_{n})\leqO(\frac{1}{\max\{f_{min}(n)^{1-\alpha},\log n\}})",,"R_{\nu}(n,\pi)=O\left(\sum_{j=1}^{M}\Delta_{j}^{-1}\log n+Mn^{\alpha}\right),\quad\max_{1\leq j\leq M}e_{\nu}(n,\hat{\Delta}(X_{j}))=O\left(\frac{1}{n^{\alpha}}\right)","Equation 4 presents the theoretical guarantees of the ConSE algorithm, showing that it achieves a regret bound of $\mathcal{O}\left(\sum_{j=1}^{M}\Delta_{j}^{-1}\log n+Mn^{\alpha}\right)$ and a maximum estimation error of $\mathcal{O}\left(\frac{1}{n^{\alpha}}\right)$ across all features."
ICML_2024_oral_99,5,"e_{\nu}(n,\hat{\Delta}_{n})R_{\nu}(n,\pi)\leqO(M)",,"R_{\nu}(n,\pi)\cdot e_{\nu}(n,\hat{\Delta}_{n})=O(M)","The product of regret and estimation error is bounded by a constant multiple of the number of features $M$, demonstrating the Pareto optimality of the ConSE algorithm."
ICML_2024_oral_99,6,O((\log n_{j}+\log\log(1/\Delta(X_{j})))(\frac{ 1}{\Delta(X_{j})^{2}}+\frac{1}{\varepsilon\Delta(X_{j})})),,O\left(\frac{\log n}{\Delta(X_{j})^{2}}+\frac{\log n}{\varepsilon\Delta(X_{j})}\right),"The number of times the suboptimal arm is pulled for feature $X_j$ in the first half of the DP-ConSE algorithm is bounded by this expression, ensuring efficient elimination with high probability under privacy constraints."
ICML_2024_oral_99,7,"e(n,\hat{\Delta})=O(\frac{1}{\max\{f_{min}(n)^{1-\alpha},\frac{\log n}{\varepsilon}\}})",,"e_{\nu}(n,\hat{\Delta}_{n})\leqO\left(\frac{1}{\max\{f_{min}(n)^{1-\alpha},\log n\}}\right)\right)",The estimation error of the DP-ConSE algorithm is bounded by the inverse of the maximum between the $(1-\alpha)$-th power of the minimum feature occurrence and the logarithm of the time horizon.
naacl_2024_short_14,1,p_{lm}(x_{t}|c)=f\circg\circenc(c),"where \(f\) is the last linear layer with softmax activation, \(g\) is the two-layer MLP network with a residual connection in the last Transformer layer, and \(\mathrm{enc}\) includes the earlier layers of the model",P(x_t|c)=Softmax(h_{t}^{L} W_{e}^{T}),"Probability distribution over the vocabulary for predicting the next token $x_t$ given the context $c$, parameterized by the model's final hidden states and embedding matrix $W_e$."
naacl_2024_short_14,2,p_{knnlm}(x_{t}|c)=\lambda p_{lm}(x_{t}|c)+(1-\lambda)p_{\text {knn}}(x_{t}|c),where \(\lambda\) is a hyperparameter for interpolation,p_{knn}(x^{\prime}_{t}|c)=\sum_{i=1}^{k}\alpha_i\cdot1(x_i=x^{\prime}_{t}),where $\alpha_i$ represents the attention weight for the $i$-th nearest neighbor and $\mathbf{1}(\cdot)$ is the indicator function.
naacl_2024_short_14,3,"z^{*}\in\operatorname*{arg\,min}_{z\inR^{d}}KL[f(z)\|p_{knnlm}]",where \(f\) is the last layer of the model with its trained parameters fixed (definition in Eq 1),\min_{z}\|f(z)-p_{knnlm}(\cdot|c)\|_{2}^{2}\s.t.\z\inIm(g\circenc),the optimization problem that finds the best approximation of the $k$NN-LM distribution within the image of the LM's last layer mapping
naacl_2024_short_16,1,"g(x)=\operatorname*{arg\,max}_{c\inY}P_{x\sim\phi(x,m)}(f(M(x,s))=c)",,"g(x)=E_{s\sim\phi(x, m)}\left[f\left(M(x,s)\right)\right]","The smoothed model $g(\mathbf{x})$ is defined as the expectation of the original model's output $f(\cdot)$ over all possible masked inputs $\mathcal{M}(\mathbf{x}, \mathbf{s})$, where the binary mask $\mathbf{s}$ is generated by the randomized masking scheme $\phi(\mathbf{x}, m)$ with $m\%$ noise intensity."
naacl_2024_short_16,2,"g^{\prime}(x)=\operatorname*{arg\,max}_{e\inY}P_{s \sim\phi(x,m)}(f(D(M(x,s)))=c)",,"f(M(x,s))\rightarrow f(D(M(x,s)))","This equation illustrates the modification where a denoiser $D(\cdot)$ is applied to the masked input before passing it to the LLM $f(\cdot)$, aiming to improve performance by reconstructing the masked tokens."
naacl_2024_short_22,1,"R_{LM}(X,\tau,a^{*})=LM(a^{*}|X,\tau)",,"s\leftarrow\operatorname*{argmax}_{s\in S} V_{\theta}(X+s,\tau)",Selection of the optimal state feature $s$ that maximizes the value function $V_{\theta}$ given current state description $X$ and task $\tau$
naacl_2024_short_22,2,"L(X,S,\tau,a^{*})=\\\sum_{t=0}^{|X|}(V_{\theta}(X_{:t},\tau)-\gamma^{|X|-t}R_{LM}( X,\tau,a^{*}))^{2}",,"L(X,\tau, a^*)=-\log R_{LM}(X,\tau, a^*)","The loss function for a single state description, defined as the negative log-likelihood of the target action given the state description and task description."
naacl_2024_short_22,3,"L_{V_{\theta}}=\underset{{c}S,\tau,a^{*}\sim D\\X\sim\pi|S,\tau}{E}[L(X,S,\tau,a^{*})+\phi]","where \(\gamma\) is a discount factor and \(\phi\) is a Kullback-Leibler penalty for normalizing \(V_{\theta}\), common when finetuning LMs with RL (Stiennon et al","L_{total}=\sum_{(S,\tau,a^{*})\in D}\sum_{X\simBLINDER(S,\tau)}L(X,S,\tau,a^{*})","The overall loss function for $V_{\theta}$ aggregates the individual state description losses across all trajectory demonstrations in the dataset $D$, where state descriptions $X$ are sampled using the BLINDER algorithm for each $(S,\tau,a^{*})$ tuple."
naacl_2024_short_23,1,"\hat{C}_{m},\hat{S}_{m},\hat{F}_{m}=\textsc{attributePredictor}(m,M) || \hat{E}=\textsc{CandidateGenerator}(m,E) || f(m|T,M,E)=\textsc{Constrainer}(\hat{E},\hat{C}_{m},\hat{S}_{m},\hat{F}_{ m})",,"(c, s, f) &=PredictAttributes(T, M, m),\\E' &=QueryOntology(m, E),\\\hat{e} &=\arg\min_{e\in E'}ConstraintViolations(e, c, s, f)","Equation 1 formalizes the geocoding function through a three-stage process: attribute prediction, ontology querying, and constraint-based candidate selection."
naacl_2024_short_23,3,L=C_{m}log(\hat{C}_{m})+S_{m}log(\hat{S}_{m})+F_{m}log(\hat{F}_{m}),"where \(C_{m}\), \(S_{m}\), and \(F_{m}\) are one-hot vectors of size \(N\) representing the true country, state, and feature class for mention \(m\)",L=-\sum_{m\in M}\left(\log\hat{C}_m+\log\hat{S}_m+\log\hat{F}_m\right),"The training loss function combines the cross-entropy losses for the predicted country, state, and feature class of each location mention $m$ in the dataset."
naacl_2024_short_25,1,"f(q,d_{i})=\frac{\exp(s_{i,1})}{\exp(s_{i,1})+\exp(s_{i,0})}",,"f(q, d_i)=\frac{\exp(s_{i,1})}{\exp(s_{i,1})+\exp(s_{i,0})}","The ranking score for a document is computed using a softmax function over the log-likelihood scores of the LLM's ""Yes"" and ""No"" responses for relevance."
naacl_2024_short_25,2,"s_{i,k}=LLM(l_{k}|q,d_{i})",,"f(q,d_{i})=\frac{\exp(s_{i,2})}{\sum_{k=0}^{2}\exp(s_{i,k})}","where $s_{i,k}=\text{LLM}(l_{k}|q,d_{i})$ represents the log-likelihood of the LLM generating the $k$-th relevance label for the $i$-th document."
naacl_2024_short_25,3,"f(q,d_{i})=\sum p_{i,k}\cdot y_{k} || where p_{i,k}=\frac{\exp(s_{i,k})}{\sum_{k^{\prime}}\exp(s_{i,k^{\prime}})}",,"E[y]=\sum_{k=0}^{2} y_{k}\cdot\frac{\exp(s_{i,k})}{\sum_{j=0}^{2}\exp(s_{i,j})}","The expected relevance value is calculated by taking a weighted sum of relevance values, where the weights are softmax-normalized log-likelihoods of each relevance label."
naacl_2024_short_25,4,"f(q,d_{i})=s_{i,k^{*}}",,"f(q,d_{i})=\exp(s_{i,k^{*}})",The ranking score is determined by the exponential of the log-likelihood of the highest relevance label assigned to the document.
naacl_2024_short_26,1,"f(x,t,k;\theta)=y",,"y=\arg\max_{s\in S} P(s\mid x, t, k;\theta)","Stance prediction model incorporating knowledge $k$, where $y$ is derived by maximizing the conditional probability over stance set $S$ given text $x$, target $t$, knowledge $k$, and parameters $\theta$."
naacl_2024_short_26,2,"L_{gen}=-\sum_{i=1}^{|u|}\log p(u_{i}|,u_{< i},h(x,t,k);\theta)","where \(p(u_{i}|,\boldsymbol{u}_{<i},h(x,t,k);\theta)\) is the probability to select a token \(u_{i}\) at step \(i\) given the input \(h(x,t,k)\) and previously generated tokens \(\boldsymbol{u}_{<i}\)","\max_{\theta}\log p(u\mid h(x,t,k);\theta)","The BART model is trained by maximizing the log-likelihood of the output sequence $\mathbf{u}$ given the combined input $h(x,t,k)$ parameterized by $\theta$."
naacl_2024_short_26,3,v_{c}arrowNormalize(\betav_{c}+(1-\beta)v_{c}^{\prime}),"where \(\beta\) is a momentum coefficient, \(\text{Normalize}(\cdot)\) is the normalization function, and \(\boldsymbol{v}_{c}^{\prime}\) is the centroid of embeddings belonging to class \(c\) in the batch",v_{c}^{(t)}=\alphav_{c}^{(t-1)}+(1-\alpha)\hat{z}_{c}^{(t)},"where $\boldsymbol{v}_{c}^{(t)}$ is the updated prototype for class $c$ at step $t$, $\alpha$ is the moving average coefficient, and $\boldsymbol{\hat{z}}_{c}^{(t)}$ is the projected stance embedding for class $c$ at step $t$"
naacl_2024_short_26,4,L_{con}=-\sum_{c=1}^{C}y_{c}\log\frac{exp(\frac{s_{c}}{\gamma})}{\sum_{j=1}^{C}exp(\frac{s_{j}}{\gamma})},where \(\gamma\) is a scalar temperature parameter and \(\boldsymbol{y}\) is the one-hot label for the current sample,"L_{con}=-\log\frac{\exp(<\hat{z},v_{y}>/\tau)}{\sum_{j=1}^{|C|}\exp(<\hat{z},v_{j}>/\tau)}","where $y$ is the ground-truth stance class, $\mathcal{C}$ is the set of all stance classes, and $\tau$ is a temperature scaling factor that controls the concentration level of the distribution."
naacl_2024_short_26,5,L=\lambda_{l}\cdotL_{gen}+(1-\lambda_{l})\cdotL _{con},where \(\lambda_{l}\) is involved to balance the optimization,L_{total}=L_{gen}+\lambdaL_{con},where $\lambda$ is a hyperparameter balancing the contributions of the generation loss $\mathcal{L}_{gen}$ and the contrastive loss $\mathcal{L}_{con}$
naacl_2024_short_27,1,"[sim_{A}^{j},sim_{B}^{j}]=X_{i}\cdot[X_{A}^{j},X_{B}^{j}]",,"sim(X_i, A_j)=X_i\cdot A_j",Similarity between example representation $X_i$ and attribute representation $A_j$ using dot product.
naacl_2024_short_27,2,"d_{sim}^{j}=\sigma(sim_{A}^{j},sim_{B}^{j})",,"[\hat{sim}_{A}^{j},\hat{sim}_{B}^{j}]=\sigma(sim_{A}^{j}, sim_{B}^{j})",Normalized similarity scores between the example representation and each attribute representation using the softmax function.
naacl_2024_short_27,3,"L_{kl}=\sum_{j=1}^{K}D_{KL}(d_{sim}^{j},d_{uni})",,L_{KL}=\sum_{j=1}^{M}KL(d_{sim}^{j}\| d_{uni}),Kullback-Leibler divergence loss computed between each similarity distribution and a uniform distribution across all M attributes
naacl_2024_short_27,4,L_{total}=L_{ce}+\lambda L_{kl},where \(L_{ce}\) is the usual cross-entropy loss,L_{total}=L_{task}+\lambda\cdot L_{kl},Weighted sum of task-specific loss and KL divergence loss with hyperparameter Î» controlling the relative contribution
naacl_2024_short_28,1,"S(y)=-\frac{1}{|H(x)|}\sum_{y^{\prime}\in H(x)}L(y^{\prime},y)",,"S(y|x)=E_{y^{\prime}\sim P(\cdot|x)}\left[L(y,y^{\prime})\right]","Expected score (negative Bayes risk) of a translation $\mathbf{y}$ given input $\mathbf{x}$, computed as the expectation of the loss function $L(\mathbf{y}, \mathbf{y}^{\prime})$ over the distribution of sampled translations $\mathbf{y}^{\prime}$."
naacl_2024_short_28,2,"y^{*}=\operatorname*{arg\,max}_{y\in H(x)}S(y)",,\hat{y}_{MBR}=\arg\min_{y\in H(x)} S(y),"The MBR hypothesis is the translation that minimizes the score function $S(\mathbf{y})$, which represents the negative Bayes risk."
naacl_2024_short_28,3,"\max_{\pi_{\theta}}E_{x\sim D,y\sim\pi_{\theta}( y|x)}[r_{\phi}(x,y)] || -\betaD_{KL}[\pi_{\theta}(y|x)\parallel\pi_{ref}(y|x)]",,"\log P_{\theta}(y^{*}|x)=\log\frac{\exp(\beta r(y^{*},x))}{\sum_{y}\exp(\beta r(y,x))}","Log probability of the optimal translation given the input under the DPO objective, parameterized by $\theta$, with reward function $r(\cdot,\cdot)$ and temperature parameter $\beta$."
naacl_2024_short_28,4,"L_{DPO}=-E_{(x,y_{w},y_{l})\sim D}[log\sigma(M(y_{w},y_{l},x,\theta))] || \beta(log\frac{\pi_{\theta}(y_{w}|x)}{\pi_{ref}(y_{w}|x)}-log\frac{\pi_{\theta}( y_{l}|x)}{\pi_{ref}(y_{l}|x)})","where the reward margin \(M(\mathbf{y}_{w},\mathbf{y}_{l},\mathbf{x},\theta)\) is

\[\beta\left(\text{log}\frac{\pi_{\theta}(\mathbf{y}_{w}|\mathbf{x})}{\pi_{ \text{ref}}(\mathbf{y}_{w}|\mathbf{x})}-\text{log}\frac{\pi_{\theta}(\mathbf{ y}_{l}|\mathbf{x})}{\pi_{\text{ref}}(\mathbf{y}_{l}|\mathbf{x})}\right) \tag{5}\]

### Related Work in Translation

Previous work has explored the effectiveness of enhancing the translation performance of LLMs via Reinforcement Learning (RL) algorithms or supervised fine-tuning","\max_{\pi_{\theta}}E_{(x,y_{w},y_{l})\sim D}\left[\log\frac{\sigma\left(\beta\log\frac{\pi_{\theta}(y_w|x)}{\pi_{ref}(y_w|x)}-\beta\log\frac{\pi_{\theta}(y_l|x)}{\pi_{ref}(y_l|x)}\right)}{\sigma\left(\beta\log\frac{\pi_{\theta}(y_l|x)}{\pi_{ref}(y_l|x)}-\beta\log\frac{\pi_{\theta}(y_w|x)}{\pi_{ref}(y_w|x)}\right)}\right]","This equation represents the DPO objective, which maximizes the expected reward margin between the winning and losing responses using a sigmoid function to model the preference probability."
naacl_2024_short_32,1,"y^{*}=\operatorname*{arg\,max}_{y\inY}E_{r\sim P_{ human}(\cdot|x)}[u(y,r)]",,"y^*=\arg\max_{y\inY}E_{r\sim p(r)}[u(y, r)]",Equation for MBR decoding that selects the candidate translation maximizing the expected utility over the reference distribution.
naacl_2024_short_32,2,"y^{*}=\operatorname*{arg\,max}_{y\inY}\frac{1}{|R^{\prime}|}\sum_{r^{\prime}\inR^{\prime}}u(y,r^{\prime})",,"y^{*}=\operatorname*{arg\,max}_{y\inY}\frac{1}{K}\sum_{k=1}^{K}u(y,r_{k}^{\prime}),\quad r_{k}^{\prime}\sim P_{model}(\cdot|x)",This equation approximates the expected utility in Equation 1 by averaging the utility over K pseudo-references sampled from the model distribution.
naacl_2024_short_33,1,"\min_{P_{n},v_{n}}-\sum_{x_{n},y_{n}}\log p(y_{n}|x_{n},P^{\prime}_{n},\theta)-\sum_{x_{n}}\cos(x_{n},v_{n})",,"L_{n}=L_{CE}(P_{n}, v_{n})-\lambda\cdot\cos(x_{n}, v_{n})","The loss function for the $n^{\text{th}}$ task in MoCL, combining cross-entropy loss and cosine similarity maximization between the task feature vector and input embeddings."
naacl_2024_short_33,2,"FWT=\frac{1}{N-1}\sum_{j=2}^{N}(a_{i,i}-\tilde{a}_{i})","where \(N\) is the number of tasks in the continual learning sequence, \(a_{i,i}\) denotes the performance evaluated on the \(i\)-th task after incremental learning on the first \(i\) tasks, \(\tilde{a}_{i}\) is the task performance of a randomly initialized reference model trained with dataset \(D_{i}\)","FWT=\frac{1}{N-1}\sum_{n=1}^{N-1} A_{n+1,n}-B_{n+1,n}","Forward transfer score (FWT) measures the average influence of previous tasks on the performance of subsequent tasks, where $A_{n+1,n}$ is the accuracy of task $n+1$ after learning task $n$, and $B_{n+1,n}$ is the accuracy of task $n+1$ without prior learning."
naacl_2024_short_34,1,x_{k}&=A_{k}x_{k-1}+Bu_{k}\\y_{k}&=h(x_{k}),,"h_t &=A_th_{t-1}+B_tx_t,\\y_t &=C_th_t","Equation 1 defines the general formulation of LRNNs, where the hidden state at time step $t$ is updated using a transition matrix $\mathbf{A}_t$ and an input matrix $\mathbf{B}_t$, and the output is generated using a projection matrix $\mathbf{C}_t$."
naacl_2024_short_34,2,x_{k}=Ax_{k-1}+Bu_{k},,x_{k} &=A x_{k-1}+B u_{k}\\y_{k} &=h(x_{k}),"Equation 2 represents the standard LRNN recurrence relation with an input-independent transition matrix $A$, where the state evolution depends linearly on the previous state and the current input."
naacl_2024_short_34,3,"x_{0-1}&=A^{3}z+A^{2}u_{0}+Au_{-}+u_{ 1},\\for ""0-1""\\x_{1-0}&=A^{3}z+A^{2}u_{1}+Au_{-}+u_{0},\\for ""1-0""",,"""0-1"": &\quad x_{0}=A z+B u_{0},\quad x_{1}=A x_{0}+B u_{-},\quad x_{2}=A x_{1}+B u_{1}\\""1-0"": &\quad x_{0}=A z+B u_{1},\quad x_{1}=A x_{0}+B u_{-},\quad x_{2}=A x_{1}+B u_{0}","Equation 3 represents the state transitions for the sequences ""0-1"" and ""1-0"" using an input-independent LRNN, which is critical for demonstrating the model's inability to represent subtraction in Proposition 1."
naacl_2024_short_34,4,A^{2}u_{0}+Au_{-}+u_{1}\neq A^{2}u_{1}+Au_{-}+u_{0},,A^{2}u_{0}+u_{1}\neq A^{2}u_{1}+u_{0},"This inequality arises from the requirement that the state representations of sequences ""0-1"" and ""1-0"" must differ due to the non-commutative nature of subtraction."
naacl_2024_short_34,5,x_{0-0-1}&=A^{3}x_{0-}+A^{2}u_{0}+Au_ {-}+u_{1}\\x_{0-1-0}&=A^{3}x_{0-}+A^{2}u_{1}+Au_{-}+u_{0},,"x_{0-0-1} &=A^{3}x_{0-}+A^{2}u_{0}+Au_{-}+u_{1},\quadfor ""0-0-1""\\x_{0-1-0} &=A^{3}x_{0-}+A^{2}u_{1}+Au_{-}+u_{0},\quadfor ""0-1-0""","Equation 5 represents the state evolution for sequences ""0-0-1"" and ""0-1-0"" to demonstrate the limitations of input-independent LRNNs in distinguishing structurally similar but semantically different sequences."
naacl_2024_short_34,6,A^{2}u_{0}+Au_{-}+u_{1}=A^{2}u_{1}+Au_{-}+u_{0},,A^{3}x_{0-}+A^{2}u_{0}+Au_{-}+u_{1} &=A^{3}x_{0-}+A^{2}u_{1}+Au_{-}+u_{0}\\\Rightarrow A^{2}u_{0}+u_{1} &=A^{2}u_{1}+u_{0},"This equation enforces equality between the state representations of the sequences ""0-0-1"" and ""0-1-0"", leading to a constraint on the matrix $A$ and input vectors $u_0$, $u_1$."
naacl_2024_short_34,7,x_{k}=diag(v_{k})x_{k-1}+Bu_{k},where \(v_{k}=f(u_{k})\) is a vector that depends on \(u_{k}\),x_{k} &=diag(g(u_{k}))x_{k-1}+Bu_{k}\\y_{k} &=h(x_{k}),"Equation 7 defines a diagonal input-dependent LRNN where the state transition matrix is diagonal and depends on the input $u_k$ through a function $g$, aiming to address the limitations of input-independent models in representing arithmetic operations and regular languages."
naacl_2024_short_34,8,x_{k}&=Ax_{k-1}+(Bu_{k})\odot x_{k-1}+Bu_{k}\\&=(A+diag(Bu_{k}))x_{k-1}+Bu_{k},where \(\odot\) denotes the Hadamard product and \(\text{diag}(w)\) constructs a diagonal matrix from \(w\),x_{k}=A_{k}x_{k-1}+Bu_{k},where $A_{k}$ is a block-diagonal and input-dependent transition matrix that enhances expressiveness compared to diagonal formulations.
naacl_2024_short_34,9,x_{k}=A_{k}x_{k-1}+Bu_{k},where \(A_{k}=g(u_{k})\) is a block diagonal matrix in practice for the sake of efficiency,x_{k} &=blockdiag(f(u_k)) x_{,
naacl_2024_short_34,10,"& A_{k}=diag(A_{k}^{(1)},...,A_{k}^{(h)} )\inR^{bh\timesbh}\\& A_{k}^{(i)}=[v_{k}^{(i,1)}\quad\ldots\quad v_{k}^{(i,b)} ]\inR^{b\times b}\\&\|v_{k}^{(i,j)}\|_{p}\leq 1,\\i\in[1,...,h],\\j\in[1,...,b]","where \(\|\cdot\|_{p}\) denotes the vector p-norm and \(v_{k}^{(i,j)}\) is a column vector that depends on \(u_{k}\)",\|A_{k}\|_{1}\leq 1,which ensures the column norms of the input-dependent transition matrix $A_{k}$ are constrained to prevent numerical instability.
naacl_2024_short_34,11,&[\|v^{(1)}\|_{1}\quad\ldots\quad\|v^{(b)}\|_{1} ]=1^{\top}|A_{k+1}^{(i)}A_{k}^{(i)}|\\&\leq1^{\top}|A_{k+1}^{(i)} || A_{k}^{(i)} |\leq1^{\top}|A_{k}^{(i)}|\leq1^{\top},,"\|v^{(j)}\|_{1}=\left\|\sum_{l=1}^{b}A_{k+1}^{(i)}(:,l)A_{k}^{(i)}(l,j)\right\|_{1}\leq\sum_{l=1}^{b}|A_{k}^{(i)}(l,j)|\cdot\|A_{k+1}^{(i)}(:,l)\|_{1}\leq\sum_{l=1}^{b}|A_{k}^{(i)}(l,j)|\leq 1","Derivation showing that the product of two consecutive block matrices preserves the column-wise $ \| \cdot \|_1 $-norm constraint, ensuring numerical stability of the recurrence relation."
naacl_2024_short_38,1,"f(C,P,N_{1},N_{2})=1&if s(C,P)>s(C,N_{1} )\\&and s(C,P)>s(C,N_{2} )\\0&otherwise",where \(s(,"f\left(C,P,N_{1},N_{2}\right)=E_{(i,j)\simD}\left[\prod_{k=1}^{2}\sigma\left( s\left(C,\mathcal{P",
naacl_2024_short_38,2,"Mean Similarity=\frac{1}{n}\sum_{i=1}^{5}s(c,p_{i})","where \(p_{i}\in P\) denotes the generated prompts, \(s(","s_{mean}(c)=\frac{1}{5}\sum_{i=1}^{5}sim\left(image,prompt_i\right)",Mean similarity score across 5 generated captions for a given compound noun in the retrieval process.
naacl_2024_short_39,1,"\underset{\theta_{P}}{\max}\underset{i}{\sum}\log p_{\theta,\theta_{P}}(y_{i}|[P;x_{i}])",,"tags. The original equation uses\max,\sum, and subscripts. I need to make sure the LaTeX is correctly formatted. Also, the description needs to succinctly explain the variables. So something like ""N is the number of training examples, Î represents the model parameters, x_i is the input text for the i-th example, and y_i is the corresponding output sequence."" Wait, the user mentioned ""one sentence variable description"". So all variables in one sentence. Let me structure that. The existing equation uses N, Î, x_i, y_i. So the description should define all of them concisely. Maybe: ""N denotes the number of training examples, Î represents the model parameters, x_i is the input text for the i-th training example, and y_i is the corresponding target output sequence."" Yes, that covers all variables in one sentence. The LaTeX code is already provided in the context, so I just need to present it properly. Make sure to use proper LaTeX syntax with\max, subscripts, etc. Also, check if there's any prior equations, but since this is Equation 1, there are none. Alright, that should do it. </think>","N denotes the number of training examples, Î represents the model parameters, x_i is the input text for the i-th training example, and y_i is the corresponding target output sequence."
naacl_2024_short_39,2,\frac{(Zero-shot\correct)\cap(PoT\incorrect)}{Zero-shot\correct},"where _Zero-shot correct_ is the case of correct responses in a zero-shot setting, and _PoT incorrect_ is the case of incorrect answers after prompt transfer in the target task",F_{prompt}=\frac{1}{T}\sum_{t=1}^{T}\left(Perf_{pre}^{(t)}-Perf_{post}^{(t)}\right),"The proposed metric calculates the average performance drop across tasks $t$ before and after prompt tuning, where $T$ is the total number of tasks."
naacl_2024_short_43,1,"I_{c,i}\sim f(c_{\ell})",,"I_i=f(c_{\ell}, z_i)","The $i$-th image generated by a multilingual T2I model $f$ for a concept $c$ in language $\ell$, where $z_i$ represents the $i$-th latent code input to the model."
naacl_2024_short_43,2,"X_{c}=\frac{1}{n^{2}}\sum_{i=0}^{n}\sum_{j=0}^{n}SIM_{F}(I_{c_{\ell}, i},I_{c_{\ell_{s}},j})","where we sample \(n\) images per-concept per-language (we use 9), and \(\mathrm{SIM}_{F}(\cdot,\cdot)\) measures the cosine similarity in feature space by image feature extractor \(F\)","X_{c}(f, c_{\ell}, c_{\ell_{s}})",Cross-consistency score measuring the correctness of images generated for concept $c$ in language $\ell$ compared to the source language $\ell_{s}$.
naacl_2024_short_43,3,"\Delta X_{c}(c,\ell)=X_{c}(f,c^{\prime}_{\ell},c_{\ell_{s}})-X_{c}(f,c_{\ell}, c_{\ell_{s}})",,"\Delta X_{c}=X_{c}(f, c^{\prime}_{\ell}, c_{\ell_{s}})-X_{c}(f, c_{\ell}, c_{\ell_{s}})",the difference in cross-consistency score for concept $c$ before and after applying the translation correction $c_{\ell} \rightarrow c^{\prime}_{\ell}$
naacl_2024_short_43,4,"\DeltaSEM=SIM_{Ft}(c_{\ell_{s}},c^{\prime}_{\ell})- SIM_{Ft}(c_{\ell_{s}},c_{\ell})",,"\DeltaSEM(c_{\ell_{s}},c_{\ell},c^{\prime}_{\ell})=SIM_{F_{t}}(c_{\ell_{s}},c^{\prime}_{\ell})-SIM_{F_{t}}(c_{\ell_{s}},c_{\ell})",where the improvement in semantic similarity is calculated as the difference in cosine similarity between the source concept and the corrected translation versus the original translation using a text feature extractor $F_{t}$.
naacl_2024_short_45,2,L_{dialect-classifier}=-\sum_{i}\log\ell[y_{i}^{*}],where \(y_{i}^{*}\) is the correct label for instance \(i\),L=-\sum_{i=1}^{N}\log\ell_{i},"The loss function for the intrinsic approach, defined as the negative log probability summed over all training instances."
naacl_2024_short_45,3,s_{j}=softmax(affine(ReLU(u_{s})-ReLU(u_{j}))) || loss=L_{{{dialect-classifier}}}+\alpha_{1}L_{{{LII}}},,\ell_{\neg x_{i}}=softmax(affine(ReLU(u_{s}-u_{j}))),Estimates the label distribution without feature $x_{i}$ by transforming the difference between the original and masked representations.
naacl_2024_short_45,4,r_{j}=[\ell]_{y_{i}^{*}}-[s_{j}]_{y_{i}^{*}},"where higher \(r_{j}\) signifies more relevant features to the prediction, serving as better explanations",r_{i}=\ell[y^{*}]-s_{j}[y^{*}],where $r_{i}$ denotes the relevance score of feature $x_{i}$ based on the probability difference of the correct label $y^{*}$ between the full input and the input excluding $x_{i}$.
naacl_2024_short_45,5,E^{\prime}=\{e\in E\midisCorrect(e)\landisUnique(e)\},,E^{\prime}=\{e_{i}\in E\midprediction is correct and  e_{i} is unique to a specific language variety\},Filtered set of sentence-level explanations that are both correctly predicted and unique to a specific language variety
naacl_2024_short_45,6,"TF-IDF(t,d,D)=TF(t,d)\timesIDF(t,D)",,"TF-IDF(t,d,D)=TF(t,d)\timesIDF(t,D)","where TF(t, d) measures the frequency of term t in document d, and IDF(t, D) measures the inverse document frequency of t across the corpus D, emphasizing terms that are rare globally but frequent in specific documents."
naacl_2024_short_45,7,"F=\{TF-IDF(t,d,E^{\prime})\mid t\in d,d\in E^{\prime}\}",,F=TF-IDF(E^{\prime}),where $F$ represents the final set of global features extracted using TF-IDF from the filtered explanations $E^{\prime}$
naacl_2024_short_46,1,"[x^{i},Q^{k}]=BERT([x^{i},Q^{k}])","where \(\mathbf{x}^{i}\) and \(\mathbf{Q}^{k}\) are the representations of \(x^{i}\) and \(\mathcal{Q}^{k}\), respectively",h^{i}=BERT(Q^{k}\oplus x^{i}),Contextual representations obtained by combining accumulated prompts with input text using a frozen BERT model.
naacl_2024_short_46,2,"Z^{i}_{t}=Linear(FFN([x^{i}_{m},x^{i}_{n}]))","where \(\overline{\mathbf{x}}^{i}_{t}=\text{FFN}([\mathbf{x}^{i}_{m},\mathbf{x}^{i}_{ n}])\) is the span representation, \(m\) and \(n\) denote the start and end index of the span, respectively",h^{i}=FFN([x^{i}_{start};x^{i}_{end}])\quadand\quadz^{i}=W_{type}h^{i}+b_{type},"where $\mathbf{h}^{i}$ is the hidden representation of the span $\overline{x}^{i}_{t}$, and $\mathbf{z}^{i}$ contains the logits for predicting its event type using learnable parameters $\mathbf{W}_{\text{type}}$ and $\mathbf{b}_{\text{type}}$."
naacl_2024_short_46,3,"L_{new}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\in D^{k}_{train}}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})",,L_{cls}=-\log\frac{\exp(Z^{i}_{t}+Z_{q})}{\sum_{j=1}^{|C^{k}|}\exp(Z^{j}_{t}+Z_{q})},"where $Z_{q}$ is the prompt probability distribution obtained via inner product between $\text{FFN}(\mathbf{Q}^{k})$ and $\overline{\mathbf{x}}^{i}_{t}$, and is combined with the span logits $Z^{i}_{t}$ for classification loss"
naacl_2024_short_46,4,"L_{mem}=-\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\in M}CE(Z^{i}_{t}+Z_{q},y^{i}_{t})",,"L_{replay}=-\sum_{(\overline{x}^{j}_{t},y^{j}_{t})\inM}CE(Z^{j}_{t}+Z_{q},y^{j}_{t})",where $Z^{j}_{t}$ and $Z_{q}$ are computed using the current model parameters and the saved prompts from $\mathcal{M}$
naacl_2024_short_46,5,"L_{sim}=\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inD^ {k}_{train}}\sum_{e_{t}\inE^{k-1}}\max(0,g(\overline {x}^{i}_{t},e_{t})-m_{1})","where \(\mathcal{E}^{k-1}\) is the prototype set of previous \(k-1\) tasks, \(g(,)\) is the similarity function (cosine similarity) and \(m_{1}\) is the margin for \(\mathcal{L}_{\text{sim}}\)","L_{margin}=\sum_{c\inC^{k-1}}\max(0,\Delta-s(v^{k}_{i},p^{c}))","where $\mathbf{v}^{k}_{i}$ is the representation of a new sample from task $\mathcal{T}^{k}$, $\mathbf{p}^{c}$ is the prototype of a learned event type $c$, $s(\cdot,\cdot)$ is the cosine similarity function, and $\Delta$ is the margin hyperparameter"
naacl_2024_short_46,6,"L_{cal}=-\sum_{(\overline{x}_{t}^{i},\overline{x}_{t}^{i})\inM}\log\frac{\exp g(\overline{x}_{t}^{i},e_{t}) }{\sum_{j=1}^{|e^{k-1}|}\exp g(\overline{x}_{t}^{i}, e_{j})}",where \(\mathbf{e}_{t}\) is the prototype of \(y_{t}^{i}\),"L_{cal}=\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inM}\|\overline{x}^{i}_{t}-e_{y^{i}_{t}}\|^{2}",where $\mathbf{e}_{y^{i}_{t}}$ is the prototype of the class $y^{i}_{t}$ in the prototype set $\mathcal{E}^{k-1}$
naacl_2024_short_46,7,L_{total}=L_{new}+\lambda_{1}L_{sim}+\lambda_{2}(L_{mem}+L_{cal}),where \(\lambda_{1}\) and \(\lambda_{2}\) are loss weights,L=L_{new}+\lambda_{1}L_{mem}+\lambda_{2}L_{sim}+\lambda_{3}L_{cal},"where $\lambda_{1}$, $\lambda_{2}$, and $\lambda_{3}$ are trade-off hyperparameters balancing the contributions of the individual loss terms"
naacl_2024_short_46,8,"e_{j}=\frac{1}{|M_{e_{j}}|}\sum_{(\overline{x}_{t}^{i},\overline{x}_{t}^{i})\inM_{e_{j}}}\overline{x}_{t}^{i}","where \(\mathcal{M}_{e_{j}}=\{(\overline{x}_{t}^{i},y_{t}^{i})|(\overline{x}_{t}^{i}, y_{t}^{i})\in\mathcal{M},y_{t}^{i}=e_{j}\}\)","e_{j}=\frac{1}{|M_{e_{j}}|}\sum_{(\overline{x}^{i}_{t},y^{i}_{t})\inM_{e_{j}}}\overline{x}^{i}_{t}",where $\mathcal{M}_{e_{j}}$ is the subset of memory samples labeled as event type $e_{j}$
naacl_2024_short_5,1,"L^{unsup}_{simce}=-\log\frac{e^{sim(h_{i},h_{i}^{\prime})/\tau}}{\sum_{j=1}^{N}e^{ sim(h_{i},h_{j}^{\prime})/\tau}} || L^{unsup}_{skice}=-\log\frac{e^{sim(h_{i},h_{i}^{ski})/\tau}}{\sum_{j=1}^{N}e^{sim(h_{i},h_{j}^{ski})/\tau}}",,"L_{unsup}=L_{contrastive}(h,h^{\prime},h^{ski})","The unsupervised loss function for SKICSE, formulated as a contrastive loss between the original, dropout-variant, and SKI-generated embeddings."
naacl_2024_short_5,2,L^{unsup}=(1-\lambda)L^{unsup}_{ simce}+\lambdaL^{unsup}_{skice},where the weight \(\lambda\) is a balanced hyperparameter and reflects the importance of SKI,L^{unsup}_{SKICSE}=\lambda\cdotL^{unsup}_{simce}+(1-\lambda)\cdotL^{unsup}_{skice},The final objective function of unsupervised SKICSE combines the SimCE and SKICE losses using a weighted sum with a hyperparameter $\lambda$.
naacl_2024_short_5,3,"L^{sup}_{simce}=-\log\frac{e^{sim(h_{i},h_{i}^{+})/\tau}}{\sum_{j=1}^{N}(e^{ sim(h_{i},h_{j}^{+})/\tau}+e^{sim(h_{i},h_{j}^{-})/\tau})} || L^{sup}_{skice_{1}}=-\log\frac{e^{sim(h_{i}^{ski},h_{i}^{+})/\tau}}{\sum_{j=1}^{N} (e^{sim(h_{i}^{ski},h_{j}^{+})/\tau}+e^{sim(h_{i}^{ski},h_{j}^{-})/\tau})} || L^{sup}_{skice_{2}}=-\log\frac{e^{sim(h_{i},h_{i}^{ski})/\tau}}{\sum_{j=1}^{N}(e ^{sim(h_{i},h_{j}^{+})/\tau}+e^{sim (h_{i},h_{j}^{-})/\tau})}",,"L^{sup}_{nli}=-\log\frac{e^{sim(h_{i},h_{i}^{+})/\tau}}{e^{sim(h_{i},h_{i}^{+})/\tau}+e^{sim(h_{i},h_{i}^{-})/\tau}}","where $\mathcal{L}^{\text{sup}}_{\text{nli}}$ represents the NLI loss for the supervised setting, contrasting entailment and contradiction examples"
naacl_2024_short_5,4,L^{sup}=(1-\lambda_{1}-\lambda_{2})L^{sup}_{simce}+\lambda_{1}L^{sup}_{skice_{1}}+\lambda_ {2}L^{sup}_{skice_{2}},,L^{sup}=(1-\lambda)L^{sup}_{simce}+\lambda\left(L^{sup}_{skice_{1}}+L^{sup}_{skice_{2}}\right),where the weight $\lambda$ balances the contributions of the SimCE and SKICE components in the supervised setting.
naacl_2024_short_51,1,"R_{d}(w)=\frac{tf(w,d)}{\sum_{d^{\prime}}tf(w,d ^{\prime})}\cdot\log\frac{N}{df(w)}","where \(\operatorname{tf}(w,d)\) is the number of times the word \(w\) occurs in the day \(d\), \(\operatorname{df}(w)\) is the number of days in which the word \(w\) occurs, and \(N\) is the total number of days in the dataset",R_{d}(t)=TF_{d}(t)\timesIDF(t),"Relevance $R_{d}$ of a token $t$ in articles from day $d$, calculated using Term Frequency-Inverse Document Frequency (TF-IDF)."
naacl_2024_short_51,2,"sim(x,x^{\prime})=\frac{\sum_{w\in x^{\prime}x^{\prime}}R_{d}(w)}{max(\hat{R}_{d}(x),\hat{R}_{d}(x^{\prime}))}",,\hat{R}_{d}(x)=\sum_{w\in x} R_{d}(w),"Relevance score of an article $x$ occurring on day $d$, defined as the sum of TF-IDF scores of the words in its title"
naacl_2024_short_52,1,"& L_{discrete}(y_{i}=t;y_{<i},x)=-\log p(y_{i}=t\midy_{<i},x)\\&\quad=-\langleE(t),h\rangle+\log\sum_{t^{\prime}\in V }\exp\langleE(t^{\prime}),h\rangle","where \(t\) is a token index, \(V\) is the vocabulary, \(\mathbf{E}:V\rightarrow\mathbb{R}^{d}\) is an embedding lookup, and \(\mathbf{h}\) is a transformer hidden state calculated in terms of \(\mathbf{x}\) and the output prefix \(\mathbf{y}_{<i}\)","L=-\sum_{t=1}^{n}\log p(y_t\midy_{<t},x)",Negative log-likelihood of target tokens given input and previous tokens
naacl_2024_short_52,2,"L_{cos}(y_{i}=t;y_{<i},x)=1-\cos(E(t),h)",,"& L_{continuous}(y_{i};y_{<i},x)=-\langleE(y_{i}),h\rangle+\log\int\exp\langleE(y^{\prime}),h\rangle dy^{\prime}","where $\mathbf{y}_{i}$ is a continuous vector representing the $i$-th output token, and the integral replaces the discrete sum over vocabulary with a continuous similarity measure."
naacl_2024_short_52,3,"E(y_{i})=u_{i}/\|u_{i}\|;\quadu_{i}\simNormal( 0,I_{d})",,"E(y_{i})=\frac{z}{\|z\|},\quadz\simN(0,I_{d})",Random embeddings are generated by normalizing standard normal vectors to lie on the unit sphere.
naacl_2024_short_52,4,E(y_{i})=r_{i}/\sqrt{d};\quadr_{i}\simRademacher(d),,"E(y_{i})=u_{i}/\sqrt{d};\quad u_{i,j}\simRademacher","Each embedding vector is sampled from a scaled Rademacher distribution, ensuring entries are Â±1 scaled by the dimensionality to maintain unit norm."
naacl_2024_short_52,5,E_{cmb}(y_{i})=\frac{\alphaE_{pre}(y_{i})+(1-\alpha)E_{rand}(y_{i})}{\|\alphaE_{pre}(y_{i})+(1-\alpha)\bm {E}_{rand}(y_{i})\|},,E_{combined}(t)=\alpha\cdotE_{pre-trained}(t)+(1-\alpha)\cdotE_{random}(t),"where $\alpha$ controls the interpolation between pre-trained and random embeddings, enabling a hybrid representation that balances learned semantic structure with random diversity for improved performance on rare tokens."
naacl_2024_short_53,1,"S(y,\bar{y};x)>S(y,\hat{y};x)",where \(\mathbf{y}\) is the reference sequence,\delta_{1:L}^*=\arg\max_{\delta_{1:L}}S\left(f(e_{1:L}+\delta_{1:L};\phi_{d})\right),Equation 1 defines the optimal perturbation $\mathbf{\delta}_{1:L}^*$ that maximizes the score $\mathcal{S}$ of the decoder output sequence $\bar{\mathbf{y}}$ obtained from the perturbed encoder outputs.
naacl_2024_short_53,2,\delta_{i}=\alpha|e_{i}|\bigg{|}\frac{\partial f(e_{1:L};\phi_{nap})}{\partiale_{i}}\bigg{|}^{-1}\frac{\partial f(e_{1:L};\phi_{nap})}{\partiale_{i}},"where \(i=1,\ldots,L\)",\delta_{1:L}=\alpha\cdot\nabla_{e_{1:L}} f(e_{1:L};\phi_{nap}),where $\alpha$ is a scaling factor controlling the magnitude of the perturbation applied to the encoder outputs
naacl_2024_short_56,1,X_{all}=L\[SEP]\X_{ori}\[SEP]\P_{C}\[SEP]\P_{L},,"P_L=""relation is not  S_{i1},\ldots, S_{ij},\ldots or  N_{random}""",Label prompt $P_L$ containing similar relations $S_{ij}$ from set $R_i$ and a randomly selected non-similar relation $N_{\text{random}}$.
naacl_2024_short_56,2,L_{MLM}=-{\sum}_{n=1}^{M}\log P(x_{n}),where \(M\) is the number of masked tokens and \(P(x_{n})\) is the predicted probability of token \(x_{n}\) over the vocabulary size,L_{prompt\_MLM}=-\frac{1}{M}\sum_{m=1}^{M}\log P(x_m |x_{\setminus m};\theta),"The negative log-likelihood loss for masked tokens in the context and label prompts during pre-training, where $M$ is the number of masked positions, $x_m$ are masked tokens, and $\theta$ represents model parameters."
naacl_2024_short_56,3,"L_{s}=\frac{1}{N}\sum_{p=1}^{N}-\frac{1}{N_{y_{p}}-1}\sum_{q=1}^{N_ {y_{p}}}\log\frac{e^{sim(h_{p},h_{q}^{+})/\tau}}{\sum_{k=1}^{N}1_{p\neq k}e^{sim(h_{p},h_{k})/\tau}}",where \(N\) is the total number of examples in the batch and \(N_{y_{p}}\) is the number of positive pairs in the batch,L_{SCL}=-\sum_{i=1}^{K}\log\frac{\exp(h_{p}\cdot h_{p}^{+}/\tau)}{\exp(h_{p}\cdot h_{p}^{+}/\tau)+\sum_{j=1}^{N}\exp(h_{p}\cdot h_{p}^{-}/\tau)},"where $K$ is the number of positive samples, $N$ is the number of negative samples, and $\tau$ is a temperature parameter that controls the concentration level of the distribution."
naacl_2024_short_56,4,L_{final}=\alphaL_{s}+(1-\alpha)L_{MLM},,L_{total}=\alphaL_{MLM}+(1-\alpha)L_{s},where $\alpha$ is a hyperparameter that balances the contribution of the prompt MLM loss $\mathcal{L}_{MLM}$ and the relation contrastive discrimination loss $\mathcal{L}_{s}$ in the total loss function $\mathcal{L}_{total}$.
naacl_2024_short_62,1,"P_{ATTN}(n_{i}|Q,A)=softmax(\sum_{t=1}^{T}\alpha_{t} || v_{t} || _{2})",where \(T\) represents the total token count in \(n_{i}\),Attention(d_i)=Softmax(\alpha_{t}\cdot\|v_{t}\|),Equation 1 computes the attention score for each document $d_i$ by applying the Softmax operator to the product of the self-attention score $\alpha_t$ and the norm of the value vector $\|\mathbf{v}_t\|$.
naacl_2024_short_62,2,"P_{RETR}(n_{i}|Q)=\frac{exp(s(n_{i},Q)/\theta)}{\sum_{k=1}^{K}exp(s(n_{k},Q)/\theta)}","where \(s\) denotes the dot-product between the representation vectors of the input question \(Q\) and document candidate \(n_{i}\), and \(\theta\) is the temperature hyper-parameter","P_{RETR}(n_{i}|Q)=softmax(s(Q,n_{i}))",the probability distribution of the retriever over the question-relevant documents
naacl_2024_short_66,1,"y_{t}\sim p_{\theta}(y_{t}\midc,x,y_{ct}) || \propto\explogit_{\theta}(y_{t}\midc,x,y _{ct})",,"y\sim p_{\theta}(y\midx,c)","Equation 1 defines the response generation process, where the model samples the output $\mathbf{y}$ from the conditional probability distribution given the query $\mathbf{x}$ and context $\mathbf{c}$."
naacl_2024_short_66,2,"y_{t}\sim\tilde{p}_{\theta}(y_{t}\midc,x,y_{ct}) || \propto p_{\theta}(y_{t}\midc,x,y_{ct})\bigg{(}\frac{p_{\theta}(y_{t}\midc,x,y_{ct})}{p_{\theta}(y_{t}\mid\bm {x},y_{ct})}\bigg{)}^{\alpha}",,"\log p_{\theta}(y_{t}\midc,x,y_{ct})=\log p_{\theta}(y_{t}\midx,y_{ct})+\log\frac{p_{\theta}(c\mid y_{t},x,y_{ct})}{p_{\theta}(c\midx,y_{ct})}","This equation decomposes the conditional probability of the token $y_t$ given the context $\mathbf{c}$, query $\mathbf{x}$, and previous tokens $\mathbf{y}_{ct}$ into a prior term and a context adjustment term via PMI."
naacl_2024_short_66,3,"y_{t}\simsoftmax[(1+\alpha)\,logit_{\theta}(y_{t}\midc,x,y_{ct}) || \qquad\qquad-\alpha\,logit_{\theta}(y_{t}\midx,y _{ct})]",,"y_{t}\sim\tilde{p}_{\theta}(y_{t}\midc,x,y_{ct})=\frac{p_{\theta}(y_{t}\midc,x,y_{ct})^{1+\alpha}}{\sum_{y'_{t}} p_{\theta}(y'_{t}\midc,x,y_{ct})^{1+\alpha}\bigg(\frac{p_{\theta}(y'_{t}\midx,y_{ct})}{p_{\theta}(y'_{t}\midc,x,y_{ct})}\bigg)^{\alpha} }}","This equation represents the normalized context-aware decoding distribution, where the model's prior knowledge is contrastively adjusted by the context-dependent likelihood raised to the power of $1+\alpha$, ensuring outputs favored by the context are prioritized."
naacl_2024_short_67,1,"h_{0}^{x},h_{1}^{x},...,h_{n}^{x}=\textbf{BERT}(w_{0}^{x},w_{1}^{x},...,w_{n}^{x}) || x^{c}=h_{0}^{x},x^{h}=h_{[E_{h}]}^{x},x^{t}=h_{[E_{t}]}^{x}",,"h_{h},h_{t},h_{c}=Encoder(x)_{[E_h]},Encoder(x)_{[E_t]},Encoder(x)_{[CLS]}","Equation 1 defines the extraction of head entity, tail entity, and contextual representations from the encoder output using special token indices."
naacl_2024_short_67,2,x^{vec}=x^{c}\oplus x^{h}\oplus x^{t},where \(d\) is the hidden dimension of the encoder and \(\oplus\) denotes the concatenation operator,tags and the description in <description> tags. No extra text. Just the two lines. </think>,"tags. No extra text. Just the two lines.
</think>

<latex>x^{vec} = \left[ x^{h} \oplus x^{t} \oplus x^{c} \right]</latex>"
naacl_2024_short_67,3,"h_{0}^{d},h_{1}^{d},...,h_{n}^{d}=\textbf{BERT}(w_{0}^{d},w_{1}^{d},...,w_{n}^ {d}) || d^{c}=h_{0}^{d} || d^{h}=\textit{WeightPooling}_{1}(h_{1}^{d},...,h_{n}^{d}) || d^{t}=\textit{WeightPooling}_{2}(h_{1}^{d},...,h_{n}^{d}) || d^{vec}=d^{c}\oplus d^{h}\oplus d^{t}",,d^{vec}=d^{c}\oplus d^{h}\oplus d^{t},"where $d^{c}$, $d^{h}$, and $d^{t}$ represent the contextual, head entity, and tail entity representations of the relation description, respectively"
naacl_2024_short_67,4,"H=(h_{1}^{d},...,h_{n}^{d}) || A=\textit{softmax}(HW+b) || d^{*}=AH",,"d^{h}=\sum_{i=1}^{n}\alpha_{i} h_{i}^{d},\quad\alpha_{i}=\textit{Softmax}(w_{1}^{T} h_{i}^{d})","where $d^{h}$ is the virtual head entity representation obtained via attention-weighted sum of hidden states, and $\alpha_{i}$ represents the attention weights computed using a learnable parameter vector $w_{1}$"
naacl_2024_short_67,5,"L_{i}=-\log\frac{e^{sim(x_{i}^{vec},d_{i}^{vec})/\tau}}{\sum_ {j=1}^{N}e^{sim(x_{i}^{vec},d_{j}^{vec})/\tau}}",where \(\tau\) is a temperature hyperparameter and \(\text{sim}(\cdot)\) is the cosine similarity,"L_{i}=-\log\frac{\exp(sim(x_{i}^{vec},d_{i}^{vec})/\tau)}{\sum_{j=1}^{N}\exp(sim(x_{i}^{vec},d_{j}^{vec})/\tau)}","The contrastive loss function (infoNCE) that minimizes the distance between matching instance and relation description representations while maximizing the distance from non-matching samples, using cosine similarity scaled by temperature parameter Ï."
naacl_2024_short_67,6,O_{i}=\textit{Pooling}(BERT(\langle x\oplus d_{j}\rangle)) || \hat{y}=\textit{MLP}(O_{0}\oplus O_{1}\oplus...O_{k}) || L_{c}=-log(\frac{e^{\hat{y}_{+}}}{\sum_{i=1}^{k}e^{\hat{y}_{i}}}),,"L_{cls}=-\log\frac{e^{sim(x^{vec}, d_{+}^{vec})/\tau}}{\sum_{d\in D} e^{sim(x^{vec}, d^{vec})/\tau}}",The classification loss function aims to select the correct relation description $d_{+}$ from a set $D$ of $k$ candidates by maximizing its similarity to the input instance $x$ relative to the others.
naacl_2024_short_69,1,ATE=E[Y^{a=1}-Y^{a=0}],,ATE=E\left[Y^{a=1}-Y^{a=0}\right],The average treatment effect (ATE) quantifies the expected difference in counterfactual outcomes between prescribing antibiotics ($Y^{a=1}$) and not prescribing antibiotics ($Y^{a=0}$).
naacl_2024_short_69,2,A=a\\Rightarrow\Y^{a}=Y,,Y=AY^{a=1}+(1-A)Y^{a=0},"This equation formalizes the consistency assumption, linking observed outcomes to potential counterfactual outcomes based on the treatment received."
naacl_2024_short_69,3,"Y^{a}\perp A\mid C\quad\forall a\in\{0,1\}",,Y^{a}\perp\!\!\!\perp A\mid C,"Conditional exchangeability ensures that, given the confounders $C$, the counterfactual outcome $Y^{a}$ is independent of the observed treatment assignment $A$."
naacl_2024_short_69,4,"E[Y^{a}]=\sum_{C}E[Y^{a}\mid C]P(C) || \overset{\eqref{eq:constraint}}{=}\sum_{C}E[Y^{a}\mid A=a,C]P(C)",,"E[Y^{a}]=E_{C}[E[Y\mid A=a, C]]","This equation expresses the counterfactual expectation $\mathbb{E}[Y^{a}]$ as a marginalization over the confounders $C$, leveraging the observed data under the identification assumptions."
naacl_2024_short_69,5,"\overset{\eqref{eq:constraint}}{=}\sum_{C}E[Y\mid A=a,C]P(C)",,"\overset{exchangeability}{=}\sum_{C}E[Y\mid A=a,C]P(C)",Equation 5 applies the conditional exchangeability assumption to replace the counterfactual outcome expectation with the observed outcome expectation conditioned on treatment and confounders.
naacl_2024_short_69,6,E[Y^{a}]=\frac{1}{N}\sum_{i\in[N]}Y_{i}\frac{\mathds{1}(A_{i}=a)}{P(A_{i}=a\mid T)},,E[Y^{a}]=\frac{1}{N}\sum_{i=1}^{N}\frac{I(A_{i}=a)Y_{i}}{e^{a}(T_{i})},"Equation 6 expresses the counterfactual expectation using inverse propensity weighting, where the expectation is computed over the observed data weighted by the inverse of the propensity score $e^{a}(T_i)$, which estimates the probability of receiving treatment $a$ given the text $T_i$."
naacl_2024_short_7,1,"\underset{\theta}{min}\,E_{S^{i}}[\frac{1}{k+1}\sum_{i=0}^{k}l( M_{\theta}(S^{i}),f(x_{i+1}))]",,"L=E_{x_{1},\ldots,x_{i+1}\simD_{x},f\simF}\left[l\left(M_{\theta}(S^{i}),f(x_{i+1})\right)\right]",The loss function $\mathcal{L}$ is defined as the expectation of the squared error between the model's prediction and the true function value over the input distribution and function class.
naacl_2024_short_7,2,"f(x)=\varphi(\langle x,w\rangle)",,f(x)=\frac{1}{\sqrt{d}}h_{p}(w^{\top}x),"where $h_p$ is the $p$-th normalized probabilist's Hermite polynomial, $w\in\mathbb{R}^{d}$ is a weight vector uniformly distributed on the unit sphere, and $x\in\mathbb{R}^{d}$ is the input."
naacl_2024_short_7,3,\varphi_{linear}(t)=t || \varphi_{quadratic}(t)=\frac{1}{\sqrt{2}}(t+\frac{1}{\sqrt{2}}(t^{2}-1)) || \varphi_{cubic}(t)=\frac{1}{\sqrt{3}}(t+\frac{1}{\sqrt{ 2}}(t^{2}-1)+\frac{1}{\sqrt{6}}(t^{3}-3t)),,"\varphi_{linear}(t)=t,\quad\varphi_{quadratic}(t)=\frac{1}{\sqrt{2}}(t^{2}-1),\quad\varphi_{cubic}(t)=\frac{1}{\sqrt{6}}(t^{3}-3t)","Equation 3 defines the three function classes used in the study, corresponding to linear, quadratic, and cubic normalized probabilist's Hermite polynomials, which are orthogonal and ensure uncorrelated function values across tasks."
naacl_2024_short_7,4,f\simF_{1}&1\leq t<\frac{T}{3}\\F_{2}&\frac{T}{3}\leq t<\frac{2T}{3}\\F_{3}&\frac{2T}{3}\leq t<T,,"T_{k}=\left\{ t\in [1, T]\mid\frac{(k-1)T}{K} < t\leq\frac{kT}{K}\right\},\quad k=1, 2,\ldots, K","Equation 4 defines the sequential curriculum learning schedule, where training steps are divided into K partitions and each partition is assigned to train on a specific function class in order of increasing difficulty."
naacl_2024_short_7,5,f\simF_{1}&1\leq t<\frac{T}{3}\\\sum_{s=1}^{2}1(\xi=s)F_{s}&\frac{T}{3}\leq t<\frac{2T}{3}\\\sum_{s=1}^{3}1(\zeta=s)F_{s}&\frac{2T}{3}\leq t<T,,f\simF_{1}&1\leq t<\frac{T}{3}\\F_{\xi}&\frac{T}{3}\leq t<\frac{2T}{3}\\F_{\zeta}&\frac{2T}{3}\leq t<T,Defines the mixed curriculum learning strategy where task selection in later partitions is randomized over previous function classes using uniform distributions $\xi$ and $\zeta$.
naacl_2024_short_7,6,"f\sim\sum_{s=1}^{3}1(\zeta=s)F_{s},\quad 1\leq t<T",,f\sim\sum_{s=1}^{K}\frac{1}{K}F_{s},"At each training step, a function class is randomly selected with equal probability from the set of all $K$ function classes."
naacl_2024_short_8,1,"s_{m}(q,d)=T_{\texttt{[CLS]}}W+b","where \(T_{\texttt{[CLS]}}\in\mathbf{R}^{D}\) is the [CLS] representation on the final layer, and \(W\in\mathbf{R}^{D\times 1}\) and \(b\in\mathbf{R}\) are the weight and bias for classification","s_{q,d}=W^\toph_{[CLS]}+b",Relevance score computed using the [CLS] token's final layer representation through a learned linear layer with weight matrix $\mathbf{W}$ and bias $b$.
naacl_2024_short_8,2,"s_{m}(q,d)=\frac{1}{n}\sum_{i}^{n}(T_{tok_{i}}W+b)","where \(T_{tok_{i}}\) is the final-layer representation of the \(i\)-th token, and \(n\) is the total number of tokens in the input sequence","s_{m}(q,d)=\frac{1}{N}\sum_{i=1}^{N}T_{i}W+b","where $T_{i}\in\mathbf{R}^{D}$ is the representation of the $i$-th token in the concatenated sequence, and $N$ is the total number of tokens."
naacl_2024_short_8,4,"s_{l}(q,d)=\sum_{q_{i}}\max_{d_{j}}(v_{q_{i}}^{T}v_{d_{j}})",,"s_{l}(q,d)=\sum_{i}^{n_q}\max_{j}^{n_d}\langle v_{q_{i}}, v_{d_{j}}\rangle","where $v_{q_i}$ and $v_{d_j}$ are the projected representations of the $i$-th query token and $j$-th document token, respectively, and $\langle \cdot, \cdot \rangle$ denotes the inner product operation"
naacl_2024_short_8,5,"L=lce(s_{m}(q,d^{+}),s_{m}(q,d_{1}^{-}),...,s_{m}(q,d_{n}^ {-})) || +lce(s_{l}(q,d^{+}),s_{l}(q,d_{1}^{-}),...,s_{l}(q,d_{n}^ {-}))",,"L_{LCE}=-\log\frac{\exp(s_{m}(q,d^+)/\tau)}{\exp(s_{m}(q,d^+)/\tau)+\sum_{d^-}\exp(s_{m}(q,d^-)/\tau)}-\log\frac{\exp(s_{l}(q,d^+)/\tau)}{\exp(s_{l}(q,d^+)/\tau)+\sum_{d^-}\exp(s_{l}(q,d^-)/\tau)}","where $d^+$ is the positive document, $d^-$ are the negative documents, and $\tau$ is the temperature parameter controlling the sharpness of the similarity distribution."
naacl_2024_short_9,1,"L_{ir}(q,p_{i})=-\log(\frac{e^{q\cdot p_{t}}}{\sum_{i=1}^{N}e^{q\cdot p_{ i}}})",,L=-\log\left(\frac{\exp(q\cdot p_t)}{\sum_{i=1}^N\exp(q\cdot p_i)}\right ),Cross-entropy loss for maximizing the similarity between query embedding $q$ and the gold passage embedding $p_t$ relative to all passage embeddings $p_i$ in the batch.
naacl_2024_short_9,2,"L_{c}(q_{s},q_{t})=-\log(\frac{e^{q_{s}\cdot q_{t}}}{\sum_{j=1}^{N}e^{q_ {s}\cdot q_{j}}})",,"L_{c}(q_{s},q_{t},q_{j})=-\log(\frac{e^{q_{s}\cdot q_{t}}}{\sum_{j=1}^{N}e^{q_{s}\cdot q_{j}}})","The contrastive loss aligns English queries with their code-mixed counterparts within a batch, facilitating language representation alignment without compromising relevance matching."
naacl_2024_short_9,3,L=L_{ir}+wL_{c},where \(w\) is a hyperparameter for weighting the contrastive loss,"L=L_{ir}(q, p_i)+\lambda L_{c}(q_s, q_t)","The overall training objective combines the information retrieval loss $L_{ir}$ and the contrastive loss $L_{c}$, weighted by a factor $\lambda$."
neurips_2024_oral_10,1,"q(x_{1:T}|x_{0})\coloneqq\prod_{t=1}^{T}q(x_{t}|x_{t-1}) || q(x_{t}|x_{t-1})\coloneqqN(x_{t};\sqrt{1-\beta_{t}}x _{t-1},\beta_{t}I)",,"x_t=\sqrt{\bar{\alpha}_t}\, x_0+\sqrt{1-\bar{\alpha}_t}\,\epsilon_t","Equation modeling the forward diffusion process where noisy features $ x_t $ at step $ t $ are generated from clean features $ x_0 $ and Gaussian noise $ \epsilon_t $, parameterized by the cumulative noise schedule $ \bar{\alpha}_t $."
neurips_2024_oral_10,2,"p_{\theta}(x_{0:T})\coloneqq p(x_{T})\prod_{t=1}^{T}p_{\theta}(x_{t-1}|x_{t}) || p_{\theta}(x_{t-1}|x_{t})\coloneqqN(x_{t-1};\mu_{\theta}(x_{t },t),\Sigma_{\theta}(x_{t},t))",,p_{\theta}(x_{0:T})\coloneqq p_{\theta}(x_{T})\prod_{t=1}^{T}p_{\theta}(x_{t-1}|x_{t}),"The joint distribution over the denoising process, starting from the noisy features at time T and iteratively reconstructing the clean features through T steps."
neurips_2024_oral_10,3,"X_{t-1}=\frac{1}{\sqrt{a_{t}}}(X_{t}-\frac{1-a_{t}}{\sqrt{1-\tilde{a_{t}}}}D_{\theta}(X_{t},t))+\sigma_{t}z","where \(a_{t}=1-\beta_{t}\), \(D_{\theta}\) are the parameters of the prediction noise network",W_{merged}=W_{embed}+W_{denoise},The merged weight matrix combines the pre-trained embedding layer weights and denoising layer weights into a single branch for efficient inference.
neurips_2024_oral_10,4,Y&=WX+b\\\frac{1}{\sqrt{a_{t}}}X_{t}-X_{t-1}&=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}D_{\theta}X_{t}-\sigma_{t}z\\\frac{1}{\sqrt{a_{t}}}Y_{t}-Y_{t-1}&=\frac{1-a_{t} }{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}D_{\theta}Y_{t}-\sigma_{t}z,,W_{merged}=W_{embed}+W_{denoise}\cdotA,Merges the embedding and denoising layer weights into a single branch using a linear combination with matrix A
neurips_2024_oral_10,5,"Y_{t-1}=[W-C_{1}(t)WW_{D}]X_{t}+WC_{2}(t)C_{3}+b\\C_{1}(t)=\frac{1-a_{t}}{\sqrt{a_{t}}\sqrt{1-\tilde{a_{t}}}}\qquad C _{2}(t)=\frac{1-a_{t-1}^{-}}{1-\tilde{a_{t}}}\beta_{t}\qquad C_{3}=Z\sim N(0,I)","where \(W_{D}\) denotes the parameters of \(D_{\theta}(X_{t},t)\), \(X_{t}\) denotes the input of this linear layer, \(Y_{t}\) denotes the output of this linear layer, and \(Y_{t-1}\) denotes the result after denoising in one step of \(Y_{t}\)",Y_{t-1}=\frac{1}{\sqrt{a_t}} Y_t-\frac{1-a_t}{\sqrt{a_t}\sqrt{1-\tilde{a}_t}} D_\theta Y_t+\sigma_t z,"This equation represents the transformed denoising step expressed in terms of the fused parameters, enabling efficient inference without additional computational overhead."
neurips_2024_oral_10,6,\frac{1}{\sqrt{a_{t}}}Y_{t}-Y_{t-1}=C_{1}(t)D_{\theta}Y_{t}-\sigma_{t}z || \frac{1}{\sqrt{a_{t-1}}}Y_{t-1}-Y_{t-2}=C_{1}(t-1)D_{\theta}Y_{t-1}-\sigma_{t-1}z,,"Y_{t-2} &=[W-C_{1}(t-1)WW_{D}']X_{t-1}+WC_{2}(t-1)C_{3}'+b\\&=[W-C_{1}(t-1)WW_{D}']\left(\frac{1}{\sqrt{a_{t}}}(X_{t}-\frac{1-a_{t}}{\sqrt{1-\tilde{a}_{t}}}D_{\theta}(X_{t}, t))+\sigma_{t}z\right)+WC_{2}(t-1)C_{3}'+b","Extension of the one-step denoising equation to two-step denoising, where $W_{D}'$ represents updated denoising layer parameters and $Y_{t-2}$ is the result after two denoising steps."
neurips_2024_oral_10,7,Y_{t-2}=W^{\prime\prime}X_{t}+C^{\prime\prime}\\W^{\prime\prime}=\frac{1}{\sqrt{a_{t}-1}}\{\frac{W}{\sqrt{a_{t} }}-[C_{1}(t)+C_{1}(t-1)]WW_{D}+\sqrt{a_{t}}C_{1}(t-1)C_{1}(t)WW_{D}W_{D}\}\\C^{\prime\prime}=\frac{1}{\sqrt{a_{t}-1}}[WC_{2}(t)+\sqrt{a_{t}}WC_{ 2}(t-1)-\sqrt{a_{t}}C_{1}(t-1)C_{2}(t)WW_{D}]Z+b,,Y_{t-2}=\left[W-C_1(t) W W_D-C_1(t-1)\frac{1}{\sqrt{a_t}} W W_D\right] X_t+\left[ b-C_1(t) W W_D b-C_1(t-1)\frac{1-a_t}{\sqrt{a_t}\sqrt{1-\tilde{a}_t}} W W_D b\right],"This equation represents the result of two-step denoising by eliminating the intermediate variable $Y_{t-1}$ and substituting $Y_t$ in terms of the input $X_t$, enabling deeper denoising while maintaining parameter efficiency."
neurips_2024_oral_10,8,"Loss_{p}=\sum_{i=1}^{N}|\epsilon_{i}-D_{\theta_{i}}(X_{t_{i}},t_{i})|","where \(\epsilon\) denotes the sampled noise, \(N\) denotes the number of denoising layers, \(X_{t}\) denotes the noise sample, \(t\) denotes the diffusion step, and \(D_{\theta}(X_{t},t)\) denotes the noise predicted by the denoising layer","L_{p} &=E_{t,x_{0},\epsilon}\left[\left\|\epsilon-D_{\theta}(x_{t}, t)\right\|^{2}\right]\\where x_{t} &=\sqrt{\tilde{a}_{t}}x_{0}+\sqrt{1-\tilde{a}_{t}}\epsilon,\quad\epsilon\simN(0,I)","Loss function for the denoising network $D_{\theta}$, where $\mathcal{L}_{p}$ minimizes the mean squared error between the predicted noise $\epsilon$ and the ground truth noise, enabling the model to learn the reverse diffusion process effectively."
neurips_2024_oral_10,9,Loss=(1-\lambda)Loss_{l}+\lambda Loss_{p},,Loss=Loss_{p}+\lambda\cdot Loss_{l},Combination of unsupervised denoising loss and supervised task-specific loss with trade-off parameter $\lambda$
neurips_2024_oral_11,1,"sim(f,g)=\int_{x\in D(f)}\frac{\mathds{1}[f(x)=g(x)]}{|D(f)|}\\\approx\sum_{x\in X|X\sim D(f)}\frac{\mathds{1}[f(x)=g(x)]}{|X|}",,"sim(f, g)=\frac{1}{|D(f)|}\sum_{x\in D(f)}1\left[f(x)=g(x)\right]","Functionality similarity between $f$ and $g$ is defined as the average agreement of their outputs over all inputs in the shared domain $D(f)$, where $\mathbb{1}[\cdot]$ denotes the indicator function."
neurips_2024_oral_12,1,"P(X_{1},\ldots,X_{d})=\prod_{i=1}^{d}P(X_{i}\midPA_{i})",,"P(X_1,\ldots, X_d)=\prod_{j=1}^{d} P(X_j\midPA_j)","The joint distribution over observable variables satisfies the Markov factorization property with respect to the graph $\mathcal{G}$, decomposing into a product of conditional distributions of each variable given its parents in the graph."
neurips_2024_oral_12,2,"P(X_{1},\ldots,X_{d}|do(X=x))=\prod_{i:X_{i}\not\inX }P(X_{i}|PA_{i})\big{|}_{X=x}","where \(|_{\mathbf{X}=\mathbf{x}}\) enforces \(X_{1},\ldots,X_{d}\) to be consistent with realizations of \(\mathbf{X}\) else Eq","P(Y|do(X))=\sum_{Z} P(Y|X,Z) P(Z)","where $\mathbf{Z}$ is a set of variables satisfying the back-door criterion relative to $(\mathbf{X}, \mathbf{Y})$ in the graph $\mathcal{G}$."
neurips_2024_oral_12,3,"P(X_{\sigma(1)},\ldots,X_{\sigma(N)})=P(X_{1},\ldots,X_{N})",,"P(X_{1}, X_{2},\ldots, X_{N})=P(X_{\sigma(1)}, X_{\sigma(2)},\ldots, X_{\sigma(N)}))","This equation defines exchangeability, where the joint distribution of a sequence remains unchanged under any finite permutation of its elements."
neurips_2024_oral_12,4,"P(X_{::[N]}=x_{:,[N]})=\int\int\prod_{n=1}^{N}\prod_{i=1}^{ d}p(x_{i;n}\mida_{i;n}^{G},\theta_{i})d\nu_{1}(\theta_{1})\ldots d\nu_{d}(\theta_{d})",,P(X_{::\infty})=\int\prod_{n=1}^{\infty} P(X_{:n}\mid\theta) dP(\theta),"where $\boldsymbol{\theta}$ represents the latent parameter governing the conditional distribution of each variable given its parents in the DAG $\mathcal{G}$, and $P(\boldsymbol{\theta})$ is the prior distribution over these parameters."
neurips_2024_oral_12,5,"P(Y=y|do(X=x))=p(y|x,\psi_{0})=P(Y=y|x),\psi_{0}\inR",,"P(X_{i;n}|a_{i;n}^{G},\theta_{i})=\delta(X_{i;n}=x_{i;n})\quadif X_{i;n}\inX",where Î´ denotes the Dirac delta function enforcing deterministic assignment when variable Xáµ¢â is intervened.
neurips_2024_oral_12,6,"P(Y=y|do(X=x))=\int p(y|x,\psi)p(\psi)d\psi=P(Y=y|x)",,"P(Y=y|do(X=x))=\int p(y|x,\psi)p(x|\theta)\delta(x) d\psi d\theta","Equation 6 defines the causal effect in an ICM generative process, where the do-operator assigns a Î´-distribution to the intervened variable X=x, and the causal effect integrates over the conditional distributions of Y given X and the fixed parameters."
neurips_2024_oral_12,7,"\textbf{i.i.d. generative process}:P(X_{1},Y_{1},\ldots,X_{N},Y_{N})\stackrel{{ ind}}{{=}}\prod_{n=1}^{N}P(X_{n},Y_{n})\stackrel{{ idc}}{{=}}[P(X,Y)]^{N}",,"P(Y=y|do(X=x))=\int p(y|x,\psi)p(\psi)d\psi=P(Y=y|x)","The causal effect in an ICM generative process integrates over both the conditional distribution and the distribution of the causal de Finetti parameter, generalizing the i.i.d. case."
neurips_2024_oral_12,8,"\textbf{ICM gen. process}:P(x_{1},y_{1},\ldots,x_{N},y_{N})=\int\int\prod_{n=1} ^{N}p(y_{n}|x_{n},\psi)p(x_{n}|\theta)d\mu(\theta)d\nu(\psi)",,"\textbf{ICM generative process}: P(X_{1},Y_{1},\ldots,X_{N},Y_{N})=\int\int\prod_{n=1}^{N}p(X_{n}|\theta)p(Y_{n}|X_{n},\psi)d\nu(\theta)d\nu(\psi)","Equation 8 illustrates that in an ICM generative process, the joint distribution of the sequence cannot be fully characterized by a single i.i.d. distribution, as it involves integration over causal de Finetti parameters $\theta$ and $\psi$, reflecting the exchangeable but non-i.i.d. nature of the data."
neurips_2024_oral_12,9,"P(X_{J;n}\mid do(X_{I;n}=x))=P(X_{J;m}\mid do (X_{I;m}=x)),\forall n\neq m",,"P(X_{J;n}|do(X_{I;n}=x_{I;n}))=P(X_{J;m}|do(X_{I;m}=x_{I;m})),\quad\forall n\neq m","Corollary 1 establishes that in an ICM generative process, identical interventions applied at different positions yield the same post-interventional distribution, generalizing the i.i.d. invariance property to exchangeable data."
neurips_2024_oral_12,10,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=P(y_{1}|\hat{x})P(y_{2}|x_{2})P(x _{2})1_{x_{1}=\hat{x}}",,"P(Y_{1},X_{2},Y_{2}|do(X_{1}=\hat{x}))=P(Y_{1}|X_{1}=\hat{x})P(X_{2})P(Y_{2}|X_{2})",Truncated factorization applied to post-interventional distribution in an ICM generative process with respect to $\mathcal{G}:=X \to Y$ under hard intervention $\text{do}(X_{1}=\hat{x})$.
neurips_2024_oral_12,11,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=\int p(y_{1}|\hat{x},\psi)p(y_{2 }|x_{2},\psi)p(\psi)d\psi p(x_{2})1_{x_{1}=\hat{x}}",,"P(x_{1},y_{1},x_{2},y_{2}|do(X_{1}=\hat{x}))=P(y_{1}|\hat{x})P(x_{2})P(y_{2}|x_{2})1_{x_{1}=\hat{x}}\int p(\theta|x_{2})d\theta",Post-interventional distribution in ICM generative processes accounting for dependence between tuples through shared causal de Finetti parameters.
neurips_2024_oral_12,12,"p(x_{:,1},\ldots,x_{:,N}|do(X=\hat{x}))=\prod_{i\in I_{X}}p(x_{i;[-N_{i}]}|pa_{i;[-N_{i}]}^{G})\prod_{i\not\in I_{ X}}p(x_{i;[N]}|pa_{i;[N]}^{G})\big{|}_{X=\hat{x}}",,"p(x\mid do(X=\hat{x}))=\prod_{i: X_i\notinX}\int p(x_i\midpa_i,\theta_i) p(\theta_i) d\theta_i\Big|_{X=\hat{x}}",The truncated factorization for ICM generative processes integrates out the causal de Finetti parameters for non-intervened variables and enforces consistency with the intervention values.
neurips_2024_oral_12,13,"P(X_{\negI;n}|do(X_{I;n}=\hat{x} ),X_{\negS})=\prod_{i\not\inI}P(X_{i;n}|X_{i;S},PA_{i;S\cup\{n\}})|_{ X_{I;n}=\hat{x}}",,"P(X_{[\negI];n}\mid do(X_{I;n}=x),X_{:;S})=P(X_{[\negI];n}\mid do(X_{I;n}=x),X_{:;S})","Lemma 1 establishes that in ICM generative processes, the post-interventional distribution of non-intervened variables at a given position, conditioned on observations at other positions, remains invariant under interventions on variables at that position."
neurips_2024_oral_12,14,"\int\int\prod_{n}p(y_{n}\mid x_{n},\psi)p(x_{n}\mid\theta)p(\theta)p(\psi)d\theta d\psi","where \(p(\theta),p(\psi)\) are Beta distributions and \(p(y_{n}\mid x_{n},\psi),p(x_{n}\mid\theta)\) are Bernoulli distributions","P(x_{1},y_{1},\ldots,x_{N},y_{N})=\int_{0}^{1}\int_{0}^{1}\prod_{n=1}^{N}p(y_{n}|x_{n},\psi)p(x_{n}|\theta)d\theta d\psi","The joint distribution of the observed sequence in the causal Polya urn model is expressed using the bivariate form of the causal de Finetti theorem, where each variable pair $(x_n, y_n)$ is conditionally independent given the causal de Finetti parameters $\theta$ and $\psi$, and the product structure reflects the ICM generative process with $X \to Y$."
neurips_2024_oral_13,1,"X_{q}=clamp(\,\lfloor\frac{X}{\Delta}\rceil\!+\!z,0,2^{b}-1),where \Delta=\frac{\max(X)-\min(X)}{2^{b}-1},z=-\lfloor\frac{\min(X)}{\Delta}\rfloor",,"X_q=clamp\left(\left\lfloor\frac{X}{s}\right\rceil+z,\, 0,\, 2^b-1\right)","Equation 1 defines the $b$-bit uniform quantization operator with scale $s$, zero-point $z$, and clamping to the integer range $[0, 2^b - 1]$."
neurips_2024_oral_13,2,"R^{1}=E_{d^{(1)}}\hat{R}QE_{d^{(1)}},\qquadQ=1&Q\\O&Q^{\prime}\!",,"\hat{R}=I-2vv^{\top}, where v=\frac{e_{d^{(1)}}-sign(X_{d^{(1)}})\|X_{d^{(1)}}\|_2}{\|e_{d^{(1)}}-sign(X_{d^{(1)}})\|X_{d^{(1)}}\|_2\|_2}","where $\mathbf{e}_{d^{(1)}}$ is the standard basis vector with 1 at the $d^{(1)}$-th position and 0 elsewhere, and $\mathbf{v}$ is the normalized reflection vector used to construct the Householder transformation matrix $\hat{\mathbf{R}}$."
neurips_2024_oral_13,3,"\hat{R}= BlockDiag(\hat{R}_{b_{1}},...,\hat{R}_{b_{K}})","where \(\hat{\mathbf{R}}_{b_{i}}\in\mathbb{R}^{2^{n}\times 2^{n}}\) denotes a square matrix of the \(i\)-th block, which is constructed following the three steps mentioned above","\hat{R}=BlockDiag(R_{1},R_{2},\ldots,R_{B})\inR^{C_{in}\times C_{in}}","where the rotation matrix is approximated as a block-diagonal matrix composed of smaller rotation blocks $\mathbf{R}_{b}\in\mathbb{R}^{\frac{C_{in}}{B}\times\frac{C_{in}}{B}}$, enabling efficient computation and memory usage."
neurips_2024_oral_13,4,"Var([M_{b_{1}},M_{b_{2}},...,M_{b_{K}}])",,Var_{block}=\frac{1}{K}\sum_{i=1}^{K} (M_{b_i}-\bar{M})^2,"where $\bar{M}$ denotes the global mean of all block means $M_{b_i}$, and $\text{Var}_{\text{block}}$ quantifies the variance in outlier magnitudes across different blocks."
neurips_2024_oral_13,5,Y=X\cdotW=[(X\cdot\underbrace{A^ {-1}}_{G})\hat{R}_{(1)}\cdotP\cdot\hat{R }_{(2)}]\cdot[\underbrace{\hat{R}_{(2)}^{\top}\cdotP^{\top}\cdot\hat{R}_{(1)}^{\top}(A}_{G^{-1}}\cdotW)],"where the notation \(\mathbf{P}\) denotes the orthogonal permutation matrix learned via the zigzag manner, the \(\hat{\mathbf{R}}_{(1)}\) and \(\hat{\mathbf{R}}_{(2)}\) represent the first and second block-diagonal rotation matrix, respectively",Y=X\cdotW=(X\hat{R}P\hat{R}')\cdot (\hat{R}'^{\top}P^{\top}\hat{R}^{\top}W),"This equation represents the reformulation of the linear layer in the transformer using the DuQuant method, which combines rotation and permutation transformations to mitigate both Normal and Massive Outliers."
neurips_2024_oral_13,6,\max_{1\leq j\leq 2^{n}}\O_{j}(X_{b_{i}}\hat{R}_{b_{i}})\leq\max_{1\leq j\leq 2^{n}}\O_{j}(X_{b_{i}}),,\max_{j}O_{j}(X_{b_{i}}\hat{R}_{b_{i}})\leq\min_{R\inO(2^{n})}\max_{j}O_{j}(X_{b_{i}}R),Rotation transformation reduces the maximum outlier magnitude within each block by constructing an approximated optimal orthogonal matrix.
neurips_2024_oral_13,7,"M_{b_{i}}\leq O^{(1)}+\frac{(2^{n}K-1)(2^{n-1}-1)}{2^{n}}\delta,\qquad i=1,2, 3,...,K",,M_{b_{i}}\leq\frac{1}{2^{n}}\sum_{k=0}^{2^{n}-1}O^{(K+k)}+\delta,"This equation provides a theoretical upper bound on the mean outlier magnitude within each block after applying the zigzag permutation, showing that the permutation ensures a balanced distribution of outliers across blocks."
neurips_2024_oral_15,1,"\forall x\inX\colonP[c_{x }=1]=\frac{1}{1+\exp(-2ax^{\top}\theta^{*})},\\E[c_{x}]=\tanh(ax^{\top}\theta^{*})\\V[c_{x}]=1-\tanh^{2}(ax^{\top}\theta^{*}),\\E[t_{x}]=\frac{a}{x^{\top}\theta^{*}}\tanh(ax^ {\top}\theta^{*})&if x^{\top}\theta^{*}\neq 0\\a^{2}&if x^{\top}\theta^{*}=0",,"P(c_x=1) &=\frac{1}{1+\exp(-2 a x^\top\theta^*)},\\E[c_x] &=\tanh(a x^\top\theta^*),\\Var(c_x) &=1-\tanh^2(a x^\top\theta^*),\\E[t_x] &=\frac{a}{x^\top\theta^*}\tanh(a x^\top\theta^*)","Choice probability, expected choice, choice variance, and expected decision time under the difference-based EZ-Diffusion Model (dEZDM) with linear utility structure."
neurips_2024_oral_15,2,\forall x\inX\colon x^{\top}\frac{\theta^{*}}{a}=\frac{E [c_{x}]}{E[t_{x}]},,"\forall x\inX\colonE[c_{x}]=\tanh(ax^{\top}\theta^{*}),\quadE[t_{x}]=\frac{a}{x^{\top}\theta^{*}}\tanh(ax^{\top}\theta^{*})\if x^{\top}\theta^{*}\neq 0","The expected choice and expected decision time as functions of the utility difference and the decision barrier, forming the basis for the choice-decision-time estimator."
neurips_2024_oral_15,3,"\widehat{\theta}_{CH,DT}\coloneqq(\sum_{x\inX_{ sample}}n_{x}\;xx^{\top})^{-1}\sum_{x\inX_{sample}}n_{x}\;x\;\frac{\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}",,"\widehat{\theta}_{CH,DT}\coloneqq\left(\sum_{x\inX_{sample}}\frac{n_{x}}{\widehat{E}[t_{x}]^{2}}xx^{\top}\right)^{-1}\sum_{x\inX_{sample}}\frac{n_{x}\widehat{E}[c_{x}]}{\widehat{E}[t_{x}]^{2}}x","Choice-decision-time estimator for $\theta^{*}/a$ derived from the linear relationship between expected choice, expected decision time, and the utility difference, using weighted ordinary least squares regression over sampled queries."
neurips_2024_oral_15,4,"\widehat{\theta}_{CH}\coloneqq\operatorname*{arg\,max}_{\theta\inR^{d}}\sum_{x\inX_{sample}}\sum_{i=1}^{n_{x}}\log\mu(c_{x,s_{x,i}}\,x^{\top}\theta)",where \(\mu(y)\coloneqq 1/[1+\exp(-y)]\) is the standard logistic function,"\widehat{\theta}_{CH}\coloneqq\arg\max_{\theta\inR^{d}}\sum_{x\inX_{sample}}\sum_{i=1}^{n_{x}}\log\left(\frac{\exp(c_{x,s_{x,i}}x^{\top}\theta)}{1+\exp(x^{\top}\theta)}\right)","The choice-only estimator formulates preference estimation as a logistic regression problem by maximizing the log-likelihood of observed choices, where the parameter $2a\theta^{*}$ is estimated without incorporating decision time information."
neurips_2024_oral_15,5,"\sqrt{n}\;y^{\top}(\widehat{\theta}_{CHD,n}-\theta^{*}/a)\overset{D}{\longrightarrow}N(0,\zeta^{2}/a^{2})",,"\sqrt{n}(\widehat{\theta}_{CH,DT}-\theta^{*}/a)\xrightarrow{d}N(0,\Sigma_{CH,DT}),\quad\Sigma_{CH,DT}\coloneqq\left(\sum_{x\inX_{sample}}\frac{xx^{\top}}{E[t_{x}]}\right)^{-1}\left(\sum_{x\inX_{sample}}\frac{xx^{\top}V[c_{x}]}{E[t_{x}]^{2}}\right)\left(\sum_{x\inX_{sample}}\frac{xx^{\top}}{E[t_{x}]}\right)^{-1}",The asymptotic covariance matrix of the choice-decision-time estimator depends on the query design and the variance of choices scaled by the expected decision times.
neurips_2024_oral_15,6,\zeta^{2}\leq\|y\|_{(\sum_{x\inX_{sample}} [\min_{x^{\prime}\inX_{sample}}E[t_{x^{\prime}}]]\cdot xx^{\top})^{-1}}^{-1},,\zeta^{2}\leq\frac{y^{\top}\left(\sum_{x\inX_{sample}}xx^{\top}\right)^{-1}y}{a^{2}},The asymptotic variance of the choice-decision-time estimator is bounded above by a term that depends on the design matrix of sampled queries and the decision barrier $a$.
neurips_2024_oral_15,7,"\sqrt{n}y^{\top}(\widehat{\theta}_{CH,n}-2a\theta^{*})\overset{D}{\longrightarrow}N(0,4a^{2}\|y\|_{(\sum_{x\inX_{sample}}[a^{2}\,V[c_{x}] ]\cdot xx^{\top})^{-1}}^{-1})",,"\sqrt{n}\;y^{\top}(\widehat{\theta}_{CH,n}-2a\theta^{*})\overset{D}{\longrightarrow}N(0,\sigma^{2})","Asymptotic normality of the choice-only estimator $\widehat{\theta}_{\text{CH}}$, where $\sigma^{2}$ is the asymptotic variance dependent on the Fisher information from logistic regression."
neurips_2024_oral_15,8,"\widehat{u}_{x,CH,DT}\coloneqq\frac{\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}}{\sum_{i=1}^{n_{x}}t_{x,s_{x,i}}}",,"\widehat{u}_{CH,DT,x,n_{x}}\coloneqq x^{\top}\widehat{\theta}_{CH,DT,n_{x}}",Estimate of the utility difference $u_{x}/a$ for a single query $x$ using the choice-decision-time estimator.
neurips_2024_oral_15,9,"\widehat{u}_{x,CH}\coloneqq\mu^{-1}(\frac{1}{n_{x}}\sum_{i=1}^{n _{x}}\frac{c_{x,s_{x,i}}+1}{2})","where \((c_{x,s_{x,i}}+1)/2\) is the binary choice coded as 0 or 1, and \(\mu^{-1}(p)\coloneqq\log\left(p/(1-p)\right)\) is the logit function (inverse of \(\mu\) introduced in eq","\widehat{u}_{x,CH}\coloneqq\frac{1}{n_{x}}\sum_{i=1}^{n_{x}}c_{x,s_{x,i}}x^{\top}\widehat{\theta}_{CH}","Estimate of the utility difference $u_{x}$ using the choice-only estimator, which relies solely on human choices to approximate $2au_{x}$."
neurips_2024_oral_15,10,"P(|\widehat{u}_{x,CH,DT}-\frac{u_{x}}{a}|>\epsilon)\leq 4\exp(-[m_{CH,DT}^{non-axym}(x^{\top}\theta^{*})]^{2}\,n_{x}\,[\epsilon\cdot a]^{2} )",,"P\left[\left|\widehat{u}_{x,CH,DT}-\frac{u_{x}}{a}\right|\geq\epsilon\right]\leq 2\exp\left(-\frac{n_{x}a^{2}\epsilon^{2}}{8E[t_{x}]}\right)+2\exp\left(-\frac{n_{x}\epsilon^{2}E[t_{x}]}{8a^{2}}\right)","Non-asymptotic concentration bound for the choice-decision-time estimator of the utility difference, showing exponential decay of error probability with sample size and dependence on expected decision time and utility difference."
neurips_2024_oral_15,11,"P(|\widehat{u}_{x,CH}-2au_{x}|>\epsilon)\leq 6\exp(-[m_{CH}^{non-asym}(x^{\top}\theta^{*} )]^{2}\,n_{x}\,[\epsilon/(2a)]^{2})",,"P(|\widehat{u}_{x,CH}-2au_{x}|>\epsilon)\leq 6\exp\left(-n_{x}\cdot\frac{\epsilon^{2}}{9}\cdot\dot{\mu}(2au_{x})\right)",where $\dot{\mu}(y)\coloneqq\mu(y)(1-\mu(y))$ is the derivative of the logistic function $\mu(y)$.
neurips_2024_oral_16,1,"H=GNN(A,X)=\tilde{A}XW^{\prime},h_{i}=\sum_{j\inN_{i}}\alpha_{ij}x_{j}\cdotW^{\prime}=\sum_{j\inN_{i}}\frac{1}{d_{ i}}x_{j}\cdotW^{\prime}","where \(\mathbf{W}^{\prime}=\xi(\mathbf{W}),\mathbf{W}\in\mathbb{R}^{D\times K}\) with \(\xi\) being an activation function like ReLU [22] for ease of understanding, \(\mathcal{N}_{i}\) denotes the set of first-order neighbors of node \(v_{i}\), inclusive of \(v_{i}\) itself","L_{DGI}=-E_{(v_i,G)\sim p_{data}}\left[\logD(z_i,G)\right]-E_{(v_i,\tilde{G})\sim p_{corrupt}}\left[\log (1-D(z_i,\tilde{G}))\right]","The DGI loss function, which minimizes the negative log-likelihood of correctly classifying node representations from the original and corrupted graphs using a discriminator $\mathcal{D}(\cdot)$."
neurips_2024_oral_16,2,"E[h_{i}]&=E [\sum_{j\inN(i)}\alpha_{ij}x_{j}\cdotW^{\prime}]=\sum_{j\inN(i)}\alpha_{ij}E[x_{j}]\cdotW^{\prime}=\sum_{j\inN(i)}\alpha_{ij}\mu_{i}\cdotW^{\prime},\\Var(h_{i})&=Var(\sum_{ j\inN(i)}\alpha_{ij}x_{j}\cdotW^{\prime})=\sum_{j\inN(i)}\alpha_{ij}Var(x_{j})\cdotW ^{\prime 2}=\sigma_{i}^{2}\sum_{j\inN(i)}\alpha_{ij}^{2}\cdotW^{\prime 2}",,"E[h_{i}]=\sum_{j\inN_{i}}\frac{1}{d_{i}}\cdotE[x_{j}]\cdotW^{\prime}=\mu_{i}\cdotW^{\prime},\quadVar[h_{i}]=\sum_{j\inN_{i}}\left(\frac{1}{d_{i}}\right)^2\cdotVar[x_{j}]\cdotW^{\prime\, 2}=\frac{\sigma_{i}^{2}}{d_{i}}\cdotW^{\prime\, 2}",Computing the mean and variance of the aggregated representation after GNN message passing for node $v_i$.
neurips_2024_oral_16,3,"\tilde{h}_{i}=Trans_{R^{d}\toS^{k}}(h_{i})=\frac{h_{i}}{Max(\|h_{i}\|_{2},\varepsilon)},\quadS^{k}=\{\tilde{h}_{i}:\|\tilde{h }_{i}\|_{2}=1\}","where \(\mathbf{h}_{i}\) is representation for node \(v_{i}\in\mathcal{V}\), generated by the target encoder, \(\|\tilde{\mathbf{h}}_{i}\|_{2}=(\sum_{j=1}^{k}\tilde{\mathbf{h}}_{ij}^{2})^{ \frac{1}{2}}\), and \(\epsilon\) is a small value to avoid division by zero",z_{i}=Trans(h_{i})=\frac{h_{i}}{\|h_{i}\|_{2}},"Equation 3 defines the transformation function $\text{Trans}(\cdot)$, which applies $\ell_2$ normalization to each row vector $\mathbf{h}_i$ in the matrix $\mathbf{H}_{\text{target}}$, mapping the representations into the subspace $\mathbb{S}^k$ for effective representation scattering."
neurips_2024_oral_16,4,"L_{scattering}=-\frac{1}{n}\sum\nolimits_{i=1}^{n}\|\tilde{h}_{i}-c\|_{2}^{2},\quadc=\frac{1}{n}\sum\nolimits _{i=1}^{n}\tilde{h}_{i}",,"$$L_{scattering}=-\frac{1}{n}\sum_{i=1}^{n}\log\left(1-sim(\tilde{h}_{i},c)\right),$$","where $\mathbf{c}$ is the center of the hypersphere $\mathbb{S}^{k}$, and the loss function $\mathcal{L}_{\text{scattering}}$ encourages node representations to be scattered away from this center"
neurips_2024_oral_16,5,H_{online}^{topology}=\hat{A}^{k}H_{online}+H_{online},where k represents the order of neighbors and \(\hat{\mathbf{A}}=\mathbf{A}+\mathbf{I}\) is the adjacency matrix with self-loops,H_{online}^{topology}=(1-\lambda)H_{online}+\lambda\hat{A}^{k}H_{online},"where $\mathbf{H}_{\text{online}}^{\text{topology}}$ denotes the topologically enhanced representations, $\hat{\mathbf{A}}^{\text{k}}$ represents the k-order adjacency matrix, and $\lambda$ is a hyperparameter balancing the contribution of the original and aggregated representations"
neurips_2024_oral_16,6,"L_{alignment}=-\frac{1}{N}\sum_{i=1}^{N}\frac{Z_{(online,i)}^{\top}H_{(target,i)}}{\|Z_{(\text {online},i)}\|\|H_{(target,i)}\|}","where \(\mathbf{Z}_{\text{online}}\) and \(\mathbf{H}_{\text{target}}\) represent the predicted and scattered representations, respectively",L_{alignment}=\frac{1}{n}\sum_{i=1}^{n}\|z_{i}-\tilde{h}_{i}\|_{2}^{2},
neurips_2024_oral_16,7,\phiarrow\tau\phi+(1-\tau)\theta,"where \(\tau\) is a target decay rate and \(\tau\in[0,1]\)",\phi_{t+1}=\eta\theta_{t}+(1-\eta)\phi_{t},"where $\phi_{t+1}$ is the updated parameter of the target encoder, $\theta_{t}$ is the parameter of the online encoder at training step $t$, and $\eta$ is the momentum coefficient that controls the update rate of the target encoder."
neurips_2024_oral_17,1,"L_{cons}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}H\Big{(}p_{m}(y\mid f_{\theta}(\alpha(x))),p_{m}(y\mid f_{\theta}(A(x)))\Big{)}",,L_{consistency}=L_{reg}+\lambda_{pl}L_{pseudo}+\lambda_{ts}L_{teacher-student},"where $\mathcal{L}_{\text{reg}}$ denotes the consistency regularization loss, $\mathcal{L}_{\text{pseudo}}$ represents the pseudo-labeling loss, and $\mathcal{L}_{\text{teacher-student}}$ corresponds to the teacher-student model loss, with $\lambda_{\text{pl}}$ and $\lambda_{\text{ts}}$ being the respective trade-off hyperparameters."
neurips_2024_oral_17,2,"L_{cons}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}d\Big{(}p_{m}(y\mid f_{\theta}(\alpha(x ))-\Delta\Re),p_{m}(y\mid f_{\theta}(A(x)) )\Big{)}",,\min_{\theta}L_{cons}\propto\min_{\theta}\frac{1}{|D_{U}|}\sum_{x\inD_{U}}\Big{\|}f_{\theta}(\alpha(x))-f_{\theta}(A(x))\Big{\|}^{2},"This equation reformulates the consistency loss as a minimization of the squared difference between teacher and student representations, highlighting the importance of representation alignment in reducing prediction inconsistency."
neurips_2024_oral_17,4,\xiarrow\xi-\eta\nabla_{\xi}E(\xi;X)=\xi-\rm{sm}(\beta\xi^{\top}X)X^{\top},,\xi^{(t+1)}=\xi^{(t)}-\nabla_{\xi}E(\xi^{(t)};X)=\sum_{i=1}^{N}\frac{\exp(\betax_{i}^{\top}\xi^{(t)})}{\sum_{j=1}^{N}\exp(\betax_{j}^{\top}\xi^{(t)})}x_{i},"This equation describes the update rule for a state pattern in the Hopfield Network, aligning the query with the most similar stored patterns through a gradient descent step on the energy function."
neurips_2024_oral_17,5,"E(Q_{s};K_{t})=\frac{\alpha}{2}diag(K_{t}K_{t}^{T})-\sum_{i=1}^{N}\rm{lse}(Q_{s}k_{t,i}^{T},\beta)+c || E(K_{t})=\rm{lse}(\frac{1}{2}diag(K_{t}K_{t}^{T}),1)=\log\sum_{i=1}^{N}\exp(\frac{ 1}{2}k_{t,i}k_{t,i}^{T})+c",,"E_{teacher-student}=\frac{1}{2}Q_{s}^{\top}Q_{s}-\rm{lse}(K_{t}^{\top}Q_{s},\beta)+c",Energy function modeling the teacher-student relationship using cross-attention between student queries and teacher keys.
neurips_2024_oral_17,6,p(K_{t}|Q_{s})=\frac{p(Q_{s}|K_{t})p(K_{t})}{p(Q_{s})},,K_{t}^{\ast}=\arg\max_{K_{t}}\log p(K_{t}\midQ_{s})=\arg\max_{K_{t}}\Big{(}\log p(Q_{s}\midK_{t})+\log p(K_{t})\Big{)},"The optimal teacher keys $\mathbf{K}_{t}^{\ast}$ are obtained by maximizing the posterior probability given the student queries, balancing the likelihood of the student queries given the teacher keys and the prior distribution of the teacher keys."
neurips_2024_oral_17,7,\nabla_{K_{t}}\log p(K_{t}|Q_{s})&=-(\nabla_{K_{t}}E(Q_{s};K_{t})+\nabla_{K_{t}}E(K_{t}))\\&=sm(\betaQ_{s}K_{t}^{T})Q_ {s}-(\alphaI+D(sm(\frac{1}{2}diag(K_{t}K_{t}^{T}))))K_{t},,\nabla_{K_{t}}\log p(K_{t}|Q_{s})=\nabla_{K_{t}}\log p(Q_{s}|K_{t})+\nabla_{K_{t}}\log p(K_{t}),The gradient of the log posterior is approximated by summing the gradients from the likelihood and prior terms modeled by energy functions.
neurips_2024_oral_17,8,"K_{t}^{update}=K_{t}+\gamma_{update}[\,(sm(\betaKQ^{T})QW_{K}^{T})-\gamma_{reg }(\alphaI+D(sm(\frac{1}{2}diag (KK^{T})))KW_{K}^{T})\, ]",,K_{t}\leftarrowK_{t}+\eta\left(sm(\betaQ_{s}K_{t}^{T})Q_{s}-(\alphaI+D(sm(\frac{1}{2}diag(K_{t}K_{t}^{T}))))K_{t}\right),"This update rule aligns teacher keys with student queries by minimizing the energy function, incorporating both alignment and regularization terms."
neurips_2024_oral_17,9,L_{rep}^{s}=\frac{1}{|B^{\prime}|}\sum_{i\inB^{\prime}}\frac{1}{|N_{i}|}\sum_{q\inN_{i}}-\log\frac{\exp(z_{i}^{T}z_{q}^{\prime}/\tau_{c})}{\sum_{i^{\prime}\neq i }\exp(z_{i}^{T}z_{i^{\prime}}^{\prime}/\tau_{c})} || L_{rep}^{u}=\frac{1}{|B|}\sum_{i\inB}-\log\frac{\exp(z_{i}^{T}z_{i}^{\prime}/\tau_{u} )}{\sum_{i^{\prime}\neq i}\exp(z_{i}^{T}z_{i^{\prime}}^{\prime}/\tau_ {u})},,"L_{contrast}=\frac{1}{|B|}\sum_{i=1}^{|B|}\left[\log\left(1+\sum_{j\neq i}\exp(-\lambda (sim(z_i,z_j)-m))\right)\right]","This contrastive loss encourages similar representations for different views of the same image while pushing apart representations of different images, enhancing discriminative feature learning for both old and new classes in the GCD task."
neurips_2024_oral_17,10,"L_{cons}=\frac{1}{|B|}\sum_{i\inB }\ell(q^{\prime}_{i},p_{i})-\varepsilon H(\bar{p})&for unlabeled,\\\frac{1}{|B|}\sum_{i\inB}\ell(y_{i},p_{i})&for labeled.",,"L_{cons}^{s}=\frac{1}{|D_{L}|}\sum_{x\inD_{L}}\ell(p_{m}(y\mid f_{\theta}(\alpha(x))),y),\quadL_{cons}^{u}=\frac{1}{|D_{U}|}\sum_{x\inD_{U}}\ell(p_{m}(y\mid f_{\theta}(\alpha(x))),p_{m}(y\mid f_{\theta}(A(x))))","Equation 10 defines the supervised and unsupervised components of the consistency regularization loss using cross-entropy, where $\mathcal{L}_{\text{cons}}^{s}$ compares predictions with ground-truth labels on labeled data and $\mathcal{L}_{\text{cons}}^{u}$ compares pseudo-labels from the teacher model with predictions from the student model on unlabeled data."
neurips_2024_oral_18,1,G(x)=\exp(-\frac{1}{2}(x-\mu_{0})^{T}\Sigma_{0}^{-1}(x-\mu_{0})),"where \(\Sigma_{0}\) can be factorized as \(\Sigma_{0}=R_{0}S_{0}S_{0}^{T}R_{0}^{T}\), in which \(R_{0}\) is a rotation matrix represented by a quaternion vector \(r_{0}\in\mathbb{R}^{4}\), and \(S_{0}\) is a a diagonal scaling matrix characterized by a 3D vector \(s_{0}\in\mathbb{R}^{3}\)","P=\left\{\mu_0,\Sigma_0,\sigma, c\right\}","A 3D Gaussian point represented by its central position $\mu_0$, covariance matrix $\Sigma_0$, density $\sigma$, and color $c$."
neurips_2024_oral_18,2,"I(u)=\sum_{i\in N}T_{i}\alpha_{i}c_{i},\qquad A(u)=\sum_{i\in N}T_{i}\alpha_{i },\qquad D(u)=\sum_{i\in N}T_{i}\alpha_{i}d_{i}","where \(T_{i}=\prod_{j=1}^{i-1}(1-\alpha_{j})\) is the accumulated transmittance, \(\alpha_{i}\) is the probability of termination at point \(i\), and \(d_{i}\) is the depth of the Gaussian point at the specific view",D(u)=\frac{\sum_{i=1}^{N} G_i(x_i)\cdot d_i\cdot\prod_{j=1}^{i-1} (1-A_j(u))}{\sum_{i=1}^{N} G_i(x_i)\cdot\prod_{j=1}^{i-1} (1-A_j(u))},"where $d_i$ denotes the depth of the $i$-th Gaussian point, and the blending weights are determined by the transparency of preceding points in the rendering order."
neurips_2024_oral_18,3,"\mu(t)=\mu_{0}+\sum_{i=1}^{N_{m}}w_{i}(\mu_{0},t)d\mu_{i}(t),\qquad s(t)=s_{0}+\sum_{i=1}^{N_{m}}w_{i}(\mu_{0},t)ds_{i}(t)",,"\mu(t)=\mu_{0}+\sum_{i=1}^{N_{m}}w_{i}(\mu_{0},t)d\mu_{i}(t),\qquad s(t)=s_{0}+\sum_{i=1}^{N_{m}}w_{i}(\mu_{0},t)ds_{i}(t)","where $\mu(t)$ and $s(t)$ are the deformed position and scale of the Gaussian point at time $t$, computed as a linear combination of motion bases weighted by motion coefficients $w_i(\mu_0, t)$."
neurips_2024_oral_18,4,"L_{gs}=L_{1}(I,\tilde{I})+\lambda_{1}L_{ssim}(I,\tilde{I})+\lambda_{2}L_{1}(s(t))",where \(\lambda_{1}\) and \(\lambda_{2}\) are balancing hyperparameters,"L=\lambda_{1}L_{L1}(I,\tilde{I})+\lambda_{2}L_{SSIM}(I,\tilde{I})+\lambda_{3}L_{scale}","where $\mathcal{L}_{\text{L1}}$ and $\mathcal{L}_{\text{SSIM}}$ are the image reconstruction losses, and $\mathcal{L}_{\text{scale}}$ regularizes the scale attributes of the Gaussians to improve shape accuracy."
neurips_2024_oral_18,5,"P_{\tilde{P}}=\{(\tilde{p},s_{\Delta x},\sigma_{F})\}","where \(\tilde{p}\in\tilde{P}\), \(s_{\Delta x}=\Delta x/2^{n_{u}}\), and \(\sigma_{F}=F[Discretize(\tilde{p})]\) (we neglect \(t\) in the notation for simplicity)","P(t)=\{(\hat{p}_{i},\hat{\sigma}_{i},\hat{s}_{i})|\hat{\sigma}_{i}=F(t)[p,q,r],\hat{s}_{i}=\Delta x\}","where $\hat{p}_{i}$ denotes the position of continuum particle $i$, $\hat{\sigma}_{i}$ is its density derived from the density field $F(t)$, and $\hat{s}_{i}$ is its scale attribute determined by the grid size $\Delta x$"
neurips_2024_oral_18,6,"L_{ppe}=\frac{1}{m}\sum_{i=1}^{m}[L_{CD}(S(t_{i}),\tilde{S} (t_{i}))+\frac{1}{n}\sum_{j=1}^{n}L_{1}(A_{j}(t_{i}),\bar{A}_{j}(t_{ i}))]","where \(\mathcal{L}_{CD}\) and \(\mathcal{L}_{1}\) are chamfer distance and L1 norm respectively, \(S(t_{i})\) denotes the simulated surface at time \(t_{i}\), \(A_{j}(t_{i})\) is the rendered mask at view \(j\), and \(\bar{A}_{j}(t_{i})\) represents the object mask of the image extracted from video \(V_{j}\) at time \(t_{i}\)",L_{phy}=\sum_{t}\left(\| S(t)-\tilde{S}(t)\|_1+\lambda_3\| A(t)-\tilde{A}(t)\|_1\right),"where $S(t)$ and $\tilde{S}(t)$ are the simulated and extracted surfaces at time $t$, $A(t)$ and $\tilde{A}(t)$ are the rendered and ground truth object masks, and $\lambda_3$ is a balancing hyperparameter."
neurips_2024_oral_2,1,"\operatorname*{minimize}_{\theta}L(\theta;D_{SFT})=-E_{(x,y)\simD_{SFT}}[\log\pi_{\theta}(y|x)]",,\theta^{SFT}=\argmax_{\theta}\frac{1}{N}\sum_{i=1}^{N}\log\pi_{\theta}^{SFT}(y^{(i)}\midx^{(i)}),"The maximum likelihood estimation objective for supervised fine-tuning, which maximizes the average log-probability of target answers given input prompts under the model parameters Î¸."
neurips_2024_oral_2,2,"\pi^{\prime}(y_{c}|x)=\sum_{y_{k}}\mu_{\phi}(y_{c}|y_{k},x)\pi_{\theta}(y_{k}|x)\geqslant\mu_{\phi} (y_{c}|y_{o},x)\pi_{\theta}(y_{o}|x)",where \(\mathbf{y}_{k}\) is a possible answer generated by upstream LLM \(\pi_{\mathbf{\theta}}\),"\operatorname*{minimize}_{\phi}L(\phi;M)=-E_{(x,y_o,y_c)\simM}[\log\mu_{\phi}(y_c|y_o,x)]",Aligner's training objective minimizes the negative log-likelihood of generating corrected answers $\mathbf{y}_c$ conditioned on original answers $\mathbf{y}_o$ and queries $\mathbf{x}$ over dataset $\mathcal{M}$.
neurips_2024_oral_2,3,"-E_{M}[\log\pi^{\prime}(y_{c}|x)]\leqslant-E_{M}[\log\mu_{\phi}(y_{c}|y_{o},x)]-E_{M}[\log\pi_{\theta}(y_{o}|x)]",,"L(\phi;M)=-E_{(x,y_{o},y_{c})\simM}[\log\mu_{\phi}(y_{c}|y_{o},x)]","Equation (3) represents the empirical loss function for training the _Aligner_ model $\mu_{\mathbf{\phi}}$ on the dataset $\mathcal{M}$, derived from the conditional generation process in Equation (2)."
neurips_2024_oral_2,4,"\operatorname*{minimize}_{\phi}L_{Aligner}(\phi,M)=-E_{M}[\log\mu_{\phi}(y_{c} |y_{o},x)]",,"\operatorname*{minimize}_{\phi}L(\phi;M)=-E_{M}[\log\mu_{\phi}(y_{c}|y_{o},x)]","Equation (4) represents the training objective for the _Aligner_ model, which minimizes the negative log-likelihood of generating the corrected answer $\mathbf{y}_{c}$ given the original answer $\mathbf{y}_{o}$ and the input $\mathbf{x}$."
neurips_2024_oral_21,1,"q(X_{V}^{t}\midX_{V}^{t-1})=Cat(X_{V}^{t};p=X_{V}^{t-1}Q_{V}^{t}),\\q(X_{E}^{t}\midX_{E}^{t-1})=Cat(X_{E}^ {t};p=X_{E}^{t-1}Q_{E}^{t})",where \(\mathrm{Cat}(\mathbf{X};\mathbf{p})\) denotes sampling from a categorical distribution with probability \(\mathbf{p}\),tags. Let me draft that. </think>,"The transition probability for graph diffusion is defined as the product of node-wise and edge-wise transitions parameterized by matrices $\mathbf{Q}_{V}$ and $\mathbf{Q}_{E}$, where $X_{V,i}^{t}$ denotes node features and $X_{E,kl}^{t}$ denotes edge features at timestep $t$."
neurips_2024_oral_21,2,p_{\theta}(\tilde{G}^{0}\mid G^{t})=\prod_{v\in V}p_{\theta}(v^{t-1}\mid G^{t})\prod_{e\in E}p_{\theta}(e^{t-1}\mid G^{t}),,"p_{\theta}(X_{V}^{t-1}\midX_{V}^{t},X_{V}^{0})=Cat(X_{V}^{t-1};p=X_{V}^{t}(\bar{Q}^{t-1}/\bar{Q}^{t})^{\top}+X_{V}^{0}(1-\bar{Q}^{t-1}/\bar{Q}^{t})^{\top}),\\p_{\theta}(X_{E}^{t-1}\midX_{E}^{t},X_{E}^{0})=Cat(X_{E}^{t-1};p=X_{E}^{t}(\bar{Q}^{t-1}/\bar{Q}^{t})^{\top}+X_{E}^{0}(1-\bar{Q}^{t-1}/\bar{Q}^{t})^{\top})",where the reverse transition probabilities are defined using the ratio of cumulative transition matrices and the initial state prediction $\tilde{G}^{0}$.
neurips_2024_oral_21,3,"p_{\theta}(v^{t-1}\mid G^{t})=\sum_{\tilde{v}\in\tilde{x}_{v}}q(v^{t-1 }\mid\tilde{v},G^{t})p_{\theta}(\tilde{v}\mid G^{t})",,"p_{\theta}(v^{t-1}\mid G^{t})=\sum_{\tilde{v}\in\tilde{x}_{v}} q(v^{t-1}\mid v^{t},\tilde{v}) p_{\theta}(\tilde{v}\mid G^{t})","Equation 3 defines the reverse process distribution $p_{\theta}(v^{t-1} \mid G^{t})$ by marginalizing over predicted node types $\tilde{v}$, combining the forward transition $q(v^{t-1} \mid v^{t}, \tilde{v})$ with the neural network prediction $p_{\theta}(\tilde{v} \mid G^{t})$."
neurips_2024_oral_21,4,L=E_{q(G^{0})}E_{q(G^{t}|G^{0})}[-E_{x\in G^{0}}\log p_{\theta}(x\mid G^{t})],,"L=-E_{G^{0},t}\left[\log p_{\theta}(G^{0}\mid G^{t})\right]","where the loss function $\mathcal{L}$ is defined as the expected negative log-likelihood of the true data $G^{0}$ given the noisy state $G^{t}$, with the expectation taken over the data distribution and timesteps $t$."
neurips_2024_oral_21,5,Q_{G}=Q_{V}&1_{N}^{\prime}\otimesQ_{VE}\\1_{N}\otimesQ_{EV}&1_{N\times N}\otimesQ_{ E},"where \(\otimes\) denotes the Kronecker product, \(\mathbf{1}_{N}\), \(\mathbf{1}_{N}^{\prime}\), and \(\mathbf{1}_{N\times N}\) represent the column vector, row vector, and matrix with all 1 elements, respectively",Q_{G}=Q_{V} &Q_{VE}^{\top} &\cdots &Q_{VE}^{\top}\\Q_{EV} &Q_{E} &\cdots &0\\\vdots &\vdots &\ddots &\vdots\\Q_{EV} &0 &\cdots &Q_{E},Transition matrix $\mathbf{Q}_{G}$ for graph tokens that captures joint node-edge dependencies in the diffusion process.
neurips_2024_oral_21,6,q(X_{G}^{t}\midX_{G}^{t-1})=\widetilde{Cat}(X_{G}^{t};\tilde{p}=X_{G}^{t-1}Q_{G}^{t} ),"where \(\tilde{\mathbf{p}}\) is the unnormalized probability and \(\widetilde{\mathrm{Cat}}\) denotes categorical sampling: The first \(F_{V}\) columns of \(\tilde{\mathbf{p}}\) are normalized to sample \(\mathbf{X}_{V}^{t}\), while the remaining \(N\cdot E\) dimensions are reshaped and normalized to sample edges \(\mathbf{X}_{E}^{t}\)",q(X_{G}^{t}\midX_{G}^{0})=Cat(X_{G}^{t};p=X_{G}^{0}\bar{Q}_{G}^{t}),"where $\mathbf{Q}_{G}^{t}$ is the transition matrix at timestep $t$, and $\bar{\mathbf{Q}}_{G}^{t} = \prod_{i \leq t} \mathbf{Q}_{G}^{i}$ represents the cumulative transition matrix up to timestep $t$"
neurips_2024_oral_21,7,"\hat{p}_{\theta}(G^{t-1}\mid G^{t},C)=\log p_{\theta}(G^{t-1}\mid G^{ t})+s(\log p_{\theta}(G^{t-1}\mid G^{t},C)-\log p_{\theta}(G^{t-1}\mid G^{t}))",where \(s\) denotes the scale of conditional guidance,"\log\hat{p}_{\theta}(G^{t-1}\mid G^{t},C)=\log p_{\theta}(G^{t-1}\mid G^{t})+\lambda\log q(C\mid G^{0})",where $\lambda$ controls the strength of the multi-condition guidance during the reverse diffusion process
neurips_2024_oral_21,8,"AdaLN(h,c)=\gamma_{\theta}(c)\odot\frac{h-\mu(h)}{\sigma(h )}+\beta_{\theta}(c)",where \(\mu(\cdot)\) and \(\sigma(\cdot)\) are mean and variance values,"AdaLN(h,c)=\gamma(c)\cdotLayerNorm(h)+\beta(c)",where $\gamma$ and $\beta$ are learnable parameters modulated by the condition representation $\mathbf{c}$ through two linear transformations
neurips_2024_oral_21,9,"AdaLN_{gate}(h,c)=\alpha_{\theta}(c)\odotAdaLN(h,c)",,"AdaLN_{gate}(h,c)=\sigma(\gamma_{\theta}^{\prime}(c))\odot\gamma_{\theta}(c)\odot\frac{h-\mu(h)}{\sigma(h)}+\beta_{\theta}(c)","where $\sigma(\cdot)$ denotes the sigmoid function, and $\gamma_{\theta}^{\prime}(\cdot)$ is an additional neural network module for gating the adaptive scaling factors."
neurips_2024_oral_21,10,"\tilde{X}_{G}^{0}=AdaLN(MLP(H),c)",,"\tilde{X}_{V}^{0},\tilde{X}_{E}^{0}=MLP_{V}(H),MLP_{E}(H)","where $\tilde{\mathbf{X}}_{V}^{0}$ and $\tilde{\mathbf{X}}_{E}^{0}$ denote the predicted node and edge probabilities at timestep $t=0$, obtained through separate MLPs applied to the hidden states $\mathbf{H}$"
neurips_2024_oral_22,1,"dx_{\sigma}\,=\,-\sigma\nabla_{x_{\sigma}}\!\log p (x_{\sigma};\sigma)\;d\sigma",,"p(x;\sigma)=p_{data}(x)*N(x;0,\sigma^2I)","Equation defining the smoothed density $p(\mathbf{x};\sigma)$ as the convolution of the data distribution $p_{\text{data}}(\mathbf{x})$ with a Gaussian kernel $\mathcal{N}(\mathbf{x}; \mathbf{0}, \sigma^2 \mathbf{I})$."
neurips_2024_oral_22,3,"D_{w}(x;\sigma,c)\,=\,wD_{1}(x;\sigma,c)+( 1-w)D_{0}(x;\sigma,c)",,"x_{guided}=(1-w) D_{0}(x;\sigma,c)+w D_{1}(x;\sigma,c)","where $w$ controls the strength of the guidance, interpolating between the unconditioned denoiser $D_0$ and the conditioned denoiser $D_1$."
neurips_2024_oral_22,4,"D_{w}(x;\sigma,c)\approxx+\sigma^{2}\nabla_{x}\log\underbrace{(p_ {0}(x|c;\sigma)[\frac{p_{1}(x|c;\sigma)}{p_{0}(x|c;\sigma)}]^{w})}_{\propto:\p_{w}(x|c;\sigma)}",,"D_{w}(x;\sigma,c)\,=\,D_{0}(x;\sigma,c)+w\big(D_{1}(x;\sigma,c)-D_{0}(x;\sigma,c)\big)",which expresses the guided denoiser as a base denoiser $D_0$ plus a weighted residual correction derived from the difference between $D_1$ and $D_0$.
neurips_2024_oral_22,5,\nabla_{x}\log p_{w}(x|c;\sigma)=\nabla_{x}\log p_{1}(x|c;\sigma)+(w-1)\nabla_{x}\log\frac{p_{1}(x|c;\sigma)}{p_{0}(x|c;\sigma)},,"\nabla_{x}\log p_{w}(x|c;\sigma)\approx\nabla_{x}\log p_{0}(x|c;\sigma)+w\,\nabla_{x}\log\frac{p_{1}(x|c;\sigma)}{p_{0}(x|c;\sigma)}",This equation decomposes the guided score into the base score and a weighted correction term derived from the ratio of two conditional densities.
neurips_2024_oral_23,1,"|Cov(f(X),Y\mid X\in S)|\leq\alpha",,\left|E[(Y-f(X))\cdot1_{X\in S}]\right|\leq\alpha,"This equation defines an $\alpha$-indistinguishable subset $S$ with respect to a function class $\mathcal{F}$ and target $Y$, capturing the idea that no predictor $f \in \mathcal{F}$ can significantly correlate with the residual $Y - f(X)$ over $S$."
neurips_2024_oral_23,2,"\gamma^{*},\beta^{*}\in\operatorname*{arg\,min}_{\gamma\inR^{K},\beta\inR^{K}}\;E[(Y-\gamma_{J(X)}+\beta_{J(X)}\hat{Y})^{2}]",,"\gamma^{*}_{k}=E[Y\mid X\in S_{k}],\quad\beta^{*}_{k}=E[\hat{Y}\mid X\in S_{k}]","These represent the expected outcome and expert prediction within each subset of the partition, respectively."
neurips_2024_oral_23,3,"E_{k}[(Y-\gamma_{k}^{*}-\beta_{k}^{*}\hat{Y})^{2} ]+4Cov_{k}(Y,\hat{Y})^{2}\leqE_{k}[(Y-f(X) )^{2}]+2\alpha",,E[(Y-\gamma^{*}_{k}+\beta^{*}_{k}\hat{Y})^{2}\mid X\in S_{k}]\leqE[(Y-f(X))^{2}\mid X\in S_{k}]+2\alpha\cdotVar_{k}(Y),This inequality shows that the expected squared error of the human-augmented predictor within each indistinguishable subset $S_k$ is bounded by the error of any algorithmic predictor $f \in \mathcal{F}$ plus a term proportional to $\alpha$ and the conditional variance of $Y$ within $S_k$.
neurips_2024_oral_23,4,E_{S}[(Y-g(H))^{2}]\leqE_{S}[(Y-\gamma-\beta g(H))^{2}]+\eta,,E[(Y-\gamma-\beta g(H))^2]\leqE[(Y-\gamma-\betaE[Y\mid H])^2]+\eta,
neurips_2024_oral_23,5,"E_{S}[(Y-g(H))^{2}]+4Cov_{S}(Y,g(H))^{2}\leqE_ {S}[(Y-f(X))^{2}]+2\alpha+\eta",,E_{S}[(Y-g(H))^{2}]\leqE_{S}[(Y-f(X))^{2}]+2\alpha+\eta,"This inequality shows that the squared error of a calibrated expert feedback function $g(H)$ is bounded by the error of any algorithmic predictor $f \in \mathcal{F}$, plus approximation errors due to the indistinguishability parameter $\alpha$ and the calibration parameter $\eta$."
neurips_2024_oral_23,6,"|Cov_{k}(Y,\hat{Y})|\leq\sqrt{\frac{\alpha}{2}}",,"Cov_{k}(Y,\hat{Y})^{2}\leq\alpha","This equation quantifies the squared conditional covariance between the outcome $Y$ and the expert prediction $\hat{Y}$ within an indistinguishable subset, showing that it is bounded by the indistinguishability parameter $\alpha$ under the assumption of conditional independence given a binary-valued model class."
neurips_2024_oral_24,1,y^{\prime}=y+\Delta y=W_{0}x+BAx,where \(y\in R\)d is the output and the \(x\in R\)k denotes the input,W=W_0+B A,The adapted weight matrix is obtained by adding the product of low-rank matrices $A$ and $B$ to the pre-trained weights $W_0$.
neurips_2024_oral_24,2,"W&=\,W_{0}+\Delta\,W\\&=\,W_{0}+\sum_{i=1}^{N}\omega_{i}\cdot B_{i}A",,"\Delta W=\sum_{i=1}^{n} B_i A,\quadwhere  A\inR^{r\times k}, B_i\inR^{d\times r}","_HydraLoRA_ introduces an asymmetric architecture where a shared matrix $A$ is combined with multiple distinct matrices $B_i$, enabling parameter sharing while allowing task-specific adaptation."
neurips_2024_oral_24,3,y=W_{0}x+\sum_{i=1}^{N}\omega_{i}E_{i}Ax\quad(MoE),"where \(N\) denotes the number of experts, i","\Delta\,W &=MoE(\cdot)\\&=\sum_{i=1}^{N}Router(x)_{i}\cdot B_{i}A","Equation 3 defines the forward process of _HydraLoRA_ during fine-tuning, where the MoE router dynamically selects and combines multiple B matrices with the shared A matrix based on input x."
neurips_2024_oral_24,4,\omega_{i}=softmax(W_{g}^{T}x)\quad(Router),,"\omega_{i}=\frac{\exp\left(g_{i}\right)}{\sum_{j=1}^{N}\exp\left(g_{j}\right)},\quadwhere g_{i}=x^{T}W_{g}^{(i)}","where $\omega_{i}$ denotes the gating score for expert $i$, computed using a softmax over the outputs of a router network with trainable weights $\mathit{W}_{g}$."
neurips_2024_oral_25,1,"{l}X=Y\beta_{Y\to X}+G^{\intercal}\gamma_{X}+\varepsilon_{X},\\Y=X\beta_{X\to Y}+G^{\intercal}\gamma_{Y}+\varepsilon_{Y}",where \(\beta_{Y\to X}\) is the causal effect of \(Y\) on \(X\) and \(\beta_{X\to Y}\) is that of \(X\) on \(Y\),"X_i &=\alpha Y_i+G_i^\intercal\gamma_X+\varepsilon_{X_i},\\Y_i &=\beta X_i+G_i^\intercal\gamma_Y+\varepsilon_{Y_i}","Equation 1 defines the bi-directional MR causal models where $X$ and $Y$ are modeled as linear functions of each other, genetic variants $\mathbf{G}$, and error terms $\varepsilon_{X}$ and $\varepsilon_{Y}$, with parameters $\alpha$, $\beta$, $\boldsymbol{\gamma}_X$, and $\boldsymbol{\gamma}_Y$."
neurips_2024_oral_25,2,"{l}X=(G^{\intercal}\gamma_{X}+G ^{\intercal}\gamma_{Y}\beta_{Y\to X}+\varepsilon_{X}+\varepsilon_{Y}\beta_{Y\to X})\Delta,\\Y=(G^{\intercal}\gamma_{X}\beta_{X\to Y}+G^{\intercal}\gamma_{Y}+\varepsilon_{X}\beta_{X\to Y}+\varepsilon_{Y})\Delta",,"{l}X=\DeltaG^{\intercal}(\gamma_{X}+\beta_{Y\to X}\gamma_{Y})+\Delta\varepsilon_{X}+\Delta\beta_{Y\to X}\varepsilon_{Y},\\Y=\DeltaG^{\intercal}(\gamma_{Y}+\beta_{X\to Y}\gamma_{X})+\Delta\beta_{X\to Y}\varepsilon_{X}+\Delta\varepsilon_{Y}","Reorganized non-recursive form of the bi-directional MR causal model under the assumption $\beta_{X\to Y}\beta_{Y\to X}\neq 1$, expressing $X$ and $Y$ in terms of genetic variants $\mathbf{G}$ and error terms scaled by $\Delta$."
neurips_2024_oral_25,3,\hat{\beta}_{X\to Y}=[X^{\intercal}PX]^{-1}X^{\intercal}PY=\beta_{X\to Y},,\beta_{X\to Y}^{TSLS}=(E[G_{V}^{X\to Y}X])^{-1}E[G_{V}^{X\to Y}Y],The TSLS estimator for the causal effect $\beta_{X\to Y}$ using valid IVs $\mathbf{G}_{\mathcal{V}}^{X\to Y}$ in the bi-directional MR model.
neurips_2024_oral_25,4,\hat{\beta}_{X\to Y}=[X^{\intercal}\tilde{P}X]^{-1}X^{\intercal}\tilde{P}Y=\beta_{X\to Y}+\underbrace{[X^{\intercal}\tilde{P}X ]^{-1}X^{\intercal}\tilde{P}(G^{\intercal}\gamma_{Y}+\varepsilon_{Y})}_{\beta_{bias}},,\hat{\beta}_{X\to Y}=[X^{\intercal}PX]^{-1}X^{\intercal}PY=\beta_{X\to Y}+\underbrace{[X^{\intercal}PX]^{-1}X^{\intercal}P\varepsilon_{Y}}_{bias term},"The TSLS estimator introduces bias in the presence of invalid IVs, as captured by the non-zero bias term involving the projection matrix and error component."
neurips_2024_oral_25,5,"corr(Y-X\omega_{\{G_{3}\}},G_{1})=0,\qquadcorr(Y-X\omega_{\{ G_{1}\}},G_{3})=0","where \(\mathrm{corr}(\cdot)\) denotes the Pearson's correlation coefficient between two random variables, and \(\omega_{\{G_{i}\}}=\mathrm{TSLS}(X,Y,\{G_{i}\})\) with \(i\in\{1,3\}\)","Cov(G_{1},X)=\beta_{Y\to X}Cov(G_{1},Y)+\gamma_{X,1},\quadCov(G_{3},X)=\beta_{Y\to X}Cov(G_{3},Y)+\gamma_{X,3}",The covariance between valid IVs and phenotype X depends on the causal effect of Y on X and the direct effect of the IV on X.
neurips_2024_oral_25,6,"corr(Y-X\omega_{\{G_{4},G_{5}\}},G_{2})\neq 0,corr(Y-X\omega_{\{ G_{2},G_{5}\}},G_{4})\neq 0,corr(Y-X\omega_{\{G_{2},G_{4}\}},G_{5})\neq 0","where \(\omega_{\{G_{i},G_{j}\}}=\mathrm{TSLS}(X,Y,\{G_{i},G_{j}\})\) with \(i\neq j\) and \(i,j\in\{2,4,5\}\)","corr(Y-X\omega_{\{G_{4}\}},G_{2})\neq 0,\qquadcorr(Y-X\omega_{\{G_{5}\}},G_{4})\neq 0","Equation 6 illustrates that correlations between residuals and excluded IVs are non-zero when using invalid IVs, indicating violation of the exclusion restriction assumption."
neurips_2024_oral_25,7,"PR_{(X,Y\,|\,G)}:=Y-X\omega_{G}",,"R(X,Y,G)=Y-X\cdotTSLS(X,Y,G)",A pseudo-residual quantifies the discrepancy between the outcome $Y$ and the predicted value of $Y$ based on the TSLS estimator using a subset of genetic variants $\mathbb{G}$.
neurips_2024_oral_25,8,"corr(PR_{\langle X,Y\,|\,\{G_{j}\}\rangle},G_{j })\neq 0",,"corr(PR_{(X,Y\,|\,G\setminus\{G_{j}\})},G_{j})\neq 0","where $\mathcal{PR}_{(X,Y\,|\,\mathbb{G}\setminus\{G_{j}\})}$ denotes the pseudo-residual computed by excluding $G_j$ from the set $\mathbb{G}$, and $\mathrm{corr}(\cdot)$ is the Pearson correlation coefficient."
neurips_2024_oral_25,9,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=0",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{1})=0","where $ \mathcal{PR}_{\langle X,Y\,|\,\{G_{1}\}\rangle} $ denotes the pseudo-residual of $ \{X,Y\} $ relative to $ \{G_{1}\} $."
neurips_2024_oral_25,10,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle}),G_{ 2})=0",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2} )=0",
neurips_2024_oral_25,11,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=\frac{\gamma_{Y,1}\gamma_{X,2}-\gamma_{Y,2}\gamma_{X,1}}{\beta_{Y\to X }\gamma_{Y,2}+\gamma_{X,2}}",,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1})\neq 0",Correlation condition for identifying an invalid IV set in subgraph (b) of Example 2.
neurips_2024_oral_25,12,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2} )=\frac{\gamma_{Y,2}\gamma_{X,1}-\gamma_{Y,1}\gamma_{X,2}}{\beta_{Y\to X }\gamma_{Y,1}+\gamma_{X,1}}",,"corr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{ 2})=\frac{\gamma_{Y,2}\gamma_{X,1}-\gamma_{Y,1}\gamma_{X,2}}{\beta_{Y\to X }\gamma_{Y,1}+\gamma_{X,1}}","These correlations depend on the direct effects of genetic variants on phenotypes and the causal effect of $Y$ on $X$, revealing conditions under which a candidate IV set may appear valid even when it is not."
neurips_2024_oral_25,13,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1} )=0,\qquadcorr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle },G_{2})=0",,"corr(PR_{\langle X,Y\,|\,\{G_{2}\}\rangle},G_{1})=0,\qquadcorr(PR_{\langle X,Y\,|\,\{G_{1}\}\rangle},G_{2})=0","Equation 13 shows that under a specific proportionality condition between the effects of $G_1$ and $G_2$ on $X$ and $Y$, the correlations between the pseudo-residuals and the genetic variants vanish, even though $\{G_1, G_2\}$ is an invalid IV set."
neurips_2024_oral_25,14,"corr(PR_{(X,Y\midG\setminus G_{j})},G_{j})=0",,"corr(PR_{\langle X,Y\,|\,G/\{G_{j}\}\rangle},G_{j })=0","where $\mathcal{PR}_{\langle X,Y\,|\,\mathbb{G}/\{G_{j}\}\rangle}$ denotes the pseudo-residual obtained by regressing $Y$ on $X$ using the subset of genetic variants $\mathbb{G}$ excluding $G_j$, and the condition ensures that $G_j$ is a valid IV given the rest of the set $\mathbb{G}$."
neurips_2024_oral_26,1,"s_{real}(x_{t},t)=\nabla_{x_{t}}\log p_{real,t}(x_{t})=-\frac{x_ {t}-\alpha_{t}\mu_{real}(x_{t},t)}{\sigma_{t}^{2}}",,"p_{real,t}(x_{t})=\int p_{real}(x)\, q(x_{t}\mid x)\, dx","The marginal distribution of the diffused sample at step $t$, derived from the forward diffusion process."
neurips_2024_oral_26,2,"\nablaL_{BMD}=E_{t}(\nabla_{\theta}KL( p_{fake,t}\|p_{real,t}))=-E_{t}(\int(s_{real}(F(G_{\theta}(z),t),t)-s_{fake}(F(G_{\theta}(z),t),t) )\frac{dG_{\theta}(z)}{d\theta}\,dz)","where \(z\sim\mathcal{N}(0,\mathbf{I})\) is a random Gaussian noise input, \(\theta\) are the generator parameters, \(F\) is the forward diffusion process (i","\nabla_{G}L_{DMD}=E_{t}\left[\nabla_{G}KL(p_{real,t} || p_{fake,t})\right]=E_{t}\left[E_{x_{t}\sim p_{fake,t}}\left[s_{real}(x_{t},t)-s_{fake}(x_{t},t)\right]\nabla_{G}x_{t}\right]",The DMD loss gradient with respect to the generator $G$ is expressed as the expectation over timesteps $t$ of the inner product between the score function difference and the generator's output sensitivity.
neurips_2024_oral_26,3,"L_{reg}=E_{(z,y)}d(G_{\theta}(z),y)","where \(d\) is a distance function, such as LPIPS [54] in their implementation","L_{reg}=E_{z}[\|G_{\theta}(z)-\mu_{real}(z,t_{reg})\|^{2}]","where $t_{\text{reg}}$ is a fixed timestep chosen for the regression loss, typically early in the diffusion process to provide stable target estimates."
neurips_2024_oral_26,4,"L_{GAN}=E_{x\sim p_{noise},t\sim[0,T]}[\log D (F(x,t))]+E_{z\sim p_{noise},t\sim[0,T]}[-\log(D(F(G_{\theta}(z ),t)))]","where \(D\) is the discriminator, and \(F\) is the forward diffusion process (i",L_{GAN}=E_{z}\left[-\log D(G_{\theta}(z))\right],"where $D$ is the discriminator trained to distinguish real images from generator outputs $G_{\theta}(z)$, and $z\sim\mathcal{N}(0,\mathbf{I})$ is Gaussian noise input."
neurips_2024_oral_27,2,"PVL^{\theta}(\pi)=\frac{1}{T}\sum_{t=0}^{T}\max(\sum_{k=t}^{T}(\gamma\lambda)^{k-t}\delta_{k}^{\theta},0)","where \(\lambda\) and \(T\) are the GAE discount factor and MDP horizon, respectively","U^{R}(\pi,\theta)=\textsc{Regret}^{\theta}(\pi,\pi^{*})=V^{\theta}(\pi^{*})-V^{\theta}(\pi)","Regret-based utility function where $ \pi^{*} $ is the optimal policy on $ \theta $, measuring the difference in return between the optimal policy and the current policy."
neurips_2024_oral_27,3,"P(\Gamma\mid\lambda_{\Gamma})=\prod_{j=1}^{J}\sum_{k=1}^{K}\alpha_{k}N (x_{j}\mid\mu_{k},\Sigma_{k})",where \(x_{j}\) is a state-action pair sample from \(\Gamma\),"p(\Gamma|\lambda_{\Gamma})=\prod_{x\in\Gamma}\sum_{k=1}^{K}\alpha_{k}N(x|\mu_{k},\Sigma_{k})","where each Gaussian component is characterized by its weight $\alpha_k$, mean vector $\mu_k$, and covariance matrix $\Sigma_k$, with $k \in \{1, \dots, K\}$"
neurips_2024_oral_27,4,\textsc{Novelty}_{l_{\theta}}=-\frac{1}{|X_{\theta}|}\logL(X_{\theta}\mid\lambda_{\Gamma})=-\frac{1}{|X_{\theta}|}\sum_{t=1}^{T}\log p(x_{t}\mid\lambda_{\Gamma}),where \(x_{t}\) is a sample state-action pair from \(X_{\theta}\),Novelty(l_{\theta})=-\frac{1}{|X_{\theta}|}\sum_{x\in X_{\theta}}\log P(x\mid\lambda_{\Gamma}),where $P(x\mid\lambda_{\Gamma})$ is the likelihood of observing a state-action pair $x$ under the GMM parameters $\lambda_{\Gamma}$
neurips_2024_oral_27,5,P_{S}=\frac{h(S_{i})^{\beta}}{\sum_{j}h(S_{j})^{\beta}},where \(h\) is a prioritization function (e,"P_{S}(l_{\theta})=\frac{\beta\cdot\textsc{Novelty}_{l_{\theta}}+(1-\beta)\cdot U^{R}(\pi,\theta)}{\max(\textsc{Novelty}_{L})+\max(U^{R}(\pi,L))}",where $ \beta $ is a hyperparameter balancing the contribution of novelty and regret in the prioritization function
neurips_2024_oral_27,6,P_{replay}=\alpha\cdot P_{N}+(1-\alpha)\cdot P_{R},"where \(P_{N}\) and \(P_{R}\) are the novelty-prioritized probability and regret-prioritized probability respectively, and \(\alpha\) allows us to adjust the weightage of each probability","P_{S}=\frac{[rank(U^{R}(\pi,\theta))]^{-\beta_{1}}\cdot[rank(\textsc{Novelty}_{l_{\theta}})]^{-\beta_{2}}}{\sum_{j}[rank(U^{R}(\pi,\theta_{j}))]^{-\beta_{1}}\cdot[rank(\textsc{Novelty}_{l_{\theta_{j}}})]^{-\beta_{2}}}}","where $\beta_{1}$ and $\beta_{2}$ are temperature parameters that control the influence of regret and novelty scores, respectively, in determining the level replay probability"
neurips_2024_oral_31,1,y^{*}=y-f_{\theta}(y)\nabla f_{\theta}(y),"where, by definition, \(f_{\theta}(\mathbf{y})\) is the distance between \(\mathbf{y}\) and \(\mathbf{y}^{*}\), and the gradient \(\nabla f_{\theta}(\mathbf{y})\) points in the opposite direction of the shortest path from \(\mathbf{y}\) to the surface of the object and is unit-norm",y^{*}=\arg\min_{y'\inM}\|y-y'\|,Computes the closest point $\mathbf{y}^{*}$ on the object surface $\mathcal{M}$ to a given 3D point $\mathbf{y}$ using the SDF.
neurips_2024_oral_31,2,c^{j}_{ik}=n_{ik}-d^{j}_{ik}T_{j}\Big{(}\nabla f_{\theta_{j}}(T^{-1}_{j}(n_{ik}))\Big{)},,c^{j}_{ik}=T_{j}\left(T^{-1}_{j}(n_{ik})-d^{j}_{ik}\nabla f_{\theta_{j}}\left(T^{-1}_{j}(n_{ik})\right)\right),"Computes the closest point on the surface of object $O_j$ from a surface node $\mathbf{n}_{ik}$ on object $O_i$, using the SDF of $O_j$ and the rigid transformation between the objects."
neurips_2024_oral_34,1,"x_{0}\simN(0,I)\quadand\quadx_{t+1}=a_{t}x_{t}+\mu(x_{t},t)+\sigma_{t}\epsilon_{t}\quadfor\quad t=0,1,\dots,T-1","where \(\epsilon_{t}\sim\mathcal{N}(0,I)\) and \(\mu(\mathbf{x},t)\) is the output of a neural network","x_t=\sqrt{\alpha_t}x_{t-1}+\sqrt{1-\alpha_t}\,\epsilon_t","The forward diffusion process in DDPM, where each step adds Gaussian noise scaled by parameters Î±_t to transition from x_{t-1} to x_t."
neurips_2024_oral_34,2,"q(x)=\frac{1}{Z}\exp(-E(x)/\tau),\quad E:X\toR","where \(\tau>0\) is temperature, \(\mathcal{X}\) is the compact domain of data, and \(Z=\int_{\mathcal{X}}\exp(-E(\mathbf{x})/\tau)d\mathbf{x}<\infty\) is the normalization constant",q(x)=\frac{\exp(-E(x))}{Z},"where $Z = \int \exp(-E(\mathbf{x})) \, d\mathbf{x}$ is the normalization constant, also known as the partition function."
neurips_2024_oral_34,3,\min_{\pi\in\Pi}KL(\pi(x) || p(x))=\max_{\pi\in\Pi}E _{\pi}[\log p(x)]+H(\pi(x)),"where \(\Pi\) is the set of feasible \(\pi(\mathbf{x})\)'s, and \(\mathcal{H}(\pi)=-\int\pi(\mathbf{x})\log\pi(\mathbf{x})d\mathbf{x}\) is the differential entropy",KL(\pi || p)=\int_{X}\pi(x)\log\left(\frac{\pi(x)}{p(x)}\right)dx,"which measures the dissimilarity between the diffusion model's distribution and the true data distribution, guiding the optimization of the diffusion process to enhance sample quality."
neurips_2024_oral_34,4,\min_{\pi\in\Pi}KL(\pi(x) || q(x))\quadand\quad\min_{ q\inQ}KL(p(x) || q(x)),where \(\mathcal{Q}\) is the feasible set of EBMs,\min_{q}KL(p(x) || q(x)),This minimization trains the energy-based model $q(\mathbf{x})$ to approximate the data distribution $p(\mathbf{x})$ by minimizing the Kullback-Leibler divergence.
neurips_2024_oral_34,5,\min_{q\inQ}\max_{\pi\in\Pi}KL(p(x) || q(x))-KL(\pi(x) || q(x)),,\min_{\pi\in\Pi}\max_{q\inQ}\E_{\pi}[\log q(x)]+H(\pi(x)),"This minimax formulation combines maximum entropy reinforcement learning with energy-based modeling, where the diffusion model $\pi(\mathbf{x})$ acts as the policy and the energy-based model $q(\mathbf{x})$ serves as the reward function."
neurips_2024_oral_34,6,KL(\pi_{\phi}(x_{T}) || q_{\theta}(x_{T}))\leq KL(\pi_{\phi}(x_{0:T}) || q_{\theta}(x_{T})\tilde{q}(x_{0:T-1}|x_{T})),,"\min_{\phi}\sum_{t=0}^{T-1}E_{\pi_{\phi}}\left[\frac{1}{2\tau}\left\|\mu_{\phi}(x_{t},t)-E_{\epsilon_{t}}[\mu_{\phi}(x_{t},t)]\right\|^{2}-\log\sigma_{t}\right]",This upper bound decomposes the KL divergence into a sum of terms involving the variance of the neural network output and the logarithm of the diffusion model's noise scale parameters.
neurips_2024_oral_34,7,"\tilde{q}(x_{0:T-1}|x_{T})=\prod_{t=0}^{T-1}\tilde{q}(x_{t}|x_{t+1}), where \tilde{q}(x_{t}|x_{t+1})=N(x_{t+1},s_{t}^{2}I),\quad s_{t}>0",,"\tilde{q}(x_{0:T-1}|x_{T})=\prod_{t=0}^{T-1}N(x_{t}|\alpha_{t}x_{t+1},\beta_{t}^{2}I)",where $\alpha_{t}\in\mathbb{R}$ and $\beta_{t}\in\mathbb{R}_{>0}$ are parameters of the auxiliary distribution
neurips_2024_oral_34,8,\min_{\phi}\mathop{E}_{\pi_{\phi}(x_{0:T})}[E_{\theta}(x_{T})+\tau\sum_{t=0}^{T-1}\log\pi_{\phi}(x_{t+1}|x _{t})+\tau\sum_{t=0}^{T-1}\frac{1}{2s_{t}^{2}} || x_{t+1}-x_ {t} || ^{2}],,\min_{\phi}E_{\pi_{\phi}(x_{0:T})}\left[E_{\theta}(x_{T})+\sum_{t=0}^{T-1}\frac{1}{2s_{t}^{2}}\|x_{t+1}-x_{t}\|^{2}\right],"This objective combines the energy term from the EBM with a sum of squared differences between consecutive states, regularized by the noise scales $s_t^2$."
neurips_2024_oral_34,9,V_{\psi}^{t}(x_{t})=E_{\pi}[E_{\theta}(x_{T})+\tau\sum_{t^{\prime}=t}^{T-1}\log\pi_{\phi}(x_{t^{\prime}+1}| x_{t^{\prime}})+\sum_{t^{\prime}=t}^{T-1}\frac{\tau}{2s_{t^{\prime}}^{2}} || x_{t^{\prime}+1}-x_{t^{\prime}} || ^{2}\bigg{|}x_{t} ],,V_{\psi}^{t}(x_{t})=E_{\pi_{\phi}(x_{t+1:T})}\left[ E_{\theta}(x_{T})+\tau\sum_{k=t}^{T-1}\log\pi_{\phi}(x_{k+1}|x_{k})+\tau\sum_{k=t}^{T-1}\frac{1}{2s_{k}^{2}} || x_{k+1}-x_{k} || ^{2}\right],"The value function $V_{\psi}^{t}(\mathbf{x}_{t})$ represents the expected cumulative cost from timestep $t$ to $T$, starting at state $\mathbf{x}_{t}$ and following the policy $\pi_{\phi}$ thereafter."
neurips_2024_oral_34,10,"\min_{\psi}E_{x_{t},x_{t+1}\sim\pi}[(sg[V_{\psi}^{t+1}(x_{t+1})]+\tau\log\pi_{\phi}(x_{t+1}|x _{t})+\frac{\tau}{2s_{t}^{2}} || x_{t}-x_{t+1} || ^{2}-V_{\psi}^ {t}(x_{t}))^{2}]",where \(\text{sg}[\cdot]\) denotes a stop-gradient operator indicating that gradient is not computed for the term,\min_{\psi}E_{\pi_{\phi}}\left[\left(V_{\psi}^{t}(x_{t})-\left(\tau\log\pi_{\phi}(x_{t+1}|x_{t})+\frac{\tau}{2s_{t}^{2}} || x_{t+1}-x_{t} || ^{2}+V_{\psi}^{t+1}(x_{t+1})\right)\right)^{2}\right],Policy evaluation minimizes the Bellman residual to update the value function parameters $\psi$ for each timestep $t$ using the current diffusion model $\pi_{\phi}$.
neurips_2024_oral_34,11,\min_{\phi}E_{\pi_{\phi}(x_{t+1}|x_{t})}[V_{\psi}^{t+1}(x_{t+1})+\tau\log\pi_{\phi}(x_{t+1}|x _{t})+\frac{\tau}{2s_{t}^{2}} || x_{t}-x_{t+1} || ^{2}\bigg{|}x_{t}],,"\min_{\phi}E_{x_{t},x_{t+1}\sim\pi_{\phi}}\left[V_{\psi}^{t+1}(x_{t+1})+\tau\log\pi_{\phi}(x_{t+1}|x_{t})+\frac{\tau}{2s_{t}^{2}}\|x_{t+1}-x_{t}\|^{2}\right]",where the policy improvement step minimizes the expected future costs using the updated value function and running costs
neurips_2024_oral_34,12,"\min_{\psi}E_{x_{t},x_{t+1}\sim\pi}[(sg[V_{\psi}(x_{t+1})]+R(t)-V_{\psi}(x_{t}))^{2}]",,"\min_{\psi}E_{x_{t},x_{t+1}\sim\pi}[(sg[V_{\psi}(x_{t+1})]+R(t)-V_{\psi}(x_{t}))^{2}]",modified value update equation with time cost function $R(t)$ replacing running cost terms in policy evaluation step
neurips_2024_oral_35,1,"varrowCrossAttention(Q=\{v\},K=\{p_{i}^{v}\}_{i=1}^{m}+\{v\},V=\{ p_{i}^{v}\}_{i=1}^{m}+\{v\})","Where \(v\) denotes a 3D voxel feature, and \(p_{i}^{v}\) denotes its projected 2D pixel feature from view \(i\), which is a concatenation of the RGB feature \(f_{i}^{v}\), the normal feature \(g_{i}^{v}\), and the RGB and normal values \(c_{i}^{v}\) and \(n_{i}^{v}\), respectively","F^{3D}_{i}=CrossAttention\left(Q_i,\left[K_{i,0},K_{i,1},\dots,K_{i,m}\right],\left[V_{i,0},V_{i,1},\dots,V_{i,m}\right]\right)","Equation 1 formulates the projection-aware cross-attention mechanism, where each 3D voxel feature is updated through cross-attention over a set of 2D multi-view features and its own key and value."
neurips_2024_oral_35,2,L=\lambda_{1}L_{MSE}^{color}+\lambda_{2 }L_{LPIPS}^{color}+\lambda_{3}L_{MSE}^{normal}+\lambda_{4}L_{LPIPS}^{normal}+\lambda_{5}L_{occ}+\lambda_{6}L _{SDF},"where \(L_{\mathrm{occ}}\) and \(L_{\mathrm{SDF}}\) are MSE losses for occupancy and SDF volumes, and \(\lambda_{i}\) denotes the weight of each loss term",L=\lambda_{rgb}L_{rgb}+\lambda_{normal}L_{normal}+\lambda_{reg}L_{reg}+\lambda_{SDF}L_{SDF},"The total training loss combines RGB rendering loss, normal rendering loss, regularization loss, and SDF supervision loss, each weighted by corresponding coefficients."
neurips_2024_oral_40,1,"m_{Ada}(\varepsilon,\delta)=O\Bigg{(}\frac{d\ln(\frac{d}{\varepsilon\gamma})\ln(\frac{1}{\varepsilon\gamma})}{\gamma^{2}\varepsilon}+\frac{\ln(1/\delta)}{\varepsilon}\Bigg{)}",,"m_{Ada}(\varepsilon,\delta)=\tilde{O}\left(\frac{d}{\gamma^2}\left(\log\left(\frac{1}{\delta}\right)+\log\left(\frac{1}{\varepsilon}\right)\right)\right)","Equation 1 defines the sample complexity of AdaBoost as a function of VC-dimension $d$, weak learner edge $\gamma$, accuracy $\varepsilon$, and confidence $\delta$, with $\tilde{O}$ suppressing logarithmic factors."
neurips_2024_oral_40,2,L_{D}(f)=O\bigg{(}\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},,L_{D}(f)\leq\tilde{O}\left(\frac{d\ln^2(1/\gamma)}{\gamma^2 m}\right),"This equation specifies the target generalization error bound for the output classifier $f$ in terms of the sample size $m$, the VC-dimension $d$, and the weak learning advantage $\gamma$, aiming to match the near-optimal sample complexity of AdaBoost up to logarithmic factors."
neurips_2024_oral_40,3,p=O\bigg{(}\frac{\ln m}{\gamma^{2}R}\bigg{)}\qquadand\qquad t=e^{O(dR)}\cdot\ln\frac{\ln m}{\delta\gamma^{2}},,L_{D}(f)=O\left(\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\right),"This equation specifies the desired bound on the expected loss of the output classifier $f$ in terms of the sample size $m$, the VC-dimension $d$, the weak learning parameter $\gamma$, and the confidence parameter $\delta$, which the proposed algorithm aims to achieve with improved parallel complexity."
neurips_2024_oral_40,4,L_{D}(A_{R}(S))=O\bigg{(}\frac {d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},,L_{D}(f)=O\bigg{(}\frac{dR\ln(m)\ln\big{(}\frac{\ln m}{\delta\gamma^{2}}\big{)}+\ln(1/\delta)}{\gamma^{2}m}\bigg{)},"This equation characterizes the expected loss of the output classifier $f$ produced by the parallel weak-to-strong learning algorithm $\mathcal{A}_R$, showing how the loss depends on the number of rounds $p$, the number of queries per round $t$, the VC-dimension $d$, the weak learning advantage $\gamma$, the number of samples $m$, and the confidence parameter $\delta$."
neurips_2024_oral_40,5,p\ln t=O\bigg{(}\frac{d\ln m}{\gamma^{2}}\bigg{)},,t=e^{O(dR)}\qquadand\qquad p=O\bigg{(}\frac{\ln m}{\gamma^{2}R}\bigg{)},"This equation presents the clean tradeoff between the number of parallel rounds $p$ and the total parallel work per round $t$ achieved by the proposed algorithm, improving upon previous bounds by a factor of $R$ in the exponent of $t$."
neurips_2024_oral_40,6,"p\geq\frac{4\ln m}{\gamma^{2}R},\qquadand\qquad t\geq e^{16C_{ a}dR}\cdot R\ln\frac{pR}{\delta}",,p\ln t=\Omega\left(\frac{d\ln m}{\gamma^{2}}\right),"This lower bound matches the upper bound tradeoff from Theorem 1.1, showing the tightness of the parallel complexity in terms of the product of rounds and logarithm of parallel queries."
neurips_2024_oral_40,7,L_{D}(sign(g))\leq C\cdot\frac{d\ln(m)\ln(m/d)+\ln(1/\delta)}{\gamma^{2}m},,L_{D}(sign(g))\leq\frac{C}{m}\Bigg{(}d\ln\Big{(}\frac{m}{d}\Big{)}\ln(m)+\ln\Big{(}\frac{1}{\delta}\Big{)}\Bigg{)},"This bound relates the generalization error of a voting classifier to the margins achieved on the training data, ensuring that large margins lead to better generalization."
neurips_2024_oral_40,8,|L_{D}(h)-L_{T}(h)|\leq\varepsilon,where \(\mathcal{L}_{T}(h)\coloneqq\mathcal{L}_{\mathrm{Uniform}(T)}(h)\) is the empirical loss of \(h\) on \(T\),\left|\Pr_{x\simD}[h(x)\neq c(x)]-\Pr_{x\sim T}[h(x)\neq c(x)]\right|\leq\varepsilon,
neurips_2024_oral_40,9,"D_{\infty}(D_{r},D_{0})\coloneqq\ln\bigl{(}\sup_{x\inX}D_{ r}(x)/D_{0}(x)\bigr{)}",,L_{D_{0}}(h)\leqL_{T}(h)+\gamma/2\leq 1/2-\gamma+\gamma/2=1/2-\gamma/2,"This inequality demonstrates that a hypothesis $h$ with advantage $\gamma$ on a $\gamma/2$-approximation $\mathbf{T}$ of $D_0$ also has advantage $\gamma/2$ on the full dataset $S$ under $D_0$, enabling the simulation of a $\gamma/2$-weak learner using bagging."
neurips_2024_oral_40,10,KL(D_{r}\parallel D_{0})\coloneqq\sum_{x\inX}D_{r}(x)\ln\frac{D_{r}(x)}{D_{0}(x)},,D_{KL}(D_{r}\parallel D_{0})\coloneqq\sum_{x\inX}D_{ r}(x)\ln\frac{D_{r}(x)}{D_{0}(x)},
neurips_2024_oral_40,11,\lnE_{P}\big{[}e^{X}\big{]}\geqE_{Q}[X]-KL(Q\parallel P),,E_{P}[X]\leqKL(P\parallel Q)+\lnE_{Q}[e^{X}],Lemma 2.4 provides a duality formula that upper bounds the expectation of a random variable under distribution $P$ in terms of the Kullback-Leibler divergence between $P$ and $Q$ and the log moment generating function under $Q$.
neurips_2024_oral_40,12,KL(D\parallel\tilde{D})\leq 4\gamma^{2}R,,KL(\tilde{D}\parallel D)\leq\frac{\gamma^{2}n}{C_{n}dR},Upper bound on the KL divergence between distributions ensuring a sufficiently high probability of sampling a Î³/2-approximation for D when sampling from DÌ
neurips_2024_oral_40,13,\Pr_{T\sim\tilde{D}^{n}}[T\inG]\geq\exp(-16C_{n}dR),,\Pr_{T\sim\tilde{D}^{n}}[T contains at least one \gamma/2-approximation for D]\geq 1-e^{-R},"Probability that a subsample $\mathbf{T}$ drawn from $\tilde{D}^n$ contains at least one $\gamma/2$-approximation for $D$, given that the KL divergence between $D$ and $\tilde{D}$ is bounded by $4\gamma^2 R$, and $n$ is sufficiently large in terms of $d$ and $\gamma$."
neurips_2024_oral_41,1,\min_{x\inR^{d}_{c}}\phi(x),where \(\phi:\mathbb{R}^{d}\rightarrow\mathbb{R}\) is a differentiable function bounded from below (e,\min_{x}\phi(x),Equation 1: Objective function minimization problem
neurips_2024_oral_41,2,x_{i}=x_{j}\quad\Leftrightarrow\quad\exists k\;:\;i\in P_{k} and j\in P_{k},,"R^{d}_{c} :=\{x\inR^{d} : |V(x)|=c\},\quadwhere  V(x) :=\{x_1,\dots, x_d\}",defines the set of all vectors in $\mathbb{R}^d$ whose entries take exactly $c$ distinct values.
neurips_2024_oral_41,3,"M_{P}(x)=M_{P,\phi}(x):=\arg\min_{y\inR^{d}}\{\phi(y)\,:\,P(y)\sqsupseteq P (x)\}",,"M_{P}(x):=\{y\inR^{d}\:\\forall i,j,\\delta_{ij}(x)=1\Rightarrow y_{i}=y_{j}\}",defines the set of vectors $y$ that preserve the partition structure of $x$ by enforcing equality among components within each partition subset.
neurips_2024_oral_41,4,"M_{V}(y)=M_{V,\phi}(y):=\arg\min_{x\inR^{d}}\{\phi(x)\,:\,V(x)\subseteq V (y)\}",,"M_{V}(y)=M_{V,\phi}(y):=\arg\min_{x\inR^{d}}\{\phi(x)\,:\,V(x)=V(y)\}",which finds the minimizer of $\phi(x)$ subject to the constraint that the set of distinct values in $x$ matches that of $y$.
neurips_2024_oral_41,5,"\phi(x)\approx\widetilde{\phi}_{y}(x):=\phi(y)+\langle\nabla\phi(y),x-y\rangle+\tfrac{L}{2}\norm{x-y}^{2}",where \(L>0\) is a sufficiently large constant,"M_{V}(y)\approx\arg\min_{x\inR^{d}_{c},\,V(x)\subseteq V(y)}\left\{\phi(y)+\nabla\phi(y)^{\top}(x-y)\right\}",Approximation of the V step by solving a discrete least squares problem using a linearization of $\phi$ around $y$.
neurips_2024_oral_41,6,"M_{V,\phi}(y)\overset{\eqref{eq:v_def}}{\approx}M_{V,\widetilde{\phi}_{y}}(y )\overset{\eqref{eq:v_def}}{=}\arg\min_{x\inR^{d}}\{\widetilde{\phi}_{y}(x)\:\V(x)\subseteq V(y)\}",,"\widetilde{M}_{V}(y):=\arg\min_{x\inR^{d}}\left\{\widetilde{\phi}_{y}(x)\,:\,V(x)\subseteq V(y)\right\}","This defines the linearized V step, which approximates the original discrete optimization problem using a convex quadratic surrogate function derived from the gradient and Hessian of $\phi$ at $y$."
neurips_2024_oral_41,7,\widehat{\phi}_{y}(x):=\norm{x-(y-\tfrac{1}{L}\nabla\phi(y))}^{2}=\norm{x-y^{+}}^{2}=\sum\limits_{i=1}^{d}(x_{i}-y_{i}^{+})^{2},,\widehat{\phi}_{y}(x):=\tfrac{L}{2}\norm{x-\left(y-\tfrac{1}{L}\nabla\phi(y)\right)}^{2},defines a simplified quadratic surrogate function based on the gradient descent update
neurips_2024_oral_41,8,"x:=M_{V,\phi}(y)\approx M_{V,\widehat{\phi}_{y}}(y):=\hat{x}",,"x=M_{V,\phi}(y)\approx M_{V,\widehat{\phi}_{y}}(y):=\arg\min_{x\inR^{d}}\left\{\sum\limits_{i=1}^{d}(x_{i}-y_{i}^{+})^{2}\:\V(x)\subseteq V(y)\right\}","where $y^{+} = y - \frac{1}{L}\nabla\phi(y)$ is the gradient descent update of $y$ with learning rate $\frac{1}{L}$, and the minimization enforces that the values in $x$ are a subset of those in $y$."
neurips_2024_oral_41,9,"\phi(x)\leq\phi(y)+\langle\nabla\phi(y),x-y\rangle+\tfrac{L}{2}\norm{x-y}^{2},\qquad\forall x,y\inR^{d}_{\leq c}",,"\|\nabla\phi(x)-\nabla\phi(y)\|\leq L\|x-y\|\quad\forall x,y\inR^{d}_{\leq c}","Equation 9 defines the $L$-smoothness condition on the gradient of $\phi$ over the set $\mathbb{R}^{d}_{\leq c}$, ensuring that the linearized V step approximation is well-justified and stable under small perturbations."
neurips_2024_oral_42,2,"\hat{B}_{T}^{\pi}\hat{Q}(\hat{s},\hat{a}):=\hat{r}-\eta_{R }R_{R}(\hat{s},\hat{a})-\eta_{T}R_{T}(\hat{s},\hat{a})+\gammaE_{\hat{s}^{\prime}\simD_{img},a^{\prime}\sim\pi_{k}(a^{\prime}|\hat{s}^{\prime})}[Q(\hat{s}^{\prime},a^{\prime})]","where \(\hat{s}^{\prime}\sim\mathcal{D}_{\mathrm{img}}\) is to sample the next state given \(\hat{s},\hat{a}\), \(\eta_{R}\) and \(\eta_{T}\) are two hyper-parameters to control the weighting of the uncertainty terms","\hat{Q}^{k}(\hat{s},\hat{a})=\hat{r}(\hat{s},\hat{a})+\gammaE_{\hat{s}'\simM_{T}}[\hat{V}^{k}(\hat{s}')]-\beta_{R}R_{R}(\hat{s},\hat{a})-\beta_{T}R_{T}(\hat{s},\hat{a})","The updated Q-value estimate incorporates reward and transition uncertainty regularization terms scaled by coefficients $\beta_{R}$ and $\beta_{T}$, respectively."
neurips_2024_oral_48,1,"x_{0}=x,\quadx_{\ell}=\sigma_{\ell}(W _{\ell}x_{\ell-1}+b_{\ell}),\quad u_{G,\theta}(x)=x_{L}","where \(L\): the number of layers, \(\mathbf{W}_{i}\in\mathbb{R}^{d_{\ell}\times d_{\ell-1}}\): the weights of the NN, \(\mathbf{b}_{i}\in\mathbb{R}^{d_{\ell}}\): the biases of the NN, \(d_{0}=d_{\text{in}}\), \(d_{L}=d_{\text{out}}\), \(\sigma_{\ell}:\mathbb{R}\to\mathbb{R}\) activation functions applied element-wise","u_{G,\theta}(x)=W_L\sigma(W_{L-1}\sigma(\cdots\sigma(W_1x+b_1)\cdots )+b_{L-1})+b_L","Feedforward Neural Network (FFNN) expressed as a composition of affine transformations and non-linear activation functions, where $\sigma$ denotes the non-linearity, $\mathbf{W}_l$ and $\mathbf{b}_l$ are the weight matrices and bias vectors at layer $l$, and $L$ is the total number of layers."
neurips_2024_oral_48,2,"W_{\ell}^{\prime}=P_{\ell}W_{\ell}P_{\ell-1}^{-1},\,b_{\ell}^{\prime}=P_{\ell}b_{\ell}\Longrightarrow(W_{\ell}^{\prime},b_{\ell}^{\prime})_ {\ell=1}^{L}=\theta^{\prime}\simeq\theta=(W_ {\ell},b_{\ell})_{\ell=1}^{L}","where \(\ell\in\{1,\ldots,L\}\), \(\mathbf{P}_{0}=\mathbf{P}_{L}=\mathbf{I}\) and \(\mathbf{P}_{\ell}\in\mathbb{R}^{d_{\ell}\times d_{\ell}}\) are arbitrary permutation matrices","\forall\pi=\left(\pi_{1},\ldots,\pi_{L-1}\right)\in\prod_{\ell=1}^{L-1}S_{d_{\ell}},\quad u_{G,\theta}\left(x\right)=u_{G,\theta^{\pi}}\left(x\right)","where $\boldsymbol{\pi}$ denotes a tuple of permutations applied to hidden neurons in each layer, and $\boldsymbol{\theta}^{\boldsymbol{\pi}}$ represents the permuted parameters preserving the network function."
neurips_2024_oral_48,4,"m_{V}^{t}(i)=\bigoplus_{j\inN(i)}\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!\!where\(h_{V}^{i},h_{E}^{i}\) are vertex and edge representations at iteration\(t\) and\(h_{G}\) is the overall graph (NN) representation. INIT, MSG, UPD are general function approximators (e.g. MLPs), while READ is a permutation invariant aggregator (e.g. DeepSets [81]). The above equations have appeared with several variations in the literature, e.g. in some cases the edge representations are not updated or the readout input involve edge representations as well. Another frequent strategy is to use _positional encodings_\(p_{V},p_{E}\) to break undesired symmetries. In FFNNs, Eq. (2) reveals that input and output vertices are not permutable, while vertices cannot be permuted across layers. Therefore, vertices (or edges) that are permutable share the same positional encoding (see Appendix A.1.2 for more details).**Remark:**Although, typically, the neighbourhood\(N(i)\) contains both incoming and outgoing edges, in Section 5 we will illustrate our method using only incoming edges: _forward neighbourhood_\(N_{FW}(i)=\{j\inV\midlayer\,(i)- layer\,(j)=1\}\) and _backward_ where layer\((i)\) gives the layer neuron\(i\) belongs. Backward neighbourhoods\(N_{BW}(i)\) are defined defined similarly. In Appendix A.2, we show a more elaborate _bidirectional version_ of our method, with both neighbourhoods considered. ## 4 Scaling symmetries in Feedforward Neural Networks**Scaling symmetries (activation functions).**Intuitively, permutation symmetries stem from the _graph structure_ of neural networks, or put differently, from the fact that hidden neurons do not possess any inherent ordering. Apart from the affine layers\(W_{\ell}\) that give rise to the graph structure, it is frequently the case that**activation functions**\(\sigma_{\ell}\) have inherent symmetries that are bestowed to the NN. Let us dive into certain illustrative examples: for the ReLU activation\(\sigma(x)=\max(x,0)\) it holds that\(\sigma(ax)=\max(ax,0)=a\max(x,0),\\forall a>0\). For the tanh and sine activations\(\sigma(x)=\tanh(x)\),\(\sigma(x)=\sin(x)\) respectively, it holds that\(\sigma(ax)=a\sigma(x),\\forall a\in\{-1,1\}\). In a slightly more complex example, polynomial activations\(\sigma(x)=x^{k}\), we have\(\sigma(ax)=a^{d}\sigma(x)\), i.e. the multiplier differs between input and output. In general, we will be talking about _scaling symmetries_ whenever there exist pairs\((a,b)\) for which it holds that\(\sigma(ax)=b\sigma(x)\). To see how such properties affect NN symmetries, let us focus on FFNNs (see Appendix A.3 for CNNs): for a neuron\(i\) (we omit layer subscripts) we have\(\sigma\big{(}aW(i,:)x+ab(i)\big{)}=\textit{b}\big{(}W(i,:)x+b(i)\big{)}\), i.e. _multiplying its bias and all incoming weights with a constant a results in scaling its output with a corresponding constant\(b\)_. Generalising this to linear transformations, we may ask the following: which are the pairs of matrices\((A,B)\) for which we have\(\sigma\big{(}AWx+Ab\big{)}=B\sigma\big{(}Wx+b\big{)}\)? Godfrey et al. [25] provide an answer for _any activation that respects certain conditions_. We restate here their most important results:**Proposition 4.1**(Lemma 3.1. and Theorem E.14 from [25]).: _Consider an activation function\(\sigma:R\toR\). Under mild conditions,5 the following hold:_ Footnote 5: See Appendix A.7.1 for the precise statement and more details about\(\phi_{\sigma,d}\).*_For any_\(d\inN^{+}\)_, there exists a (non-empty) group of invertible matrices defined as:_\(I_{\sigma,d}=\{A\inR^{d\times d}: invertible\mid\exists\B\inR^{d\times d} invertible, such that: \sigma(Ax)=B\sigma(x)\}\) _(_intertwiner group_)_, and a mapping function_\(\phi_{\sigma,d}\) _such that_\(B=\phi_{\sigma,d}(A)\)_._*_Every_\(A\in I_{\sigma,d}\) _is of the form_\(PQ\)_, where_\(P\)_: permutation matrix and_\(Q=\textit{diag}\big{(}q_{1},\ldots q_{d}\big{)}\) _diagonal, with_\(q_{i}\in D_{\sigma}=\{a\inR\setminus\{0\}\mid\sigma(ax)=\phi_{\sigma,1}(a)\sigma(x)\}\)_: the 1-dimensional group, and_\(\phi_{\sigma,d}(A)=P\textit{diag}\big{(}\phi_{\sigma,1}(q_{1} ),\ldots\phi_{\sigma,1}(q_{d})\big{)}\)_._ This is a powerful result that completely answers the question above for most practical activation functions. Importantly, not only does it recover permutation symmetries, but also reveals symmetries to diagonal matrix groups, which can be identified by solely examining\(\phi_{\sigma,1}\), i.e. the one-dimensional case and the set\(D_{\sigma}\) (easily proved to be a group) we have already discussed in our examples above. Using this statement, Godfrey et al. [25] characterised various activation functions (or recovered existing results), e.g. ReLU:\(I_{\sigma,d}\) contains**generalised permutation matrices with positive entries**of the form\(PQ\),\(Q=diag(q_{1},\ldots,q_{d})\),\(q_{i}>0\) and\(\phi_{\sigma,d}(PQ)=PQ\)[56]. Additionally, here we characterise the intertwiner group of sine (used in the popular SIREN architecture [70] for INRs). Not surprisingly, it has the same intertwiner group with tanh [11, 21] (we also recover this here using Proposition 4.1). Formally, (proof in Appendix A.7.1):**Corollary 4.2**.: _Hyperbolic tangent\(\sigma(x)=\tanh(x)\) and sine activation\(\sigma(x)=\sin(\omega x)\), satisfy the conditions of Proposition 4.1, when (for the latter)\(\omega\neq k\pi,k\inZ\). Additionally,\(I_{\sigma,d}\) contains**signed permutation matrices**of the form\(PQ\), with\(Q=diag(q_{1},\ldots,q_{d})\),\(q_{i}=\pm 1\) and\(\phi_{\sigma_{d}}(PQ)=PQ\)._It is straightforward to see that the symmetries of Proposition 4.1, induce equivalent parameterisations for FNNs. In particular, it follows directly from Proposition 3.4. in [25], that for activation functions\(\sigma_{\ell}\) satisfying the conditions of Proposition 4.1 and when\(\phi_{\sigma,\ell}(Q)=Q\), we have that:\[W^{\prime}_{\ell}=P_{\ell}Q_{\ell}W_{\ell}Q_{\ell-1}^{-1}P_{\ell-1}^{-1},\;b^{\prime}_{\ell}=P_{\ell}Q_{\ell}b_{\ell}\implies(W^{\prime }_{\ell},b^{\prime}_{\ell})_{\ell=1}^{L}=\theta^{\prime}\simeq\theta=(W_{\ell},b_{\ell})_{\ell=1}^{L}","where again \(\ell\in\{1,\ldots,L\}\), \(\mathbf{P}_{0}=\mathbf{Q}_{0}=\mathbf{P}_{L}=\mathbf{Q}_{L}=\mathbf{I}\)","h_{V}^{t+1}(i)=UPDATE_{V}\left(h_{V}^{t}(i),\bigoplus_{j:(i,j)\inE}h_{E}^{t}(i,j)\right),\quadh_{E}^{t+1}(i,j)=UPDATE_{E}\left(h_{E}^{t}(i,j),h_{V}^{t}(i),h_{V}^{t}(j)\right)","where $t = 0, \dots, T-1$, and $\bigoplus$ denotes a permutation-invariant aggregation (e.g., sum, mean, or max) over incoming edge features"
neurips_2024_oral_48,5,"h^{\prime}_{V}(i)=q_{\ell}(\pi_{\ell}(i))h_{V} (\pi_{\ell}(i)),\quad\ell=layer(i)\in\{1,\ldots,L-1\} || h^{\prime}_{E}(i,j)=q_{\ell}(\pi_{\ell}(i))h_{E} (\pi_{\ell}(i),\pi_{\ell-1}(j))q_{\ell-1}^{-1}(\pi_{\ell-1}(j)),\;\ell=layer(i)\in\{2,\ldots,L-1\}",,"h_{V}(i)\mapstoP_{\ell}Q_{\ell}h_{V}(i ),\quadh_{E}(i,j)\mapstoP_{\ell}Q_{\ell}h _{E}(i,j)Q_{\ell-1}^{-1}P_{\ell-1}^{-1}","Transformation rules for vertex and edge representations under permutation and scaling symmetries, ensuring equivariance in the proposed Graph Metanetwork architecture."
neurips_2024_oral_48,7,"ScaleInv^{k}(X)=\rho^{k}(\tilde{x }_{1},\ldots,\tilde{x}_{n})",,"g_{i}\big{(}q_{1}x_{1},\ldots,q_{n}x_{n}\big{)}=q_{i}g_{i}\big{(}x_{1},\ldots,x_{n}\big{)},\quad\forall q_{j}\in D_{j},\,j=1,\ldots,n","where $D_{i}$ is a 1-dimensional scaling group associated with the $i$-th input, e.g., $\mathbb{R}^+$ for ReLU or $\{\pm1\}$ for tanh/sine"
neurips_2024_oral_48,8,"ScaleEq=f^{K}\circ\cdots\circf^{1},\;f^{k}(X)=\big{(}\Gamma^{k}_{1}x_{1},\ldots,\Gamma^{k}_{n}x_{n}\big{)}\odotScalelInv^{k }(X)",,"ScaleInv^{k}(X)=\rho^{k}\left(\frac{x_{1}}{\|x_{1}\|},\ldots,\frac{x_{n}}{\|x_{n}\|}\right)","where $\rho^{k}$ is a scale-invariant function applied to normalised inputs $\tilde{\mathbf{x}}_{i}$, ensuring invariance under scaling transformations"
neurips_2024_oral_48,9,"g\big{(}q_{1}x_{1},\ldots q_{n}x_{n}\big{)}=g(x_{1},\ldotsx_{n})\prod_{i=1}^{n}q_{i},\forall q_{i}\in D_{i}",,"ScaleEq=f^{K}\circ\cdots\circf^{1},\;f^{k}(X)=\big{(}\Gamma^{k}_{1}x_{1},\ldots,\Gamma^{k}_{n}x_{n}\big{)}\odotScaleInv^{k }(X)","where $\rho^{k}:\prod_{i=1}^{n}\mathcal{X}_{i}\rightarrow\mathbb{R}^{\sum_{i=1}^{n} d_{i}^{k}}$ are universal approximators (e.g., MLPs), $\boldsymbol{\Gamma}^{k}_{i}:\mathcal{X}_{i}\rightarrow\mathbb{R}^{d_{i}^{k}}$ are linear transforms, and $\tilde{\mathbf{x}}_{i}$ are canonicalized/symmetrized inputs ensuring scale invariance"
neurips_2024_oral_48,10,"ReScaleEq(x_{1},\ldotsx_{n})=ScaleEq\big{(}vec(\textbf{X}_{n})\big{)}",,"g(x_{1},\ldots,x_{n})=\langle\textbf{W},x_{1}\otimes\cdots\otimesx_{n}\rangle=\sum_{j_{1},\ldots,j_{n}}\textbf{W }(j_{1},\ldots,j_{n})\prod_{i=1}^{n}x_{i}(j_{i})","where \(\textbf{W}\) is a learnable tensor and the inner product is taken over all indices, enabling rescale equivariance through the outer product structure."
neurips_2024_oral_48,11,"MSG_{V}(x,y,e)=ScaleEq ([x,ReScaleEq(y,e) ])","where \([\cdot,\cdot]\) denotes concatenation, \(\mathsf{ReScaleEq}(q_{y}\mathbf{y},q_{x}q_{y}^{-1}\mathbf{e})=q_{x}\mathsf{ ReScaleEq}(\mathbf{y},\mathbf{e})\)","MSG_{V}(x,y,e)=ReScaleEq\left(x,e\odoty\right)",Message function ensuring scale equivariance by combining vertex and edge representations through rescale-equivariant operations.
neurips_2024_oral_48,12,"UPD_{V}(x,m)=ScaleEq( [x,m])",,"UPD_{V}(x,m)=ScaleEq([x,m])",Update function that ensures scale equivariance by applying a scale-equivariant network to the concatenation of the vertex representation and the aggregated message.
neurips_2024_oral_48,13,"READ_{V}(X):=DeepSets(\tilde{x}_{1},\ldots,\tilde{x}_{n}),\quad\tilde{x}_{ i}=canon_{i}(x_{i}) or \tilde{x}_{i}=symm_{i}(x_{i})",,READ(\{h_{V}(i)\}_{i\inV})=\rho\left(\sum_{i\inV}canon(h_{V}(i))\right),"where $\rho$ is a universal approximator (e.g., an MLP) and $\mathsf{canon}$ is a canonicalisation function ensuring scale invariance."
neurips_2024_oral_54,2,"(TQ)(s,a)=r(s,a)+\gamma\cdotE_{s^{\prime}\sim P(\cdot|s,a) }[\max_{a^{\prime}\inA}Q(s^{\prime},a^{\prime})]",,"Q^{\star}(s,a)=TQ^{\star}(s,a) :=r(s,a)+\gammaE_{s'\sim P(\cdot|s,a)}\left[\max_{a'} Q^{\star}(s',a')\right]",where the Bellman operator $\mathcal{T}$ acts on the optimal Q-function $Q^{\star}$ by combining the immediate reward and the expected discounted future rewards under the optimal action selection.
neurips_2024_oral_54,3,"(T_{Z}Q)(s,a)=r(s,a)+\gamma V(Z(s,a))","where \(V(s^{\prime})=\max_{a^{\prime}\in\mathcal{A}}Q(s^{\prime},a^{\prime})\)","(T_{Z}Q)(s,a)=r(s,a)+\gamma\cdot\max_{a^{\prime}\inA}Q(Z_{(s,a)},a^{\prime})","where $Z_{(s,a)}$ denotes the $(s,a)^{\text{th}}$ coordinate of the random vector $Z$, representing a sampled next state from the transition distribution $P(\cdot|s,a)$."
neurips_2024_oral_54,4,"ER(A;N,M):=\sup_{M=(P,r)}E[\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty }]",where the expectation is taken over the samples and any randomness in the algorithm,"ER(A;N,M):=\sup_{M}E\left[\left\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\right\|_{\infty}\right]",where the supremum is taken over all MDPs $\mathcal{M}$ and the expectation is over the randomness in the samples and the algorithm $\mathscr{A}$.
neurips_2024_oral_54,5,"SC(A;\varepsilon,M):=|S || A|\cdot\min\{N\inN:ER(A;N,M)\leq\varepsilon\}",,"SC(A;\varepsilon,M):=\inf\{N\geq 0:ER(A;N,M)\leq\varepsilon\}",the smallest number of samples per agent required to achieve an $\varepsilon$-optimal estimate of the optimal Q-function in the $\ell_{\infty}$ sense
neurips_2024_oral_54,6,"SC(A;\varepsilon,M,\delta):=|S || A|\cdot\min\{N\inN:\Pr(\sup_{M}\|\widehat{Q}_{M}(A,N,M)-Q^{\star}_{M}\|_{\infty}\leq\varepsilon)\geq 1-\delta\}",,"ER(A;N,M,\delta):=\sup_{M=(P,r)}\inf\left\{\varepsilon>0:P\left(\|\widehat{Q}_{M}(A,N,M)-Q^{\star }_{M}\|_{\infty}>\varepsilon\right)\leq\delta\right\}",where the probability is taken over the samples and any randomness in the algorithm
neurips_2024_oral_54,7,CC_{round}(A;N):=\frac{1}{M}\sum_{m=1}^{M}C^{m}_{round}(A;N);\quadCC_{bit}(A;N ):=\frac{1}{M}\sum_{m=1}^{M}C^{m}_{bit}(A;N),,"C_{round}(A;N,M):=\max_{1\leq m\leq M}C^{m}_{round}(A;N),\quad C_{bit}(A;N,M):=\sum_{m=1}^{M}C^{m}_{bit}(A;N)","where the first term captures the maximum number of communication rounds any agent participates in, and the second term captures the total number of bits uploaded across all agents"
neurips_2024_oral_54,8,Q_{t-\frac{1}{2}}^{m}=(1-\eta_{t})Q_{t-1}^{m}+\frac{\eta_{t}}{B}\sum_{b=1}^{B}T_{Zs}(Q_{t-1}^{m}),,\overline{Q}_{t}^{m}=Q_{t-1}^{m}+\eta_{t}\cdot\left(\frac{1}{B}\sum_{b=1}^{B}\widehat{T}_{Z_{b}^{m}}(Q_{t-1}^{m})-Q_{t-1}^{m}\right),Intermediate local Q-learning update at agent $m$ using a minibatch of $B$ samples and the current estimate $Q_{t-1}^{m}$.
neurips_2024_oral_54,9,"Q_{t}^{m}=\frac{1}{M}\sum_{j=1}^{M}Q_{t-\frac{1}{2}}^{j}& if t\inC,\\Q_{t-\frac{1}{2}}^{m}& otherwise.",,"Q_{t}^{m}=\frac{1}{M}\sum_{m^{\prime}=1}^{M}Q_{t-\frac{1}{2}}^{m^{\prime}},\quadif t\inC,\quadand\quad Q_{t}^{m}=Q_{t-\frac{1}{2}}^{m},\quadotherwise","Agents either update their local estimate by averaging the intermediate estimates across all agents if a communication round occurs at time $t$, or retain their intermediate estimate otherwise."
neurips_2024_oral_54,10,R=\textsf{CC}_{\textsf{round}}(A;N)\leq\frac{c_{0}}{(1-\gamma)\log ^{2}N}; or\textsf{CC}_{\textsf{left}}(A;N)\leq\frac{c_{1}|S || A|}{(1-\gamma)\log^{2}N},,\varepsilon\leq\frac{1}{4(1-\gamma)^{1/2}(T)^{1/2}},upper bound on the target error level $\varepsilon$ in terms of the time horizon $T$ and the discount factor $\gamma$
neurips_2024_oral_54,11,"\textsf{ER}(A;N,M)\geq\frac{C_{\gamma}}{\log^{3}N\sqrt{N}}",,"ER(A;N,M)\geq\frac{c_{2}}{(1-\gamma)^{2}M\sqrt{N}}}",where $c_{2}>0$ is a universal constant.
neurips_2024_oral_56,1,"B_{Acc=K_{1}}(t|m)=\sup_{d}\{d|Acc(t|d,m)\leq K_{1}\}","where \(Acc(t|d,m)\) represents the accuracy of the model's accuracy on task \(t\) with difficulty \(d\)","RB(m, t)=\max\{ d\midAccuracy(m, t, d)\geq K_{1}\}",Equation 1 defines the reasoning boundary (RB) for a model $m$ and task $t$ as the maximum problem difficulty $d$ at which the model's accuracy remains above a threshold $K_{1}$.
neurips_2024_oral_56,2,"B_{Acc=K_{1}}(t_{1},t_{2},\dots,t_{n}|m)\approx\frac{1}{\sum _{i=1}^{n}\frac{N_{i}}{B_{Acc=K_{1}}(t_{i}|m)-b_{i}}}",where \(\mathcal{B}_{\text{Acc}=K_{1}}(t_{i}|m)\) denotes the reasoning boundary of model \(m\) for task \(t_{i}\),"B_{Acc=K_{1}}(t_{1},t_{2},\dots,t_{n}|m)=\prod_{i=1}^{n}B(t_i|m)",the unified reasoning boundary for multiple tasks is the product of individual reasoning boundaries for each task under the same model
neurips_2024_oral_56,3,"B^{\texttt{CGT}}(c,p)=\frac{1}{\frac{N_{1}}{(B(c)-b_{1})}+\frac{N_{2}}{(B(p)-b_{2})}}",,"B(t_{1},t_{2},\dots,t_{n}|m)\approx\frac{1}{\sum _{i=1}^{n}\frac{1}{B(t_{i}|m)}}","Equation 3 represents the simplified form of the combination law of reasoning boundary, where the combined reasoning boundary is approximated by the harmonic average of individual task reasoning boundaries."
neurips_2024_oral_56,4,"B^{Tool}(c,p)=\lim_{B(c)arrow+\infty}\frac{ 1}{\frac{N_{1}}{(B(c)-b_{1})}+\frac{N_{2}}{(B(p)-b_{2})}}=\frac{B(p)-b_{2}}{N_{2}}",,"B_{Acc=K_{1}}(t_{1},t_{2},\dots,t_{n}|m)\approx\frac{1}{\sum _{i=1}^{n}\frac{N_{i}}{B_{Acc=K_{1}}(t_{i}|m)-b_{i}}}",where $ \mathcal{B}_{\text{Acc}=K_{1}}(t_{i}|m) $ denotes the reasoning boundary of model $ m $ for task $ t_{i} $
neurips_2024_oral_57,1,"E_{t\simU[1,T],\;X^{0},C\sim q( X^{0},C)}(\|X^{0}-H(X^{t},t,C)\|^{2})","where \(t\) denotes the time step, \(\mathbf{X}^{0}=\mathbf{X}\) is the raw motion latent sequence, and \(\mathbf{X}^{t}\) is the noisy inputs generated by the diffusion forward process \(q(\mathbf{X}^{t}|\mathbf{X}^{t-1})=\mathcal{N}(\mathbf{X}^{t};\sqrt{1-\beta_{ t}}\mathbf{X}^{t-1},\beta_{t}\text{I})\)","L=E_{t,x_t,\epsilon}\left[\|\epsilon-\epsilon_\theta(x_t, t,A)\|^2\right]","where $\boldsymbol{\epsilon}_\theta$ is the neural network predicting the noise residual conditioned on the audio features $\mathbf{A}$, and $\mathcal{L}$ represents the expected loss over time steps $t$, noisy samples $\mathbf{x}_t$, and noise terms $\boldsymbol{\epsilon}$."
neurips_2024_oral_57,2,"\hat{X}^{0}=(1+\sum_{e\inC}\lambda_{e})\cdotH(X^{t},t,C)-\sum_{e\inC}\lambda_{c}\cdotH(X^{t},t,C|_{e=\emptyset})",,"C=[X^{pre},A^{pre};A,g, d,e]","Concatenated conditioning signal including previous motion and audio, current audio, gaze direction, head distance, and emotion offset."
neurips_2024_oral_58,1,"p(x_{1},x_{2},\dots,x_{T})=\prod_{t=1}^{T}p(x_{t}\mid x_{1},x_{2},\dots,x_{t-1 })",,P(x)=\prod_{t=1}^T P(x_t\mid x_{<t}),"The likelihood of a sequence $x$ factorized into the product of conditional probabilities of each token $x_t$ given its prefix, with $T$ tokens and vocabulary size $V$."
neurips_2024_oral_58,2,"f=E(im),\\\\\q=Q(f)","where \(im\) denotes the raw image, \(\mathcal{E}(\cdot)\) a encoder, and \(\mathcal{Q}(\cdot)\) a quantizer",q=Quantize(f)\in [V]^{h\times w},The quantization function maps a continuous feature map $f$ to a grid of discrete tokens $q$ from a vocabulary of size $V$.
neurips_2024_oral_58,3,"q^{(i,j)}=(\operatorname*{arg\,min}_{v\in[V]}\|lookup(Z,v)-f^{(i,j)}\|_{2})\in[V]","where \(\text{lookup}(Z,v)\) means taking the \(v\)-th vector in codebook \(Z\)","q^{(i,j)}=\arg\min_{k\in [V]}\|f^{(i,j)}-Z_k\|^2","where $Z_k$ denotes the $k$-th codevector in the codebook $Z$, and $\|\cdot\|^2$ represents the squared Euclidean distance used for nearest-neighbor quantization."
neurips_2024_oral_58,4,"\hat{f}=lookup(Z,q),\\\\\\\\\hat{im}=D(\hat{f}) || L=\|im-\hat{im}\|_{2}+\|f-\hat{f}\|_{2}+\lambda_{P}L_{P}(\hat{im})+\lambda_{G}L_{G}(\hat{im})",,"\hat{f}=lookup(Z,q),\\\\\\hat{im}=D(\hat{f}),\\\\\L=\underbrace{\|\hat{im}-im\|_{2}^{2}}_{reconstruction loss}+\beta\underbrace{\|sg[f]-\hat{f}\|_{2}^{2}}_{codebook loss}+\gamma\underbrace{\|sg[\hat{f}]-f\|_{2}^{2}}_{commitment loss}","where $\text{sg}[\cdot]$ denotes the stop-gradient operation, and $\beta,\gamma$ are weighting coefficients for the codebook and commitment losses, respectively."
neurips_2024_oral_58,5,"p(r_{1},r_{2},\dots,r_{K})=\prod_{k=1}^{K}p(r_{k}\mid r_{1},r_{2},\dots,r_{k-1 })","where each autoregressive unit \(r_{k}\in[V]^{h_{k}\times w_{k}}\) is the token map at scale \(k\) containing \(h_{k}\times w_{k}\) tokens, and the sequence \((r_{1},r_{2},\dots,r_{k-1})\) serves as the the ""prefix"" for \(r_{k}\)","p(r_{1},r_{2},\dots,r_{K})=\prod_{k=1}^{K}p(r_{k}\mid r_{1},r_{2},\dots,r_{k-1})","The joint probability of multi-scale token maps is factorized into a product of conditional probabilities, where each scale $r_k$ is predicted autoregressively based on all previous coarser scales $r_1, \dots, r_{k-1}$."
neurips_2024_oral_58,6,"w=64d,\qquad h=d,\qquad dr=0.1\cdot d/24",,"R=(r_{1},r_{2},\dots,r_{K})\simMulti-scale VQVAE(im)","where $R$ denotes the set of multi-scale token maps generated by the Multi-scale VQVAE from the input image $im$, with each $r_{k}$ representing a token map at resolution $h_{k}\times w_{k}$"
neurips_2024_oral_58,7,"N(d)=\underbrace{d\cdot 4w^{2}}_{self-attention}+\underbrace{d\cdot 8w^{2}} _{feed-forward}+\underbrace{d\cdot 6w^{2}}_{adaptive layernorm}=18\,dw^{2}=73728\,d^{3}",,N\approx 12dw^{2}+6w^{2}+6dw^{2}/d=18dw^{2}+6w^{2},"The main parameter count $N$ of a VAR transformer with depth $d$ is derived from the model's architecture components, including attention blocks and adaptive normalization layers."
neurips_2024_oral_59,1,"c^{(t+1)}(v)\gets f^{(t+1)}(c^{(t)}(v),g^{(t+1)}(\{\{c ^{(t)}(u)\mid u\inN(v)\}\}))",,"tags and the description in <description>. The example equation uses a function c_v^{(t)} that updates based on the previous color and the sum of colors from neighbors. I should follow that structure. Let me think about the notation. The node's color at iteration t would be c_v^{(t)}, and it's a function of the previous color c_v^{(t-1)} and the sum of the neighbors' colors. The function f is likely a neural network or some aggregation function. The equation should show the update rule. So, the left side would be c_v^{(t)}, and the right side would involve f applied to c_v^{(t-1)} and the sum over neighbors. The sum could be written as\sum_{u\in N(v)} c_u^{(t-1)}, where N(v) is the neighborhood of v. I need to make sure the LaTeX is correct. UseN(v) for the neighborhood? Or maybe just N(v). Let me check standard notation. In graph theory, N(v) is common for neighbors. Also, the description should be a one-sentence variable description. The example used ""where $f$ is a learnable function..."", so I should mirror that. Putting it all together: The equation is c_v^{(t)}=f\left(c_v^{(t-1)},\sum_{u\in N(v)} c_u^{(t-1)}\right). Check for proper LaTeX syntax. The subscript in the sum should be in braces if needed. Also, using\left and\right for parentheses. Yes, that looks right. The description would explain that f is learnable and how the node's color is updated based on its previous state and neighbors' colors. </think>",". The example equation uses a function c_v^{(t)} that updates based on the previous color and the sum of colors from neighbors. 

I should follow that structure. Let me think about the notation. The node's color at iteration t would be c_v^{(t)}, and it's a function of the previous color c_v^{(t-1)} and the sum of the neighbors' colors. The function f is likely a neural network or some aggregation function. 

The equation should show the update rule. So, the left side would be c_v^{(t)}, and the right side would involve f applied to c_v^{(t-1)} and the sum over neighbors. The sum could be written as \sum_{u \in N(v)} c_u^{(t-1)}, where N(v) is the neighborhood of v. 

I need to make sure the LaTeX is correct. Use \mathcal{N}(v) for the neighborhood? Or maybe just N(v). Let me check standard notation. In graph theory, N(v) is common for neighbors. 

Also, the description should be a one-sentence variable description. The example used ""where $f$ is a learnable function..."", so I should mirror that. 

Putting it all together: The equation is c_v^{(t)} = f\left(c_v^{(t-1)}, \sum_{u \in N(v)} c_u^{(t-1)}\right). 

Check for proper LaTeX syntax. The subscript in the sum should be in braces if needed. Also, using \left and \right for parentheses. 

Yes, that looks right. The description would explain that f is learnable and how the node's color is updated based on its previous state and neighbors' colors.
</think>

<latex>
$$
c_v^{(t)} = f\left(c_v^{(t-1)}, \sum_{u \in N(v)} c_u^{(t-1)}\right)
$$
</latex>"
neurips_2024_oral_59,2,c^{(t)}(G)\coloneqq h(\{\{c^{(t)}(v)\mid v\in V(G)\}\} ),,h^{(t)}(G)\gets h^{(t)}(\{\{c^{(t)}(v)\mid v\in V(G)\}\}),The graph-level representation at iteration $t$ is obtained by applying a readout function $h^{(t)}$ to the multiset of node colors $c^{(t)}(v)$ across all nodes $v$ in the graph $G$.
neurips_2024_oral_59,3,"N_{r}(v)\coloneqq\{p\midp simple path of length r,\,p_{1},p_{r+1}\inN(v),v\notinp\}\",,"N_r(v)\coloneqq\left\{ u\in V(G)\midthere exists a simple path p=\{p_i\}_{i=1}^{r+1} with  p_1=v, p_{r+1}=u\right\}",The $r$-neighborhood $\mathcal{N}_r(v)$ of a node $v$ consists of all nodes $u$ reachable from $v$ via a simple path of length $r$.
neurips_2024_oral_59,4,"c_{r}^{(t+1)}(v)arrowHASH_{r}(c_{r}^{(t)}(v),\{\{c _{r}^{(t)}(p)\midp\inN_{0}(v)\}\},\ldots,\{\{c_{r}^{(t)}(p)\midp\inN_{r}(v )\}\})",,"c^{(t+1)}(v)\gets f^{(t+1)}\left(c^{(t)}(v),g^{(t+1)}\left(\left\{\left\{c^{(t)}(u),\left(N_{r}(u)\right)\right\}\mid u\inN(v)\right\}\right)\right)",The $r$-$\ell$WL color update rule extends 1-WL by incorporating both node colors and $r$-neighborhoods of simple paths into the message passing framework.
neurips_2024_oral_59,5,c_{r}^{(t)}(G)=HASH_{r}(\{\{c_{r}^{(t)}(v)\mid v\in V(G)\}\}\}),,c_{r}^{(t)}(G)\coloneqq\{\{c_{r}^{(t)}(v)\mid v\in V(G)\}\},The final graph output after $t$ iterations of $r$-$\ell$WL is defined as the multiset of node colors at iteration $t$.
neurips_2024_oral_59,6,"m_{k}^{(t+1)}(v)&=f_{k}^{(t+1)}(\{\{c_{k}^{(t)}(p)\midp\inN_{k}(v)\}\}),\\c_{r}^{(t+1)}(v)&=g^{(t+1)}(c_{r}^{(t)}(v),\,m_{0 }^{(t+1)}(v),\ldots,m_{r}^{(t+1)}(v))",,c_{r}^{(t+1)}(v)\getsReLU\left(\sum_{k=0}^{r}W_{k}^{(t)}\cdot\{\{c_{r}^{(t)}(p)\midp\inN_{k}(v)\}\}\right),The color update for $r$-$\ell$MPNN aggregates multisets of path colors from $k$-neighborhoods using learnable weights and ReLU activation.
neurips_2024_oral_59,7,f_{k}^{(t+1)}(\{\{c_{k}^{(t)}(p)\midp\inN_{k}(v)\}\}):=f(\sum_{p\inN_{k}(v)}g(p)),,c_{r}^{(T)}(G)=h\left(\left\{\left\{c_{r}^{(T)}(v)\mid v\in V(G)\right\}\right\}\right),"Final graph representation after T iterations of r-loop Message Passing Neural Network, obtained by applying a readout function h to the multiset of node colors."
neurips_2024_oral_59,8,x_{r}^{(t+1)}(v):=MLP(x_{r}^{(t)}(v)+(1+\varepsilon_{0})\sum_{u\inN_{0}(v)}x_{r}^{(t)}(u)+\sum_{k=1}^{r}(1+\varepsilon_{k})\sum_{p\inN_{k}(v)}GIN_{k}(p)),,c_{r}^{(t+1)}(v)=MLP^{(t+1)}\left(c_{r}^{(t)}(v)\oplus\bigoplus_{k=0}^{r}\sum_{p\inN_{k}(v)}GIN^{(t+1)}(c_{r}^{(t)}(p))\right),Node feature update in $r$-$\ell$GIN using MLP and GIN layers to aggregate path information from $k$-neighborhoods.
neurips_2024_oral_6,1,"f_{z}(a_{1},a_{2})=E_{i\simS(z)\,,\,A_{1}\simB(a_{1})\,,\,A_{2}\simB(a_{2})}\Big{[}g_{i}(A_{1},A_{2 })\Big{]}=\sum_{i=0}^{15}\frac{\exp(z_{i})}{\sum_{j}\exp(z_{j})}\cdot g_{i}(a_ {1},a_{2})\",,\bar{g}(a)=\sum_{i=0}^{15}\sigma(z)_i\cdot g_i(a),"Equation 1 defines the differentiable logic gate as a convex combination of all possible logic gate operations, where the weights are given by the softmax of a trainable parameter vector z."
neurips_2024_oral_6,2,"f_{3}(\,f_{1}(a_{1},a_{2}),f_{2}(a_{3},a_{4})\,)",,"f_{z_{1},z_{2},z_{3}}(a_{1},a_{2},a_{3},a_{4})=f_{z_{1}}\left(f_{z_{2}}(a_{1},a_{2}), f_{z_{3}}(a_{3},a_{4})\right)","This equation defines the output of a depth-2 logic gate tree kernel, composed of three differentiable logic gates $f_{\mathbf{z}_1}, f_{\mathbf{z}_2}, f_{\mathbf{z}_3}$, applied hierarchically to four input activations $a_1, a_2, a_3, a_4$."
neurips_2024_oral_6,3,"A^{\prime}[k,i,j]=f_{3}^{k}\big{(}f_{1}^{k}\big{(}A\big{[}C_{M}[k,\!1]\!,C_{H}[k,\!1]\!+\!i,C_{W}[k,\!1]\!+\! j\big{]},A\big{[}C_{M}[k,\!2]\!,C_{H}[k,\!2]\!+\!i,C_{W}[k,\!2]\!+\!j\big{]}\big{)} || \qquad\qquad\qquad f_{2}^{k}\big{(}A\big{[}C_{M} [k,\!3]\!,C_{H}[k,\!3]\!+\!i,C_{W}[k,\!3]\!+\!j\big{]},A\big{[}C_{M}[k,\!4]\!,C_{H}[k,\!4]\!+\!i,C _{W}[k,\!4]\!+\!j\big{]}\big{)}\big{)}",,"Y_{k}=\sum_{i=0}^{15}\frac{\exp(z_{k,i})}{\sum_{j=0}^{15}\exp(z_{k,j})}\cdot g_{i}(A_{C_{M}[k,1],C_{H}[k,1],C_{W}[k,1]},A_{C_{M}[k,2],C_{H}[k,2],C_{W}[k,2]})",Equation 3 defines the output of a logic gate tree kernel as a softmax-weighted expectation over all 16 possible binary logic operations applied to selected input activations from the receptive field.
neurips_2024_oral_60,1,Y^{l}=ESA(LN(X^{l}))+X^{l} || X^{l+1}=SwiGLU(LN(Y^{l}))+Y^{l},,X^{\nicefrac{L}{2}}=Self-Decoder(X^{0}),Intermediate vector representation computed by the Self-Decoder from initial embeddings $X^{0}$
neurips_2024_oral_60,2,"\hat{K}=LN(X^{\nicefrac{{L}}{{2}}})W_{K},\quad\hat{V}=LN(X^ {\nicefrac{{L}}{{2}}})W_{V}","where \(W_{K},W_{V}\in\mathbb{R}^{d\times d}\) are learnable",|C|=O(1),"The efficient self-attention module maintains constant KV cache size independent of input length, with sliding-window attention [4] as a specific example where cache size scales with window size rather than sequence length."
neurips_2024_oral_60,3,"Q^{l}=LN(X^{l})W_{Q}^{l} || Y^{l}=Attention(Q^{l},\hat{K},\hat{V})+X^{l} || X^{l+1}=SwiGLU(LN(Y^{l}))+Y^{l}",,"Y^{l}=ECA(LN(X^{l}),\hat{K},\hat{V})+X^{l}","where ECA denotes efficient cross-attention that reuses the global KV caches $\hat{K}, \hat{V}$"
neurips_2024_oral_60,4,"Q=XW_{Q},\quad K=XW_{K},\quad V=XW_{V}\\head_{i}=softmax(Q_{[i]}K_{[i]}^{\intercal}+B)V,\quad B_{ij}=0,&i-C<j\leq i\\-\infty,&otherwise\\SWA(X)=Concat(head_{1},\cdots,head_{h})W_ {O}","where \(W_{Q},W_{K},W_{V},W_{O}\in\mathbb{R}^{d\times d}\) are learnable matrices, and the window causal mask \(B\) controls each query only attends to the previous keys whose distances are less than \(C\)",Y^{l}=ESA(LN(X^{l}))+X^{l},"Sliding-window attention computes output using a fixed window size, reducing KV cache memory complexity to $\mathcal{O}(C)$ during inference."
neurips_2024_oral_60,5,"Q=(XW_{Q})\odot\Theta,\quad K=(XW_{K})\odot\overline{\Theta},\quad V=XW_{V},\quad\Theta_{n}=e^{in\theta}\\\gamma=sigmoid(XW_{\gamma})^{1/\tau},\quad D_{nm}=\prod\nolimits_{i=m+1}^{n}\gamma_{i},&n\geq m\\0,&n<m\\gRet(X)=(QK^{\intercal}\odot D)V","where \(W_{Q},W_{K},W_{V}\in\mathbb{R}^{d\times d}\) and \(W_{\gamma}\in\mathbb{R}^{d\times 1}\) are learnable weights, and the temperature term \(\tau\) encourages \(\gamma\) to 1 for better memorization [46]","Q=XW_Q,\quad K=XW_K,\quad V=XW_V\\GatedRet(X)=Concat_{h=1}^{H}\left(\sigma(Q_h\odot K_h^{\top}) V_h\right) W_O","Parallel computation of gated retention, where $\sigma$ denotes a learnable activation function, $\odot$ represents element-wise multiplication, and $W_O$ is the output projection matrix."
neurips_2024_oral_60,6,"S_{n}=\gamma_{n}S_{n-1}+K_{n}^{\intercal}V_{n}\\gRet(X_{n})=Q_{n}S_{n},\quad n=1,\cdots,|x|","where \(Q,K,V,\gamma\) are the same as in Equation (5)",h_{n}=\gamma_{n}h_{n-1}+K_{n-1}V_{n-1}^{\intercal}\\gRet(X)_{n}=Q_{n}h_{n},"where $h_n$ is the recurrent state at timestep $n$, updated using the decay factor $\gamma_n$ and the previous key-value outer product."
neurips_2024_oral_60,7,"\beta_{(i-1)B+j}&=\prod\limits_{k=(i-1)B+1}^{(i-1)B+j}\gamma_{k},\quad D_{[i]}(j,k)=\frac{\beta_{(i-1)B+k}}{\beta_{ (i-1)B+j}}\\if\\j\leq k\\else\\0\\R_{i}&=K_{[i]}^{\intercal}(V_{[i]}\odot\frac{\beta_{iB}}{\beta_{[i]}})+\beta_{iB}R_{i-1},\\\beta_{[i]}(j,k)=\beta_{(i-1)B+j}\\gRet(X)&=\underbrace{(Q_{[i]}K_{[i]}^{\intercal}\odot D_{[i]})V_{[i]}}_{Inner-Chunk}+\underbrace{(Q_{[i]}R_{i-1})\odot\beta_{[i]}}_{Cross-Chunk}","where \(R_{i}\) is the intermediate state of the \(i\)-th chunk, and \(\beta\) summarizes the data-controlled decay \(\gamma\)","Y_{[i]}=SWA(X_{[i]})+gRet_{cross}(X_{[i]}, S_{(i-1)B})\\S_{iB}=\gamma_{iB}S_{(i-1)B}+\sum_{j=(i-1)B+1}^{iB} K_j^\intercal V_j","Chunk-wise recurrent computation splits sequence into chunks of size B, where inner-chunk outputs use sliding-window attention (SWA) and cross-chunk dependencies update state S through data-controlled decay Î³."
neurips_2024_oral_60,8,"head_{i}=gRet(X) || Y=GroupNorm_{h}(Concat(head_{1},\cdots,head_{n})) || MHGR(X)=(swish(XW_{G})\odot Y)W_{O}",,"MgRet(X)=Concat(gRet_{1}(X),\cdots,gRet_{h}(X))W_{O}","where $W_{O}\in\mathbb{R}^{hd\times d}$ is a learnable projection matrix, and each head uses different learnable parameters"
neurips_2024_oral_8,1,w_{i}^{t}=\alpha^{t}W^{t-1}+(1-\alpha^{t})\hat{w}_{i}^{t},where \(\alpha^{t}\) is the fusion factor used to control the quality of the fused global model \(\mathcal{W}^{t-1}\),\tilde{w}_{i}^{t}=\lambdaW^{t-1}+(1-\lambda)\hat{w}_{i}^{t},Equation 1 represents the fusion of the global
neurips_2024_oral_8,2,"\alpha^{t}=\max\{(1-\epsilon)^{t-1}\alpha_{0},\alpha_{min}\}",,"\alpha^{t}=\max\left(\alpha_{0}\cdot e^{-\epsilon\cdot t},\alpha_{\min}\right)","Dynamic adjustment of the fusion factor $\alpha^{t}$ based on the FL round $t$, ensuring a balance between global and local knowledge."
neurips_2024_oral_8,3,L^{DAR}_{i}= || g_{e}(w_{e}\odotM_{e};x_{i}) || _{2}^{2},,"L^{DAR}(w,M;D_{i})=E_{(x_{i},y_{i})\simD_{i}}\left[\Omega\left(g_{e}(w_{e}\odotM_{e};x_{i}),y_{i}\right)\right]","where $\Omega(\cdot)$ is a domain adaptive regularization function that penalizes biased representations $z_i$ based on the corresponding labels $y_i$, encouraging domain-invariant feature learning across clients."
neurips_2024_oral_8,4,"L^{CE}_{i}=-\frac{1}{|K_{i}|}\sum_{k\inK_{i}}y_{ i,k}\log(\hat{y}_{i,k})","where \(\mathcal{K}_{i}\) denotes the set of possible labels on the client \(i\), \(\hat{y}_{i,k}\) denotes predicting label, and \(y_{i,k}\) denotes ground-truth label","L_{i}^{CE}=-\frac{1}{N_i}\sum_{n=1}^{N_i} y_{i,n}\log(\hat{y}_{i,n})","where $\mathcal{L}_{i}^{CE}$ denotes the cross-entropy loss for client $i$, $y_{i,n}$ is the true label, and $\hat{y}_{i,n}$ is the predicted probability for sample $n$ in local dataset $\mathcal{D}_i$."
neurips_2024_oral_8,5,L_{i}=L^{CE}_{i}+\gammaL^{DAR}_{i},where the \(\gamma\) is a pre-defined coefficient controlling the importance of \(\mathcal{L}^{DAR}_{i}\) relative to \(\mathcal{L}^{CE}_{i}\),L_{i}=L^{CE}_{i}+\lambdaL^{DAR}_{i},where $\lambda$ is a hyperparameter that balances the cross-entropy loss $\mathcal{L}^{CE}_{i}$ and the domain adaptive regularization term $\mathcal{L}^{DAR}_{i}$ in the client's training objective.
neurips_2024_oral_8,6,w^{t}_{i}:=\underbrace{w^{t}_{i}\odotM^{t}_{i}}_{local knowledge}+\underbrace{W^{t-1}\odot\overline{M}^{t}_{i}}_{global knowledge},"where \(\mathcal{W}^{t-1}\) is the global model aggregated at the \((t-1)\)-th round, and \(\overline{\mathbf{M}}^{t}_{i}\) denotes the logical NOT operation applied to \(\mathbf{M}^{t}_{i}\)",\tilde{w}_{i}^{t}=w_{i}^{t}\oslash (M_{i}^{t}+\delta),where the recovery process involves expanding the pruned local model using the binary mask matrix to restore its original structure
neurips_2024_oral_8,7,W^{t}=\sum_{i\inC}\frac{|D_{i}|}{|D|}w_{i}^{t},"where \(|\mathcal{D}_{i}|\) is the sample number in the local dataset on client \(i\), and \(|\mathcal{D}|\) is the total number of samples in the entire FL system",W^{t}=\frac{1}{|S^{t}|}\sum_{i\inS^{t}}w_{i}^{t},"where $ \mathcal{W}^{t} $ is the updated global model at round $ t $, and $ \mathcal{S}^{t} $ denotes the set of selected clients in round $ t $"
neurips_2024_oral_9,1,"lh_{Q}=(Q_{i}^{d},subqs^{i})(i=1,2,...,K)",,"Similarity(Q, Q_i^d)=\frac{Q\cdot Q_i^d}{\|Q\|\cdot\|Q_i^d\|}",Computes cosine similarity between input question $Q$ and each demonstration example $Q_i^d$ in pool $P$ to identify top-$K$ nearest neighbors.
neurips_2024_oral_9,2,"\{q_{t+1}^{j},j=1,...,J\}\gets Decompose(p_{\theta},\;h_{1},\;lh_{Q},\;q_ {t})",,\{q_{t+1}^{j}\}_{j=1}^{J}=LLM\left( h_1\parallellh_{Q}\parallel q_t\right),Equation (2) formulates the decomposition of sub-question $q_t$ into $J$ sub-questions at level $t+1$ using a logic-heuristic-enhanced prompt composed of prompt head $h_1$ and retrieved logic heuristics $\text{lh}_{Q}$.
neurips_2024_oral_9,3,"r_{t+1}^{j}\gets Solve(p_{\theta},\;h_{2},\;q_{t+1}^{j})",,"\{r_{t+1}^{j}\}\gets Analyze(p_{\theta},\;h_{2},\;\{q_{t+1}^{j}\})",where $h_{2}$ is the prompt head describing the rationale generation task for sub-questions at level $t+1$.
neurips_2024_oral_9,4,"\hat{r}_{t+1}^{j}\gets Self\_Check(p_{\theta},\;h_{3},\;q_{t+1}^{j},\;r_{t+1}^{j})",,"\hat{r}_{t+1}^{j}\gets SelfCheck(p_{\theta},\;h_{3},\;q_{t+1}^{j},\;r_{t+1}^{j})",This equation represents the self-check process where the LLM verifies and corrects the generated rationale for a sub-question based on the provided prompt head and the original rationale.
neurips_2024_oral_9,5,"s_{t+1}^{j}\gets Score(p_{\theta},\;h_{4},\;q_{t+1}^{j},\;\hat{r}_{t+1}^{j })",,"s_{t+1}^{j}\gets Evaluate(p_{\theta},\;h_{4},\;q_{t+1}^{j},\;\hat{r}_{t+1}^{j})",Coherence score $s_{t+1}^{j}$ is generated by evaluating the logical alignment between the refined rationale $\hat{r}_{t+1}^{j}$ and the corresponding sub-question $q_{t+1}^{j}$.
neurips_2024_oral_9,6,"n_{t+1}^{j}=(q_{t+1}^{j},\hat{r}_{t+1}^{j},s_{t+1}^{j})",where \(s_{t+1}^{j}\) can support the current or subsequent cycles in _Rethink_ (4,"\forall j,\;n_{t+1}^{j}.rationale=\hat{r}_{t+1}^{j},\;n_{t+1}^{j}.score=s_{t+1}^{j}",This equation assigns the refined rationale $\hat{r}_{t+1}^{j}$ and the coherence score $s_{t+1}^{j}$ to the corresponding node $n_{t+1}^{j}$ at level $t+1$ after the self-check and scoring processes are completed.
neurips_2024_oral_9,7,"L_{k}\gets Extract(p_{\theta},\h_{5},\L,q_{t+1}^{j}),\L_{k}\subseteq L",where \(h_{5}\) is a prompt head (_Appendix_ A,L_{k}\getsTop-k\nodes in  L most related to  q_{t+1}^{j} based on cosine similarity,We extract the top-$k$ nodes from the set $L$ that are most related to the sub-question $q_{t+1}^{j}$ using cosine similarity.
neurips_2024_oral_9,8,"r^{\prime}\gets Update(p_{\theta},\h_{6},\n_{e}(q,r,s),\\hat{r}_{t+1}^{j})",,"\hat{r}_{e}\gets Update(p_{\theta},\h_{6},\n_{e},\\hat{r}_{t+1}^{j}),\\forall n_{e}\in L_{k}","This equation represents the process of updating the rationale of previously extracted nodes using the refined rationale of the current sub-question, simulating human reflective reasoning by incorporating new insights into earlier reasoning steps."
neurips_2024_oral_9,9,"n_{e}(q,r^{\prime},s)\gets n_{e}(q,r,s)",,"n_{e}(q,r^{\prime},s)\gets Replace(n_{e}(q,r,s),\r^{\prime})",This operation updates the rationale of the selected ancestral node $n_{e}$ with the refined rationale $r^{\prime}$ derived from the newly generated sub-question $q_{t+1}^{j}$.
